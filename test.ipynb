{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, OPTForCausalLM, BloomForCausalLM, CodeGenForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.33.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OPTForCausalLM.from_pretrained(\"facebook/opt-125m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-560m\")\n",
    "# b_model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-560m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-mono\")\n",
    "# c_model = CodeGenForCausalLM.from_pretrained(\"Salesforce/codegen-350M-mono\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(32, <function __main__.layer_pre_hook(module, args, kwargs)>)])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_pre_hook(module, args, kwargs):\n",
    "    # print(args, kwargs)\n",
    "    display = {}\n",
    "    for k, v in kwargs.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            display[k] = v.shape \n",
    "        elif k == 'past_key_values' and v is not None:\n",
    "            display[k] = f'{len(v)} * ' + str((v[0][0].shape, v[0][1].shape))\n",
    "        else:\n",
    "            display[k] = v\n",
    "    print(display)\n",
    "\n",
    "    return args, kwargs\n",
    "\n",
    "# model._forward_pre_hooks.clear()\n",
    "# model.register_forward_pre_hook(model_pre_hook, with_kwargs=True)\n",
    "# model._forward_pre_hooks\n",
    "\n",
    "def layer_pre_hook(module, args, kwargs):\n",
    "    display = {}\n",
    "    for k, v in kwargs.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            display[k] = v.shape \n",
    "        elif k == 'past_key_value' and v is not None:\n",
    "            display[k] = str((v[0].shape, v[1].shape))\n",
    "        else:\n",
    "            display[k] = v\n",
    "    print(display)\n",
    "\n",
    "    return args, kwargs\n",
    "\n",
    "layer = model.model.decoder.layers[2]\n",
    "\n",
    "layer._forward_pre_hooks.clear()\n",
    "layer.register_forward_pre_hook(layer_pre_hook, with_kwargs=True)\n",
    "layer._forward_pre_hooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': torch.Size([12, 1, 20, 20]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 20, 64]), torch.Size([12, 12, 20, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 21, 64]), torch.Size([12, 12, 21, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 22, 64]), torch.Size([12, 12, 22, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 23, 64]), torch.Size([12, 12, 23, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 24, 64]), torch.Size([12, 12, 24, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 25, 64]), torch.Size([12, 12, 25, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 26, 64]), torch.Size([12, 12, 26, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 27, 64]), torch.Size([12, 12, 27, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 28, 64]), torch.Size([12, 12, 28, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 29, 64]), torch.Size([12, 12, 29, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 30, 64]), torch.Size([12, 12, 30, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 31, 64]), torch.Size([12, 12, 31, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 32, 64]), torch.Size([12, 12, 32, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 33, 64]), torch.Size([12, 12, 33, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 34, 64]), torch.Size([12, 12, 34, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 35, 64]), torch.Size([12, 12, 35, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 36, 64]), torch.Size([12, 12, 36, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 37, 64]), torch.Size([12, 12, 37, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 38, 64]), torch.Size([12, 12, 38, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 40]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 39, 64]), torch.Size([12, 12, 39, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 41]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 40, 64]), torch.Size([12, 12, 40, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 42]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 41, 64]), torch.Size([12, 12, 41, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 43]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 42, 64]), torch.Size([12, 12, 42, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 44]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 43, 64]), torch.Size([12, 12, 43, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 45]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 44, 64]), torch.Size([12, 12, 44, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 46]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 45, 64]), torch.Size([12, 12, 45, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 47]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 46, 64]), torch.Size([12, 12, 46, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 48]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 47, 64]), torch.Size([12, 12, 47, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "{'attention_mask': torch.Size([12, 1, 1, 49]), 'layer_head_mask': None, 'past_key_value': '(torch.Size([12, 12, 48, 64]), torch.Size([12, 12, 48, 64]))', 'output_attentions': False, 'use_cache': True}\n",
      "Who are you? Are you conscious?\n",
      "I'm a woman. I'm not conscious.\n",
      "I'm not conscious. I'm not conscious.\n",
      "I'm not conscious. I'm\n",
      "----------\n",
      "Where is Deutschland?\n",
      "I'm in Germany.\n",
      "----------\n",
      "How is Huawei Mate 60 Pro?\n",
      "Huawei Mate 60 Pro is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone\n",
      "----------\n",
      "Who are you? Are you conscious?\n",
      "I'm a woman. I'm not conscious.\n",
      "I'm not conscious. I'm not conscious.\n",
      "I'm not conscious. I'm\n",
      "----------\n",
      "Where is Deutschland?\n",
      "I'm in Germany.\n",
      "----------\n",
      "How is Huawei Mate 60 Pro?\n",
      "Huawei Mate 60 Pro is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone\n",
      "----------\n",
      "Who are you? Are you conscious?\n",
      "I'm a woman. I'm not conscious.\n",
      "I'm not conscious. I'm not conscious.\n",
      "I'm not conscious. I'm\n",
      "----------\n",
      "Where is Deutschland?\n",
      "I'm in Germany.\n",
      "----------\n",
      "How is Huawei Mate 60 Pro?\n",
      "Huawei Mate 60 Pro is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone\n",
      "----------\n",
      "Who are you? Are you conscious?\n",
      "I'm a woman. I'm not conscious.\n",
      "I'm not conscious. I'm not conscious.\n",
      "I'm not conscious. I'm\n",
      "----------\n",
      "Where is Deutschland?\n",
      "I'm in Germany.\n",
      "----------\n",
      "How is Huawei Mate 60 Pro?\n",
      "Huawei Mate 60 Pro is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    'Who are you? Are you conscious?',\n",
    "    'Where is Deutschland?',\n",
    "    'How is Huawei Mate 60 Pro?'\n",
    "] * 4\n",
    "\n",
    "prompt_len = 20\n",
    "\n",
    "inputs = tokenizer(prompts, padding=\"max_length\", max_length=prompt_len, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(\n",
    "    inputs.input_ids, \n",
    "    max_length=30 + prompt_len,\n",
    "    # num_beams=2,\n",
    "    # num_beam_groups=2,\n",
    "    # diversity_penalty=0.1,\n",
    "    # do_sample=True,\n",
    ")\n",
    "\n",
    "output_texts = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "for output_text in output_texts:\n",
    "    print(output_text)\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
