{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 13:49:58,020 [4101423154.py:11 in <module>] INFO - Importing...\n",
      "/home/fsuser/miniconda3/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2023-09-19 13:50:07,036 [instantiator.py:21 in <module>] INFO - Created a temporary directory at /tmp/tmphgcqvz6l\n",
      "2023-09-19 13:50:07,040 [instantiator.py:76 in _write] INFO - Writing /tmp/tmphgcqvz6l/_remote_module_non_scriptable.py\n",
      "2023-09-19 13:50:10.576196: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-19 13:50:19,622 [4101423154.py:19 in <module>] INFO - Done!\n",
      "2023-09-19 13:50:19,624 [4101423154.py:23 in <module>] INFO - Initializing CausalLM: 'facebook/opt-6.7b'\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    style='{',\n",
    "    format='{asctime} [{filename}:{lineno} in {funcName}] {levelname} - {message}',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\".log\", 'w'),\n",
    "        logging.StreamHandler()\n",
    "    ],\n",
    "    level=logging.INFO\n",
    ")\n",
    "logging.info('Importing...')\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Module, ModuleList\n",
    "from transformers import PreTrainedModel\n",
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "from accelerate import load_checkpoint_and_dispatch, init_empty_weights\n",
    "logging.info('Done!')\n",
    "\n",
    "checkpoint = \"facebook/opt-6.7b\" # 6.7b 13b 30b 66b \n",
    "\n",
    "logging.info(f'Initializing CausalLM: \\'{checkpoint}\\'')\n",
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "with init_empty_weights():\n",
    "    model = AutoModelForCausalLM.from_config(config)\n",
    "\n",
    "from accelerate.utils import (\n",
    "    check_tied_parameters_on_same_device,\n",
    "    find_tied_parameters,\n",
    "    get_balanced_memory,\n",
    "    get_max_memory,\n",
    "    load_offloaded_weights,\n",
    "    offload_weight,\n",
    "    save_offload_index,\n",
    "    set_module_tensor_to_device,\n",
    ")\n",
    "    \n",
    "model.tie_weights()\n",
    "tied_params = find_tied_parameters(model)\n",
    "# model.base_model_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 13:50:20,681 [4062821495.py:124 in get_policy_weight_map] INFO - Loading weights of CausalLM\n",
      " facebook/opt-6.7b: GPU Mem 0.00 GiB (0.00%), CPU Mem 3.72 GiB (29.09%), Disk Mem 9.07 Gib (70.91%)\n"
     ]
    }
   ],
   "source": [
    "class AttrDict(dict):\n",
    "    __slots__ = () \n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Policy:\n",
    "    gpu_batch_size: int\n",
    "    num_gpu_batches: int\n",
    "\n",
    "    # percent of weights/cache/activations on GPU/CPU/Disk %\n",
    "    weights_gpu_percent: float\n",
    "    weights_cpu_percent: float\n",
    "    cache_gpu_percent: float\n",
    "    cache_cpu_percent: float\n",
    "    act_gpu_percent: float\n",
    "    act_cpu_percent: float\n",
    "\n",
    "    # Whether to overlap the I/O and compute\n",
    "    overlap: bool\n",
    "\n",
    "    # Whether to use pinned memory for weights on CPU\n",
    "    pin_weight: bool\n",
    "\n",
    "    @property\n",
    "    def weights_disk_percent(self):\n",
    "        return 1.0 - self.weights_gpu_percent - self.weights_cpu_percent\n",
    "\n",
    "    @property\n",
    "    def cache_disk_percent(self):\n",
    "        return 1.0 - self.cache_gpu_percent - self.cache_cpu_percent\n",
    "\n",
    "    @property\n",
    "    def act_disk_percent(self):\n",
    "        return 1.0 - self.act_gpu_percent - self.act_cpu_percent\n",
    "\n",
    "policy = Policy(\n",
    "    gpu_batch_size=8, \n",
    "    num_gpu_batches=8, \n",
    "    weights_gpu_percent=0.0, \n",
    "    weights_cpu_percent=0.3, \n",
    "    cache_gpu_percent=0.0, \n",
    "    cache_cpu_percent=0.2, \n",
    "    act_gpu_percent=0.0, \n",
    "    act_cpu_percent=0.5, \n",
    "    overlap=True, \n",
    "    pin_weight=True,\n",
    ")\n",
    "\n",
    "def get_policy_weight_map(lm_model: PreTrainedModel, policy: Policy):\n",
    "    \"\"\"{module_name: device}\"\"\"\n",
    "    assert lm_model.device == torch.device('meta')\n",
    "\n",
    "    def get_layers_dict(lm_model: Module, prefix: str='') -> dict:\n",
    "        # {layer_name : layer_module ('meta')}\n",
    "        layers_dict = {}\n",
    "        for name, module in lm_model.named_children():\n",
    "            if len(list(module.named_children())) == 0:\n",
    "                layers_dict[prefix+name] = module\n",
    "            # Assume only transformer blocks are stored in ModuleList\n",
    "            elif isinstance(module, ModuleList):\n",
    "                for block_name, block_module in module.named_children():\n",
    "                    layers_dict[prefix+name+'.'+block_name] = block_module\n",
    "            else:\n",
    "                layers_dict.update(get_layers_dict(module, prefix+name+'.'))\n",
    "        return layers_dict\n",
    "    layers_dict = get_layers_dict(lm_model)\n",
    "\n",
    "    \n",
    "    def get_choice(cur_percent, percents, choices):\n",
    "        percents = np.cumsum(percents)\n",
    "        assert np.abs(percents[-1] - 1.0) < 1e-5, f'{percents}'\n",
    "\n",
    "        for i in range(len(percents)):\n",
    "            if cur_percent < percents[i]:\n",
    "                return choices[i]\n",
    "        return choices[-1]\n",
    "    weight_assign_dict = {}\n",
    "\n",
    "    choices = ['cuda', 'cpu', 'disk']\n",
    "    percents_target = [policy.weights_gpu_percent, policy.weights_cpu_percent, policy.weights_disk_percent]\n",
    "    percents_target = np.array(percents_target)\n",
    "    \n",
    "    size_total = sum([\n",
    "        sum([\n",
    "            np.prod(para.shape) for _, para in layer_module.named_parameters()\n",
    "        ]) for _, layer_module in layers_dict.items()\n",
    "    ])\n",
    "    size_past, size_future = 0, size_total\n",
    "    percents_past, percents_future = 0 * percents_target, percents_target  \n",
    "\n",
    "    for layer_name, layer_module in layers_dict.items():\n",
    "        # current layer\n",
    "        param_sizes = [np.prod(para.shape) for _, para in layer_module.named_parameters()]\n",
    "        param_sizes_cumsum = np.cumsum(param_sizes)\n",
    "        size_layer = param_sizes_cumsum[-1]\n",
    "\n",
    "        size_layer_devices = {device: 0 for device in choices}\n",
    "        for i, (param_name, param) in enumerate(layer_module.named_parameters()):\n",
    "            param_mid = (param_sizes_cumsum[i] - param_sizes[i] / 2) / param_sizes_cumsum[-1]\n",
    "            device = get_choice(param_mid, percents_future, choices)\n",
    "\n",
    "            weight_assign_dict[layer_name+'.'+param_name] = {\n",
    "                'shape':  param.shape,\n",
    "                'assigned_device': device\n",
    "            }\n",
    "            size_layer_devices[device] += param_sizes[i]\n",
    "\n",
    "        percents_layer = np.array([size_layer_devices[device] * 1. for device in choices]) / size_layer\n",
    "        \n",
    "        # update past & future\n",
    "        percents_past = (percents_past * size_past + percents_layer * size_layer) / (size_past + size_layer)      \n",
    "        size_past += param_sizes_cumsum[-1]\n",
    "        size_future -= param_sizes_cumsum[-1]\n",
    "        percents_future = (size_total * percents_target - size_past * percents_past) / size_future if size_future > 0 else 0\n",
    "        \n",
    "        # logging.info(percents_past)\n",
    "\n",
    "\n",
    "    mem_g = sum([np.prod(v['shape']) for k, v in weight_assign_dict.items() if 'cuda' in v['assigned_device']]) * 2 / (2 ** 30)\n",
    "    mem_c = sum([np.prod(v['shape']) for k, v in weight_assign_dict.items() if v['assigned_device'] == 'cpu']) * 2 / (2 ** 30)\n",
    "    mem_d = sum([np.prod(v['shape']) for k, v in weight_assign_dict.items() if v['assigned_device'] == 'disk']) * 2 / (2 ** 30)\n",
    "    mem = mem_d + mem_c + mem_g\n",
    "    logging.info(f'Loading weights of CausalLM\\n {checkpoint}: ' \n",
    "                 f'GPU Mem {mem_g:.2f} GiB ({mem_g / mem:.2%}), ' \n",
    "                 f'CPU Mem {mem_c:.2f} GiB ({mem_c / mem:.2%}), '\n",
    "                 f'Disk Mem {mem_d:.2f} Gib ({mem_d / mem:.2%})')\n",
    "\n",
    "    device_map = {k:v['assigned_device'] for k, v in weight_assign_dict.items()}\n",
    "\n",
    "    # prepare output\n",
    "    output = {\n",
    "        'model': model,\n",
    "        'layers_dict': layers_dict,\n",
    "        'weight_assign_dict': weight_assign_dict,\n",
    "        'device_map': device_map\n",
    "    }\n",
    "    output = AttrDict(output)\n",
    "    return output\n",
    "\n",
    "output = get_policy_weight_map(model, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.decoder.embed_tokens.weight': 'disk',\n",
       " 'model.decoder.embed_positions.weight': 'disk',\n",
       " 'model.decoder.final_layer_norm.weight': 'cpu',\n",
       " 'model.decoder.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.0.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.0.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.0.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.0.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.0.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.0.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.0.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.0.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.0.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.0.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.0.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.0.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.0.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.0.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.0.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.0.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.1.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.1.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.1.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.1.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.1.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.1.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.1.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.1.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.1.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.1.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.1.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.1.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.1.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.1.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.1.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.1.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.2.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.2.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.2.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.2.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.2.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.2.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.2.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.2.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.2.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.2.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.2.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.2.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.2.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.2.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.2.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.2.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.3.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.3.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.3.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.3.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.3.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.3.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.3.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.3.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.3.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.3.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.3.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.3.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.3.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.3.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.3.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.3.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.4.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.4.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.4.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.4.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.4.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.4.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.4.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.4.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.4.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.4.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.4.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.4.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.4.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.4.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.4.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.4.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.5.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.5.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.5.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.5.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.5.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.5.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.5.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.5.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.5.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.5.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.5.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.5.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.5.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.5.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.5.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.5.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.6.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.6.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.6.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.6.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.6.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.6.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.6.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.6.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.6.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.6.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.6.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.6.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.6.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.6.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.6.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.6.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.7.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.7.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.7.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.7.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.7.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.7.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.7.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.7.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.7.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.7.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.7.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.7.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.7.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.7.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.7.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.7.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.8.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.8.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.8.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.8.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.8.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.8.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.8.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.8.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.8.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.8.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.8.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.8.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.8.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.8.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.8.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.8.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.9.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.9.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.9.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.9.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.9.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.9.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.9.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.9.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.9.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.9.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.9.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.9.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.9.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.9.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.9.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.9.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.10.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.10.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.10.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.10.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.10.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.10.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.10.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.10.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.10.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.10.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.10.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.10.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.10.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.10.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.10.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.10.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.11.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.11.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.11.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.11.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.11.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.11.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.11.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.11.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.11.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.11.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.11.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.11.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.11.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.11.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.11.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.11.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.12.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.12.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.12.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.12.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.12.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.12.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.12.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.12.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.12.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.12.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.12.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.12.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.12.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.12.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.12.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.12.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.13.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.13.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.13.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.13.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.13.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.13.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.13.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.13.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.13.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.13.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.13.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.13.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.13.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.13.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.13.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.13.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.14.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.14.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.14.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.14.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.14.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.14.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.14.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.14.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.14.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.14.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.14.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.14.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.14.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.14.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.14.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.14.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.15.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.15.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.15.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.15.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.15.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.15.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.15.self_attn.out_proj.weight': 'disk',\n",
       " 'model.decoder.layers.15.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.15.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.15.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.15.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.15.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.15.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.15.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.15.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.15.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.16.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.16.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.16.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.16.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.16.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.16.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.16.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.16.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.16.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.16.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.16.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.16.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.16.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.16.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.16.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.16.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.17.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.17.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.17.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.17.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.17.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.17.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.17.self_attn.out_proj.weight': 'disk',\n",
       " 'model.decoder.layers.17.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.17.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.17.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.17.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.17.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.17.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.17.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.17.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.17.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.18.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.18.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.18.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.18.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.18.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.18.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.18.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.18.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.18.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.18.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.18.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.18.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.18.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.18.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.18.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.18.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.19.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.19.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.19.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.19.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.19.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.19.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.19.self_attn.out_proj.weight': 'disk',\n",
       " 'model.decoder.layers.19.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.19.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.19.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.19.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.19.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.19.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.19.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.19.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.19.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.20.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.20.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.20.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.20.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.20.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.20.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.20.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.20.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.20.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.20.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.20.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.20.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.20.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.20.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.20.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.20.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.21.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.21.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.21.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.21.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.21.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.21.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.21.self_attn.out_proj.weight': 'disk',\n",
       " 'model.decoder.layers.21.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.21.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.21.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.21.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.21.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.21.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.21.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.21.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.21.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.22.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.22.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.22.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.22.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.22.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.22.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.22.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.22.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.22.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.22.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.22.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.22.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.22.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.22.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.22.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.22.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.23.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.23.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.23.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.23.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.23.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.23.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.23.self_attn.out_proj.weight': 'disk',\n",
       " 'model.decoder.layers.23.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.23.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.23.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.23.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.23.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.23.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.23.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.23.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.23.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.24.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.24.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.24.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.24.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.24.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.24.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.24.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.24.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.24.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.24.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.24.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.24.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.24.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.24.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.24.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.24.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.25.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.25.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.25.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.25.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.25.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.25.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.25.self_attn.out_proj.weight': 'disk',\n",
       " 'model.decoder.layers.25.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.25.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.25.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.25.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.25.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.25.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.25.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.25.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.25.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.26.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.26.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.26.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.26.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.26.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.26.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.26.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.26.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.26.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.26.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.26.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.26.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.26.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.26.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.26.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.26.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.27.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.27.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.27.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.27.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.27.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.27.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.27.self_attn.out_proj.weight': 'disk',\n",
       " 'model.decoder.layers.27.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.27.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.27.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.27.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.27.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.27.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.27.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.27.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.27.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.28.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.28.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.28.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.28.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.28.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.28.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.28.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.28.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.28.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.28.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.28.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.28.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.28.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.28.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.28.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.28.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.29.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.29.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.29.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.29.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.29.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.29.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.29.self_attn.out_proj.weight': 'disk',\n",
       " 'model.decoder.layers.29.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.29.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.29.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.29.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.29.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.29.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.29.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.29.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.29.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.30.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.30.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.30.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.30.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.30.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.30.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.30.self_attn.out_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.30.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.30.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.30.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.30.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.30.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.30.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.30.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.30.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.30.final_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.31.self_attn.k_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.31.self_attn.k_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.31.self_attn.v_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.31.self_attn.v_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.31.self_attn.q_proj.weight': 'cpu',\n",
       " 'model.decoder.layers.31.self_attn.q_proj.bias': 'cpu',\n",
       " 'model.decoder.layers.31.self_attn.out_proj.weight': 'disk',\n",
       " 'model.decoder.layers.31.self_attn.out_proj.bias': 'disk',\n",
       " 'model.decoder.layers.31.self_attn_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.31.self_attn_layer_norm.bias': 'disk',\n",
       " 'model.decoder.layers.31.fc1.weight': 'disk',\n",
       " 'model.decoder.layers.31.fc1.bias': 'disk',\n",
       " 'model.decoder.layers.31.fc2.weight': 'disk',\n",
       " 'model.decoder.layers.31.fc2.bias': 'disk',\n",
       " 'model.decoder.layers.31.final_layer_norm.weight': 'disk',\n",
       " 'model.decoder.layers.31.final_layer_norm.bias': 'disk',\n",
       " 'lm_head.weight': 'disk'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_map = output.device_map\n",
    "device_map\n",
    "\n",
    "# check_tied_parameters_on_same_device(tied_params, device_map)\n",
    "# for tie_param in tied_params:\n",
    "#     dev = set([device_map[p] for p in tie_param]).pop()\n",
    "#     for p in tie_param:\n",
    "#         device_map[p] = dev\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3321f7ef774e63940730479c7b84c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "decoder.embed_tokens.weight doesn't have any device set.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m \u001b[39mimport\u001b[39;00m snapshot_download\n\u001b[1;32m      2\u001b[0m weights_location \u001b[39m=\u001b[39m snapshot_download(checkpoint, allow_patterns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m*.bin\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpytorch_model.bin.index.json\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m model\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m load_checkpoint_and_dispatch(\n\u001b[1;32m      4\u001b[0m     output\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mmodel, \u001b[39m# should be base model? e.g. output.model.model\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m     weights_location,\n\u001b[1;32m      6\u001b[0m     device_map\u001b[39m=\u001b[39;49mdevice_map, \n\u001b[1;32m      7\u001b[0m     offload_folder\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39moffload/\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m checkpoint\u001b[39m.\u001b[39;49mreplace(\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m'\u001b[39;49m), \n\u001b[1;32m      8\u001b[0m     offload_state_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[39m# model = AutoModelForCausalLM.from_pretrained(\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m#     checkpoint, \u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m#     device_map=device_map, \u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#     offload_folder='offload/' + checkpoint.replace('/', '.'), \u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m#     offload_state_dict=True\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     18\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mModel initialized!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/accelerate/big_modeling.py:535\u001b[0m, in \u001b[0;36mload_checkpoint_and_dispatch\u001b[0;34m(model, checkpoint, device_map, max_memory, no_split_module_classes, offload_folder, offload_buffers, dtype, offload_state_dict, skip_keys, preload_module_classes, force_hooks)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[39mif\u001b[39;00m offload_state_dict \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m device_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdisk\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m device_map\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    534\u001b[0m     offload_state_dict \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m load_checkpoint_in_model(\n\u001b[1;32m    536\u001b[0m     model,\n\u001b[1;32m    537\u001b[0m     checkpoint,\n\u001b[1;32m    538\u001b[0m     device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m    539\u001b[0m     offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m    540\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    541\u001b[0m     offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m    542\u001b[0m     offload_buffers\u001b[39m=\u001b[39;49moffload_buffers,\n\u001b[1;32m    543\u001b[0m )\n\u001b[1;32m    544\u001b[0m \u001b[39mif\u001b[39;00m device_map \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    545\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/accelerate/utils/modeling.py:1372\u001b[0m, in \u001b[0;36mload_checkpoint_in_model\u001b[0;34m(model, checkpoint, device_map, offload_folder, dtype, offload_state_dict, offload_buffers, keep_in_fp32_modules, offload_8bit_bnb)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     module_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(module_name\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m module_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m device_map:\n\u001b[1;32m   1371\u001b[0m     \u001b[39m# TODO: group all errors and raise at the end.\u001b[39;00m\n\u001b[0;32m-> 1372\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have any device set.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1373\u001b[0m param_device \u001b[39m=\u001b[39m device_map[module_name]\n\u001b[1;32m   1374\u001b[0m new_dtype \u001b[39m=\u001b[39m dtype\n",
      "\u001b[0;31mValueError\u001b[0m: decoder.embed_tokens.weight doesn't have any device set."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "weights_location = snapshot_download(checkpoint, allow_patterns=[\"*.bin\", 'pytorch_model.bin.index.json'])\n",
    "model.model = load_checkpoint_and_dispatch(\n",
    "    output.model.model, # should be base model? e.g. output.model.model\n",
    "    weights_location,\n",
    "    device_map=device_map, \n",
    "    offload_folder='offload/' + checkpoint.replace('/', '.'), \n",
    "    offload_state_dict=True\n",
    ")\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     checkpoint, \n",
    "#     device_map=device_map, \n",
    "#     offload_folder='offload/' + checkpoint.replace('/', '.'), \n",
    "#     offload_state_dict=True\n",
    "# )\n",
    "\n",
    "logging.info(f'Model initialized!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(..., device='meta', size=(50272, 4096), requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model.decoder.embed_tokens', 'model.decoder.embed_positions', 'model.decoder.final_layer_norm', 'model.decoder.layers.0', 'model.decoder.layers.1', 'model.decoder.layers.2', 'model.decoder.layers.3', 'model.decoder.layers.4', 'model.decoder.layers.5', 'model.decoder.layers.6', 'model.decoder.layers.7', 'model.decoder.layers.8', 'model.decoder.layers.9', 'model.decoder.layers.10', 'model.decoder.layers.11', 'model.decoder.layers.12', 'model.decoder.layers.13', 'model.decoder.layers.14', 'model.decoder.layers.15', 'model.decoder.layers.16', 'model.decoder.layers.17', 'model.decoder.layers.18', 'model.decoder.layers.19', 'model.decoder.layers.20', 'model.decoder.layers.21', 'model.decoder.layers.22', 'model.decoder.layers.23', 'model.decoder.layers.24', 'model.decoder.layers.25', 'model.decoder.layers.26', 'model.decoder.layers.27', 'model.decoder.layers.28', 'model.decoder.layers.29', 'model.decoder.layers.30', 'model.decoder.layers.31', 'lm_head'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.layers_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load / offload\n",
    "#     module object, .dat file path\n",
    "#     layer: pre / post forward hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OffloadConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m             act_assign_dict[act_key]\u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39massigned_device\u001b[39m\u001b[39m'\u001b[39m: device}\n\u001b[1;32m     18\u001b[0m     \u001b[39mreturn\u001b[39;00m act_assign_dict\n\u001b[0;32m---> 21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_kv_cache_assignment\u001b[39m(num_layers, offload_config: OffloadConfig):\n\u001b[1;32m     22\u001b[0m     logging\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<compute_kv_cache_assignment> enter\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m     gpu_batch_limit \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(offload_config\u001b[39m.\u001b[39mnum_gpu_batches \u001b[39m*\u001b[39m offload_config\u001b[39m.\u001b[39mcache_gpu_percent)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OffloadConfig' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_activation_assignment(num_layers, offload_config: Policy):\n",
    "    logging.debug(f\"<compute_activation_assignment> enter\")\n",
    "    gpu_batch_limit = int(offload_config.num_gpu_batches * offload_config.act_gpu_percent)\n",
    "    cpu_batch_limit = int(offload_config.num_gpu_batches * (offload_config.act_gpu_percent + offload_config.act_cpu_percent))\n",
    "    logging.debug(f\"<compute_activation_assignment> gpu_batch_limit: {gpu_batch_limit}, cpu_batch_limit: {cpu_batch_limit}\")\n",
    "    \n",
    "    act_assign_dict = {}\n",
    "    for l in range(num_layers):\n",
    "        for i in range(offload_config.num_gpu_batches):\n",
    "            act_key = f\"layer.{l}_index.{i}\"\n",
    "            if i < gpu_batch_limit:\n",
    "                device = 'cuda'\n",
    "            elif i < cpu_batch_limit:\n",
    "                device = 'cpu'\n",
    "            else:\n",
    "                device = 'disk'\n",
    "            act_assign_dict[act_key]= {'assigned_device': device}\n",
    "    return act_assign_dict\n",
    "\n",
    "\n",
    "def compute_kv_cache_assignment(num_layers, offload_config: OffloadConfig):\n",
    "    logging.debug(f\"<compute_kv_cache_assignment> enter\")\n",
    "    gpu_batch_limit = int(offload_config.num_gpu_batches * offload_config.cache_gpu_percent)\n",
    "    cpu_batch_limit = int(offload_config.num_gpu_batches * (offload_config.cache_gpu_percent + offload_config.cache_cpu_percent))\n",
    "    logging.debug(f\"<compute_kv_cache_assignment> gpu_batch_limit: {gpu_batch_limit}, cpu_batch_limit: {cpu_batch_limit}\")\n",
    "    \n",
    "    act_assign_dict = {}\n",
    "    for l in range(num_layers):\n",
    "        for i in range(offload_config.num_gpu_batches):\n",
    "            key_cache_key = f\"key_layer.{l}_index.{i}\"\n",
    "            value_cache_key = f\"key_layer.{l}_index.{i}\"\n",
    "            if i < gpu_batch_limit:\n",
    "                device = 'cuda'\n",
    "            elif i < cpu_batch_limit:\n",
    "                device = 'cpu'\n",
    "            else:\n",
    "                device = 'disk'\n",
    "            act_assign_dict[key_cache_key] = {'assigned_device': device}\n",
    "            act_assign_dict[value_cache_key] = {'assigned_device': device}\n",
    "    return act_assign_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
