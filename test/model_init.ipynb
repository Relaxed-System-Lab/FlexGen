{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-24 10:35:40,934 [361951628.py:11 in <module>] INFO - Importing...\n",
      "/home/fsuser/miniconda3/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2023-09-24 10:35:43,552 [instantiator.py:21 in <module>] INFO - Created a temporary directory at /tmp/tmprkiwv02p\n",
      "2023-09-24 10:35:43,554 [instantiator.py:76 in _write] INFO - Writing /tmp/tmprkiwv02p/_remote_module_non_scriptable.py\n",
      "2023-09-24 10:35:44.197372: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-24 10:35:46,800 [361951628.py:22 in <module>] INFO - Done!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    style='{',\n",
    "    format='{asctime} [{filename}:{lineno} in {funcName}] {levelname} - {message}',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\".log\", 'w'),\n",
    "        logging.StreamHandler()\n",
    "    ],\n",
    "    level=logging.INFO\n",
    ")\n",
    "logging.info('Importing...')\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Module, ModuleList\n",
    "from transformers import PreTrainedModel\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "from accelerate import init_empty_weights\n",
    "from accelerate.utils import find_tied_parameters, named_module_tensors, set_module_tensor_to_device\n",
    "\n",
    "from policy import Policy\n",
    "logging.info('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"facebook/opt-125m\" \n",
    "# checkpoint = \"facebook/opt-13b\" # 1.3b 6.7b 13b 30b 66b \n",
    "offload_folder = 'offload/' + checkpoint.replace('/', '.')\n",
    "\n",
    "# empty model\n",
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "with init_empty_weights():\n",
    "    model = AutoModelForCausalLM.from_config(config)\n",
    "model.tie_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-24 10:35:47,095 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.embed_tokens, [0. 0. 1.], size_todo: 86630400\n",
      "2023-09-24 10:35:47,097 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.embed_positions, [0. 0. 1.], size_todo: 85056000\n",
      "2023-09-24 10:35:47,098 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.final_layer_norm, [0.00000000e+00 1.91116887e-05 9.99980888e-01], size_todo: 85054464\n",
      "2023-09-24 10:35:47,101 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.layers.0, [0.         0.05002193 0.94997807], size_todo: 77966592\n",
      "2023-09-24 10:35:47,103 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.layers.1, [0.         0.08698539 0.91301461], size_todo: 70878720\n",
      "2023-09-24 10:35:47,104 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.layers.2, [0.         0.11542163 0.88457837], size_todo: 63790848\n",
      "2023-09-24 10:35:47,106 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.layers.3, [0.         0.13797624 0.86202376], size_todo: 56702976\n",
      "2023-09-24 10:35:47,108 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.layers.4, [0.       0.156303 0.843697], size_todo: 49615104\n",
      "2023-09-24 10:35:47,110 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.layers.5, [0.       0.200013 0.799987], size_todo: 42527232\n",
      "2023-09-24 10:35:47,113 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.layers.6, [0.         0.21055017 0.78944983], size_todo: 35439360\n",
      "2023-09-24 10:35:47,117 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.layers.7, [0.         0.24389645 0.75610355], size_todo: 28351488\n",
      "2023-09-24 10:35:47,120 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.layers.8, [0.         0.25000554 0.74999446], size_todo: 21263616\n",
      "2023-09-24 10:35:47,123 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.layers.9, [0.         0.27657765 0.72342235], size_todo: 14175744\n",
      "2023-09-24 10:35:47,126 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.layers.10, [0.         0.27999324 0.72000676], size_todo: 7087872\n",
      "2023-09-24 10:35:47,129 [1132556772.py:124 in get_policy_weight_map] INFO - model.decoder.layers.11, [0.         0.30186053 0.69813947], size_todo: 0\n",
      "2023-09-24 10:35:47,130 [1132556772.py:124 in get_policy_weight_map] INFO - lm_head, [0.         0.30186053 0.69813947], size_todo: 0\n",
      "2023-09-24 10:35:47,132 [1132556772.py:128 in get_policy_weight_map] INFO - device_map is prepared!\n",
      "2023-09-24 10:35:47,138 [1132556772.py:134 in get_policy_weight_map] INFO - CausalLM facebook/opt-125m is to be loaded on: \n",
      "GPU Mem 0.00 GiB (0.00%), CPU Mem 0.07 GiB (30.19%), Disk Mem 0.16 Gib (69.81%)\n"
     ]
    }
   ],
   "source": [
    "class AttrDict(dict):\n",
    "    __slots__ = () \n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "\n",
    "policy = Policy(\n",
    "    gpu_batch_size=16, \n",
    "    num_gpu_batches=8, \n",
    "    weights_gpu_percent=0.0, \n",
    "    weights_cpu_percent=0.3, \n",
    "    cache_gpu_percent=0.0, \n",
    "    cache_cpu_percent=0.2, \n",
    "    act_gpu_percent=0.0, \n",
    "    act_cpu_percent=0.5, \n",
    "    overlap=True, \n",
    "    pin_weight=True,\n",
    ")\n",
    "\n",
    "def get_layers_dict(lm_model: Module, prefix: str='') -> dict:\n",
    "    # return a dict of {layer_name : layer_module ('meta')} with only leaf nodes & transformer layers\n",
    "    layers_dict = {}\n",
    "    for name, module in lm_model.named_children():\n",
    "        # leaf nodes\n",
    "        if len(list(module.named_children())) == 0:\n",
    "            layers_dict[prefix+name] = module\n",
    "        # ModuleList: transformer  \n",
    "        elif isinstance(module, ModuleList):\n",
    "            for block_name, block_module in module.named_children():\n",
    "                layers_dict[prefix+name+'.'+block_name] = block_module\n",
    "        else:\n",
    "            layers_dict.update(get_layers_dict(module, prefix+name+'.'))\n",
    "    return layers_dict\n",
    "\n",
    "def named_module_tensors(module: Module, include_buffers: bool = True, recurse: bool = True):\n",
    "    for named_parameter in module.named_parameters(recurse=recurse):\n",
    "        yield named_parameter\n",
    "\n",
    "    if include_buffers:\n",
    "        for named_buffer in module.named_buffers(recurse=recurse):\n",
    "            yield named_buffer\n",
    "\n",
    "def get_device(cur_percent, percents, choices):\n",
    "    # choose a device (gpu / cpu / disk) for a weight tensor by its percent of size\n",
    "    percents = np.cumsum(percents)\n",
    "    assert np.abs(percents[-1] - 1.0) < 1e-5, f'{percents}'\n",
    "\n",
    "    for i in range(len(percents)):\n",
    "        if cur_percent < percents[i]:\n",
    "            return choices[i]\n",
    "    return choices[-1]\n",
    "\n",
    "def get_policy_weight_map(model: PreTrainedModel, policy: Policy):\n",
    "    \"\"\"{module_name: device}\"\"\"\n",
    "    assert model.device == torch.device('meta'), 'model is not on device meta.'\n",
    "    \n",
    "    # to ensure the tied params are allocated to the same device in the weight_map\n",
    "    model.tie_weights()\n",
    "    tied_params = find_tied_parameters(model)\n",
    "\n",
    "    # layers to be scheduled\n",
    "    layers_dict = get_layers_dict(model)\n",
    "\n",
    "    # device assignment for each tensor in the model\n",
    "    weight_assign_dict = {}\n",
    "    devices = ['cuda', 'cpu', 'disk']\n",
    "    percents_target = np.array([\n",
    "        policy.weights_gpu_percent, \n",
    "        policy.weights_cpu_percent, \n",
    "        policy.weights_disk_percent\n",
    "    ])\n",
    "    \n",
    "    # model size (parameters + buffers), here we do not repeatly sum the tied paramters \n",
    "    size_total = sum(np.prod(tensor.shape) for _, tensor in named_module_tensors(model))\n",
    "    size_done, size_todo = 0, size_total\n",
    "    percents_done, percents_todo = 0 * percents_target, percents_target  \n",
    "\n",
    "    for layer_name, layer_module in layers_dict.items():\n",
    "        # current layer\n",
    "        tensor_sizes = [np.prod(tensor.shape) for _, tensor in named_module_tensors(layer_module)]\n",
    "        tensor_sizes_cumsum = np.cumsum(tensor_sizes)\n",
    "\n",
    "        device_allo_size_dict = {device: 0 for device in devices} # to balance the percents\n",
    "        for i, (tensor_name, tensor) in enumerate(named_module_tensors(layer_module)):\n",
    "            abs_tensor_name = layer_name + '.' + tensor_name\n",
    "\n",
    "            def find_processed_tied(abs_tensor_name, tied_params, weight_assign_dict):\n",
    "                # find the processed parameter (in weight_assign_dict) of the tied parameters.\n",
    "                for tp in tied_params:\n",
    "                    if abs_tensor_name in tp:\n",
    "                        for p in tp:\n",
    "                            if p in weight_assign_dict:\n",
    "                                return p, tuple(tp)\n",
    "                return None\n",
    "            \n",
    "            processed_tied = find_processed_tied(abs_tensor_name, tied_params, weight_assign_dict) \n",
    "            if processed_tied: # this tensor is tied and processed.\n",
    "                p, tp = processed_tied\n",
    "                weight_assign_dict[abs_tensor_name] = {\n",
    "                    # 'shape':  tensor.shape,\n",
    "                    'assigned_device': weight_assign_dict[p]['assigned_device'],\n",
    "                    'tied': tp\n",
    "                }\n",
    "            else:\n",
    "                mid_percent = (tensor_sizes_cumsum[i] - tensor_sizes[i] / 2) / tensor_sizes_cumsum[-1] # tensor mid size percent \n",
    "                device = get_device(mid_percent, percents_todo, devices)\n",
    "                weight_assign_dict[abs_tensor_name] = {\n",
    "                    'shape':  tensor.shape,\n",
    "                    'assigned_device': device\n",
    "                }\n",
    "                \n",
    "                device_allo_size_dict[device] += tensor_sizes[i]\n",
    "\n",
    "        # update percents_todo\n",
    "        size_layer = sum(device_allo_size_dict.values())\n",
    "        if size_layer > 0:\n",
    "            device_allo_percents = np.array([device_allo_size_dict[device] * 1. for device in devices]) / size_layer\n",
    "            percents_done = (percents_done * size_done + device_allo_percents * size_layer) / (size_done + size_layer)      \n",
    "        size_done += size_layer\n",
    "        size_todo -= size_layer\n",
    "        if size_todo > 0:\n",
    "            percents_todo = (size_total * percents_target - size_done * percents_done) / size_todo \n",
    "        \n",
    "        logging.info(f'{layer_name}, {percents_done}, size_todo: {size_todo}')\n",
    "\n",
    "\n",
    "    device_map = {k:v['assigned_device'] for k, v in weight_assign_dict.items()}\n",
    "    logging.info('device_map is prepared!')\n",
    "\n",
    "    mem_g = sum([np.prod(v['shape']) for _, v in weight_assign_dict.items() if 'cuda' in v['assigned_device'] and 'shape' in v]) * 2 / (2 ** 30)\n",
    "    mem_c = sum([np.prod(v['shape']) for _, v in weight_assign_dict.items() if v['assigned_device'] == 'cpu' and 'shape' in v]) * 2 / (2 ** 30)\n",
    "    mem_d = sum([np.prod(v['shape']) for _, v in weight_assign_dict.items() if v['assigned_device'] == 'disk' and 'shape' in v]) * 2 / (2 ** 30)\n",
    "    mem = mem_d + mem_c + mem_g\n",
    "    logging.info(f'CausalLM {checkpoint} is to be loaded on: ' \n",
    "                 f'\\nGPU Mem {mem_g:.2f} GiB ({mem_g / mem:.2%}), ' \n",
    "                 f'CPU Mem {mem_c:.2f} GiB ({mem_c / mem:.2%}), '\n",
    "                 f'Disk Mem {mem_d:.2f} Gib ({mem_d / mem:.2%})')\n",
    "    \n",
    "    # prepare output\n",
    "    output = {\n",
    "        'model': model,\n",
    "        'tied_params': tied_params,\n",
    "        'layers_dict': layers_dict,\n",
    "        'weight_assign_dict': weight_assign_dict,\n",
    "        'device_map': device_map\n",
    "    }\n",
    "    output = AttrDict(output)\n",
    "    return output\n",
    "\n",
    "output = get_policy_weight_map(model, policy)\n",
    "policy_device_map = output.device_map\n",
    "flexgen_layers = output.layers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-24 10:35:47,604 [1111749824.py:28 in <module>] INFO - The whole model has been downloaded an processed to offload_folder: 'offload/facebook.opt-125m'\n",
      "2023-09-24 10:35:47,730 [1111749824.py:40 in <module>] INFO - Got empty CausalLM: 'facebook/opt-125m' on meta device.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['lm_head.weight', 'model.decoder.embed_tokens.weight']]\n"
     ]
    }
   ],
   "source": [
    "def check_disk(checkpoint, offload_folder):\n",
    "    if not os.path.isdir(offload_folder):\n",
    "        return False \n",
    "    \n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "    with init_empty_weights():\n",
    "        model = AutoModelForCausalLM.from_config(config)\n",
    "    model.tie_weights()\n",
    "    tensor_names = [n for n, _ in named_module_tensors(model, include_buffers=True, recurse=True)]\n",
    "    dat_file_names = [file[:-4] for file in os.listdir(offload_folder) if file.endswith('.dat')]\n",
    "    # logging.info(set(tensor_names) - set(dat_file_names), set(dat_file_names) - set(tensor_names))\n",
    "    return len(set(tensor_names) - set(dat_file_names)) == 0\n",
    "\n",
    "if not check_disk(checkpoint, offload_folder):\n",
    "    # download and process to .dat files\n",
    "    disk_weight_map = {name:'disk' for name in policy_device_map}\n",
    "    try:\n",
    "        AutoModelForCausalLM.from_pretrained(\n",
    "            checkpoint, \n",
    "            device_map=disk_weight_map, \n",
    "            offload_folder=offload_folder, \n",
    "            offload_state_dict=True\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if check_disk(checkpoint, offload_folder):\n",
    "    logging.info(f'The whole model has been downloaded an processed to offload_folder: \\'{offload_folder}\\'')\n",
    "else:\n",
    "    err_msg = 'Mismatch between offload folder and model'\n",
    "    logging.error(err_msg)\n",
    "    raise RuntimeError(err_msg)\n",
    "\n",
    "# get empty model\n",
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "with init_empty_weights():\n",
    "    model = AutoModelForCausalLM.from_config(config)\n",
    "model.tie_weights()\n",
    "model.eval()\n",
    "logging.info(f'Got empty CausalLM: \\'{checkpoint}\\' on meta device.')\n",
    "\n",
    "tied_params = find_tied_parameters(model)\n",
    "print(tied_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_from_name(lm_model, name):\n",
    "    splits = name.split('.')\n",
    "    module = lm_model\n",
    "    for split in splits:\n",
    "        if split == '': \n",
    "            continue \n",
    "\n",
    "        new_module = getattr(module, split)\n",
    "        if new_module is None:\n",
    "            raise ValueError(f\"{module} has no attribute {split}.\")\n",
    "        module = new_module\n",
    "    return module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model init: loading by policy...: 100%|██████████| 197/197 [00:00<00:00, 5320.94it/s]\n",
      "2023-09-24 10:51:23,077 [3593259108.py:60 in policy_init] INFO - model has been loaded by policy.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm \n",
    "import gc \n",
    "\n",
    "dat_files = [f for f in os.listdir(offload_folder) if f.endswith('.dat')]\n",
    "with open(os.path.join(offload_folder, 'index.json'), 'r') as f:\n",
    "    index = json.load(f) # {name: {dtype, shape}}\n",
    "\n",
    "def get_tied_target(tensor_name):\n",
    "    # if tensor_name is tied and without a .dat file, if it is not tied, return itself\n",
    "    for group in tied_params:\n",
    "        if tensor_name in group:\n",
    "            for name in group:\n",
    "                if name + '.dat' in dat_files:\n",
    "                    return name \n",
    "    return tensor_name\n",
    "\n",
    "def flexgen_load_module_tensor(model, tensor_name, device):\n",
    "    tensor = get_obj_from_name(model, tensor_name)\n",
    "    if tensor.device == device:\n",
    "        return \n",
    "    \n",
    "    # else\n",
    "    old_tensor_name = tensor_name\n",
    "    \n",
    "    tensor_name = get_tied_target(tensor_name) \n",
    "    metadata = index[tensor_name]\n",
    "\n",
    "    # copied from accelerate.utils.offload\n",
    "    shape = tuple(metadata[\"shape\"])\n",
    "    if shape == ():\n",
    "        # NumPy memory-mapped arrays can't have 0 dims so it was saved as 1d tensor\n",
    "        shape = (1,)\n",
    "\n",
    "    dtype = metadata[\"dtype\"]\n",
    "    if dtype == \"bfloat16\":\n",
    "        # NumPy does not support bfloat16 so this was saved as a int16\n",
    "        dtype = \"int16\"\n",
    "    \n",
    "    # load .dat file\n",
    "    save_path = os.path.join(offload_folder, tensor_name + '.dat')\n",
    "\n",
    "    # to device \n",
    "    np_memmap = np.memmap(save_path, dtype=dtype, shape=shape, mode='r') \n",
    "    tmp = torch.from_numpy(np_memmap).to(device) \n",
    "    set_module_tensor_to_device(model, old_tensor_name, device, tmp)\n",
    "\n",
    "def flexgen_offload_module_tensor(model, tensor_name):\n",
    "    tensor = get_obj_from_name(model, tensor_name)\n",
    "    device = policy_device_map[tensor_name]\n",
    "    device = device if device != 'disk' else 'meta' \n",
    "    if tensor.device != device:\n",
    "        set_module_tensor_to_device(model, tensor_name, device, tensor) # gtoc, ctog\n",
    "\n",
    "def policy_init(model, policy_device_map):\n",
    "    for tensor_name, device in tqdm(policy_device_map.items(), desc='model init: loading by policy...'):\n",
    "        if device != 'disk':\n",
    "            flexgen_load_module_tensor(model, tensor_name, device) \n",
    "\n",
    "    logging.info('model has been loaded by policy.')        \n",
    "\n",
    "policy_init(model, policy_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "/home/fsuser/miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1535: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on meta. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('meta') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "2023-09-24 10:52:51,485 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:51,489 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:51,492 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:51,496 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:51,505 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:51,570 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:51,573 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:51,613 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:51,616 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:51,642 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:51,647 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:51,666 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:51,670 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:51,690 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:51,694 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:51,714 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:51,718 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:51,737 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:51,740 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:51,764 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:51,767 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:51,787 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:51,791 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:51,815 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:51,818 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:51,839 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:51,842 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:51,860 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:51,863 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:51,869 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:51,871 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:51,919 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:51,930 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:51,932 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:51,934 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:51,936 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:51,937 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:51,950 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:51,953 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:51,966 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:51,969 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:51,982 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:51,985 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:51,997 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:52,000 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:52,012 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:52,015 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:52,029 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:52,032 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:52,045 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:52,050 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:52,061 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:52,064 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:52,077 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:52,080 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:52,093 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:52,097 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:52,110 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:52,113 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:52,122 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:52,124 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:52,130 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:52,133 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:52,152 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:52,162 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:52,164 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:52,166 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:52,168 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:52,169 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:52,181 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:52,184 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:52,196 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:52,199 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:52,211 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:52,214 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:52,232 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:52,235 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:52,247 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:52,250 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:52,263 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:52,266 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:52,278 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:52,282 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:52,294 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:52,298 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:52,309 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:52,315 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:52,345 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:52,349 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:52,362 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:52,367 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:52,376 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:52,379 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:52,386 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:52,388 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:52,405 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:52,418 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:52,420 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:52,422 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:52,424 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:52,426 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:52,439 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:52,442 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:52,455 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:52,458 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:52,472 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:52,475 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:52,496 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:52,500 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:52,512 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:52,516 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:52,529 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:52,532 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:52,544 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:52,548 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:52,559 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:52,562 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:52,579 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:52,583 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:52,599 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:52,602 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:52,619 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:52,623 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:52,632 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:52,635 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:52,641 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:52,643 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:52,661 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:52,675 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:52,677 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:52,678 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:52,680 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:52,682 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:52,696 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:52,700 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:52,713 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:52,716 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:52,728 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:52,732 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:52,744 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:52,747 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:52,759 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:52,763 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:52,775 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:52,778 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:52,790 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:52,794 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:52,806 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:52,809 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:52,821 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:52,824 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:52,836 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:52,839 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:52,853 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:52,856 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:52,865 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:52,867 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:52,873 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:52,875 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:52,895 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:52,908 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:52,910 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:52,911 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:52,913 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:52,915 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:52,926 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:52,930 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:52,942 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:52,947 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:52,958 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:52,961 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:52,973 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:52,976 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:52,988 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:52,992 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:53,006 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:53,009 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:53,021 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:53,024 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:53,040 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:53,043 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:53,063 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:53,066 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:53,080 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:53,083 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:53,105 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:53,109 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:53,117 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:53,121 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:53,126 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:53,128 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:53,141 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:53,152 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:53,154 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:53,156 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:53,158 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:53,159 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:53,171 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:53,175 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:53,200 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:53,203 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:53,215 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:53,218 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:53,230 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:53,233 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:53,245 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:53,248 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:53,260 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:53,263 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:53,275 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:53,279 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:53,290 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:53,293 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:53,310 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:53,313 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:53,332 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:53,336 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:53,349 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:53,354 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:53,367 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:53,370 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:53,376 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:53,378 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:53,393 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:53,404 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:53,406 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:53,408 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:53,410 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:53,411 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:53,423 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:53,426 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:53,439 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:53,443 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:53,456 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:53,459 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:53,472 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:53,475 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:53,491 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:53,495 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:53,508 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:53,511 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:53,524 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:53,528 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:53,541 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:53,544 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:53,557 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:53,560 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:53,573 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:53,577 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:53,590 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:53,594 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:53,602 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:53,606 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:53,612 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:53,613 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:53,626 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:53,635 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:53,636 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:53,638 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:53,640 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:53,642 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:53,654 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:53,657 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:53,673 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:53,677 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:53,689 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:53,694 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:53,707 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:53,711 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:53,724 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:53,728 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:53,740 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:53,743 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:53,755 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:53,759 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:53,771 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:53,774 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:53,787 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:53,791 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:53,803 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:53,807 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:53,820 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:53,823 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:53,832 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:53,835 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:53,840 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:53,842 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:53,853 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:53,866 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:53,869 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:53,870 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:53,872 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:53,873 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:53,887 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:53,891 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:53,906 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:53,910 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:53,923 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:53,926 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:53,939 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:53,943 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:53,957 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:53,960 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:53,973 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:53,978 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:53,992 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:53,995 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:54,009 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:54,012 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:54,026 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:54,030 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:54,062 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:54,066 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:54,084 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:54,087 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:54,112 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:54,119 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:54,132 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:54,135 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:54,155 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:54,171 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:54,173 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:54,175 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:54,176 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:54,177 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:54,189 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:54,192 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:54,203 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:54,206 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:54,218 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:54,222 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:54,234 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:54,237 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:54,249 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:54,252 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:54,269 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:54,275 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:54,292 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:54,296 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:54,309 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:54,313 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:54,327 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:54,331 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:54,349 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:54,352 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:54,367 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:54,371 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:54,380 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:54,383 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:54,389 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:54,391 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:54,409 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:54,419 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:54,422 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:54,424 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:54,426 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:54,427 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:54,443 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:54,447 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:54,459 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:54,464 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:54,475 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:54,479 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:54,492 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:54,495 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:54,510 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:54,514 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:54,526 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:54,530 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:54,544 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:54,548 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:54,560 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:54,563 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:54,576 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:54,580 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:54,595 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:54,598 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:54,610 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:54,613 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:54,621 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:54,625 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:54,631 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:54,632 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:54,644 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:54,655 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:54,659 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:54,662 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:54,665 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:54,667 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:54,696 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:54,700 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:54,712 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:54,716 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:54,729 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:54,733 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:54,747 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:54,750 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:54,763 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:54,766 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:54,778 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:54,781 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:54,793 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:54,797 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:54,809 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:54,813 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:54,827 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:54,831 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:54,843 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:54,846 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:54,865 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:54,869 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:54,877 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:54,880 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:54,885 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:54,887 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:54,898 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:54,908 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:54,910 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:54,911 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:54,913 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:54,914 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:54,926 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:54,930 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:54,941 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:54,944 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:54,964 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:54,967 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:54,978 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:54,981 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:54,997 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:55,000 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:55,014 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:55,017 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:55,129 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:55,134 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:55,242 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:55,247 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:55,299 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:55,303 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:55,367 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:55,370 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:55,404 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:55,408 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:55,416 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:55,419 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:55,425 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:55,427 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:55,437 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:55,447 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:55,449 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:55,450 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:55,453 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:55,454 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:55,467 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:55,471 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:55,483 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:55,487 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:55,499 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:55,502 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:55,515 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:55,519 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:55,531 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:55,535 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:55,547 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:55,550 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:55,565 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:55,568 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:55,580 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:55,583 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:55,595 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:55,598 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:55,610 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:55,613 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:55,625 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:55,628 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:55,636 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:55,639 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:55,644 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:55,646 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:55,658 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:55,666 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:55,668 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:55,670 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:55,672 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:55,673 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:55,685 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:55,688 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:55,701 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:55,704 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:55,718 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:55,722 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:55,733 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:55,737 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:55,749 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:55,753 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:55,766 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:55,770 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:55,783 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:55,787 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:55,799 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:55,802 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:55,815 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:55,818 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:55,831 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:55,834 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:55,848 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:55,852 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:55,861 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:55,864 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:55,870 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:55,872 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:55,891 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:55,900 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:55,903 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:55,904 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:55,906 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:55,908 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:55,919 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:55,922 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:55,934 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:55,937 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:55,949 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:55,953 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:55,965 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:55,968 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:55,981 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:55,985 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:55,996 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:55,999 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:56,018 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:56,023 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:56,043 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:56,047 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:56,060 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:56,065 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:56,077 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:56,082 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:56,094 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:56,098 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:56,106 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:56,110 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:56,115 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:56,117 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:56,129 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:56,142 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:56,144 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:56,146 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:56,148 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:56,149 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:56,161 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:56,165 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:56,177 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:56,180 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:56,192 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:56,195 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:56,208 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:56,212 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:56,224 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:56,228 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:56,240 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:56,244 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:56,257 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:56,261 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:56,274 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:56,277 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:56,291 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:56,295 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:56,308 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:56,312 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:56,326 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:56,330 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:56,339 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:56,342 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:56,348 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:56,350 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:56,369 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:56,381 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:56,383 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:56,385 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:56,387 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:56,388 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:56,400 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:56,404 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:56,419 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:56,423 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:56,435 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:56,439 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:56,451 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:56,454 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:56,467 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:56,471 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:56,484 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:56,487 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:56,501 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:56,504 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:56,525 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:56,528 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:56,545 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:56,549 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:56,590 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:56,593 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:56,606 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:56,609 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:56,618 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:56,622 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:56,627 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:56,629 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:56,646 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:56,658 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:56,660 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:56,662 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:56,664 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:56,665 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:56,680 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:56,684 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:56,697 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:56,700 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:56,713 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:56,717 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:56,730 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:56,734 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:56,747 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:56,751 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:56,764 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:56,767 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:56,780 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:56,784 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:56,797 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:56,801 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:56,814 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:56,817 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:56,830 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:56,834 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:56,847 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:56,851 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:56,860 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:56,864 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:56,870 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:56,871 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:56,887 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:56,899 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:56,901 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:56,903 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:56,905 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:56,906 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:56,918 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:56,922 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:56,935 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:56,938 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:56,951 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:56,954 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:56,967 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:56,970 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:56,983 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:56,987 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:56,999 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:57,003 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:57,016 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:57,019 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:57,042 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:57,045 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:57,060 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:57,064 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:57,077 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:57,081 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:57,164 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:57,170 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:57,182 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:57,185 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:57,191 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:57,192 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:57,207 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:57,217 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:57,219 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:57,221 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:57,223 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:57,225 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:57,237 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:57,240 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:57,252 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:57,255 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:57,272 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:57,276 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:57,288 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:57,291 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:57,303 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:57,307 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:57,319 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:57,322 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:57,334 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:57,338 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:57,349 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:57,353 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:57,364 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:57,368 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:57,382 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:57,386 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:57,399 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:57,403 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:57,411 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:57,414 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:57,419 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:57,421 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:57,433 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:57,445 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:57,447 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:57,449 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:57,451 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:57,452 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:57,464 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:57,467 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:57,489 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:57,493 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:57,504 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:57,507 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:57,519 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:57,522 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:57,534 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:57,538 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:57,551 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:57,554 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:57,567 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:57,570 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:57,583 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:57,586 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:57,598 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:57,601 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:57,613 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:57,616 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:57,628 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:57,631 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:57,640 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:57,644 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:57,649 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:57,651 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:57,667 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:57,679 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:57,682 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:57,683 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:57,685 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:57,686 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:57,698 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:57,703 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:57,717 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:57,720 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:57,733 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:57,736 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:57,748 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:57,751 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:57,766 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:57,770 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:57,783 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:57,787 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:57,800 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:57,803 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:57,816 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:57,819 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:57,833 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:57,836 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:57,850 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:57,854 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:57,868 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:57,873 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:57,885 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:57,888 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:57,895 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:57,896 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:57,914 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:57,929 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:57,931 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:57,932 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:57,934 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:57,936 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:57,950 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:57,954 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:57,969 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:57,974 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:57,989 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:57,992 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:58,004 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:58,008 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:58,080 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:58,083 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:58,096 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:58,099 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:58,112 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:58,116 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:58,128 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:58,132 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:58,150 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:58,153 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:58,171 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:58,175 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:58,192 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:58,195 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:58,209 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:58,212 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:58,218 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:58,219 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:58,234 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:58,252 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:58,254 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:58,256 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:58,258 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:58,259 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:58,272 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:58,275 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:58,288 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:58,291 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:58,303 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:58,307 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:58,319 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:58,322 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:58,335 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:58,339 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:58,351 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:58,354 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:58,368 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:58,372 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:58,387 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:58,390 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:58,407 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:58,410 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:58,424 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:58,427 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:58,440 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:58,443 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:58,460 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:58,463 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:58,469 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:58,471 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:58,489 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:58,500 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:58,503 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:58,504 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:58,506 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:58,508 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:58,525 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:58,528 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:58,545 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:58,551 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:58,569 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:58,573 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:58,591 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:58,595 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:58,608 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:58,611 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:58,627 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:58,631 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:58,644 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:58,648 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:58,662 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:58,667 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:58,680 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:58,684 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:58,697 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:58,701 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:58,716 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:58,719 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:58,742 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:58,745 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:58,751 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:58,753 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:58,769 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:58,783 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:58,785 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:58,786 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:58,788 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:58,789 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:58,801 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:58,805 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:58,816 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:58,819 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:58,831 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:58,834 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:58,846 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:58,849 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:58,862 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:58,866 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:58,878 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:58,881 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:58,908 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:58,912 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:58,923 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:58,926 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:58,938 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:58,942 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:58,954 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:58,957 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:58,969 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:58,972 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:58,981 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:58,984 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:58,990 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:58,993 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:59,005 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:59,015 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:59,017 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:59,018 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:59,020 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:59,022 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:59,033 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:59,037 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:59,048 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:59,053 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:59,066 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:59,070 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:59,082 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:59,085 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:59,097 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:59,100 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:59,112 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:59,116 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:59,128 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:59,132 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:59,152 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:59,156 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:59,169 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:59,172 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:59,186 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:59,189 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:59,248 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:59,252 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:59,266 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:59,269 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:59,274 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:59,276 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:59,287 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:59,298 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:59,300 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_tokens forward\n",
      "2023-09-24 10:52:59,302 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:59,304 [1683479187.py:82 in post_forward] INFO - post model.decoder.embed_positions forward\n",
      "2023-09-24 10:52:59,305 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:59,320 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.0 forward\n",
      "2023-09-24 10:52:59,323 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:59,335 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.1 forward\n",
      "2023-09-24 10:52:59,338 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:59,351 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.2 forward\n",
      "2023-09-24 10:52:59,353 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:59,365 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.3 forward\n",
      "2023-09-24 10:52:59,368 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:59,386 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.4 forward\n",
      "2023-09-24 10:52:59,389 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:59,401 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.5 forward\n",
      "2023-09-24 10:52:59,404 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:59,416 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.6 forward\n",
      "2023-09-24 10:52:59,419 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:59,431 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.7 forward\n",
      "2023-09-24 10:52:59,435 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:59,448 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.8 forward\n",
      "2023-09-24 10:52:59,452 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:59,466 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.9 forward\n",
      "2023-09-24 10:52:59,469 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:59,484 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.10 forward\n",
      "2023-09-24 10:52:59,487 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:59,496 [1683479187.py:82 in post_forward] INFO - post model.decoder.layers.11 forward\n",
      "2023-09-24 10:52:59,500 [1683479187.py:73 in pre_forward] INFO - pre model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:59,505 [1683479187.py:82 in post_forward] INFO - post model.decoder.final_layer_norm forward\n",
      "2023-09-24 10:52:59,507 [1683479187.py:73 in pre_forward] INFO - pre lm_head forward\n",
      "2023-09-24 10:52:59,523 [1683479187.py:82 in post_forward] INFO - post lm_head forward\n",
      "2023-09-24 10:52:59,536 [1683479187.py:135 in <module>] INFO - Who are you? Are you conscious?\n",
      "Yea\n",
      "2023-09-24 10:52:59,537 [1683479187.py:136 in <module>] INFO - ----------\n",
      "2023-09-24 10:52:59,538 [1683479187.py:135 in <module>] INFO - Where is Deutschland?\n",
      "Ludwig-Westphalia.\n",
      "I have to be honest, I'm a little surprised.\n",
      "I am a bit surprised too,\n",
      "2023-09-24 10:52:59,539 [1683479187.py:136 in <module>] INFO - ----------\n",
      "2023-09-24 10:52:59,541 [1683479187.py:135 in <module>] INFO - How is Huawei Mate 60 Pro?)\n",
      "The Huawei 5G smartphone is currently in the Indian market. It is priced at $499 for the base model and $500 for the extra\n",
      "2023-09-24 10:52:59,541 [1683479187.py:136 in <module>] INFO - ----------\n",
      "2023-09-24 10:52:59,542 [1683479187.py:135 in <module>] INFO - Who are you? Are you conscious?>\n",
      "I live in a country surrounded by a high concentration of idiots, some of them even as I'm still a teenager!\n",
      "> some of\n",
      "2023-09-24 10:52:59,543 [1683479187.py:136 in <module>] INFO - ----------\n",
      "2023-09-24 10:52:59,544 [1683479187.py:135 in <module>] INFO - Where is Deutschland?:)  I am in the middle of Europe, so you must be there.\n",
      "I don't know - I don't have any friends here\n",
      "2023-09-24 10:52:59,545 [1683479187.py:136 in <module>] INFO - ----------\n",
      "2023-09-24 10:52:59,546 [1683479187.py:135 in <module>] INFO - How is Huawei Mate 60 Pro?�\n",
      "With an 8MP main camera and 6MP selfie shooter, Huawei’s Mate 60 Pro appears to be a smartphone with a great camera\n",
      "2023-09-24 10:52:59,547 [1683479187.py:136 in <module>] INFO - ----------\n",
      "2023-09-24 10:52:59,547 [1683479187.py:135 in <module>] INFO - Who are you? Are you conscious?1 of a thousand...\n",
      "I wish this were true.\n",
      "2023-09-24 10:52:59,549 [1683479187.py:136 in <module>] INFO - ----------\n",
      "2023-09-24 10:52:59,550 [1683479187.py:135 in <module>] INFO - Where is Deutschland?\n",
      "Die Zeit ist die Zeit!\n",
      "Ich denke ihn, die Frage ist das so groß ist und s\n",
      "2023-09-24 10:52:59,551 [1683479187.py:136 in <module>] INFO - ----------\n",
      "2023-09-24 10:52:59,551 [1683479187.py:135 in <module>] INFO - How is Huawei Mate 60 Pro?)\n",
      "With two-to-four screen, 4K display and an 8-megapixel shooter, this is not a phone I'd be interested\n",
      "2023-09-24 10:52:59,552 [1683479187.py:136 in <module>] INFO - ----------\n",
      "2023-09-24 10:52:59,553 [1683479187.py:135 in <module>] INFO - Who are you? Are you conscious?) You don't have a pulse. Your brain is processing the information.   If you don't have a pulse, you're fucked. \n",
      "2023-09-24 10:52:59,554 [1683479187.py:136 in <module>] INFO - ----------\n",
      "2023-09-24 10:52:59,554 [1683479187.py:135 in <module>] INFO - Where is Deutschland?\n",
      "When is the next war coming?\n",
      "2023-09-24 10:52:59,556 [1683479187.py:136 in <module>] INFO - ----------\n",
      "2023-09-24 10:52:59,557 [1683479187.py:135 in <module>] INFO - How is Huawei Mate 60 Pro?\n",
      "Its much better than what you might expect. It's more compact, less ugly, and has more features and functions than I want. Plus this\n",
      "2023-09-24 10:52:59,558 [1683479187.py:136 in <module>] INFO - ----------\n"
     ]
    }
   ],
   "source": [
    "from accelerate.hooks import (\n",
    "    ModelHook, \n",
    "    SequentialHook, \n",
    "    add_hook_to_module, \n",
    "    remove_hook_from_module\n",
    ")\n",
    "# TODO: add_zigzag_hook, remove_zigzag_hook\n",
    "\n",
    "from accelerate.utils import (\n",
    "    find_device,\n",
    "    named_module_tensors,\n",
    "    send_to_device,\n",
    "    set_module_tensor_to_device,\n",
    ")\n",
    "\n",
    "# global buffers: {layer_name: value_holder}\n",
    "weight_home = {}\n",
    "weight_load_buf = {}\n",
    "\n",
    "act_home = {}\n",
    "act_load_buf = {}\n",
    "act_store_buf = {}\n",
    "\n",
    "kv_home = {} \n",
    "kv_load_buf = {}\n",
    "kv_store_buf = {}\n",
    "\n",
    "# TODO: cuda streams / cpu threads (?)\n",
    "\n",
    "\n",
    "from typing import Optional, Union, Mapping\n",
    "class LayerWeightHook(ModelHook):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model, \n",
    "        layer_name,\n",
    "        next_layer_name,\n",
    "        compute_device,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.layer_name = layer_name\n",
    "        self.next_layer_name = next_layer_name\n",
    "        self.compute_device = compute_device\n",
    "\n",
    "        # get weight names\n",
    "        layer_module = get_obj_from_name(model, layer_name)\n",
    "        self.weight_names = [layer_name + '.' + name for name, _ in named_module_tensors(layer_module, True, True)]\n",
    "        dat_files = [os.path.join(offload_folder, get_tied_target(w) + '.dat') for w in self.weight_names]\n",
    "        assert all([self.check_dat(f) for f in dat_files]), f'dat file error, {dat_files}'\n",
    "        \n",
    "        if next_layer_name:\n",
    "            next_layer_module = get_obj_from_name(model, next_layer_name)\n",
    "            self.next_weight_names = [next_layer_name + '.' + name for name, _ in named_module_tensors(next_layer_module, True, True)]\n",
    "            dat_files = [os.path.join(offload_folder, get_tied_target(w) + '.dat') for w in self.next_weight_names]\n",
    "            assert all([self.check_dat(f) for f in dat_files]), f'dat file error, {dat_files}'\n",
    "\n",
    "        \n",
    "    def check_dat(self, dat_file):\n",
    "        return os.path.isfile(dat_file)\n",
    "\n",
    "    def init_hook(self, module):\n",
    "        return module \n",
    "\n",
    "    def load_layer(self, weight_names):\n",
    "        for w in weight_names:\n",
    "            flexgen_load_module_tensor(self.model, w, self.compute_device)\n",
    "\n",
    "    def offload_layer(self, weight_names):\n",
    "        for w in weight_names:\n",
    "            flexgen_offload_module_tensor(self.model, w)\n",
    "    \n",
    "    def pre_forward(self, module: Module, *args, **kwargs):\n",
    "        logging.info(f'pre {self.layer_name} forward')\n",
    "\n",
    "        self.load_layer(self.weight_names) \n",
    "        if self.next_layer_name:\n",
    "            self.load_layer(self.next_weight_names) \n",
    "\n",
    "        return args, kwargs\n",
    "    \n",
    "    def post_forward(self, module, output):\n",
    "        logging.info(f'post {self.layer_name} forward')\n",
    "\n",
    "        self.offload_layer(self.weight_names)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def detach_hook(self, module):\n",
    "        return module \n",
    "\n",
    "class LayerActHook(ModelHook): pass \n",
    "class LayerKVCacheHook(ModelHook): pass \n",
    "\n",
    "\n",
    "# clear hooks \n",
    "remove_hook_from_module(model, recurse=True)\n",
    "\n",
    "compute_device = 'cpu' \n",
    "\n",
    "layer_names = list(flexgen_layers)\n",
    "for i, layer_name in enumerate(layer_names): # layer names\n",
    "    layer_module = get_obj_from_name(model, layer_name)\n",
    "    next_layer_name = layer_names[i + 1] if i < len(layer_names) - 1 else None \n",
    "\n",
    "    layer_weight_hook = LayerWeightHook(\n",
    "        model=model, layer_name=layer_name, next_layer_name=next_layer_name, compute_device=compute_device)\n",
    "    add_hook_to_module(layer_module, layer_weight_hook, append=True)\n",
    "    # break\n",
    "\n",
    "# generate test\n",
    "\n",
    "prompts = [\n",
    "    'Who are you? Are you conscious?',\n",
    "    'Where is Deutschland?',\n",
    "    'How is Huawei Mate 60 Pro?'\n",
    "] * 4\n",
    "\n",
    "prompt_len = 10\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "inputs = tokenizer(prompts, padding=\"max_length\", max_length=prompt_len, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(\n",
    "    inputs.input_ids, \n",
    "    max_length=30 + prompt_len,\n",
    "    # num_beams=2,\n",
    "    # num_beam_groups=2,\n",
    "    # diversity_penalty=0.1,\n",
    "    do_sample=True,\n",
    ")\n",
    "\n",
    "output_texts = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "for output_text in output_texts:\n",
    "    logging.info(output_text)\n",
    "    logging.info('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LayerWeightHook at 0x7f31836cac20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_module._hf_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load / offload\n",
    "#     module object, .dat file path\n",
    "#     layer: pre / post forward hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def compute_activation_assignment(num_layers, offload_config: Policy):\n",
    "#     logging.debug(f\"<compute_activation_assignment> enter\")\n",
    "#     gpu_batch_limit = int(offload_config.num_gpu_batches * offload_config.act_gpu_percent)\n",
    "#     cpu_batch_limit = int(offload_config.num_gpu_batches * (offload_config.act_gpu_percent + offload_config.act_cpu_percent))\n",
    "#     logging.debug(f\"<compute_activation_assignment> gpu_batch_limit: {gpu_batch_limit}, cpu_batch_limit: {cpu_batch_limit}\")\n",
    "    \n",
    "#     act_assign_dict = {}\n",
    "#     for l in range(num_layers):\n",
    "#         for i in range(offload_config.num_gpu_batches):\n",
    "#             act_key = f\"layer.{l}_index.{i}\"\n",
    "#             if i < gpu_batch_limit:\n",
    "#                 device = 'cuda'\n",
    "#             elif i < cpu_batch_limit:\n",
    "#                 device = 'cpu'\n",
    "#             else:\n",
    "#                 device = 'disk'\n",
    "#             act_assign_dict[act_key]= {'assigned_device': device}\n",
    "#     return act_assign_dict\n",
    "\n",
    "\n",
    "# def compute_kv_cache_assignment(num_layers, offload_config: OffloadConfig):\n",
    "#     logging.debug(f\"<compute_kv_cache_assignment> enter\")\n",
    "#     gpu_batch_limit = int(offload_config.num_gpu_batches * offload_config.cache_gpu_percent)\n",
    "#     cpu_batch_limit = int(offload_config.num_gpu_batches * (offload_config.cache_gpu_percent + offload_config.cache_cpu_percent))\n",
    "#     logging.debug(f\"<compute_kv_cache_assignment> gpu_batch_limit: {gpu_batch_limit}, cpu_batch_limit: {cpu_batch_limit}\")\n",
    "    \n",
    "#     act_assign_dict = {}\n",
    "#     for l in range(num_layers):\n",
    "#         for i in range(offload_config.num_gpu_batches):\n",
    "#             key_cache_key = f\"key_layer.{l}_index.{i}\"\n",
    "#             value_cache_key = f\"key_layer.{l}_index.{i}\"\n",
    "#             if i < gpu_batch_limit:\n",
    "#                 device = 'cuda'\n",
    "#             elif i < cpu_batch_limit:\n",
    "#                 device = 'cpu'\n",
    "#             else:\n",
    "#                 device = 'disk'\n",
    "#             act_assign_dict[key_cache_key] = {'assigned_device': device}\n",
    "#             act_assign_dict[value_cache_key] = {'assigned_device': device}\n",
    "#     return act_assign_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
