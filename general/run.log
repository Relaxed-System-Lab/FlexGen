2023-10-08 09:09:05,771 [instantiator.py:21 in <module>] INFO - Created a temporary directory at /tmp/tmpc3twzic2
2023-10-08 09:09:05,772 [instantiator.py:76 in _write] INFO - Writing /tmp/tmpc3twzic2/_remote_module_non_scriptable.py
2023-10-08 09:09:06,272 [connectionpool.py:1003 in _new_conn] DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2023-10-08 09:09:06,395 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1" 200 0
2023-10-08 09:09:08,095 [tpu_cluster_resolver.py:32 in <module>] DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2023-10-08 09:09:08,448 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5
2023-10-08 09:09:08,448 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7
2023-10-08 09:09:08,448 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5
2023-10-08 09:09:08,448 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7
2023-10-08 09:09:09,553 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1" 200 0
2023-10-08 09:09:09,645 [model_loader.py:159 in check_disk] INFO - [], ['lm_head.weight']
2023-10-08 09:09:09,688 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1" 200 0
2023-10-08 09:09:09,778 [model_loader.py:159 in check_disk] INFO - [], ['lm_head.weight']
2023-10-08 09:09:09,778 [model_loader.py:182 in download] INFO - The whole model has been downloaded an processed to offload_folder: 'offload_dir/facebook.opt-125m'
2023-10-08 09:09:09,785 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.embed_tokens, [0. 0. 1.], size_todo: 86630400
2023-10-08 09:09:09,786 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.embed_positions, [0. 0. 1.], size_todo: 85056000
2023-10-08 09:09:09,786 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.final_layer_norm, [0.00000000e+00 1.91116887e-05 9.99980888e-01], size_todo: 85054464
2023-10-08 09:09:09,787 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.0, [0.         0.05002193 0.94997807], size_todo: 77966592
2023-10-08 09:09:09,788 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.1, [0.         0.08698539 0.91301461], size_todo: 70878720
2023-10-08 09:09:09,789 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.2, [0.         0.11542163 0.88457837], size_todo: 63790848
2023-10-08 09:09:09,790 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.3, [0.         0.13797624 0.86202376], size_todo: 56702976
2023-10-08 09:09:09,791 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.4, [0.       0.156303 0.843697], size_todo: 49615104
2023-10-08 09:09:09,791 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.5, [0.       0.200013 0.799987], size_todo: 42527232
2023-10-08 09:09:09,792 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.6, [0.         0.21055017 0.78944983], size_todo: 35439360
2023-10-08 09:09:09,793 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.7, [0.         0.24389645 0.75610355], size_todo: 28351488
2023-10-08 09:09:09,794 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.8, [0.         0.25000554 0.74999446], size_todo: 21263616
2023-10-08 09:09:09,795 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.9, [0.         0.27657765 0.72342235], size_todo: 14175744
2023-10-08 09:09:09,796 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.10, [0.         0.27999324 0.72000676], size_todo: 7087872
2023-10-08 09:09:09,797 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.11, [0.         0.30186053 0.69813947], size_todo: 0
2023-10-08 09:09:09,797 [model_loader.py:138 in get_policy_weight_map] DEBUG - lm_head, [0.         0.30186053 0.69813947], size_todo: 0
2023-10-08 09:09:09,797 [model_loader.py:142 in get_policy_weight_map] INFO - device_map is prepared!
2023-10-08 09:09:09,799 [model_loader.py:148 in get_policy_weight_map] INFO - CausalLM facebook/opt-125m is to be loaded on: 
GPU Mem 0.00 GiB (0.00%), CPU Mem 0.07 GiB (30.19%), Disk Mem 0.16 Gib (69.81%)
2023-10-08 09:09:09,800 [model_loader.py:241 in init_all_weights] DEBUG - init all weights...
2023-10-08 09:09:09,828 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.embed_tokens to test forward
2023-10-08 09:09:09,828 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.embed_positions to test forward
2023-10-08 09:09:09,828 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.final_layer_norm to test forward
2023-10-08 09:09:09,828 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.layers.0 to test forward
2023-10-08 09:09:09,828 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.layers.1 to test forward
2023-10-08 09:09:09,828 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.layers.2 to test forward
2023-10-08 09:09:09,829 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.layers.3 to test forward
2023-10-08 09:09:09,829 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.layers.4 to test forward
2023-10-08 09:09:09,829 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.layers.5 to test forward
2023-10-08 09:09:09,829 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.layers.6 to test forward
2023-10-08 09:09:09,829 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.layers.7 to test forward
2023-10-08 09:09:09,829 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.layers.8 to test forward
2023-10-08 09:09:09,829 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.layers.9 to test forward
2023-10-08 09:09:09,829 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.layers.10 to test forward
2023-10-08 09:09:09,830 [layer_forward.py:47 in to_test_forward] DEBUG - model.decoder.layers.11 to test forward
2023-10-08 09:09:09,830 [layer_forward.py:47 in to_test_forward] DEBUG - lm_head to test forward
2023-10-08 09:09:09,943 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2023-10-08 09:09:10,164 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:10,165 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:10,166 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:10,167 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:10,167 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:10,182 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:10,184 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:10,192 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:10,194 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:10,201 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:10,203 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:10,211 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:10,213 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:10,220 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:10,222 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:10,230 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:10,231 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:10,239 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:10,240 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:10,248 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:10,250 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:10,258 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:10,259 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:10,267 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:10,268 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:10,277 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:10,279 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:10,286 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:10,287 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:10,288 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:10,288 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:10,302 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:10,308 [generate_test.py:40 in test_hf_gen] INFO - 0.
2023-10-08 09:09:10,308 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-08 09:09:10,316 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.embed_tokens from test to old.
2023-10-08 09:09:10,317 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.embed_positions from test to old.
2023-10-08 09:09:10,317 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.final_layer_norm from test to old.
2023-10-08 09:09:10,317 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.layers.0 from test to old.
2023-10-08 09:09:10,317 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.layers.1 from test to old.
2023-10-08 09:09:10,317 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.layers.2 from test to old.
2023-10-08 09:09:10,317 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.layers.3 from test to old.
2023-10-08 09:09:10,317 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.layers.4 from test to old.
2023-10-08 09:09:10,318 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.layers.5 from test to old.
2023-10-08 09:09:10,318 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.layers.6 from test to old.
2023-10-08 09:09:10,318 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.layers.7 from test to old.
2023-10-08 09:09:10,318 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.layers.8 from test to old.
2023-10-08 09:09:10,318 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.layers.9 from test to old.
2023-10-08 09:09:10,318 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.layers.10 from test to old.
2023-10-08 09:09:10,318 [layer_forward.py:27 in reset_forward] DEBUG - model.decoder.layers.11 from test to old.
2023-10-08 09:09:10,318 [layer_forward.py:27 in reset_forward] DEBUG - lm_head from test to old.
2023-10-08 09:09:10,319 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.embed_tokens to flexgen forward
2023-10-08 09:09:10,319 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.embed_positions to flexgen forward
2023-10-08 09:09:10,319 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.layers.0 to flexgen forward
2023-10-08 09:09:10,319 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.layers.1 to flexgen forward
2023-10-08 09:09:10,319 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.layers.2 to flexgen forward
2023-10-08 09:09:10,319 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.layers.3 to flexgen forward
2023-10-08 09:09:10,319 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.layers.4 to flexgen forward
2023-10-08 09:09:10,320 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.layers.5 to flexgen forward
2023-10-08 09:09:10,320 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.layers.6 to flexgen forward
2023-10-08 09:09:10,320 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.layers.7 to flexgen forward
2023-10-08 09:09:10,320 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.layers.8 to flexgen forward
2023-10-08 09:09:10,320 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.layers.9 to flexgen forward
2023-10-08 09:09:10,320 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.layers.10 to flexgen forward
2023-10-08 09:09:10,320 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.layers.11 to flexgen forward
2023-10-08 09:09:10,320 [layer_forward.py:118 in to_flexgen_forward] DEBUG - model.decoder.final_layer_norm to flexgen forward
2023-10-08 09:09:10,321 [layer_forward.py:118 in to_flexgen_forward] DEBUG - lm_head to flexgen forward
2023-10-08 09:09:10,366 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2023-10-08 09:09:10,539 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:10,540 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:10,540 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9]),)
2023-10-08 09:09:10,540 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:10,540 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9]),)
2023-10-08 09:09:10,540 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:10,540 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:10,541 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:10,541 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:10,541 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:10,541 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 9, 768])
2023-10-08 09:09:10,542 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 9, 768])
2023-10-08 09:09:10,542 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:10,542 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:10,543 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:10,547 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9]), 0)
2023-10-08 09:09:10,547 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:10,547 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9]), 0)
2023-10-08 09:09:10,547 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:10,547 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:10,547 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:10,548 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:10,548 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:10,548 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 9, 768])
2023-10-08 09:09:10,548 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 9, 768])
2023-10-08 09:09:10,549 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:10,549 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:10,552 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:10,556 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,556 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,556 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,556 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,556 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:10,561 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:10,564 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:10,567 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:10,570 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-08 09:09:10,570 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-08 09:09:10,570 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:10,572 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:10,576 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:10,579 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,580 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,580 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,580 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,580 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:10,584 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:10,587 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:10,590 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:10,593 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-08 09:09:10,593 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-08 09:09:10,594 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:10,595 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:10,599 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:10,602 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,603 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,603 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,603 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,603 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:10,607 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:10,610 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:10,613 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:10,616 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-08 09:09:10,616 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-08 09:09:10,617 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:10,618 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:10,622 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:10,626 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,626 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,626 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,626 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,626 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:10,630 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:10,633 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:10,635 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:10,638 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-08 09:09:10,639 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-08 09:09:10,639 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:10,641 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:10,644 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:10,648 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,648 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,648 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,649 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,649 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:10,653 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:10,656 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:10,660 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:10,664 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-08 09:09:10,664 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-08 09:09:10,664 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:10,666 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:10,670 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:10,673 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,674 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,674 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,674 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,674 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:10,678 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:10,681 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:10,684 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:10,687 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-08 09:09:10,688 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-08 09:09:10,688 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:10,689 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:10,693 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:10,697 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,697 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,697 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,697 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,697 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:10,701 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:10,705 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:10,709 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:10,711 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-08 09:09:10,712 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-08 09:09:10,712 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:10,714 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:10,717 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:10,721 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,721 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,721 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,721 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,721 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:10,726 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:10,728 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:10,731 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:10,733 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-08 09:09:10,734 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-08 09:09:10,734 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:10,735 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:10,739 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:10,743 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,743 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,743 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,743 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,743 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:10,747 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:10,750 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:10,753 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:10,755 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-08 09:09:10,756 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-08 09:09:10,756 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:10,757 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:10,761 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:10,765 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,765 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,765 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,765 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,765 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:10,769 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:10,772 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:10,775 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:10,779 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-08 09:09:10,779 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-08 09:09:10,779 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:10,781 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:10,784 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:10,788 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,788 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,788 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,789 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,789 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:10,792 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:10,795 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:10,798 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:10,800 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-08 09:09:10,801 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-08 09:09:10,801 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:10,803 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:10,806 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:10,807 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,807 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,807 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,808 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,808 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:10,811 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:10,814 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:10,817 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:10,820 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-08 09:09:10,820 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-08 09:09:10,820 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:10,822 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:10,822 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:10,823 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,823 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:10,823 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,823 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:10,823 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:10,824 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:10,824 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:10,824 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:10,824 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 9, 768])
2023-10-08 09:09:10,825 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 9, 768])
2023-10-08 09:09:10,825 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:10,825 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:10,826 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:10,826 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-08 09:09:10,826 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:10,826 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-08 09:09:10,826 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:10,827 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:10,837 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:10,847 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:10,856 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:10,870 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 9, 50272])
2023-10-08 09:09:10,876 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 9, 50272])
2023-10-08 09:09:10,876 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:10,884 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:10,885 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:10,886 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:10,886 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:10,887 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:10,887 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:10,887 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:10,888 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:10,888 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:10,889 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:10,890 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:10,891 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:10,891 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:10,892 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:10,893 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:10,899 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 10]), 9)
2023-10-08 09:09:10,900 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:10,900 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 10]), 9)
2023-10-08 09:09:10,900 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:10,901 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:10,901 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:10,902 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:10,902 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:10,903 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:10,903 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:10,903 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:10,904 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:10,907 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:10,911 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:10,911 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,911 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:10,911 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,911 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:10,917 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:10,919 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:10,921 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:10,923 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-08 09:09:10,923 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-08 09:09:10,923 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:10,925 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:10,929 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:10,932 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:10,933 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,933 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:10,933 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,933 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:10,937 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:10,940 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:10,941 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:10,944 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-08 09:09:10,944 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-08 09:09:10,944 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:10,946 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:10,950 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:10,954 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:10,954 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,954 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:10,954 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,954 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:10,959 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:10,961 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:10,964 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:10,967 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-08 09:09:10,967 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-08 09:09:10,967 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:10,970 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:10,973 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:10,978 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:10,979 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,979 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:10,979 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:10,979 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:10,984 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:10,987 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:10,989 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:10,991 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-08 09:09:10,992 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-08 09:09:10,992 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:10,994 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:10,998 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:11,002 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,002 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,003 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,003 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,003 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:11,007 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:11,009 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:11,011 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:11,014 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-08 09:09:11,014 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-08 09:09:11,014 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:11,017 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:11,020 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:11,024 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,024 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,024 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,025 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,025 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:11,030 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:11,033 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:11,035 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:11,037 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-08 09:09:11,038 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-08 09:09:11,038 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:11,039 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:11,043 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:11,047 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,047 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,048 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,048 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,048 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:11,051 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:11,054 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:11,056 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:11,059 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-08 09:09:11,059 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-08 09:09:11,059 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:11,061 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:11,065 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:11,069 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,069 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,070 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,070 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,070 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:11,074 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:11,076 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:11,079 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:11,081 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-08 09:09:11,082 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-08 09:09:11,082 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:11,084 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:11,088 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:11,092 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,092 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,092 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,092 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,093 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:11,097 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:11,099 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:11,101 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:11,104 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-08 09:09:11,104 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-08 09:09:11,104 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:11,107 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:11,110 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:11,114 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,115 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,115 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,115 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,115 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:11,119 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:11,122 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:11,124 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:11,127 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-08 09:09:11,127 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-08 09:09:11,128 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:11,129 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:11,133 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:11,137 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,137 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,137 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,137 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,138 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:11,141 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:11,143 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:11,146 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:11,148 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-08 09:09:11,149 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-08 09:09:11,149 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:11,151 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:11,155 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:11,155 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,155 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,156 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,156 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,156 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:11,159 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:11,162 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:11,164 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:11,166 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-08 09:09:11,167 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-08 09:09:11,167 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:11,169 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:11,170 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:11,170 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,170 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:11,170 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,171 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:11,171 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:11,171 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:11,171 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:11,172 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:11,172 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:11,172 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:11,172 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:11,173 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:11,173 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:11,174 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,174 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:11,175 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,175 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:11,175 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:11,186 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:11,194 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:11,203 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:11,212 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:11,213 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:11,213 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:11,220 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:11,221 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:11,221 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:11,221 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:11,221 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:11,222 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:11,222 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:11,222 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:11,222 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:11,223 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:11,223 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:11,223 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:11,223 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:11,224 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:11,224 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:11,228 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 11]), 10)
2023-10-08 09:09:11,228 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:11,229 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 11]), 10)
2023-10-08 09:09:11,229 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:11,229 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:11,229 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:11,230 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:11,230 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:11,230 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:11,231 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:11,231 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:11,231 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:11,235 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:11,239 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,239 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,239 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,239 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,240 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:11,244 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:11,246 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:11,248 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:11,251 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-08 09:09:11,251 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-08 09:09:11,252 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:11,254 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:11,257 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:11,261 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,262 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,262 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,262 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,262 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:11,266 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:11,268 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:11,270 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:11,274 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-08 09:09:11,274 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-08 09:09:11,274 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:11,276 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:11,280 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:11,284 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,284 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,284 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,285 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,285 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:11,289 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:11,291 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:11,294 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:11,296 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-08 09:09:11,296 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-08 09:09:11,296 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:11,299 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:11,302 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:11,306 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,306 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,307 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,307 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,307 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:11,311 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:11,313 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:11,315 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:11,318 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-08 09:09:11,318 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-08 09:09:11,318 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:11,320 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:11,324 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:11,328 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,328 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,328 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,329 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,329 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:11,334 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:11,336 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:11,338 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:11,341 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-08 09:09:11,341 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-08 09:09:11,341 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:11,343 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:11,347 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:11,351 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,351 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,351 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,352 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,352 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:11,355 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:11,358 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:11,360 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:11,362 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-08 09:09:11,363 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-08 09:09:11,363 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:11,365 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:11,368 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:11,372 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,372 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,373 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,373 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,373 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:11,377 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:11,380 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:11,382 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:11,384 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-08 09:09:11,385 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-08 09:09:11,385 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:11,387 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:11,390 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:11,394 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,394 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,395 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,395 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,395 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:11,398 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:11,401 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:11,404 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:11,406 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-08 09:09:11,406 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-08 09:09:11,407 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:11,408 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:11,412 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:11,416 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,416 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,416 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,417 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,417 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:11,421 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:11,424 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:11,426 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:11,428 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-08 09:09:11,429 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-08 09:09:11,429 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:11,432 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:11,435 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:11,439 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,439 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,439 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,440 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,440 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:11,449 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:11,451 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:11,453 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:11,456 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-08 09:09:11,456 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-08 09:09:11,456 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:11,458 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:11,462 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:11,466 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,466 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,466 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,466 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,467 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:11,470 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:11,473 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:11,475 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:11,478 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-08 09:09:11,478 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-08 09:09:11,478 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:11,480 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:11,484 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:11,485 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,485 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,485 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,485 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,485 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:11,489 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:11,491 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:11,494 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:11,497 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-08 09:09:11,497 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-08 09:09:11,497 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:11,499 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:11,500 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:11,500 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,500 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:11,501 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,501 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:11,501 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:11,501 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:11,501 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:11,502 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:11,502 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:11,502 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:11,503 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:11,503 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:11,504 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:11,504 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,504 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:11,504 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,505 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:11,505 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:11,516 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:11,527 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:11,536 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:11,546 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:11,547 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:11,547 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:11,553 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:11,554 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:11,554 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:11,555 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:11,555 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:11,555 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:11,556 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:11,556 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:11,556 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:11,557 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:11,557 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:11,558 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:11,558 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:11,558 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:11,559 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:11,563 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 12]), 11)
2023-10-08 09:09:11,563 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:11,563 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 12]), 11)
2023-10-08 09:09:11,564 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:11,564 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:11,564 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:11,565 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:11,565 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:11,565 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:11,566 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:11,566 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:11,566 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:11,570 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:11,574 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,574 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,575 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,575 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,575 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:11,580 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:11,583 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:11,586 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:11,588 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-08 09:09:11,588 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-08 09:09:11,589 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:11,591 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:11,595 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:11,599 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,599 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,599 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,599 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,600 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:11,604 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:11,606 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:11,609 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:11,611 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-08 09:09:11,612 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-08 09:09:11,612 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:11,614 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:11,618 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:11,622 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,622 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,622 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,622 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,622 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:11,626 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:11,628 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:11,630 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:11,632 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-08 09:09:11,632 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-08 09:09:11,633 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:11,634 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:11,638 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:11,642 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,642 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,642 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,642 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,642 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:11,650 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:11,653 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:11,656 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:11,658 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-08 09:09:11,659 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-08 09:09:11,659 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:11,662 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:11,668 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:11,673 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,674 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,674 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,674 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,674 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:11,678 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:11,681 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:11,683 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:11,685 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-08 09:09:11,686 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-08 09:09:11,686 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:11,689 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:11,694 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:11,699 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,699 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,699 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,699 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,699 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:11,703 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:11,706 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:11,708 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:11,710 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-08 09:09:11,710 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-08 09:09:11,710 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:11,712 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:11,715 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:11,719 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,719 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,719 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,720 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,720 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:11,723 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:11,725 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:11,727 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:11,729 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-08 09:09:11,729 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-08 09:09:11,729 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:11,731 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:11,734 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:11,738 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,738 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,739 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,739 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,739 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:11,742 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:11,744 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:11,746 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:11,748 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-08 09:09:11,748 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-08 09:09:11,748 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:11,750 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:11,753 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:11,757 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,757 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,758 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,758 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,758 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:11,761 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:11,763 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:11,765 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:11,767 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-08 09:09:11,767 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-08 09:09:11,768 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:11,769 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:11,773 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:11,777 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,777 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,777 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,777 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,777 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:11,780 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:11,782 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:11,798 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:11,801 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-08 09:09:11,801 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-08 09:09:11,802 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:11,803 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:11,807 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:11,811 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,811 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,811 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,811 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,812 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:11,815 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:11,817 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:11,818 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:11,820 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-08 09:09:11,820 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-08 09:09:11,821 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:11,822 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:11,826 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:11,826 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,826 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,827 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,827 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,827 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:11,830 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:11,832 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:11,834 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:11,835 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-08 09:09:11,836 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-08 09:09:11,836 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:11,837 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:11,838 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:11,838 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,838 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:11,839 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,839 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:11,839 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:11,839 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:11,839 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:11,839 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:11,840 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:11,840 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:11,840 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:11,840 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:11,841 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:11,841 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,841 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:11,841 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,842 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:11,842 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:11,855 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:11,862 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:11,870 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:11,877 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:11,878 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:11,878 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:11,883 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:11,883 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:11,884 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:11,884 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:11,885 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:11,885 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:11,885 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:11,885 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:11,885 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:11,886 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:11,886 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:11,886 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:11,886 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:11,887 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:11,887 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:11,891 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 13]), 12)
2023-10-08 09:09:11,891 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:11,891 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 13]), 12)
2023-10-08 09:09:11,891 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:11,891 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:11,892 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:11,892 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:11,892 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:11,893 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:11,893 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:11,893 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:11,893 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:11,897 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:11,901 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,901 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,901 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,901 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,901 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:11,905 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:11,907 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:11,908 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:11,910 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-08 09:09:11,910 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-08 09:09:11,911 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:11,912 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:11,916 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:11,920 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,920 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,920 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,920 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,921 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:11,924 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:11,926 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:11,928 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:11,930 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-08 09:09:11,930 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-08 09:09:11,930 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:11,932 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:11,936 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:11,940 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,940 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,940 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,940 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,940 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:11,944 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:11,946 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:11,948 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:11,950 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-08 09:09:11,950 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-08 09:09:11,951 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:11,952 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:11,956 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:11,960 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,960 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,960 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,960 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,960 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:11,964 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:11,966 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:11,968 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:11,970 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-08 09:09:11,970 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-08 09:09:11,970 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:11,972 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:11,976 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:11,980 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:11,980 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,980 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:11,980 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:11,981 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:11,984 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:11,986 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:11,988 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:11,990 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-08 09:09:11,990 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-08 09:09:11,990 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:11,992 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:11,996 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:11,999 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,000 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,000 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,000 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,000 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:12,003 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:12,005 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:12,007 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:12,009 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-08 09:09:12,009 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-08 09:09:12,009 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:12,011 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:12,014 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:12,019 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,019 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,019 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,019 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,019 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:12,022 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:12,024 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:12,026 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:12,028 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-08 09:09:12,028 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-08 09:09:12,028 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:12,030 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:12,034 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:12,038 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,038 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,038 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,038 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,038 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:12,041 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:12,043 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:12,045 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:12,046 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-08 09:09:12,047 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-08 09:09:12,047 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:12,048 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:12,052 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:12,056 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,056 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,056 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,057 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,057 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:12,060 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:12,062 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:12,063 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:12,065 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-08 09:09:12,065 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-08 09:09:12,065 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:12,067 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:12,071 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:12,074 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,075 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,075 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,075 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,075 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:12,078 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:12,080 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:12,082 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:12,084 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-08 09:09:12,084 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-08 09:09:12,084 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:12,085 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:12,089 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:12,093 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,093 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,094 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,094 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,094 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:12,097 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:12,099 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:12,101 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:12,102 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-08 09:09:12,103 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-08 09:09:12,103 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:12,104 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:12,108 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:12,109 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,109 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,109 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,109 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,109 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:12,112 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:12,114 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:12,116 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:12,118 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-08 09:09:12,118 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-08 09:09:12,118 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:12,120 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:12,120 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:12,121 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,121 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,121 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,121 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,121 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:12,121 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:12,122 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:12,122 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:12,122 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:12,122 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:12,122 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:12,123 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:12,123 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:12,124 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,124 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,124 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,124 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,124 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:12,133 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:12,140 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:12,148 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:12,155 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:12,155 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:12,156 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:12,160 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:12,161 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:12,162 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:12,162 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,162 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:12,162 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,163 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:12,163 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:12,163 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:12,164 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:12,164 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:12,164 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:12,164 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:12,165 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:12,165 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:12,169 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 14]), 13)
2023-10-08 09:09:12,170 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,170 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 14]), 13)
2023-10-08 09:09:12,170 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,170 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:12,170 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:12,171 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:12,171 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:12,171 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:12,171 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:12,172 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:12,172 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:12,175 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:12,179 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,179 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,180 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,180 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,180 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:12,183 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:12,185 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:12,187 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:12,189 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-08 09:09:12,189 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-08 09:09:12,189 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:12,191 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:12,195 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:12,198 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,199 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,199 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,199 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,199 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:12,202 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:12,205 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:12,207 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:12,209 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-08 09:09:12,210 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-08 09:09:12,210 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:12,212 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:12,215 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:12,219 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,219 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,220 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,220 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,220 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:12,224 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:12,226 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:12,228 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:12,229 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-08 09:09:12,230 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-08 09:09:12,230 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:12,232 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:12,235 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:12,239 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,239 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,240 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,240 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,240 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:12,243 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:12,247 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:12,249 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:12,251 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-08 09:09:12,251 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-08 09:09:12,251 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:12,253 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:12,257 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:12,261 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,261 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,261 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,261 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,261 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:12,264 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:12,266 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:12,269 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:12,270 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-08 09:09:12,271 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-08 09:09:12,271 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:12,273 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:12,276 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:12,280 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,281 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,281 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,281 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,281 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:12,284 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:12,288 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:12,289 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:12,291 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-08 09:09:12,292 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-08 09:09:12,292 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:12,293 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:12,297 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:12,301 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,301 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,301 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,301 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,302 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:12,304 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:12,306 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:12,309 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:12,311 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-08 09:09:12,311 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-08 09:09:12,311 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:12,313 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:12,316 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:12,320 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,320 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,321 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,321 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,321 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:12,324 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:12,326 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:12,329 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:12,330 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-08 09:09:12,331 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-08 09:09:12,331 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:12,332 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:12,336 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:12,340 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,341 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,341 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,341 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,341 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:12,345 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:12,347 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:12,348 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:12,350 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-08 09:09:12,351 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-08 09:09:12,351 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:12,352 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:12,356 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:12,360 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,360 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,360 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,360 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,361 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:12,363 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:12,365 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:12,368 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:12,369 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-08 09:09:12,370 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-08 09:09:12,370 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:12,371 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:12,375 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:12,379 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,379 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,379 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,380 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,380 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:12,386 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:12,388 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:12,390 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:12,392 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-08 09:09:12,392 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-08 09:09:12,393 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:12,394 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:12,398 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:12,399 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,399 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,399 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,399 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,399 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:12,402 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:12,404 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:12,406 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:12,408 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-08 09:09:12,408 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-08 09:09:12,409 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:12,410 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:12,411 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:12,411 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,411 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,411 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,411 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,412 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:12,412 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:12,412 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:12,412 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:12,412 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:12,413 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:12,413 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:12,413 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:12,413 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:12,414 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,414 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,414 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,414 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,414 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:12,423 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:12,430 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:12,437 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:12,444 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:12,445 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:12,445 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:12,449 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:12,450 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:12,450 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:12,450 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,451 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:12,451 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,451 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:12,451 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:12,451 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:12,451 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:12,452 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:12,452 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:12,452 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:12,452 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:12,453 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:12,457 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 15]), 14)
2023-10-08 09:09:12,457 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,457 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 15]), 14)
2023-10-08 09:09:12,457 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,457 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:12,458 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:12,458 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:12,458 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:12,458 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:12,459 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:12,459 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:12,459 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:12,463 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:12,466 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,467 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,467 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,467 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,467 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:12,470 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:12,472 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:12,474 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:12,476 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-08 09:09:12,476 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-08 09:09:12,476 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:12,478 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:12,482 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:12,485 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,486 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,486 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,486 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,486 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:12,490 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:12,491 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:12,494 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:12,497 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-08 09:09:12,497 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-08 09:09:12,497 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:12,499 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:12,503 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:12,506 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,506 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,507 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,507 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,507 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:12,510 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:12,512 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:12,514 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:12,516 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-08 09:09:12,516 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-08 09:09:12,516 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:12,518 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:12,522 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:12,525 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,526 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,526 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,526 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,526 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:12,540 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:12,542 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:12,544 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:12,546 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-08 09:09:12,546 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-08 09:09:12,547 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:12,548 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:12,552 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:12,556 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,556 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,556 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,556 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,557 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:12,560 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:12,562 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:12,563 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:12,565 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-08 09:09:12,565 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-08 09:09:12,565 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:12,567 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:12,570 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:12,574 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,574 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,574 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,575 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,575 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:12,579 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:12,581 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:12,583 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:12,584 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-08 09:09:12,585 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-08 09:09:12,585 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:12,586 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:12,590 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:12,594 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,594 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,595 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,595 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,595 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:12,598 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:12,600 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:12,602 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:12,604 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-08 09:09:12,604 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-08 09:09:12,604 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:12,606 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:12,609 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:12,614 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,614 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,614 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,614 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,614 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:12,617 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:12,619 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:12,622 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:12,623 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-08 09:09:12,624 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-08 09:09:12,624 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:12,625 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:12,629 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:12,634 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,634 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,634 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,634 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,634 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:12,637 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:12,639 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:12,641 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:12,642 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-08 09:09:12,643 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-08 09:09:12,643 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:12,645 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:12,649 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:12,653 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,653 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,653 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,653 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,653 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:12,657 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:12,660 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:12,662 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:12,664 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-08 09:09:12,665 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-08 09:09:12,665 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:12,667 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:12,672 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:12,676 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,677 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,677 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,677 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,677 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:12,680 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:12,682 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:12,684 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:12,686 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-08 09:09:12,686 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-08 09:09:12,686 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:12,688 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:12,692 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:12,692 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,693 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,693 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,693 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,693 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:12,696 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:12,698 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:12,700 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:12,701 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-08 09:09:12,702 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-08 09:09:12,702 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:12,703 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:12,704 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:12,704 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,704 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,704 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,704 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,705 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:12,705 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:12,705 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:12,705 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:12,705 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:12,706 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:12,706 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:12,706 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:12,707 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:12,707 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,707 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,707 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,707 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,707 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:12,716 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:12,723 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:12,731 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:12,738 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:12,739 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:12,739 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:12,743 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:12,744 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:12,744 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:12,745 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,745 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:12,745 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,745 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:12,745 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:12,746 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:12,746 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:12,746 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:12,746 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:12,746 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:12,747 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:12,747 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:12,751 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 16]), 15)
2023-10-08 09:09:12,751 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,751 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 16]), 15)
2023-10-08 09:09:12,751 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,751 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:12,752 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:12,752 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:12,752 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:12,753 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:12,753 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:12,753 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:12,753 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:12,757 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:12,763 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,764 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,764 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,764 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,764 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:12,768 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:12,771 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:12,773 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:12,775 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-08 09:09:12,776 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-08 09:09:12,776 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:12,777 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:12,781 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:12,785 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,785 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,785 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,786 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,786 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:12,789 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:12,791 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:12,792 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:12,794 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-08 09:09:12,795 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-08 09:09:12,795 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:12,796 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:12,800 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:12,804 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,804 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,804 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,805 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,805 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:12,808 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:12,809 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:12,812 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:12,813 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-08 09:09:12,814 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-08 09:09:12,814 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:12,816 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:12,820 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:12,823 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,823 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,824 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,824 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,824 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:12,828 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:12,830 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:12,832 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:12,834 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-08 09:09:12,834 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-08 09:09:12,834 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:12,836 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:12,840 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:12,844 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,844 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,844 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,844 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,844 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:12,847 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:12,849 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:12,851 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:12,853 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-08 09:09:12,854 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-08 09:09:12,854 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:12,855 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:12,859 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:12,863 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,863 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,863 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,863 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,863 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:12,867 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:12,869 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:12,870 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:12,872 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-08 09:09:12,872 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-08 09:09:12,872 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:12,874 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:12,877 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:12,882 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,882 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,882 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,882 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,882 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:12,885 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:12,887 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:12,889 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:12,891 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-08 09:09:12,891 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-08 09:09:12,892 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:12,893 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:12,897 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:12,901 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,901 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,902 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,902 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,902 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:12,905 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:12,907 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:12,909 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:12,911 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-08 09:09:12,911 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-08 09:09:12,911 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:12,913 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:12,916 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:12,920 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,920 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,920 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,921 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,921 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:12,924 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:12,926 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:12,928 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:12,930 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-08 09:09:12,931 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-08 09:09:12,931 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:12,932 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:12,936 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:12,939 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,940 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,940 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,940 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,940 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:12,943 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:12,945 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:12,947 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:12,949 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-08 09:09:12,949 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-08 09:09:12,950 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:12,951 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:12,954 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:12,958 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,959 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,959 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,959 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,959 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:12,963 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:12,965 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:12,966 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:12,968 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-08 09:09:12,968 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-08 09:09:12,968 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:12,970 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:12,973 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:12,974 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,974 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,974 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,975 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:12,975 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:12,981 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:12,982 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:12,984 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:12,985 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-08 09:09:12,986 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-08 09:09:12,986 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:12,987 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:12,988 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:12,989 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,989 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,989 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,989 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,989 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:12,990 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:12,990 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:12,990 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:12,990 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:12,991 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:12,991 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:12,991 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:12,992 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:12,992 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:12,992 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:12,992 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:12,992 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:12,993 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:13,003 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:13,012 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:13,021 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:13,029 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:13,030 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:13,030 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:13,036 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:13,037 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:13,038 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:13,038 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:13,038 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:13,039 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:13,039 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:13,039 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:13,040 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:13,040 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:13,040 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:13,041 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:13,041 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:13,042 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:13,042 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:13,046 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 17]), 16)
2023-10-08 09:09:13,047 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:13,047 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 17]), 16)
2023-10-08 09:09:13,047 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:13,047 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:13,048 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:13,048 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:13,049 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:13,049 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:13,050 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:13,050 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:13,050 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:13,054 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:13,058 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,058 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,059 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,059 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,059 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:13,073 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:13,076 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:13,078 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:13,080 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-08 09:09:13,080 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-08 09:09:13,081 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:13,082 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:13,086 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:13,090 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,090 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,091 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,091 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,091 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:13,095 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:13,097 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:13,099 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:13,101 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-08 09:09:13,101 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-08 09:09:13,101 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:13,103 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:13,107 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:13,111 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,111 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,111 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,111 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,111 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:13,114 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:13,116 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:13,119 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:13,121 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-08 09:09:13,122 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-08 09:09:13,122 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:13,124 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:13,127 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:13,131 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,131 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,131 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,132 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,132 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:13,136 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:13,138 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:13,140 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:13,142 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-08 09:09:13,142 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-08 09:09:13,142 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:13,144 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:13,148 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:13,152 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,152 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,152 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,152 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,152 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:13,155 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:13,157 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:13,160 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:13,161 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-08 09:09:13,162 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-08 09:09:13,162 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:13,164 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:13,167 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:13,171 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,171 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,171 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,171 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,172 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:13,175 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:13,177 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:13,179 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:13,181 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-08 09:09:13,181 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-08 09:09:13,181 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:13,183 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:13,187 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:13,191 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,191 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,191 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,191 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,191 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:13,195 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:13,197 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:13,199 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:13,202 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-08 09:09:13,202 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-08 09:09:13,203 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:13,204 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:13,208 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:13,212 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,212 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,212 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,212 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,213 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:13,216 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:13,218 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:13,219 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:13,221 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-08 09:09:13,221 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-08 09:09:13,221 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:13,223 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:13,226 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:13,231 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,231 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,231 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,231 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,231 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:13,234 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:13,236 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:13,238 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:13,240 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-08 09:09:13,240 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-08 09:09:13,240 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:13,242 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:13,245 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:13,249 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,250 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,250 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,250 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,250 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:13,272 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:13,282 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:13,284 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:13,286 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-08 09:09:13,286 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-08 09:09:13,287 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:13,288 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:13,292 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:13,296 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,296 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,297 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,297 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,297 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:13,300 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:13,302 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:13,304 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:13,306 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-08 09:09:13,307 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-08 09:09:13,307 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:13,308 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:13,312 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:13,313 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,313 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,313 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,313 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,314 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:13,316 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:13,318 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:13,321 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:13,322 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-08 09:09:13,323 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-08 09:09:13,323 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:13,324 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:13,325 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:13,326 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,326 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:13,326 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,326 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:13,326 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:13,328 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:13,328 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:13,329 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:13,329 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:13,329 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:13,330 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:13,330 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:13,331 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:13,332 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,332 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:13,332 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,332 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:13,332 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:13,342 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:13,349 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:13,357 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:13,365 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:13,366 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:13,366 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:13,371 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:13,371 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:13,372 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:13,372 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:13,372 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:13,373 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:13,373 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:13,373 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:13,373 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:13,373 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:13,374 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:13,374 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:13,374 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:13,374 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:13,375 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:13,379 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 18]), 17)
2023-10-08 09:09:13,379 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:13,379 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 18]), 17)
2023-10-08 09:09:13,379 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:13,379 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:13,380 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:13,380 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:13,380 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:13,381 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:13,381 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:13,381 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:13,381 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:13,385 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:13,389 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,389 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,390 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,390 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,390 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:13,396 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:13,398 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:13,400 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:13,402 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-08 09:09:13,402 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-08 09:09:13,402 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:13,404 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:13,408 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:13,412 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,412 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,412 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,413 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,413 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:13,417 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:13,419 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:13,421 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:13,423 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-08 09:09:13,423 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-08 09:09:13,424 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:13,425 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:13,429 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:13,433 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,433 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,433 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,434 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,434 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:13,437 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:13,439 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:13,441 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:13,443 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-08 09:09:13,444 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-08 09:09:13,444 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:13,446 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:13,449 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:13,453 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,454 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,454 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,454 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,454 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:13,457 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:13,459 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:13,461 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:13,463 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-08 09:09:13,463 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-08 09:09:13,463 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:13,465 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:13,469 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:13,473 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,473 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,473 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,473 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,473 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:13,477 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:13,479 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:13,480 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:13,482 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-08 09:09:13,483 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-08 09:09:13,483 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:13,484 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:13,488 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:13,492 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,493 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,493 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,493 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,493 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:13,497 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:13,500 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:13,503 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:13,507 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-08 09:09:13,508 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-08 09:09:13,508 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:13,512 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:13,518 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:13,524 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,525 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,525 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,525 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,526 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:13,531 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:13,535 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:13,539 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:13,543 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-08 09:09:13,544 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-08 09:09:13,544 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:13,547 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:13,551 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:13,555 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,555 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,556 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,556 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,556 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:13,559 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:13,567 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:13,570 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:13,572 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-08 09:09:13,572 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-08 09:09:13,573 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:13,574 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:13,578 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:13,583 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,583 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,584 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,584 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,584 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:13,592 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:13,595 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:13,597 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:13,599 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-08 09:09:13,600 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-08 09:09:13,600 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:13,602 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:13,606 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:13,610 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,610 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,610 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,610 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,611 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:13,614 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:13,617 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:13,619 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:13,621 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-08 09:09:13,622 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-08 09:09:13,622 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:13,623 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:13,627 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:13,632 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,632 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,632 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,633 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,633 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:13,640 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:13,643 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:13,645 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:13,647 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-08 09:09:13,648 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-08 09:09:13,648 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:13,650 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:13,653 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:13,654 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,654 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,654 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,655 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,655 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:13,658 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:13,661 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:13,663 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:13,665 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-08 09:09:13,666 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-08 09:09:13,666 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:13,667 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:13,668 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:13,668 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,668 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:13,668 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,669 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:13,669 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:13,671 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:13,674 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:13,675 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:13,676 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:13,676 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:13,676 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:13,677 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:13,677 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:13,678 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,678 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:13,678 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,678 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:13,679 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:13,690 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:13,700 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:13,709 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:13,719 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:13,724 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:13,725 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:13,730 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:13,731 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:13,732 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:13,732 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:13,732 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:13,733 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:13,733 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:13,733 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:13,734 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:13,734 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:13,735 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:13,735 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:13,735 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:13,736 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:13,737 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:13,741 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 19]), 18)
2023-10-08 09:09:13,741 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:13,742 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 19]), 18)
2023-10-08 09:09:13,742 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:13,742 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:13,742 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:13,743 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:13,743 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:13,744 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:13,744 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:13,744 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:13,744 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:13,748 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:13,752 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,752 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,753 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,753 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,753 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:13,757 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:13,759 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:13,761 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:13,763 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-08 09:09:13,764 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-08 09:09:13,764 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:13,766 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:13,770 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:13,774 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,775 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,775 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,775 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,775 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:13,779 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:13,782 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:13,784 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:13,786 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-08 09:09:13,787 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-08 09:09:13,787 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:13,789 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:13,792 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:13,796 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,796 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,797 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,797 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,797 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:13,800 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:13,803 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:13,805 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:13,807 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-08 09:09:13,808 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-08 09:09:13,808 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:13,809 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:13,813 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:13,817 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,817 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,817 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,818 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,818 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:13,821 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:13,824 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:13,826 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:13,828 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-08 09:09:13,829 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-08 09:09:13,829 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:13,830 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:13,834 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:13,839 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,839 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,839 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,839 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,839 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:13,842 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:13,845 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:13,847 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:13,850 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-08 09:09:13,850 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-08 09:09:13,851 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:13,852 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:13,856 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:13,860 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,860 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,860 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,861 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,861 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:13,864 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:13,867 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:13,869 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:13,871 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-08 09:09:13,872 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-08 09:09:13,872 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:13,873 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:13,877 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:13,881 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,881 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,882 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,882 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,882 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:13,885 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:13,888 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:13,890 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:13,892 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-08 09:09:13,893 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-08 09:09:13,893 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:13,895 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:13,899 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:13,903 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,903 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,903 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,903 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,903 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:13,907 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:13,909 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:13,911 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:13,913 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-08 09:09:13,914 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-08 09:09:13,914 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:13,915 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:13,919 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:13,923 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,923 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,923 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,924 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,924 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:13,927 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:13,929 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:13,931 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:13,933 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-08 09:09:13,933 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-08 09:09:13,933 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:13,935 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:13,939 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:13,943 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,943 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,943 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,943 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,944 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:13,947 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:13,948 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:13,950 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:13,952 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-08 09:09:13,952 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-08 09:09:13,953 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:13,954 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:13,958 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:13,963 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,963 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,963 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,963 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,963 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:13,967 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:13,968 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:13,970 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:13,972 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-08 09:09:13,973 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-08 09:09:13,973 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:13,975 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:13,979 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:13,979 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,980 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,980 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,980 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:13,980 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:13,983 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:13,985 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:13,987 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:13,988 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-08 09:09:13,989 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-08 09:09:13,989 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:13,991 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:13,991 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:13,992 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,992 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:13,992 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,992 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:13,992 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:13,992 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:13,993 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:13,993 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:13,993 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:13,993 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:13,993 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:13,994 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:13,995 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:13,995 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:13,995 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:13,996 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:13,996 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:13,996 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:14,004 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:14,011 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:14,018 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:14,025 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:14,026 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:14,026 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:14,031 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:14,032 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:14,032 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:14,033 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,033 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:14,033 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,033 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:14,034 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:14,034 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:14,034 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:14,035 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:14,035 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:14,035 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:14,036 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:14,036 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:14,041 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 20]), 19)
2023-10-08 09:09:14,041 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,041 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 20]), 19)
2023-10-08 09:09:14,041 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,042 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:14,042 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:14,042 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:14,043 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:14,043 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:14,043 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:14,044 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:14,044 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:14,048 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:14,052 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,052 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,052 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,053 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,053 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:14,056 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:14,058 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:14,060 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:14,062 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-08 09:09:14,063 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-08 09:09:14,063 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:14,065 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:14,069 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:14,073 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,073 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,073 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,073 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,073 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:14,077 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:14,078 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:14,080 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:14,082 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-08 09:09:14,082 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-08 09:09:14,082 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:14,084 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:14,088 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:14,092 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,092 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,092 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,092 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,092 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:14,095 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:14,097 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:14,099 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:14,101 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-08 09:09:14,102 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-08 09:09:14,102 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:14,104 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:14,107 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:14,111 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,112 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,112 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,112 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,112 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:14,115 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:14,118 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:14,120 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:14,121 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-08 09:09:14,122 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-08 09:09:14,122 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:14,124 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:14,127 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:14,132 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,132 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,132 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,132 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,132 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:14,135 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:14,137 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:14,139 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:14,141 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-08 09:09:14,141 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-08 09:09:14,141 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:14,143 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:14,147 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:14,151 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,151 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,151 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,151 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,152 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:14,155 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:14,157 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:14,159 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:14,161 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-08 09:09:14,161 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-08 09:09:14,161 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:14,163 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:14,167 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:14,171 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,171 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,171 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,172 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,172 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:14,175 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:14,177 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:14,179 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:14,181 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-08 09:09:14,181 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-08 09:09:14,182 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:14,183 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:14,187 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:14,191 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,191 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,191 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,191 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,191 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:14,195 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:14,197 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:14,198 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:14,200 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-08 09:09:14,200 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-08 09:09:14,201 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:14,202 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:14,205 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:14,210 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,210 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,210 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,211 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,211 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:14,215 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:14,217 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:14,219 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:14,221 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-08 09:09:14,221 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-08 09:09:14,222 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:14,223 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:14,227 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:14,231 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,231 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,231 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,231 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,232 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:14,235 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:14,236 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:14,238 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:14,240 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-08 09:09:14,240 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-08 09:09:14,240 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:14,242 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:14,246 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:14,250 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,250 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,250 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,250 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,250 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:14,253 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:14,255 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:14,258 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:14,259 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-08 09:09:14,260 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-08 09:09:14,260 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:14,261 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:14,265 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:14,266 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,266 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,266 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,266 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,267 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:14,269 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:14,271 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:14,274 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:14,275 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-08 09:09:14,276 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-08 09:09:14,276 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:14,277 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:14,278 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:14,278 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,278 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,279 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,279 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,279 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:14,279 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:14,279 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:14,279 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:14,280 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:14,280 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:14,280 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:14,280 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:14,281 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:14,281 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,281 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,281 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,282 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,282 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:14,294 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:14,303 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:14,311 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:14,319 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:14,320 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:14,320 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:14,325 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:14,325 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:14,326 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:14,326 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,326 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:14,326 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,327 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:14,327 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:14,327 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:14,328 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:14,328 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:14,328 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:14,328 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:14,329 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:14,329 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:14,333 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 21]), 20)
2023-10-08 09:09:14,333 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,334 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 21]), 20)
2023-10-08 09:09:14,334 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,334 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:14,334 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:14,335 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:14,335 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:14,335 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:14,335 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:14,336 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:14,336 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:14,340 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:14,345 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,345 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,345 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,345 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,345 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:14,349 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:14,351 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:14,353 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:14,355 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-08 09:09:14,355 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-08 09:09:14,356 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:14,358 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:14,362 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:14,366 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,366 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,367 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,367 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,367 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:14,371 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:14,373 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:14,375 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:14,377 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-08 09:09:14,377 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-08 09:09:14,377 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:14,379 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:14,383 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:14,389 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,389 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,389 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,390 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,390 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:14,393 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:14,395 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:14,397 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:14,399 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-08 09:09:14,399 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-08 09:09:14,399 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:14,401 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:14,405 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:14,409 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,409 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,410 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,410 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,410 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:14,413 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:14,415 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:14,417 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:14,418 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-08 09:09:14,419 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-08 09:09:14,419 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:14,420 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:14,424 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:14,429 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,429 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,429 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,429 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,429 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:14,432 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:14,434 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:14,436 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:14,438 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-08 09:09:14,439 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-08 09:09:14,439 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:14,441 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:14,445 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:14,449 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,450 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,450 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,450 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,450 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:14,453 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:14,455 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:14,458 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:14,459 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-08 09:09:14,460 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-08 09:09:14,460 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:14,461 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:14,465 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:14,470 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,470 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,470 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,470 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,470 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:14,473 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:14,475 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:14,478 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:14,479 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-08 09:09:14,480 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-08 09:09:14,480 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:14,482 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:14,486 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:14,490 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,491 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,491 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,491 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,491 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:14,495 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:14,498 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:14,500 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:14,502 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-08 09:09:14,502 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-08 09:09:14,502 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:14,504 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:14,508 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:14,513 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,513 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,513 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,513 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,513 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:14,518 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:14,520 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:14,522 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:14,524 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-08 09:09:14,525 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-08 09:09:14,525 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:14,526 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:14,530 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:14,535 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,535 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,535 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,536 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,536 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:14,539 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:14,541 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:14,543 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:14,544 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-08 09:09:14,545 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-08 09:09:14,545 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:14,546 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:14,551 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:14,555 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,555 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,556 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,556 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,556 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:14,559 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:14,561 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:14,563 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:14,565 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-08 09:09:14,565 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-08 09:09:14,566 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:14,567 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:14,571 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:14,572 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,572 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,572 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,573 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,573 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:14,577 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:14,579 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:14,581 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:14,583 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-08 09:09:14,584 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-08 09:09:14,584 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:14,585 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:14,586 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:14,586 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,587 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,587 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,587 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,587 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:14,587 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:14,587 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:14,588 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:14,588 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:14,588 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:14,588 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:14,589 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:14,589 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:14,590 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,590 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,590 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,590 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,590 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:14,599 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:14,606 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:14,614 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:14,621 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:14,622 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:14,623 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:14,628 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:14,628 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:14,629 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:14,629 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,629 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:14,630 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,630 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:14,630 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:14,631 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:14,631 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:14,631 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:14,632 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:14,632 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:14,632 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:14,633 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:14,637 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 22]), 21)
2023-10-08 09:09:14,638 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,638 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 22]), 21)
2023-10-08 09:09:14,638 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,638 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:14,639 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:14,639 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:14,640 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:14,640 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:14,640 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:14,641 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:14,641 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:14,645 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:14,650 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,650 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,650 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,650 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,651 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:14,654 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:14,656 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:14,658 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:14,660 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-08 09:09:14,661 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-08 09:09:14,661 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:14,663 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:14,667 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:14,671 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,671 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,671 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,671 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,672 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:14,675 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:14,677 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:14,679 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:14,681 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-08 09:09:14,682 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-08 09:09:14,682 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:14,684 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:14,688 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:14,693 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,694 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,694 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,694 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,694 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:14,697 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:14,700 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:14,702 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:14,704 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-08 09:09:14,704 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-08 09:09:14,705 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:14,706 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:14,711 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:14,715 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,715 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,715 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,716 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,716 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:14,719 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:14,721 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:14,722 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:14,724 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-08 09:09:14,724 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-08 09:09:14,725 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:14,726 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:14,730 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:14,734 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,734 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,734 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,734 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,735 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:14,738 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:14,740 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:14,741 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:14,743 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-08 09:09:14,744 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-08 09:09:14,744 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:14,745 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:14,749 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:14,753 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,753 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,753 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,753 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,754 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:14,756 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:14,758 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:14,761 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:14,762 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-08 09:09:14,764 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-08 09:09:14,764 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:14,766 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:14,769 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:14,774 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,774 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,774 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,774 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,774 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:14,777 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:14,779 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:14,783 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:14,784 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-08 09:09:14,785 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-08 09:09:14,785 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:14,787 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:14,791 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:14,794 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,794 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,795 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,795 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,795 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:14,798 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:14,800 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:14,802 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:14,804 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-08 09:09:14,804 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-08 09:09:14,805 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:14,806 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:14,809 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:14,814 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,814 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,814 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,814 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,814 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:14,818 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:14,820 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:14,822 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:14,824 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-08 09:09:14,824 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-08 09:09:14,824 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:14,826 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:14,829 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:14,833 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,833 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,834 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,834 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,834 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:14,837 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:14,839 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:14,841 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:14,843 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-08 09:09:14,843 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-08 09:09:14,844 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:14,845 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:14,848 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:14,853 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,853 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,853 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,853 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,853 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:14,856 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:14,858 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:14,861 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:14,863 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-08 09:09:14,864 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-08 09:09:14,864 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:14,865 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:14,869 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:14,870 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,870 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,870 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,870 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,870 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:14,873 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:14,875 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:14,877 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:14,879 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-08 09:09:14,881 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-08 09:09:14,881 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:14,882 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:14,883 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:14,883 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,884 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,884 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,884 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,884 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:14,884 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:14,885 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:14,885 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:14,885 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:14,885 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:14,885 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:14,886 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:14,886 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:14,887 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,887 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,887 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,887 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,887 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:14,896 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:14,904 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:14,915 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:14,928 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:14,930 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:14,931 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:14,937 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:14,939 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:14,939 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:14,940 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,940 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:14,940 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,941 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:14,941 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:14,942 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:14,942 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:14,943 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:14,943 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:14,944 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:14,945 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:14,946 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:14,952 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 23]), 22)
2023-10-08 09:09:14,952 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:14,953 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 23]), 22)
2023-10-08 09:09:14,953 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:14,953 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:14,954 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:14,954 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:14,955 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:14,955 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:14,955 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:14,956 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:14,956 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:14,962 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:14,967 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,968 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,968 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,968 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,968 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:14,973 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:14,975 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:14,978 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:14,980 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-08 09:09:14,981 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-08 09:09:14,981 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:14,983 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:14,987 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:14,991 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:14,992 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,992 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:14,992 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:14,992 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:14,996 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:14,999 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:15,002 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:15,004 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-08 09:09:15,005 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-08 09:09:15,006 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:15,008 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:15,012 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:15,016 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,016 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,017 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,017 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,017 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:15,021 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:15,023 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:15,026 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:15,028 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-08 09:09:15,029 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-08 09:09:15,029 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:15,031 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:15,035 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:15,039 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,039 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,040 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,040 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,040 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:15,044 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:15,046 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:15,049 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:15,051 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-08 09:09:15,052 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-08 09:09:15,052 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:15,054 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:15,058 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:15,062 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,063 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,063 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,063 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,063 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:15,067 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:15,069 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:15,072 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:15,074 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-08 09:09:15,075 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-08 09:09:15,075 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:15,077 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:15,081 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:15,086 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,086 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,086 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,086 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,087 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:15,090 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:15,093 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:15,095 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:15,097 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-08 09:09:15,098 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-08 09:09:15,098 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:15,100 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:15,104 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:15,108 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,108 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,108 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,108 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,109 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:15,112 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:15,115 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:15,117 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:15,120 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-08 09:09:15,120 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-08 09:09:15,120 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:15,123 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:15,127 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:15,131 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,131 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,132 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,132 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,132 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:15,136 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:15,138 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:15,141 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:15,143 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-08 09:09:15,144 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-08 09:09:15,144 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:15,145 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:15,149 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:15,154 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,154 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,154 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,154 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,154 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:15,157 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:15,159 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:15,162 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:15,164 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-08 09:09:15,164 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-08 09:09:15,164 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:15,166 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:15,170 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:15,174 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,174 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,174 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,174 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,175 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:15,178 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:15,180 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:15,182 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:15,184 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-08 09:09:15,184 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-08 09:09:15,184 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:15,186 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:15,190 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:15,194 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,195 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,195 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,195 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,195 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:15,203 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:15,205 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:15,207 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:15,209 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-08 09:09:15,209 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-08 09:09:15,209 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:15,211 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:15,215 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:15,216 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,216 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,216 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,216 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,217 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:15,219 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:15,233 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:15,235 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:15,237 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-08 09:09:15,238 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-08 09:09:15,238 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:15,239 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:15,240 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:15,241 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,241 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:15,241 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,241 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:15,241 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:15,242 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:15,243 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:15,243 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:15,243 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:15,243 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:15,243 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:15,244 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:15,244 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:15,245 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,245 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:15,245 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,245 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:15,245 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:15,253 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:15,260 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:15,267 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:15,274 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:15,275 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:15,275 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:15,280 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:15,280 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:15,281 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:15,281 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:15,281 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:15,281 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:15,281 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:15,282 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:15,282 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:15,282 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:15,282 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:15,282 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:15,283 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:15,283 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:15,283 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:15,287 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 24]), 23)
2023-10-08 09:09:15,288 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:15,288 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 24]), 23)
2023-10-08 09:09:15,288 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:15,288 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:15,288 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:15,289 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:15,289 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:15,289 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:15,289 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:15,289 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:15,290 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:15,293 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:15,297 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,298 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,298 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,298 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,298 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:15,301 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:15,304 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:15,306 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:15,307 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-08 09:09:15,308 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-08 09:09:15,308 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:15,310 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:15,314 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:15,318 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,318 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,318 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,318 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,318 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:15,321 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:15,323 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:15,325 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:15,327 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-08 09:09:15,327 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-08 09:09:15,328 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:15,329 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:15,333 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:15,336 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,337 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,337 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,337 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,337 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:15,340 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:15,342 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:15,344 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:15,346 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-08 09:09:15,347 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-08 09:09:15,347 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:15,348 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:15,352 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:15,356 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,356 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,356 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,356 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,356 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:15,360 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:15,362 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:15,364 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:15,366 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-08 09:09:15,367 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-08 09:09:15,367 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:15,369 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:15,372 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:15,376 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,376 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,377 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,377 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,377 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:15,381 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:15,383 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:15,385 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:15,386 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-08 09:09:15,387 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-08 09:09:15,387 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:15,389 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:15,392 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:15,396 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,396 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,397 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,397 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,397 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:15,400 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:15,402 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:15,404 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:15,405 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-08 09:09:15,406 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-08 09:09:15,406 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:15,407 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:15,411 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:15,415 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,415 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,415 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,416 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,416 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:15,419 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:15,420 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:15,423 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:15,425 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-08 09:09:15,425 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-08 09:09:15,425 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:15,427 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:15,430 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:15,434 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,434 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,435 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,435 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,435 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:15,438 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:15,440 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:15,442 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:15,443 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-08 09:09:15,444 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-08 09:09:15,444 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:15,445 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:15,449 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:15,453 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,453 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,453 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,453 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,453 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:15,457 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:15,459 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:15,460 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:15,462 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-08 09:09:15,463 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-08 09:09:15,463 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:15,464 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:15,468 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:15,472 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,472 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,472 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,473 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,473 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:15,476 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:15,479 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:15,481 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:15,483 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-08 09:09:15,483 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-08 09:09:15,484 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:15,485 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:15,489 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:15,493 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,493 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,493 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,493 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,493 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:15,497 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:15,499 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:15,501 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:15,503 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-08 09:09:15,503 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-08 09:09:15,504 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:15,505 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:15,509 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:15,509 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,509 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,510 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,510 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,510 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:15,513 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:15,515 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:15,517 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:15,519 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-08 09:09:15,520 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-08 09:09:15,520 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:15,521 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:15,522 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:15,522 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,523 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:15,523 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,523 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:15,523 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:15,523 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:15,523 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:15,524 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:15,524 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:15,524 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:15,524 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:15,524 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:15,525 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:15,525 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,525 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:15,526 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,526 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:15,526 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:15,534 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:15,542 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:15,549 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:15,557 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:15,559 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:15,559 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:15,563 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:15,564 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:15,564 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:15,564 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:15,565 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:15,565 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:15,565 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:15,565 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:15,565 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:15,566 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:15,566 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:15,566 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:15,566 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:15,567 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:15,567 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:15,571 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 25]), 24)
2023-10-08 09:09:15,571 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:15,571 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 25]), 24)
2023-10-08 09:09:15,571 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:15,571 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:15,572 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:15,572 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:15,572 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:15,572 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:15,573 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:15,573 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:15,573 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:15,576 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:15,580 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,581 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,581 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,581 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,581 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:15,584 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:15,586 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:15,588 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:15,590 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-08 09:09:15,590 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-08 09:09:15,590 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:15,592 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:15,596 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:15,600 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,600 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,600 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,600 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,601 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:15,604 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:15,606 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:15,608 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:15,610 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-08 09:09:15,611 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-08 09:09:15,611 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:15,613 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:15,616 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:15,620 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,621 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,621 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,621 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,621 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:15,624 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:15,626 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:15,628 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:15,629 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-08 09:09:15,630 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-08 09:09:15,630 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:15,632 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:15,635 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:15,640 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,640 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,640 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,640 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,640 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:15,643 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:15,645 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:15,647 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:15,649 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-08 09:09:15,649 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-08 09:09:15,650 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:15,651 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:15,655 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:15,659 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,659 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,659 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,660 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,660 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:15,663 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:15,665 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:15,667 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:15,668 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-08 09:09:15,669 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-08 09:09:15,669 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:15,671 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:15,674 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:15,678 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,678 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,679 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,679 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,679 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:15,682 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:15,684 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:15,686 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:15,688 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-08 09:09:15,688 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-08 09:09:15,688 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:15,689 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:15,693 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:15,697 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,697 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,698 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,698 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,698 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:15,702 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:15,704 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:15,706 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:15,708 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-08 09:09:15,708 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-08 09:09:15,708 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:15,710 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:15,714 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:15,717 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,718 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,718 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,718 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,718 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:15,721 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:15,723 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:15,725 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:15,727 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-08 09:09:15,750 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-08 09:09:15,751 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:15,752 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:15,756 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:15,760 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,760 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,761 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,761 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,761 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:15,765 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:15,767 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:15,769 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:15,771 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-08 09:09:15,772 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-08 09:09:15,772 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:15,774 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:15,777 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:15,781 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,781 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,782 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,782 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,782 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:15,786 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:15,788 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:15,790 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:15,792 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-08 09:09:15,792 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-08 09:09:15,792 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:15,794 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:15,798 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:15,802 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,802 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,803 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,803 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,803 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:15,806 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:15,808 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:15,811 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:15,812 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-08 09:09:15,813 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-08 09:09:15,813 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:15,815 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:15,819 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:15,819 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,820 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,820 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,820 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,820 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:15,824 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:15,826 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:15,828 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:15,830 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-08 09:09:15,830 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-08 09:09:15,831 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:15,832 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:15,833 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:15,833 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,833 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:15,834 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,834 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:15,834 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:15,835 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:15,835 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:15,835 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:15,835 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:15,836 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:15,836 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:15,836 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:15,836 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:15,837 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,837 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:15,837 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,837 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:15,837 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:15,846 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:15,854 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:15,861 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:15,872 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:15,875 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:15,876 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:15,884 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:15,885 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:15,886 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:15,886 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:15,886 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:15,887 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:15,887 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:15,887 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:15,888 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:15,888 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:15,889 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:15,889 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:15,889 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:15,891 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:15,891 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:15,898 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 26]), 25)
2023-10-08 09:09:15,898 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:15,899 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 26]), 25)
2023-10-08 09:09:15,899 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:15,899 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:15,900 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:15,900 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:15,901 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:15,901 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:15,902 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:15,902 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:15,902 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:15,906 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:15,910 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,910 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,910 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,910 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,910 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:15,915 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:15,917 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:15,919 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:15,921 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-08 09:09:15,922 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-08 09:09:15,922 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:15,923 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:15,927 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:15,931 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,931 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,931 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,931 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,931 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:15,935 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:15,937 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:15,938 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:15,940 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-08 09:09:15,941 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-08 09:09:15,941 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:15,943 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:15,946 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:15,950 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,950 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,951 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,951 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,951 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:15,954 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:15,956 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:15,959 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:15,962 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-08 09:09:15,963 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-08 09:09:15,963 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:15,966 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:15,972 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:15,979 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:15,979 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,980 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:15,980 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:15,980 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:15,990 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:15,995 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:15,998 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:16,001 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-08 09:09:16,002 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-08 09:09:16,002 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:16,004 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:16,007 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:16,011 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,011 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,012 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,012 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,012 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:16,018 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:16,020 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:16,022 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:16,025 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-08 09:09:16,026 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-08 09:09:16,026 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:16,028 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:16,031 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:16,035 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,035 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,036 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,036 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,036 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:16,040 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:16,043 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:16,045 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:16,047 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-08 09:09:16,047 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-08 09:09:16,047 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:16,049 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:16,052 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:16,056 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,057 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,057 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,057 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,057 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:16,060 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:16,063 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:16,065 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:16,067 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-08 09:09:16,068 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-08 09:09:16,068 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:16,070 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:16,073 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:16,077 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,077 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,078 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,078 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,078 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:16,085 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:16,087 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:16,089 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:16,091 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-08 09:09:16,092 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-08 09:09:16,092 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:16,094 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:16,097 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:16,101 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,101 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,102 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,102 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,102 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:16,105 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:16,108 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:16,110 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:16,112 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-08 09:09:16,113 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-08 09:09:16,113 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:16,115 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:16,119 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:16,123 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,123 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,123 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,124 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,124 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:16,127 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:16,130 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:16,132 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:16,134 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-08 09:09:16,135 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-08 09:09:16,135 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:16,137 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:16,140 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:16,144 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,144 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,145 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,145 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,145 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:16,148 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:16,150 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:16,153 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:16,155 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-08 09:09:16,156 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-08 09:09:16,156 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:16,158 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:16,161 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:16,162 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,162 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,162 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,162 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,163 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:16,166 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:16,168 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:16,171 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:16,173 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-08 09:09:16,174 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-08 09:09:16,174 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:16,175 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:16,176 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:16,177 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,177 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:16,177 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,177 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:16,177 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:16,177 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:16,178 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:16,178 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:16,178 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:16,178 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:16,178 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:16,179 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:16,179 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:16,180 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,180 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:16,180 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,180 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:16,180 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:16,190 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:16,199 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:16,208 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:16,216 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:16,217 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:16,217 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:16,222 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:16,222 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:16,223 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:16,223 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:16,223 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:16,223 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:16,223 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:16,224 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:16,224 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:16,224 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:16,224 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:16,224 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:16,225 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:16,225 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:16,226 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:16,230 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 27]), 26)
2023-10-08 09:09:16,230 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:16,230 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 27]), 26)
2023-10-08 09:09:16,230 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:16,230 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:16,231 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:16,231 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:16,231 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:16,232 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:16,232 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:16,232 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:16,232 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:16,236 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:16,240 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,240 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,240 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,240 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,240 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:16,244 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:16,246 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:16,248 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:16,251 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-08 09:09:16,251 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-08 09:09:16,252 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:16,253 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:16,257 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:16,261 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,261 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,261 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,262 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,262 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:16,265 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:16,268 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:16,270 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:16,272 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-08 09:09:16,273 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-08 09:09:16,273 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:16,275 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:16,279 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:16,282 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,283 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,283 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,283 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,283 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:16,287 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:16,289 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:16,291 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:16,293 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-08 09:09:16,294 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-08 09:09:16,294 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:16,296 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:16,300 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:16,303 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,304 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,304 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,304 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,304 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:16,308 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:16,310 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:16,312 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:16,315 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-08 09:09:16,315 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-08 09:09:16,316 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:16,317 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:16,321 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:16,325 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,326 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,326 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,326 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,326 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:16,329 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:16,332 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:16,334 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:16,336 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-08 09:09:16,337 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-08 09:09:16,337 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:16,338 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:16,342 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:16,346 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,346 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,346 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,347 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,347 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:16,350 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:16,352 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:16,354 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:16,356 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-08 09:09:16,357 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-08 09:09:16,357 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:16,358 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:16,362 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:16,366 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,366 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,366 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,366 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,367 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:16,370 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:16,372 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:16,374 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:16,376 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-08 09:09:16,376 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-08 09:09:16,376 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:16,378 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:16,382 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:16,386 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,386 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,386 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,386 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,386 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:16,390 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:16,392 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:16,394 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:16,396 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-08 09:09:16,397 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-08 09:09:16,397 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:16,398 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:16,402 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:16,406 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,406 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,407 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,407 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,407 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:16,410 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:16,412 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:16,414 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:16,416 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-08 09:09:16,417 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-08 09:09:16,417 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:16,419 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:16,422 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:16,426 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,426 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,427 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,427 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,427 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:16,430 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:16,432 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:16,435 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:16,436 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-08 09:09:16,437 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-08 09:09:16,437 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:16,439 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:16,442 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:16,447 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,447 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,447 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,447 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,447 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:16,451 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:16,453 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:16,456 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:16,458 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-08 09:09:16,459 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-08 09:09:16,459 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:16,461 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:16,465 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:16,465 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,465 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,466 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,466 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,466 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:16,469 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:16,471 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:16,473 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:16,475 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-08 09:09:16,476 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-08 09:09:16,476 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:16,477 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:16,478 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:16,478 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,478 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:16,479 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,479 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:16,479 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:16,479 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:16,479 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:16,479 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:16,480 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:16,480 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:16,480 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:16,480 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:16,481 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:16,481 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,481 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:16,481 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,482 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:16,482 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:16,495 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:16,504 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:16,512 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:16,520 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:16,521 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:16,521 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:16,526 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:16,527 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:16,527 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:16,528 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:16,528 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:16,528 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:16,528 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:16,528 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:16,528 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:16,529 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:16,529 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:16,529 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:16,529 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:16,530 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:16,530 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:16,534 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 28]), 27)
2023-10-08 09:09:16,534 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:16,534 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 28]), 27)
2023-10-08 09:09:16,534 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:16,534 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:16,535 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:16,535 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:16,535 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:16,536 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:16,536 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:16,536 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:16,536 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:16,540 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:16,544 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,544 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,544 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,544 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,544 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:16,549 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:16,551 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:16,553 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:16,555 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-08 09:09:16,556 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-08 09:09:16,556 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:16,557 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:16,561 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:16,565 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,565 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,565 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,566 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,566 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:16,569 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:16,571 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:16,573 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:16,575 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-08 09:09:16,576 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-08 09:09:16,576 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:16,578 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:16,581 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:16,585 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,585 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,585 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,586 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,586 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:16,589 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:16,592 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:16,594 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:16,596 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-08 09:09:16,596 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-08 09:09:16,596 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:16,598 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:16,602 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:16,606 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,606 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,606 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,607 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,607 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:16,610 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:16,612 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:16,614 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:16,616 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-08 09:09:16,617 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-08 09:09:16,617 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:16,619 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:16,623 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:16,627 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,627 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,627 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,627 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,627 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:16,631 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:16,634 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:16,636 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:16,638 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-08 09:09:16,639 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-08 09:09:16,639 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:16,641 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:16,644 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:16,648 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,648 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,648 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,649 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,649 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:16,653 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:16,656 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:16,658 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:16,660 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-08 09:09:16,660 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-08 09:09:16,661 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:16,662 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:16,666 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:16,670 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,670 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,670 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,671 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,671 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:16,674 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:16,676 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:16,678 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:16,680 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-08 09:09:16,680 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-08 09:09:16,680 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:16,682 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:16,686 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:16,689 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,690 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,690 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,690 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,690 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:16,693 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:16,695 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:16,697 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:16,699 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-08 09:09:16,700 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-08 09:09:16,700 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:16,701 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:16,705 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:16,709 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,709 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,709 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,709 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,710 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:16,713 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:16,715 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:16,717 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:16,719 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-08 09:09:16,719 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-08 09:09:16,719 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:16,721 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:16,725 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:16,728 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,729 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,729 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,729 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,729 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:16,732 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:16,734 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:16,736 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:16,738 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-08 09:09:16,739 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-08 09:09:16,739 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:16,740 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:16,744 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:16,748 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,748 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,749 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,749 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,749 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:16,752 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:16,755 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:16,757 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:16,759 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-08 09:09:16,759 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-08 09:09:16,759 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:16,761 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:16,765 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:16,765 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,765 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,766 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,766 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,766 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:16,769 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:16,771 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:16,773 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:16,775 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-08 09:09:16,776 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-08 09:09:16,776 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:16,777 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:16,778 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:16,779 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,779 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:16,779 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,779 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:16,779 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:16,779 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:16,780 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:16,780 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:16,780 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:16,780 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:16,780 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:16,781 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:16,781 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:16,782 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,782 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:16,782 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,782 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:16,782 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:16,790 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:16,797 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:16,804 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:16,810 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:16,811 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:16,812 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:16,816 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:16,817 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:16,817 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:16,817 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:16,817 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:16,818 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:16,818 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:16,818 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:16,818 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:16,818 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:16,819 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:16,819 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:16,819 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:16,819 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:16,820 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:16,824 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 29]), 28)
2023-10-08 09:09:16,824 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:16,824 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 29]), 28)
2023-10-08 09:09:16,824 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:16,824 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:16,824 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:16,825 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:16,825 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:16,825 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:16,825 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:16,826 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:16,826 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:16,829 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:16,833 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,833 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,834 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,834 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,834 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:16,840 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:16,842 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:16,844 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:16,849 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-08 09:09:16,849 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-08 09:09:16,849 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:16,851 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:16,855 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:16,859 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,859 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,859 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,859 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,859 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:16,864 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:16,867 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:16,869 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:16,872 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-08 09:09:16,872 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-08 09:09:16,872 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:16,874 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:16,878 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:16,882 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,882 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,882 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,882 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,882 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:16,886 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:16,888 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:16,890 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:16,892 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-08 09:09:16,893 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-08 09:09:16,893 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:16,895 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:16,899 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:16,903 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,903 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,903 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,903 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,903 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:16,907 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:16,909 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:16,911 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:16,913 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-08 09:09:16,914 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-08 09:09:16,914 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:16,916 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:16,920 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:16,924 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,924 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,924 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,924 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,924 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:16,928 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:16,931 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:16,933 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:16,935 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-08 09:09:16,936 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-08 09:09:16,936 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:16,938 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:16,942 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:16,945 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,946 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,946 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,946 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,946 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:16,950 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:16,953 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:16,955 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:16,957 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-08 09:09:16,958 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-08 09:09:16,958 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:16,960 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:16,964 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:16,968 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,968 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,968 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,968 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,968 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:16,972 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:16,975 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:16,978 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:16,980 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-08 09:09:16,981 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-08 09:09:16,981 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:16,983 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:16,986 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:16,990 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:16,990 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,990 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:16,991 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:16,991 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:16,995 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:16,998 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:17,000 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:17,002 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-08 09:09:17,003 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-08 09:09:17,003 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:17,004 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:17,008 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:17,012 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,012 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,013 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,013 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,013 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:17,017 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:17,020 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:17,023 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:17,025 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-08 09:09:17,026 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-08 09:09:17,026 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:17,028 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:17,031 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:17,035 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,036 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,036 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,036 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,036 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:17,040 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:17,043 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:17,045 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:17,047 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-08 09:09:17,048 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-08 09:09:17,048 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:17,049 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:17,053 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:17,057 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,057 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,058 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,058 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,058 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:17,062 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:17,064 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:17,067 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:17,069 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-08 09:09:17,070 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-08 09:09:17,070 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:17,072 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:17,076 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:17,076 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,076 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,077 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,077 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,077 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:17,080 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:17,084 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:17,086 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:17,088 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-08 09:09:17,089 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-08 09:09:17,090 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:17,091 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:17,092 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:17,092 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,093 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:17,093 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,093 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:17,093 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:17,093 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:17,094 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:17,096 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:17,096 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:17,096 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:17,096 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:17,097 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:17,097 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:17,098 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,098 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:17,098 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,098 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:17,098 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:17,107 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:17,116 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:17,124 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:17,132 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:17,133 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:17,133 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:17,138 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:17,139 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:17,139 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:17,139 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:17,140 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:17,140 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:17,140 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:17,140 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:17,140 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:17,141 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:17,141 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:17,141 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:17,141 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:17,142 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:17,142 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:17,146 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 30]), 29)
2023-10-08 09:09:17,146 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:17,146 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 30]), 29)
2023-10-08 09:09:17,146 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:17,147 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:17,147 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:17,147 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:17,147 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:17,148 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:17,148 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:17,148 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:17,148 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:17,152 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:17,156 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,156 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,156 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,156 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,156 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:17,160 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:17,162 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:17,164 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:17,167 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-08 09:09:17,167 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-08 09:09:17,167 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:17,169 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:17,173 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:17,177 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,177 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,177 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,177 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,177 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:17,181 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:17,183 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:17,185 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:17,188 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-08 09:09:17,188 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-08 09:09:17,189 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:17,190 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:17,194 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:17,198 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,198 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,198 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,199 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,199 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:17,236 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:17,239 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:17,242 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:17,249 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-08 09:09:17,251 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-08 09:09:17,251 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:17,253 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:17,258 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:17,263 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,263 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,264 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,264 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,264 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:17,268 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:17,271 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:17,273 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:17,276 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-08 09:09:17,277 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-08 09:09:17,277 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:17,280 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:17,284 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:17,289 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,290 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,290 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,290 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,291 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:17,294 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:17,297 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:17,299 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:17,301 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-08 09:09:17,302 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-08 09:09:17,302 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:17,304 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:17,308 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:17,312 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,312 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,313 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,313 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,313 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:17,326 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:17,329 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:17,331 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:17,334 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-08 09:09:17,334 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-08 09:09:17,335 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:17,336 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:17,340 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:17,345 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,345 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,345 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,345 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,345 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:17,349 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:17,351 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:17,353 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:17,355 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-08 09:09:17,356 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-08 09:09:17,356 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:17,358 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:17,362 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:17,366 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,367 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,367 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,367 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,367 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:17,371 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:17,374 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:17,376 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:17,378 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-08 09:09:17,379 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-08 09:09:17,379 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:17,380 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:17,384 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:17,389 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,389 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,389 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,389 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,390 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:17,393 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:17,395 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:17,397 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:17,399 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-08 09:09:17,400 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-08 09:09:17,400 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:17,402 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:17,406 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:17,410 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,411 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,411 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,411 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,411 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:17,415 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:17,417 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:17,419 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:17,421 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-08 09:09:17,421 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-08 09:09:17,422 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:17,423 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:17,427 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:17,432 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,432 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,432 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,432 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,432 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:17,436 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:17,438 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:17,440 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:17,442 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-08 09:09:17,443 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-08 09:09:17,443 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:17,445 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:17,449 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:17,449 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,450 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,450 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,450 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,450 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:17,453 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:17,456 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:17,458 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:17,460 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-08 09:09:17,461 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-08 09:09:17,461 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:17,462 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:17,463 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:17,464 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,464 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:17,464 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,464 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:17,464 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:17,464 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:17,465 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:17,465 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:17,465 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:17,465 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:17,465 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:17,466 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:17,466 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:17,467 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,467 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:17,467 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,467 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:17,467 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:17,477 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:17,484 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:17,491 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:17,499 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:17,500 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:17,500 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:17,505 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:17,506 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:17,507 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:17,507 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:17,507 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:17,508 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:17,508 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:17,508 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:17,509 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:17,509 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:17,509 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:17,510 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:17,510 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:17,511 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:17,511 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:17,515 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 31]), 30)
2023-10-08 09:09:17,515 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:17,516 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 31]), 30)
2023-10-08 09:09:17,516 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:17,516 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:17,516 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:17,517 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:17,517 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:17,518 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:17,518 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:17,518 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:17,519 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:17,522 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:17,527 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,527 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,527 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,527 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,527 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:17,531 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:17,533 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:17,535 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:17,537 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-08 09:09:17,538 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-08 09:09:17,538 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:17,540 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:17,544 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:17,548 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,548 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,549 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,549 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,549 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:17,560 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:17,563 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:17,565 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:17,567 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-08 09:09:17,568 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-08 09:09:17,569 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:17,571 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:17,575 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:17,579 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,580 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,580 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,580 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,580 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:17,584 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:17,586 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:17,588 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:17,591 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-08 09:09:17,591 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-08 09:09:17,592 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:17,594 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:17,598 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:17,602 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,603 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,603 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,603 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,603 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:17,607 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:17,610 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:17,612 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:17,614 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-08 09:09:17,615 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-08 09:09:17,615 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:17,617 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:17,621 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:17,626 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,626 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,626 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,626 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,626 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:17,630 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:17,632 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:17,634 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:17,636 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-08 09:09:17,637 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-08 09:09:17,637 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:17,639 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:17,643 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:17,647 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,647 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,647 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,647 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,647 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:17,650 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:17,653 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:17,655 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:17,657 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-08 09:09:17,658 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-08 09:09:17,658 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:17,659 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:17,663 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:17,668 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,668 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,668 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,668 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,669 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:17,672 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:17,674 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:17,676 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:17,678 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-08 09:09:17,679 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-08 09:09:17,679 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:17,681 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:17,685 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:17,689 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,689 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,689 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,689 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,689 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:17,693 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:17,695 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:17,697 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:17,699 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-08 09:09:17,700 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-08 09:09:17,700 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:17,701 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:17,705 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:17,710 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,710 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,710 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,710 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,710 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:17,715 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:17,718 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:17,720 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:17,722 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-08 09:09:17,722 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-08 09:09:17,722 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:17,724 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:17,728 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:17,733 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,733 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,733 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,733 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,733 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:17,736 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:17,739 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:17,741 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:17,743 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-08 09:09:17,743 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-08 09:09:17,743 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:17,745 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:17,749 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:17,753 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,753 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,754 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,754 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,754 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:17,757 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:17,760 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:17,762 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:17,764 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-08 09:09:17,765 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-08 09:09:17,765 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:17,767 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:17,771 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:17,771 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,772 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,772 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,772 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,772 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:17,784 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:17,786 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:17,788 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:17,790 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-08 09:09:17,791 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-08 09:09:17,791 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:17,793 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:17,794 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:17,794 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,794 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:17,794 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,794 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:17,795 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:17,795 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:17,795 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:17,795 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:17,796 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:17,796 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:17,796 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:17,797 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:17,797 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:17,797 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,797 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:17,798 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,798 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:17,798 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:17,807 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:17,816 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:17,823 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:17,832 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:17,833 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:17,833 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:17,838 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:17,839 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:17,840 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:17,840 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:17,840 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:17,840 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:17,840 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:17,840 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:17,841 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:17,841 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:17,841 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:17,841 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:17,841 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:17,842 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:17,842 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:17,846 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 32]), 31)
2023-10-08 09:09:17,846 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:17,847 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 32]), 31)
2023-10-08 09:09:17,847 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:17,847 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:17,847 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:17,847 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:17,848 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:17,848 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:17,848 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:17,848 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:17,848 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:17,852 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:17,856 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,856 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,856 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,856 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,856 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:17,860 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:17,862 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:17,864 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:17,866 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-08 09:09:17,867 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-08 09:09:17,867 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:17,869 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:17,872 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:17,876 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,876 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,876 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,876 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,877 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:17,880 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:17,882 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:17,884 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:17,886 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-08 09:09:17,887 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-08 09:09:17,887 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:17,889 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:17,892 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:17,896 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,896 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,896 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,897 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,897 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:17,901 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:17,904 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:17,906 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:17,908 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-08 09:09:17,908 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-08 09:09:17,909 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:17,910 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:17,914 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:17,918 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,918 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,918 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,918 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,918 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:17,922 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:17,925 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:17,927 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:17,929 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-08 09:09:17,930 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-08 09:09:17,931 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:17,932 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:17,936 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:17,940 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,940 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,940 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,940 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,940 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:17,944 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:17,946 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:17,948 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:17,951 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-08 09:09:17,979 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-08 09:09:17,980 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:17,981 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:17,985 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:17,988 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:17,989 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,989 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:17,989 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:17,989 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:17,993 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:17,996 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:17,998 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:18,000 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-08 09:09:18,001 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-08 09:09:18,001 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:18,002 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:18,006 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:18,009 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,010 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,010 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,010 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,010 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:18,014 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:18,016 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:18,019 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:18,020 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-08 09:09:18,021 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-08 09:09:18,021 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:18,023 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:18,026 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:18,030 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,030 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,030 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,031 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,031 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:18,034 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:18,036 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:18,038 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:18,040 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-08 09:09:18,041 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-08 09:09:18,041 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:18,042 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:18,046 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:18,050 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,050 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,050 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,050 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,051 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:18,054 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:18,056 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:18,058 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:18,060 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-08 09:09:18,061 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-08 09:09:18,061 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:18,063 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:18,066 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:18,070 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,070 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,070 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,070 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,070 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:18,074 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:18,076 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:18,078 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:18,080 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-08 09:09:18,081 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-08 09:09:18,081 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:18,082 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:18,086 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:18,089 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,090 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,090 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,090 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,090 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:18,093 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:18,095 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:18,097 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:18,099 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-08 09:09:18,099 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-08 09:09:18,099 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:18,101 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:18,104 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:18,105 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,105 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,105 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,105 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,106 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:18,109 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:18,111 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:18,113 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:18,116 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-08 09:09:18,117 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-08 09:09:18,117 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:18,119 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:18,119 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:18,120 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,120 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:18,120 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,120 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:18,120 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:18,120 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:18,121 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:18,121 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:18,121 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:18,121 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:18,121 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:18,122 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:18,122 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:18,122 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,123 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:18,123 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,123 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:18,123 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:18,131 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:18,138 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:18,144 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:18,152 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:18,153 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:18,153 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:18,157 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:18,158 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:18,158 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:18,159 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:18,159 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:18,159 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:18,159 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:18,159 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:18,159 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:18,160 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:18,160 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:18,160 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:18,160 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:18,160 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:18,161 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:18,165 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 33]), 32)
2023-10-08 09:09:18,165 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:18,165 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 33]), 32)
2023-10-08 09:09:18,165 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:18,165 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:18,165 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:18,166 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:18,166 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:18,166 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:18,166 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:18,167 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:18,167 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:18,170 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:18,174 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,174 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,174 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,174 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,174 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:18,178 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:18,180 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:18,182 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:18,184 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-08 09:09:18,184 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-08 09:09:18,184 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:18,186 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:18,189 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:18,193 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,193 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,194 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,194 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,194 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:18,197 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:18,199 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:18,201 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:18,203 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-08 09:09:18,203 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-08 09:09:18,203 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:18,205 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:18,209 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:18,212 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,212 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,213 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,213 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,213 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:18,216 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:18,218 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:18,220 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:18,223 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-08 09:09:18,223 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-08 09:09:18,224 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:18,225 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:18,229 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:18,233 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,233 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,233 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,233 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,233 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:18,236 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:18,238 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:18,241 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:18,243 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-08 09:09:18,244 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-08 09:09:18,244 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:18,249 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:18,255 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:18,261 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,262 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,262 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,262 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,262 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:18,289 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:18,292 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:18,294 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:18,296 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-08 09:09:18,297 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-08 09:09:18,297 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:18,299 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:18,303 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:18,307 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,307 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,307 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,307 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,307 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:18,311 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:18,313 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:18,315 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:18,317 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-08 09:09:18,318 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-08 09:09:18,318 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:18,319 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:18,323 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:18,327 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,327 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,328 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,328 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,328 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:18,332 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:18,334 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:18,336 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:18,337 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-08 09:09:18,338 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-08 09:09:18,338 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:18,340 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:18,343 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:18,347 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,347 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,347 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,347 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,348 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:18,351 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:18,352 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:18,355 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:18,356 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-08 09:09:18,357 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-08 09:09:18,357 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:18,358 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:18,362 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:18,366 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,366 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,366 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,366 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,366 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:18,370 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:18,372 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:18,374 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:18,376 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-08 09:09:18,377 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-08 09:09:18,377 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:18,379 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:18,382 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:18,386 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,386 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,387 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,387 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,387 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:18,391 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:18,393 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:18,396 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:18,397 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-08 09:09:18,398 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-08 09:09:18,398 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:18,400 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:18,403 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:18,407 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,408 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,408 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,408 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,408 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:18,411 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:18,413 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:18,416 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:18,417 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-08 09:09:18,418 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-08 09:09:18,418 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:18,420 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:18,423 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:18,424 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,424 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,424 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,424 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,425 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:18,427 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:18,430 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:18,432 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:18,435 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-08 09:09:18,436 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-08 09:09:18,436 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:18,437 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:18,438 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:18,438 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,439 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:18,439 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,439 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:18,439 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:18,439 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:18,439 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:18,440 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:18,440 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:18,440 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:18,440 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:18,440 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:18,441 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:18,442 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,442 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:18,442 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,442 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:18,443 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:18,452 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:18,460 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:18,467 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:18,474 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:18,476 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:18,476 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:18,480 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:18,481 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:18,481 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:18,482 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:18,482 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:18,482 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:18,482 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:18,482 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:18,483 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:18,483 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:18,483 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:18,483 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:18,483 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:18,484 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:18,484 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:18,488 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 34]), 33)
2023-10-08 09:09:18,488 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:18,488 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 34]), 33)
2023-10-08 09:09:18,489 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:18,489 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:18,489 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:18,489 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:18,490 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:18,490 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:18,490 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:18,490 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:18,491 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:18,494 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:18,498 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,498 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,498 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,498 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,498 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:18,502 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:18,504 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:18,506 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:18,508 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-08 09:09:18,509 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-08 09:09:18,509 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:18,510 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:18,514 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:18,518 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,518 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,518 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,518 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,518 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:18,522 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:18,525 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:18,527 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:18,530 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-08 09:09:18,530 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-08 09:09:18,530 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:18,532 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:18,535 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:18,539 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,539 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,540 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,540 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,540 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:18,545 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:18,548 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:18,550 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:18,552 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-08 09:09:18,552 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-08 09:09:18,553 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:18,555 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:18,559 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:18,563 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,563 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,563 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,564 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,564 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:18,567 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:18,569 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:18,571 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:18,573 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-08 09:09:18,574 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-08 09:09:18,574 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:18,576 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:18,580 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:18,584 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,584 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,584 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,584 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,584 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:18,588 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:18,590 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:18,592 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:18,595 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-08 09:09:18,595 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-08 09:09:18,596 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:18,597 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:18,601 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:18,606 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,606 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,606 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,606 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,607 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:18,611 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:18,614 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:18,615 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:18,617 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-08 09:09:18,618 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-08 09:09:18,618 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:18,619 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:18,624 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:18,628 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,628 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,628 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,628 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,628 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:18,632 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:18,634 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:18,636 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:18,638 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-08 09:09:18,639 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-08 09:09:18,639 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:18,641 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:18,645 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:18,648 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,649 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,649 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,649 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,649 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:18,652 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:18,655 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:18,657 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:18,659 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-08 09:09:18,660 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-08 09:09:18,660 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:18,661 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:18,665 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:18,669 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,669 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,669 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,670 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,670 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:18,673 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:18,675 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:18,677 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:18,679 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-08 09:09:18,680 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-08 09:09:18,680 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:18,682 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:18,686 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:18,690 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,690 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,690 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,691 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,691 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:18,694 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:18,696 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:18,698 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:18,700 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-08 09:09:18,701 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-08 09:09:18,701 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:18,703 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:18,708 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:18,712 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,712 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,713 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,713 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,713 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:18,719 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:18,722 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:18,724 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:18,727 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-08 09:09:18,727 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-08 09:09:18,728 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:18,730 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:18,733 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:18,734 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,734 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,734 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,734 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,734 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:18,738 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:18,740 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:18,742 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:18,750 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-08 09:09:18,751 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-08 09:09:18,751 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:18,752 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:18,753 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:18,753 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,754 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:18,754 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,754 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:18,754 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:18,755 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:18,755 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:18,755 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:18,756 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:18,756 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:18,756 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:18,756 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:18,757 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:18,757 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,757 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:18,757 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,758 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:18,758 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:18,769 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:18,777 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:18,784 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:18,791 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:18,792 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:18,792 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:18,797 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:18,797 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:18,798 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:18,798 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:18,798 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:18,798 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:18,798 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:18,798 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:18,799 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:18,799 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:18,799 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:18,799 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:18,799 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:18,800 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:18,800 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:18,804 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 35]), 34)
2023-10-08 09:09:18,804 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:18,804 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 35]), 34)
2023-10-08 09:09:18,804 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:18,804 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:18,805 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:18,805 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:18,805 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:18,806 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:18,806 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:18,806 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:18,806 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:18,810 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:18,813 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,813 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,814 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,814 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,814 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:18,818 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:18,820 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:18,821 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:18,823 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-08 09:09:18,824 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-08 09:09:18,825 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:18,827 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:18,831 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:18,836 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,837 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,837 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,837 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,837 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:18,841 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:18,843 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:18,845 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:18,847 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-08 09:09:18,848 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-08 09:09:18,848 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:18,850 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:18,853 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:18,857 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,857 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,857 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,858 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,858 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:18,862 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:18,864 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:18,866 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:18,869 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-08 09:09:18,870 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-08 09:09:18,870 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:18,872 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:18,875 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:18,879 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,879 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,879 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,879 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,879 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:18,883 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:18,885 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:18,887 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:18,890 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-08 09:09:18,890 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-08 09:09:18,891 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:18,892 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:18,896 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:18,900 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,900 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,900 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,900 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,900 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:18,904 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:18,906 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:18,908 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:18,910 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-08 09:09:18,911 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-08 09:09:18,911 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:18,913 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:18,916 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:18,920 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,920 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,921 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,921 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,921 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:18,924 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:18,926 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:18,929 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:18,930 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-08 09:09:18,931 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-08 09:09:18,931 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:18,932 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:18,936 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:18,940 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,940 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,940 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,940 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,941 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:18,944 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:18,946 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:18,949 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:18,951 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-08 09:09:18,952 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-08 09:09:18,953 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:18,954 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:18,958 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:18,961 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,962 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,962 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,962 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,962 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:18,965 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:18,968 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:18,970 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:18,972 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-08 09:09:18,972 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-08 09:09:18,973 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:18,974 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:18,978 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:18,981 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:18,982 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,982 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:18,982 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:18,982 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:18,985 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:18,987 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:18,989 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:18,991 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-08 09:09:18,992 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-08 09:09:18,992 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:18,993 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:18,997 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:19,001 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,001 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,001 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,001 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,001 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:19,004 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:19,007 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:19,008 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:19,010 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-08 09:09:19,011 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-08 09:09:19,011 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:19,012 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:19,016 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:19,020 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,020 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,020 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,020 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,020 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:19,029 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:19,031 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:19,032 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:19,034 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-08 09:09:19,035 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-08 09:09:19,035 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:19,037 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:19,040 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:19,041 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,041 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,041 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,041 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,041 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:19,044 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:19,046 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:19,048 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:19,050 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-08 09:09:19,051 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-08 09:09:19,051 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:19,052 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:19,053 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:19,053 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,053 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,054 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,054 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,054 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:19,054 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:19,054 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:19,054 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:19,055 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:19,055 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:19,055 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:19,055 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:19,056 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:19,056 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,056 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,056 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,056 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,057 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:19,067 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:19,076 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:19,083 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:19,091 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:19,092 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:19,092 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:19,097 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:19,097 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:19,098 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:19,098 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,098 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:19,098 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,098 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:19,098 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:19,099 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:19,099 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:19,099 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:19,099 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:19,099 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:19,100 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:19,100 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:19,104 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 36]), 35)
2023-10-08 09:09:19,104 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,104 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 36]), 35)
2023-10-08 09:09:19,104 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,104 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:19,105 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:19,105 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:19,105 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:19,105 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:19,106 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:19,106 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:19,106 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:19,109 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:19,113 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,113 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,113 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,114 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,114 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:19,117 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:19,119 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:19,121 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:19,123 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-08 09:09:19,124 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-08 09:09:19,124 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:19,126 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:19,129 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:19,133 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,133 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,133 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,134 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,134 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:19,137 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:19,139 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:19,140 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:19,142 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-08 09:09:19,143 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-08 09:09:19,143 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:19,144 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:19,148 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:19,152 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,152 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,152 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,152 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,152 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:19,155 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:19,157 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:19,159 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:19,161 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-08 09:09:19,161 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-08 09:09:19,161 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:19,163 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:19,166 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:19,170 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,170 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,170 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,170 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,171 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:19,173 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:19,175 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:19,178 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:19,180 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-08 09:09:19,180 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-08 09:09:19,180 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:19,182 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:19,185 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:19,189 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,189 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,189 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,190 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,190 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:19,194 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:19,196 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:19,197 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:19,199 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-08 09:09:19,200 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-08 09:09:19,200 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:19,202 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:19,206 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:19,209 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,209 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,209 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,210 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,210 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:19,213 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:19,215 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:19,217 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:19,220 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-08 09:09:19,220 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-08 09:09:19,220 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:19,222 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:19,225 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:19,229 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,229 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,229 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,230 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,230 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:19,233 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:19,235 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:19,237 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:19,238 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-08 09:09:19,239 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-08 09:09:19,239 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:19,241 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:19,244 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:19,248 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,249 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,249 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,249 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,249 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:19,252 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:19,254 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:19,256 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:19,259 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-08 09:09:19,259 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-08 09:09:19,259 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:19,261 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:19,264 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:19,268 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,268 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,268 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,269 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,269 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:19,272 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:19,274 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:19,276 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:19,278 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-08 09:09:19,278 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-08 09:09:19,278 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:19,280 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:19,283 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:19,287 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,287 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,287 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,288 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,288 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:19,291 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:19,293 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:19,294 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:19,296 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-08 09:09:19,297 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-08 09:09:19,297 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:19,298 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:19,302 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:19,305 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,306 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,306 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,306 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,306 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:19,309 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:19,311 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:19,313 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:19,314 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-08 09:09:19,315 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-08 09:09:19,315 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:19,316 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:19,320 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:19,321 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,321 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,321 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,321 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,321 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:19,324 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:19,326 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:19,328 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:19,330 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-08 09:09:19,331 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-08 09:09:19,331 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:19,332 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:19,333 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:19,333 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,333 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,333 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,333 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,334 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:19,334 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:19,334 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:19,334 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:19,335 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:19,335 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:19,335 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:19,335 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:19,336 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:19,336 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,336 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,336 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,336 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,337 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:19,345 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:19,353 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:19,360 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:19,368 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:19,369 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:19,369 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:19,374 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:19,374 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:19,375 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:19,375 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,375 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:19,375 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,375 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:19,376 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:19,376 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:19,376 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:19,376 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:19,376 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:19,376 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:19,377 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:19,377 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:19,381 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 37]), 36)
2023-10-08 09:09:19,381 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,381 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 37]), 36)
2023-10-08 09:09:19,381 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,381 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:19,382 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:19,382 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:19,382 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:19,382 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:19,383 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:19,383 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:19,383 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:19,386 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:19,390 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,390 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,391 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,391 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,391 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:19,396 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:19,398 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:19,399 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:19,401 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-08 09:09:19,402 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-08 09:09:19,402 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:19,404 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:19,407 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:19,411 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,411 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,411 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,411 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,412 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:19,415 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:19,417 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:19,419 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:19,421 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-08 09:09:19,422 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-08 09:09:19,422 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:19,424 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:19,428 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:19,431 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,432 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,432 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,432 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,432 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:19,436 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:19,438 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:19,441 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:19,444 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-08 09:09:19,445 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-08 09:09:19,445 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:19,447 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:19,450 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:19,454 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,454 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,454 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,454 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,454 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:19,458 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:19,460 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:19,462 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:19,464 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-08 09:09:19,465 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-08 09:09:19,465 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:19,467 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:19,471 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:19,476 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,476 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,476 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,476 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,476 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:19,480 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:19,482 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:19,484 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:19,486 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-08 09:09:19,487 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-08 09:09:19,487 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:19,489 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:19,492 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:19,496 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,496 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,496 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,497 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,497 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:19,500 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:19,502 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:19,505 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:19,508 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-08 09:09:19,508 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-08 09:09:19,509 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:19,510 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:19,514 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:19,517 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,518 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,518 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,518 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,518 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:19,522 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:19,525 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:19,527 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:19,529 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-08 09:09:19,529 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-08 09:09:19,530 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:19,531 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:19,535 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:19,539 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,539 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,539 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,539 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,539 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:19,542 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:19,544 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:19,548 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:19,549 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-08 09:09:19,550 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-08 09:09:19,550 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:19,552 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:19,555 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:19,559 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,559 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,560 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,560 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,560 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:19,563 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:19,565 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:19,567 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:19,569 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-08 09:09:19,570 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-08 09:09:19,570 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:19,572 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:19,576 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:19,579 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,579 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,580 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,580 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,580 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:19,584 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:19,586 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:19,588 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:19,590 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-08 09:09:19,591 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-08 09:09:19,591 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:19,592 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:19,596 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:19,600 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,600 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,600 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,600 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,600 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:19,605 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:19,607 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:19,609 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:19,611 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-08 09:09:19,612 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-08 09:09:19,612 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:19,614 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:19,617 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:19,618 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,618 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,618 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,619 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,619 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:19,623 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:19,625 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:19,627 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:19,630 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-08 09:09:19,631 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-08 09:09:19,631 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:19,632 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:19,633 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:19,634 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,634 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,634 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,634 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,634 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:19,635 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:19,635 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:19,635 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:19,636 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:19,636 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:19,636 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:19,637 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:19,637 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:19,638 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,638 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,638 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,638 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,638 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:19,648 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:19,655 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:19,662 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:19,669 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:19,671 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:19,671 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:19,677 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:19,678 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:19,678 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-08 09:09:19,679 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,679 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-08 09:09:19,679 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,679 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-08 09:09:19,680 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-08 09:09:19,680 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-08 09:09:19,680 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-08 09:09:19,681 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:19,681 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:19,681 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-08 09:09:19,682 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-08 09:09:19,682 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:19,686 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 38]), 37)
2023-10-08 09:09:19,686 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,686 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 38]), 37)
2023-10-08 09:09:19,686 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,686 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-08 09:09:19,687 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-08 09:09:19,687 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-08 09:09:19,687 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-08 09:09:19,688 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:19,688 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:19,688 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-08 09:09:19,688 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-08 09:09:19,692 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:19,696 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,696 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,696 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,696 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,696 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-08 09:09:19,700 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-08 09:09:19,702 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-08 09:09:19,704 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-08 09:09:19,706 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-08 09:09:19,707 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-08 09:09:19,707 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-08 09:09:19,709 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-08 09:09:19,712 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:19,716 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,716 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,717 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,717 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,717 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-08 09:09:19,720 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-08 09:09:19,722 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-08 09:09:19,728 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-08 09:09:19,732 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-08 09:09:19,733 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-08 09:09:19,733 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-08 09:09:19,735 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-08 09:09:19,739 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:19,743 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,743 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,743 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,743 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,744 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-08 09:09:19,747 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-08 09:09:19,749 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-08 09:09:19,751 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-08 09:09:19,753 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-08 09:09:19,754 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-08 09:09:19,754 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-08 09:09:19,756 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-08 09:09:19,759 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:19,763 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,763 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,764 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,764 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,764 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-08 09:09:19,767 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-08 09:09:19,769 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-08 09:09:19,771 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-08 09:09:19,773 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-08 09:09:19,774 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-08 09:09:19,774 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-08 09:09:19,776 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-08 09:09:19,779 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:19,783 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,783 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,784 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,784 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,784 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-08 09:09:19,787 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-08 09:09:19,789 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-08 09:09:19,791 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-08 09:09:19,793 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-08 09:09:19,794 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-08 09:09:19,794 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-08 09:09:19,795 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-08 09:09:19,799 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:19,803 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,803 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,804 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,804 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,804 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-08 09:09:19,808 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-08 09:09:19,810 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-08 09:09:19,812 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-08 09:09:19,813 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-08 09:09:19,814 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-08 09:09:19,814 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-08 09:09:19,815 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-08 09:09:19,819 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:19,823 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,823 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,823 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,823 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,824 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-08 09:09:19,826 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-08 09:09:19,828 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-08 09:09:19,831 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-08 09:09:19,832 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-08 09:09:19,833 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-08 09:09:19,833 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-08 09:09:19,835 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-08 09:09:19,838 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:19,842 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,842 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,842 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,842 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,843 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-08 09:09:19,846 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-08 09:09:19,848 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-08 09:09:19,850 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-08 09:09:19,852 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-08 09:09:19,853 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-08 09:09:19,853 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-08 09:09:19,854 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-08 09:09:19,858 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:19,861 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,862 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,862 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,862 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,862 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-08 09:09:19,866 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-08 09:09:19,867 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-08 09:09:19,869 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-08 09:09:19,871 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-08 09:09:19,872 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-08 09:09:19,872 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-08 09:09:19,873 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-08 09:09:19,877 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:19,881 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,881 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,881 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,881 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,881 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-08 09:09:19,884 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-08 09:09:19,886 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-08 09:09:19,888 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-08 09:09:19,890 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-08 09:09:19,891 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-08 09:09:19,891 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-08 09:09:19,892 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-08 09:09:19,896 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:19,900 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,900 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,900 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,900 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,900 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-08 09:09:19,904 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-08 09:09:19,906 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-08 09:09:19,907 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-08 09:09:19,909 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-08 09:09:19,910 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-08 09:09:19,910 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-08 09:09:19,912 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-08 09:09:19,916 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:19,916 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,916 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,916 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,917 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-08 09:09:19,917 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-08 09:09:19,920 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-08 09:09:19,921 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-08 09:09:19,924 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-08 09:09:19,926 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-08 09:09:19,927 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-08 09:09:19,927 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-08 09:09:19,928 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-08 09:09:19,929 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:19,930 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,930 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,930 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,930 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,930 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-08 09:09:19,930 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-08 09:09:19,931 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-08 09:09:19,931 [layer_forward.py:97 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-08 09:09:19,931 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-08 09:09:19,931 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-08 09:09:19,931 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-08 09:09:19,932 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-08 09:09:19,932 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-08 09:09:19,933 [layer_forward.py:83 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-08 09:09:19,933 [layer_forward.py:84 in new_forward] DEBUG - kwargs: {}
2023-10-08 09:09:19,933 [layer_forward.py:90 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-08 09:09:19,933 [layer_forward.py:91 in new_forward] DEBUG - kwargs_0: {}
2023-10-08 09:09:19,933 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-08 09:09:19,942 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-08 09:09:19,949 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-08 09:09:19,956 [layer_forward.py:97 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-08 09:09:19,964 [layer_forward.py:109 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-08 09:09:19,966 [layer_forward.py:111 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-08 09:09:19,966 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-08 09:09:19,971 [generate_test.py:40 in test_hf_gen] INFO - for i in range(10):                               
2023-10-08 09:09:19,971 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-08 09:09:19,971 [generate_test.py:40 in test_hf_gen] INFO - Who are you? Are you conscious?
I'm a woman. I'm not conscious.
I'm not conscious. I'm not conscious.
I'm not conscious. I'm
2023-10-08 09:09:19,972 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-08 09:09:19,972 [generate_test.py:40 in test_hf_gen] INFO - Where is Deutschland?
I'm in Germany.
2023-10-08 09:09:19,972 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-08 09:09:19,972 [generate_test.py:40 in test_hf_gen] INFO - How is Huawei Mate 60 Pro?
Huawei Mate 60 Pro is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone
2023-10-08 09:09:19,972 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-08 09:09:19,972 [generate_test.py:40 in test_hf_gen] INFO - for i in range(10):                               
2023-10-08 09:09:19,972 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-08 09:09:19,973 [generate_test.py:40 in test_hf_gen] INFO - Who are you? Are you conscious?
I'm a woman. I'm not conscious.
I'm not conscious. I'm not conscious.
I'm not conscious. I'm
2023-10-08 09:09:19,973 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-08 09:09:19,973 [generate_test.py:40 in test_hf_gen] INFO - Where is Deutschland?
I'm in Germany.
2023-10-08 09:09:19,973 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-08 09:09:19,973 [generate_test.py:40 in test_hf_gen] INFO - How is Huawei Mate 60 Pro?
Huawei Mate 60 Pro is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone
2023-10-08 09:09:19,973 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-08 09:09:19,982 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.embed_tokens from flexgen to old.
2023-10-08 09:09:19,983 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.embed_positions from flexgen to old.
2023-10-08 09:09:19,983 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.layers.0 from flexgen to old.
2023-10-08 09:09:19,983 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.layers.1 from flexgen to old.
2023-10-08 09:09:19,983 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.layers.2 from flexgen to old.
2023-10-08 09:09:19,983 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.layers.3 from flexgen to old.
2023-10-08 09:09:19,983 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.layers.4 from flexgen to old.
2023-10-08 09:09:19,983 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.layers.5 from flexgen to old.
2023-10-08 09:09:19,984 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.layers.6 from flexgen to old.
2023-10-08 09:09:19,984 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.layers.7 from flexgen to old.
2023-10-08 09:09:19,984 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.layers.8 from flexgen to old.
2023-10-08 09:09:19,984 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.layers.9 from flexgen to old.
2023-10-08 09:09:19,984 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.layers.10 from flexgen to old.
2023-10-08 09:09:19,984 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.layers.11 from flexgen to old.
2023-10-08 09:09:19,984 [layer_forward.py:22 in reset_forward] DEBUG - model.decoder.final_layer_norm from flexgen to old.
2023-10-08 09:09:19,984 [layer_forward.py:22 in reset_forward] DEBUG - lm_head from flexgen to old.
