2023-10-09 05:35:45,840 [instantiator.py:21 in <module>] INFO - Created a temporary directory at /tmp/tmpamwro_wa
2023-10-09 05:35:45,841 [instantiator.py:76 in _write] INFO - Writing /tmp/tmpamwro_wa/_remote_module_non_scriptable.py
2023-10-09 05:35:46,065 [connectionpool.py:1003 in _new_conn] DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2023-10-09 05:35:46,133 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1" 200 0
2023-10-09 05:35:50,430 [tpu_cluster_resolver.py:32 in <module>] DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2023-10-09 05:35:51,577 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5
2023-10-09 05:35:51,577 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7
2023-10-09 05:35:51,577 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5
2023-10-09 05:35:51,578 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7
2023-10-09 05:35:53,228 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1" 200 0
2023-10-09 05:35:53,364 [model_loader.py:159 in check_disk] INFO - [], ['lm_head.weight']
2023-10-09 05:35:53,402 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1" 200 0
2023-10-09 05:35:53,491 [model_loader.py:159 in check_disk] INFO - [], ['lm_head.weight']
2023-10-09 05:35:53,492 [model_loader.py:182 in download] INFO - The whole model has been downloaded an processed to offload_folder: 'offload_dir/facebook.opt-125m'
2023-10-09 05:35:53,502 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.embed_tokens, [0. 0. 1.], size_todo: 86630400
2023-10-09 05:35:53,503 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.embed_positions, [0. 0. 1.], size_todo: 85056000
2023-10-09 05:35:53,505 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.final_layer_norm, [0.00000000e+00 1.91116887e-05 9.99980888e-01], size_todo: 85054464
2023-10-09 05:35:53,506 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.0, [0.         0.05002193 0.94997807], size_todo: 77966592
2023-10-09 05:35:53,507 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.1, [0.         0.08698539 0.91301461], size_todo: 70878720
2023-10-09 05:35:53,507 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.2, [0.         0.11542163 0.88457837], size_todo: 63790848
2023-10-09 05:35:53,508 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.3, [0.         0.13797624 0.86202376], size_todo: 56702976
2023-10-09 05:35:53,509 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.4, [0.       0.156303 0.843697], size_todo: 49615104
2023-10-09 05:35:53,510 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.5, [0.       0.200013 0.799987], size_todo: 42527232
2023-10-09 05:35:53,511 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.6, [0.         0.21055017 0.78944983], size_todo: 35439360
2023-10-09 05:35:53,512 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.7, [0.         0.24389645 0.75610355], size_todo: 28351488
2023-10-09 05:35:53,513 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.8, [0.         0.25000554 0.74999446], size_todo: 21263616
2023-10-09 05:35:53,514 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.9, [0.         0.27657765 0.72342235], size_todo: 14175744
2023-10-09 05:35:53,515 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.10, [0.         0.27999324 0.72000676], size_todo: 7087872
2023-10-09 05:35:53,515 [model_loader.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.11, [0.         0.30186053 0.69813947], size_todo: 0
2023-10-09 05:35:53,516 [model_loader.py:138 in get_policy_weight_map] DEBUG - lm_head, [0.         0.30186053 0.69813947], size_todo: 0
2023-10-09 05:35:53,516 [model_loader.py:142 in get_policy_weight_map] INFO - device_map is prepared!
2023-10-09 05:35:53,518 [model_loader.py:148 in get_policy_weight_map] INFO - CausalLM facebook/opt-125m is to be loaded on: 
GPU Mem 0.00 GiB (0.00%), CPU Mem 0.07 GiB (30.19%), Disk Mem 0.16 Gib (69.81%)
2023-10-09 05:35:53,520 [model_loader.py:241 in init_all_weights] DEBUG - init all weights...
2023-10-09 05:35:53,550 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.embed_tokens to test forward
2023-10-09 05:35:53,550 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.embed_positions to test forward
2023-10-09 05:35:53,550 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.final_layer_norm to test forward
2023-10-09 05:35:53,550 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.layers.0 to test forward
2023-10-09 05:35:53,551 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.layers.1 to test forward
2023-10-09 05:35:53,551 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.layers.2 to test forward
2023-10-09 05:35:53,551 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.layers.3 to test forward
2023-10-09 05:35:53,551 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.layers.4 to test forward
2023-10-09 05:35:53,551 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.layers.5 to test forward
2023-10-09 05:35:53,551 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.layers.6 to test forward
2023-10-09 05:35:53,551 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.layers.7 to test forward
2023-10-09 05:35:53,551 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.layers.8 to test forward
2023-10-09 05:35:53,552 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.layers.9 to test forward
2023-10-09 05:35:53,552 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.layers.10 to test forward
2023-10-09 05:35:53,552 [layer_forward.py:44 in to_test_forward] DEBUG - model.decoder.layers.11 to test forward
2023-10-09 05:35:53,552 [layer_forward.py:44 in to_test_forward] DEBUG - lm_head to test forward
2023-10-09 05:35:53,587 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2023-10-09 05:35:53,888 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:53,898 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:53,917 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:53,925 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:53,925 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:54,068 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:54,072 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:54,145 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:54,147 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:54,213 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:54,216 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:54,294 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:54,296 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:54,371 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:54,374 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:54,456 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:54,458 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:54,536 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:54,538 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:54,613 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:54,615 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:54,696 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:54,698 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:54,764 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:54,766 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:54,835 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:54,838 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:54,910 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:54,912 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:54,914 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:54,915 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:55,074 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:55,087 [generate_test.py:40 in test_hf_gen] INFO - 0.
2023-10-09 05:35:55,087 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-09 05:35:55,096 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.embed_tokens from test to old.
2023-10-09 05:35:55,096 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.embed_positions from test to old.
2023-10-09 05:35:55,096 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.final_layer_norm from test to old.
2023-10-09 05:35:55,096 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.layers.0 from test to old.
2023-10-09 05:35:55,096 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.layers.1 from test to old.
2023-10-09 05:35:55,096 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.layers.2 from test to old.
2023-10-09 05:35:55,097 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.layers.3 from test to old.
2023-10-09 05:35:55,097 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.layers.4 from test to old.
2023-10-09 05:35:55,097 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.layers.5 from test to old.
2023-10-09 05:35:55,097 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.layers.6 from test to old.
2023-10-09 05:35:55,097 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.layers.7 from test to old.
2023-10-09 05:35:55,097 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.layers.8 from test to old.
2023-10-09 05:35:55,097 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.layers.9 from test to old.
2023-10-09 05:35:55,097 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.layers.10 from test to old.
2023-10-09 05:35:55,097 [layer_forward.py:24 in reset_forward] DEBUG - model.decoder.layers.11 from test to old.
2023-10-09 05:35:55,098 [layer_forward.py:24 in reset_forward] DEBUG - lm_head from test to old.
2023-10-09 05:35:55,098 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.embed_tokens to flexgen forward
2023-10-09 05:35:55,098 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.embed_positions to flexgen forward
2023-10-09 05:35:55,098 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.layers.0 to flexgen forward
2023-10-09 05:35:55,098 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.layers.1 to flexgen forward
2023-10-09 05:35:55,098 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.layers.2 to flexgen forward
2023-10-09 05:35:55,098 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.layers.3 to flexgen forward
2023-10-09 05:35:55,098 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.layers.4 to flexgen forward
2023-10-09 05:35:55,099 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.layers.5 to flexgen forward
2023-10-09 05:35:55,099 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.layers.6 to flexgen forward
2023-10-09 05:35:55,099 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.layers.7 to flexgen forward
2023-10-09 05:35:55,099 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.layers.8 to flexgen forward
2023-10-09 05:35:55,099 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.layers.9 to flexgen forward
2023-10-09 05:35:55,099 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.layers.10 to flexgen forward
2023-10-09 05:35:55,099 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.layers.11 to flexgen forward
2023-10-09 05:35:55,099 [layer_forward.py:115 in to_flexgen_forward] DEBUG - model.decoder.final_layer_norm to flexgen forward
2023-10-09 05:35:55,100 [layer_forward.py:115 in to_flexgen_forward] DEBUG - lm_head to flexgen forward
2023-10-09 05:35:55,147 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2023-10-09 05:35:55,334 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:55,335 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:55,335 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9]),)
2023-10-09 05:35:55,335 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:55,336 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9]),)
2023-10-09 05:35:55,336 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:55,336 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:55,336 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:55,336 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:55,336 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:55,337 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 9, 768])
2023-10-09 05:35:55,337 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 9, 768])
2023-10-09 05:35:55,337 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:55,338 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:55,338 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:55,342 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9]), 0)
2023-10-09 05:35:55,342 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:55,342 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9]), 0)
2023-10-09 05:35:55,342 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:55,342 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:55,343 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:55,343 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:55,343 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:55,344 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 9, 768])
2023-10-09 05:35:55,344 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 9, 768])
2023-10-09 05:35:55,344 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:55,344 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:55,348 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:55,352 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,352 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,352 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,352 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,352 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:55,375 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:55,380 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:55,387 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:55,391 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-09 05:35:55,392 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-09 05:35:55,392 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:55,397 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:55,402 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:55,408 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,408 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,408 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,408 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,408 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:55,415 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:55,419 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:55,425 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:55,429 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-09 05:35:55,430 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-09 05:35:55,430 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:55,434 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:55,440 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:55,446 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,447 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,447 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,447 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,447 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:55,453 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:55,457 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:55,463 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:55,467 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-09 05:35:55,468 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-09 05:35:55,468 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:55,472 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:55,478 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:55,481 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,482 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,482 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,482 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,482 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:55,487 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:55,493 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:55,497 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:55,500 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-09 05:35:55,501 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-09 05:35:55,501 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:55,505 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:55,511 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:55,518 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,518 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,518 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,519 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,519 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:55,539 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:55,543 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:55,548 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:55,553 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-09 05:35:55,553 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-09 05:35:55,554 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:55,556 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:55,560 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:55,563 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,564 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,564 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,564 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,564 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:55,571 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:55,575 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:55,580 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:55,584 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-09 05:35:55,585 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-09 05:35:55,585 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:55,587 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:55,591 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:55,595 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,595 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,595 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,595 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,595 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:55,600 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:55,605 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:55,609 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:55,615 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-09 05:35:55,615 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-09 05:35:55,615 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:55,618 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:55,622 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:55,625 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,625 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,626 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,626 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,626 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:55,631 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:55,635 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:55,639 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:55,643 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-09 05:35:55,643 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-09 05:35:55,643 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:55,645 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:55,649 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:55,653 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,653 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,653 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,653 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,654 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:55,658 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:55,663 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:55,667 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:55,672 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-09 05:35:55,673 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-09 05:35:55,673 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:55,676 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:55,679 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:55,683 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,683 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,683 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,683 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,683 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:55,689 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:55,693 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:55,698 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:55,701 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-09 05:35:55,702 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-09 05:35:55,702 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:55,704 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:55,707 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:55,712 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,712 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,712 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,712 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,713 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:55,716 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:55,720 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:55,723 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:55,727 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-09 05:35:55,727 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-09 05:35:55,728 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:55,730 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:55,734 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:55,734 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,734 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,735 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,735 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 9, 9]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,735 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:55,740 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:55,744 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:55,748 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:55,752 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 9, 768]), (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])))
2023-10-09 05:35:55,752 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 9, 768]), (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])))
2023-10-09 05:35:55,752 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:55,754 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:55,755 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:55,755 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,755 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:55,756 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,756 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:55,756 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:55,756 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:55,756 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:55,756 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:55,757 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 9, 768])
2023-10-09 05:35:55,757 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 9, 768])
2023-10-09 05:35:55,757 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:55,757 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:55,758 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:55,758 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 9, 768]),)
2023-10-09 05:35:55,758 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:55,759 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 9, 768]),)
2023-10-09 05:35:55,759 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:55,759 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:55,773 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:55,788 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:55,803 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:55,814 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 9, 50272])
2023-10-09 05:35:55,817 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 9, 50272])
2023-10-09 05:35:55,818 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:55,830 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:55,831 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:55,832 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:55,832 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:55,833 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:55,833 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:55,833 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:55,833 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:55,834 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:55,834 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:55,834 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:55,835 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:55,835 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:55,835 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:55,836 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:55,840 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 10]), 9)
2023-10-09 05:35:55,840 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:55,840 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 10]), 9)
2023-10-09 05:35:55,840 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:55,841 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:55,841 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:55,841 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:55,841 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:55,842 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:55,842 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:55,842 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:55,842 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:55,846 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:55,850 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:55,850 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,850 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:55,851 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,851 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:55,857 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:55,859 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:55,861 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:55,864 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-09 05:35:55,865 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-09 05:35:55,865 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:55,866 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:55,870 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:55,875 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:55,875 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,876 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:55,876 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,876 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:55,879 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:55,882 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:55,885 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:55,888 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-09 05:35:55,888 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-09 05:35:55,889 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:55,890 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:55,895 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:55,901 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:55,902 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,902 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:55,902 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,902 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:55,908 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:55,910 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:55,913 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:55,915 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-09 05:35:55,915 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-09 05:35:55,915 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:55,917 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:55,921 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:55,925 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:55,925 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,925 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:55,925 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,925 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:55,928 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:55,931 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:55,933 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:55,936 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-09 05:35:55,937 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-09 05:35:55,937 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:55,938 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:55,942 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:55,946 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:55,947 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,947 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:55,947 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,947 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:55,950 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:55,953 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:55,955 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:55,957 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-09 05:35:55,958 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-09 05:35:55,958 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:55,959 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:55,963 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:55,968 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:55,968 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,968 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:55,968 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:55,968 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:55,971 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:55,983 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:55,993 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:55,996 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-09 05:35:55,996 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-09 05:35:55,997 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:55,998 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:56,003 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:56,008 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,009 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,009 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,009 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,009 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:56,013 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:56,016 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:56,018 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:56,020 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-09 05:35:56,021 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-09 05:35:56,021 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:56,023 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:56,026 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:56,031 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,031 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,031 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,032 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,032 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:56,035 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:56,038 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:56,040 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:56,042 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-09 05:35:56,042 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-09 05:35:56,042 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:56,043 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:56,048 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:56,053 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,053 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,054 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,054 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,054 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:56,057 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:56,060 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:56,063 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:56,065 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-09 05:35:56,065 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-09 05:35:56,066 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:56,067 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:56,071 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:56,075 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,076 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,076 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,076 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,076 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:56,080 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:56,082 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:56,085 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:56,087 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-09 05:35:56,087 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-09 05:35:56,088 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:56,089 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:56,092 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:56,097 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,097 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,098 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,098 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,098 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:56,101 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:56,104 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:56,107 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:56,109 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-09 05:35:56,109 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-09 05:35:56,109 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:56,111 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:56,114 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:56,115 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,115 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 9, 64]), torch.Size([8, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,115 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,115 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 10]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 9, 64]), torch.Size([2, 12, 9, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,115 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:56,121 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:56,124 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:56,126 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:56,129 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-09 05:35:56,130 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-09 05:35:56,130 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:56,131 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:56,132 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:56,132 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,132 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:56,133 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,133 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:56,133 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:56,133 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:56,133 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:56,134 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:56,134 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:56,134 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:56,134 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:56,135 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:56,135 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:56,135 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,135 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:56,136 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,136 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:56,136 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:56,146 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:56,154 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:56,162 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:56,170 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:35:56,171 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:35:56,171 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:56,177 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:56,177 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:56,178 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:56,178 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:56,178 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:56,178 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:56,178 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:56,179 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:56,179 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:56,179 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:56,179 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:56,179 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:56,179 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:56,180 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:56,180 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:56,184 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 11]), 10)
2023-10-09 05:35:56,184 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:56,184 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 11]), 10)
2023-10-09 05:35:56,184 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:56,185 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:56,185 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:56,185 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:56,185 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:56,186 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:56,186 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:56,186 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:56,186 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:56,190 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:56,193 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,194 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,194 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,194 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,194 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:56,198 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:56,200 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:56,202 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:56,204 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-09 05:35:56,204 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-09 05:35:56,204 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:56,206 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:56,210 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:56,213 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,213 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,214 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,214 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,214 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:56,217 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:56,219 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:56,223 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:56,225 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-09 05:35:56,225 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-09 05:35:56,225 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:56,227 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:56,231 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:56,234 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,235 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,235 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,235 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,235 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:56,239 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:56,241 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:56,243 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:56,244 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-09 05:35:56,245 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-09 05:35:56,245 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:56,247 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:56,250 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:56,254 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,254 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,254 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,255 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,255 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:56,258 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:56,260 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:56,263 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:56,264 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-09 05:35:56,265 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-09 05:35:56,265 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:56,267 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:56,270 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:56,274 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,274 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,275 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,275 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,275 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:56,280 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:56,282 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:56,284 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:56,286 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-09 05:35:56,287 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-09 05:35:56,287 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:56,288 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:56,292 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:56,296 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,297 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,297 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,297 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,297 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:56,306 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:56,308 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:56,310 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:56,312 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-09 05:35:56,312 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-09 05:35:56,313 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:56,314 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:56,317 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:56,321 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,322 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,322 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,322 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,322 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:56,326 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:56,328 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:56,330 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:56,332 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-09 05:35:56,333 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-09 05:35:56,333 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:56,335 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:56,338 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:56,343 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,343 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,343 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,343 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,343 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:56,347 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:56,350 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:56,352 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:56,354 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-09 05:35:56,355 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-09 05:35:56,355 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:56,356 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:56,360 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:56,364 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,364 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,365 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,365 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,365 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:56,369 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:56,371 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:56,379 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:56,382 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-09 05:35:56,382 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-09 05:35:56,383 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:56,385 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:56,389 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:56,393 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,393 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,393 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,394 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,394 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:56,397 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:56,399 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:56,401 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:56,403 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-09 05:35:56,403 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-09 05:35:56,404 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:56,405 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:56,409 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:56,414 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,414 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,414 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,414 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,414 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:56,419 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:56,421 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:56,423 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:56,425 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-09 05:35:56,426 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-09 05:35:56,426 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:56,428 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:56,432 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:56,432 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,432 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,433 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,433 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,433 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:56,438 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:56,441 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:56,444 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:56,446 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-09 05:35:56,447 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-09 05:35:56,447 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:56,448 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:56,449 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:56,450 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,450 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:56,450 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,450 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:56,450 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:56,451 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:56,451 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:56,451 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:56,451 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:56,451 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:56,452 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:56,452 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:56,452 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:56,453 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,453 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:56,453 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,453 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:56,453 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:56,463 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:56,471 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:56,479 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:56,488 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:35:56,490 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:35:56,490 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:56,495 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:56,495 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:56,496 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:56,496 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:56,496 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:56,496 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:56,496 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:56,497 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:56,497 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:56,497 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:56,497 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:56,498 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:56,498 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:56,498 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:56,499 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:56,503 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 12]), 11)
2023-10-09 05:35:56,503 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:56,503 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 12]), 11)
2023-10-09 05:35:56,503 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:56,503 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:56,504 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:56,504 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:56,504 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:56,505 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:56,505 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:56,505 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:56,505 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:56,509 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:56,513 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,513 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,514 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,514 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,514 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:56,518 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:56,520 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:56,522 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:56,525 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-09 05:35:56,526 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-09 05:35:56,526 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:56,528 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:56,532 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:56,536 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,537 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,537 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,537 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,537 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:56,541 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:56,544 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:56,546 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:56,552 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-09 05:35:56,553 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-09 05:35:56,554 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:56,555 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:56,559 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:56,563 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,563 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,563 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,563 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,563 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:56,567 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:56,569 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:56,572 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:56,574 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-09 05:35:56,575 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-09 05:35:56,575 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:56,576 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:56,580 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:56,584 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,584 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,584 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,584 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,584 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:56,588 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:56,590 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:56,592 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:56,595 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-09 05:35:56,595 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-09 05:35:56,595 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:56,597 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:56,600 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:56,604 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,604 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,605 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,605 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,605 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:56,616 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:56,618 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:56,621 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:56,624 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-09 05:35:56,624 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-09 05:35:56,624 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:56,626 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:56,629 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:56,633 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,633 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,633 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,633 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,633 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:56,637 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:56,640 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:56,642 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:56,645 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-09 05:35:56,645 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-09 05:35:56,646 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:56,647 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:56,650 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:56,654 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,654 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,654 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,654 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,655 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:56,657 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:56,659 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:56,662 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:56,664 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-09 05:35:56,665 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-09 05:35:56,665 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:56,666 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:56,670 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:56,673 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,673 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,674 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,674 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,674 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:56,677 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:56,679 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:56,681 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:56,684 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-09 05:35:56,684 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-09 05:35:56,684 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:56,685 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:56,689 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:56,692 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,692 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,693 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,693 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,693 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:56,696 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:56,698 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:56,701 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:56,703 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-09 05:35:56,704 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-09 05:35:56,704 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:56,705 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:56,709 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:56,712 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,713 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,713 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,713 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,713 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:56,716 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:56,719 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:56,723 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:56,725 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-09 05:35:56,725 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-09 05:35:56,725 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:56,727 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:56,731 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:56,735 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,735 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,735 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,735 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,735 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:56,739 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:56,742 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:56,744 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:56,746 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-09 05:35:56,747 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-09 05:35:56,747 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:56,749 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:56,752 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:56,752 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,752 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,753 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,753 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,753 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:56,756 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:56,759 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:56,762 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:56,765 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-09 05:35:56,765 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-09 05:35:56,766 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:56,768 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:56,769 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:56,769 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,769 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:56,769 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,770 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:56,770 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:56,770 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:56,770 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:56,771 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:56,771 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:56,772 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:56,772 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:56,773 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:56,773 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:56,774 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,774 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:56,774 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,774 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:56,774 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:56,783 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:56,789 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:56,797 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:56,804 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:35:56,805 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:35:56,805 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:56,810 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:56,810 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:56,811 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:56,811 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:56,811 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:56,811 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:56,811 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:56,811 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:56,812 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:56,812 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:56,812 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:56,812 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:56,812 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:56,813 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:56,813 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:56,817 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 13]), 12)
2023-10-09 05:35:56,817 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:56,817 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 13]), 12)
2023-10-09 05:35:56,817 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:56,817 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:56,818 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:56,818 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:56,818 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:56,819 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:56,819 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:56,819 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:56,819 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:56,823 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:56,827 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,827 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,827 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,827 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,827 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:56,831 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:56,832 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:56,835 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:56,837 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-09 05:35:56,837 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-09 05:35:56,838 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:56,839 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:56,843 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:56,846 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,846 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,846 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,847 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,847 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:56,853 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:56,855 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:56,857 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:56,859 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-09 05:35:56,860 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-09 05:35:56,860 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:56,861 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:56,865 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:56,868 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,869 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,869 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,869 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,869 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:56,879 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:56,882 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:56,884 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:56,886 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-09 05:35:56,886 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-09 05:35:56,886 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:56,888 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:56,891 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:56,895 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,895 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,895 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,896 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,896 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:56,899 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:56,901 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:56,903 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:56,904 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-09 05:35:56,905 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-09 05:35:56,905 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:56,906 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:56,910 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:56,914 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,914 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,914 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,914 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,914 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:56,917 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:56,919 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:56,922 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:56,923 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-09 05:35:56,924 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-09 05:35:56,924 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:56,926 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:56,929 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:56,933 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,933 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,933 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,933 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,933 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:56,936 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:56,938 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:56,940 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:56,942 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-09 05:35:56,943 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-09 05:35:56,943 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:56,944 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:56,947 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:56,951 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,951 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,952 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,952 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,952 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:56,955 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:56,957 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:56,959 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:56,961 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-09 05:35:56,962 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-09 05:35:56,962 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:56,963 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:56,967 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:56,970 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,971 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,971 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,971 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,971 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:56,975 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:56,977 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:56,979 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:56,981 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-09 05:35:56,982 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-09 05:35:56,982 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:56,983 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:56,987 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:56,991 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:56,991 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,991 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:56,991 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:56,991 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:56,994 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:56,996 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:56,999 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:57,001 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-09 05:35:57,001 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-09 05:35:57,001 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:57,003 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:57,007 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:57,011 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,011 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,011 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,011 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,012 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:57,015 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:57,017 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:57,020 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:57,022 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-09 05:35:57,023 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-09 05:35:57,023 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:57,024 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:57,028 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:57,032 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,032 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,033 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,033 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,033 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:57,036 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:57,039 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:57,041 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:57,044 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-09 05:35:57,044 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-09 05:35:57,044 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:57,046 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:57,050 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:57,050 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,050 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,051 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,051 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,051 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:57,054 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:57,058 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:57,060 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:57,063 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-09 05:35:57,063 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-09 05:35:57,063 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:57,065 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:57,065 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:57,066 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,066 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:57,066 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,066 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:57,066 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:57,067 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:57,067 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:57,068 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:57,068 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:57,068 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:57,069 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:57,069 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:57,070 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:57,070 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,070 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:57,070 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,070 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:57,070 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:57,080 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:57,089 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:57,097 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:57,106 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:35:57,107 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:35:57,107 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:57,112 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:57,113 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:57,113 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:57,113 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:57,113 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:57,114 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:57,114 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:57,114 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:57,114 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:57,114 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:57,114 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:57,115 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:57,115 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:57,115 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:57,116 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:57,119 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 14]), 13)
2023-10-09 05:35:57,119 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:57,120 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 14]), 13)
2023-10-09 05:35:57,120 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:57,120 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:57,120 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:57,120 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:57,121 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:57,121 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:57,121 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:57,121 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:57,122 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:57,125 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:57,129 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,129 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,129 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,130 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,130 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:57,134 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:57,136 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:57,138 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:57,140 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-09 05:35:57,141 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-09 05:35:57,141 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:57,143 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:57,146 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:57,150 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,150 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,151 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,151 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,151 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:57,154 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:57,156 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:57,158 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:57,160 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-09 05:35:57,160 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-09 05:35:57,161 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:57,162 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:57,166 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:57,169 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,169 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,170 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,170 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,170 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:57,173 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:57,175 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:57,177 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:57,178 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-09 05:35:57,179 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-09 05:35:57,179 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:57,181 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:57,184 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:57,188 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,188 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,189 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,189 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,189 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:57,192 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:57,195 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:57,198 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:57,201 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-09 05:35:57,201 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-09 05:35:57,202 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:57,203 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:57,208 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:57,213 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,213 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,214 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,214 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,214 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:57,217 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:57,219 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:57,221 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:57,223 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-09 05:35:57,224 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-09 05:35:57,224 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:57,225 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:57,229 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:57,232 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,232 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,233 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,233 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,233 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:57,236 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:57,239 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:57,241 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:57,243 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-09 05:35:57,243 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-09 05:35:57,243 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:57,245 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:57,248 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:57,252 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,252 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,252 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,252 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,253 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:57,255 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:57,259 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:57,261 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:57,263 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-09 05:35:57,264 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-09 05:35:57,264 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:57,265 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:57,269 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:57,272 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,273 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,273 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,273 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,273 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:57,276 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:57,279 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:57,282 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:57,284 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-09 05:35:57,284 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-09 05:35:57,285 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:57,286 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:57,290 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:57,294 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,294 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,294 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,294 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,294 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:57,298 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:57,300 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:57,303 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:57,305 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-09 05:35:57,305 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-09 05:35:57,305 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:57,307 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:57,310 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:57,314 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,314 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,314 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,314 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,314 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:57,318 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:57,320 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:57,322 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:57,325 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-09 05:35:57,326 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-09 05:35:57,326 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:57,327 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:57,330 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:57,334 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,334 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,335 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,335 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,335 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:57,338 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:57,340 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:57,342 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:57,344 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-09 05:35:57,345 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-09 05:35:57,345 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:57,346 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:57,350 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:57,350 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,351 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,351 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,351 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,351 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:57,354 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:57,357 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:57,359 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:57,361 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-09 05:35:57,362 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-09 05:35:57,362 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:57,363 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:57,364 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:57,364 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,365 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:57,365 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,365 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:57,365 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:57,367 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:57,370 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:57,373 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:57,374 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:57,374 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:57,374 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:57,375 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:57,375 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:57,376 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,376 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:57,376 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,376 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:57,376 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:57,391 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:57,399 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:57,410 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:57,418 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:35:57,419 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:35:57,419 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:57,424 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:57,424 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:57,424 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:57,425 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:57,425 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:57,425 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:57,425 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:57,425 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:57,426 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:57,426 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:57,426 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:57,426 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:57,426 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:57,427 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:57,428 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:57,432 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 15]), 14)
2023-10-09 05:35:57,432 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:57,432 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 15]), 14)
2023-10-09 05:35:57,433 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:57,433 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:57,433 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:57,434 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:57,434 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:57,434 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:57,435 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:57,435 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:57,435 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:57,439 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:57,443 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,443 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,443 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,443 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,443 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:57,447 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:57,449 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:57,450 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:57,452 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-09 05:35:57,453 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-09 05:35:57,453 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:57,455 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:57,458 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:57,462 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,462 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,462 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,463 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,463 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:57,466 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:57,468 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:57,469 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:57,471 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-09 05:35:57,472 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-09 05:35:57,472 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:57,474 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:57,477 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:57,481 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,481 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,481 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,481 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,482 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:57,485 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:57,487 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:57,489 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:57,490 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-09 05:35:57,491 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-09 05:35:57,491 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:57,493 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:57,496 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:57,500 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,500 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,500 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,500 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,501 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:57,504 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:57,506 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:57,508 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:57,509 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-09 05:35:57,510 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-09 05:35:57,510 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:57,512 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:57,515 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:57,519 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,519 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,520 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,520 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,520 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:57,523 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:57,525 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:57,527 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:57,529 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-09 05:35:57,529 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-09 05:35:57,530 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:57,531 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:57,535 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:57,538 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,539 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,539 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,539 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,539 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:57,542 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:57,544 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:57,546 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:57,548 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-09 05:35:57,549 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-09 05:35:57,549 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:57,550 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:57,554 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:57,558 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,558 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,558 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,559 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,559 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:57,577 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:57,580 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:57,581 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:57,583 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-09 05:35:57,584 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-09 05:35:57,584 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:57,586 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:57,590 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:57,594 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,594 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,594 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,594 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,595 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:57,607 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:57,610 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:57,611 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:57,613 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-09 05:35:57,614 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-09 05:35:57,614 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:57,615 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:57,619 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:57,623 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,623 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,623 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,623 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,623 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:57,626 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:57,628 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:57,631 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:57,632 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-09 05:35:57,633 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-09 05:35:57,633 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:57,635 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:57,638 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:57,642 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,642 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,642 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,642 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,642 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:57,646 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:57,648 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:57,650 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:57,652 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-09 05:35:57,653 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-09 05:35:57,653 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:57,654 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:57,658 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:57,662 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,662 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,662 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,662 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,662 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:57,665 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:57,667 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:57,670 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:57,671 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-09 05:35:57,672 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-09 05:35:57,672 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:57,674 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:57,677 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:57,678 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,678 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,678 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,678 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,678 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:57,681 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:57,695 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:57,697 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:57,701 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-09 05:35:57,702 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-09 05:35:57,702 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:57,704 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:57,704 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:57,705 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,705 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:57,705 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,705 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:57,706 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:57,707 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:57,711 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:57,714 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:57,716 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:57,716 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:57,716 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:57,717 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:57,718 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:57,718 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,718 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:57,719 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,719 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:57,719 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:57,729 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:57,736 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:57,743 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:57,751 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:35:57,752 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:35:57,752 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:57,757 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:57,758 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:57,758 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:57,759 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:57,759 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:57,759 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:57,759 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:57,759 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:57,759 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:57,760 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:57,760 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:57,760 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:57,760 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:57,760 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:57,761 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:57,765 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 16]), 15)
2023-10-09 05:35:57,765 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:57,765 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 16]), 15)
2023-10-09 05:35:57,765 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:57,765 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:57,765 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:57,766 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:57,766 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:57,766 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:57,766 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:57,766 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:57,767 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:57,770 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:57,774 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,774 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,774 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,774 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,774 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:57,779 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:57,781 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:57,783 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:57,785 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-09 05:35:57,786 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-09 05:35:57,786 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:57,787 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:57,791 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:57,794 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,795 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,795 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,795 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,795 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:57,798 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:57,800 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:57,806 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:57,809 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-09 05:35:57,809 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-09 05:35:57,809 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:57,811 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:57,814 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:57,818 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,818 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,818 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,819 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,819 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:57,822 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:57,824 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:57,826 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:57,827 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-09 05:35:57,828 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-09 05:35:57,828 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:57,830 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:57,833 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:57,837 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,837 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,837 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,837 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,837 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:57,840 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:57,842 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:57,844 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:57,846 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-09 05:35:57,847 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-09 05:35:57,847 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:57,848 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:57,852 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:57,856 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,856 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,856 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,856 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,856 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:57,874 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:57,877 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:57,879 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:57,882 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-09 05:35:57,883 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-09 05:35:57,883 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:57,885 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:57,888 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:57,892 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,892 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,892 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,892 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,893 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:57,896 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:57,898 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:57,900 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:57,902 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-09 05:35:57,902 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-09 05:35:57,902 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:57,903 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:57,907 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:57,911 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,911 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,911 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,912 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,912 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:57,915 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:57,918 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:57,920 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:57,922 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-09 05:35:57,922 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-09 05:35:57,922 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:57,924 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:57,928 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:57,932 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,932 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,932 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,932 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,932 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:57,936 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:57,939 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:57,941 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:57,943 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-09 05:35:57,944 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-09 05:35:57,944 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:57,945 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:57,949 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:57,953 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,953 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,954 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,954 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,954 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:57,961 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:57,963 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:57,965 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:57,967 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-09 05:35:57,968 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-09 05:35:57,968 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:57,970 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:57,975 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:57,979 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:57,980 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,980 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:57,980 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:57,980 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:57,984 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:57,987 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:57,989 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:57,991 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-09 05:35:57,991 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-09 05:35:57,992 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:57,993 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:57,997 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:58,002 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,003 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,003 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,003 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,003 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:58,007 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:58,011 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:58,015 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:58,018 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-09 05:35:58,019 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-09 05:35:58,019 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:58,021 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:58,027 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:58,027 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,027 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,028 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,028 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,028 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:58,031 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:58,035 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:58,037 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:58,039 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-09 05:35:58,039 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-09 05:35:58,039 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:58,041 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:58,042 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:58,042 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,042 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:58,042 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,043 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:58,043 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:58,043 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:58,043 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:58,044 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:58,044 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:58,044 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:58,044 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:58,045 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:58,045 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:58,045 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,046 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:58,046 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,046 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:58,046 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:58,092 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:58,102 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:58,111 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:58,122 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:35:58,124 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:35:58,124 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:58,130 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:58,131 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:58,132 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:58,132 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:58,132 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:58,132 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:58,132 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:58,132 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:58,133 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:58,133 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:58,133 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:58,133 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:58,133 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:58,134 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:58,134 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:58,138 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 17]), 16)
2023-10-09 05:35:58,139 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:58,139 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 17]), 16)
2023-10-09 05:35:58,139 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:58,139 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:58,139 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:58,140 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:58,140 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:58,140 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:58,140 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:58,140 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:58,141 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:58,144 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:58,148 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,148 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,148 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,149 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,149 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:58,154 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:58,156 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:58,158 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:58,160 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-09 05:35:58,161 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-09 05:35:58,161 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:58,163 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:58,166 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:58,170 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,170 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,171 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,171 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,171 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:58,182 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:58,184 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:58,186 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:58,188 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-09 05:35:58,189 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-09 05:35:58,189 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:58,191 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:58,194 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:58,198 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,198 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,198 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,199 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,199 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:58,209 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:58,213 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:58,215 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:58,218 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-09 05:35:58,219 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-09 05:35:58,219 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:58,220 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:58,224 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:58,230 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,230 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,230 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,231 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,231 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:58,235 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:58,239 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:58,242 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:58,244 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-09 05:35:58,244 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-09 05:35:58,244 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:58,246 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:58,250 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:58,254 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,254 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,254 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,254 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,254 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:58,259 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:58,262 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:58,265 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:58,267 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-09 05:35:58,267 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-09 05:35:58,267 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:58,269 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:58,272 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:58,276 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,276 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,276 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,276 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,277 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:58,280 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:58,283 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:58,285 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:58,289 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-09 05:35:58,289 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-09 05:35:58,290 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:58,291 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:58,294 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:58,298 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,298 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,298 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,299 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,299 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:58,302 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:58,305 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:58,307 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:58,310 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-09 05:35:58,310 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-09 05:35:58,310 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:58,312 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:58,316 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:58,323 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,325 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,326 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,326 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,327 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:58,351 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:58,355 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:58,360 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:58,363 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-09 05:35:58,364 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-09 05:35:58,365 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:58,367 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:58,370 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:58,374 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,374 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,375 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,375 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,375 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:58,382 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:58,385 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:58,388 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:58,391 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-09 05:35:58,392 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-09 05:35:58,392 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:58,394 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:58,397 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:58,401 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,401 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,401 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,401 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,402 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:58,405 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:58,408 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:58,411 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:58,413 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-09 05:35:58,414 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-09 05:35:58,414 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:58,415 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:58,419 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:58,423 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,423 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,423 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,423 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,423 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:58,449 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:58,452 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:58,455 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:58,459 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-09 05:35:58,459 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-09 05:35:58,460 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:58,462 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:58,468 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:58,468 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,469 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,469 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,469 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,469 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:58,473 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:58,477 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:58,482 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:58,485 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-09 05:35:58,486 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-09 05:35:58,486 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:58,488 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:58,489 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:58,489 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,490 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:58,490 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,490 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:58,490 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:58,492 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:58,495 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:58,498 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:58,501 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:58,501 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:58,502 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:58,503 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:58,504 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:58,505 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,505 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:58,506 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,506 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:58,506 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:58,521 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:58,531 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:58,542 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:58,553 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:35:58,555 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:35:58,555 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:58,560 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:58,560 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:58,561 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:58,561 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:58,561 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:58,562 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:58,562 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:58,562 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:58,562 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:58,563 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:58,563 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:58,563 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:58,563 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:58,564 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:58,564 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:58,568 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 18]), 17)
2023-10-09 05:35:58,569 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:58,569 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 18]), 17)
2023-10-09 05:35:58,569 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:58,569 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:58,569 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:58,570 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:58,570 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:58,570 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:58,570 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:58,571 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:58,571 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:58,574 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:58,578 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,578 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,578 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,579 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,579 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:58,583 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:58,585 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:58,588 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:58,591 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-09 05:35:58,592 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-09 05:35:58,592 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:58,594 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:58,597 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:58,601 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,601 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,601 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,601 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,601 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:58,605 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:58,608 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:58,610 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:58,613 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-09 05:35:58,613 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-09 05:35:58,614 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:58,615 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:58,619 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:58,622 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,622 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,623 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,623 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,623 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:58,627 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:58,629 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:58,633 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:58,636 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-09 05:35:58,636 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-09 05:35:58,636 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:58,638 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:58,641 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:58,645 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,645 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,645 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,645 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,646 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:58,655 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:58,658 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:58,661 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:58,664 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-09 05:35:58,665 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-09 05:35:58,665 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:58,667 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:58,671 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:58,675 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,675 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,675 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,676 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,676 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:58,679 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:58,682 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:58,685 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:58,688 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-09 05:35:58,688 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-09 05:35:58,689 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:58,691 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:58,694 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:58,698 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,698 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,698 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,698 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,699 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:58,703 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:58,706 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:58,709 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:58,712 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-09 05:35:58,712 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-09 05:35:58,712 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:58,714 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:58,718 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:58,722 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,722 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,723 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,723 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,723 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:58,727 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:58,730 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:58,732 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:58,735 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-09 05:35:58,735 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-09 05:35:58,736 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:58,738 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:58,741 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:58,745 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,745 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,745 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,745 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,745 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:58,749 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:58,753 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:58,755 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:58,758 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-09 05:35:58,758 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-09 05:35:58,759 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:58,760 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:58,764 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:58,767 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,767 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,768 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,768 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,768 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:58,772 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:58,774 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:58,776 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:58,778 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-09 05:35:58,779 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-09 05:35:58,779 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:58,780 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:58,784 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:58,787 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,788 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,788 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,788 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,788 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:58,791 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:58,794 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:58,796 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:58,798 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-09 05:35:58,799 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-09 05:35:58,799 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:58,800 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:58,803 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:58,807 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,807 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,807 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,807 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,807 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:58,811 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:58,812 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:58,814 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:58,816 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-09 05:35:58,817 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-09 05:35:58,817 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:58,818 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:58,821 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:58,822 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,822 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,822 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,822 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,823 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:58,826 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:58,828 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:58,830 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:58,831 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-09 05:35:58,832 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-09 05:35:58,832 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:58,833 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:58,834 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:58,834 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,834 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:58,835 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,835 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:58,835 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:58,835 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:58,835 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:58,835 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:58,835 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:58,836 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:58,836 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:58,836 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:58,836 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:58,837 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,837 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:58,837 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,837 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:58,837 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:58,846 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:58,853 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:58,861 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:58,869 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:35:58,870 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:35:58,870 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:58,875 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:58,876 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:58,876 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:58,877 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:58,877 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:58,877 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:58,877 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:58,877 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:58,877 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:58,878 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:58,878 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:58,878 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:58,878 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:58,879 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:58,879 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:58,883 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 19]), 18)
2023-10-09 05:35:58,883 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:58,883 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 19]), 18)
2023-10-09 05:35:58,883 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:58,883 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:58,884 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:58,884 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:58,884 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:58,884 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:58,885 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:58,885 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:58,885 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:58,888 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:58,892 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,892 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,892 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,892 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,892 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:58,896 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:58,899 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:58,900 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:58,902 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-09 05:35:58,903 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-09 05:35:58,903 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:58,905 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:58,908 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:58,911 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,911 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,912 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,912 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,912 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:58,915 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:58,917 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:58,919 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:58,921 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-09 05:35:58,922 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-09 05:35:58,922 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:58,923 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:58,927 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:58,930 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,930 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,930 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,931 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,931 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:58,934 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:58,936 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:58,938 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:58,939 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-09 05:35:58,940 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-09 05:35:58,940 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:58,941 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:58,945 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:58,948 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,948 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,948 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,948 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,949 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:58,952 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:58,954 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:58,955 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:58,957 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-09 05:35:58,958 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-09 05:35:58,958 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:58,959 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:58,963 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:58,966 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,967 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,967 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,967 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,967 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:58,971 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:58,973 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:58,975 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:58,977 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-09 05:35:58,978 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-09 05:35:58,978 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:58,979 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:58,983 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:58,986 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:58,986 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,986 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:58,987 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:58,987 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:58,990 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:58,992 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:58,994 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:58,995 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-09 05:35:58,996 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-09 05:35:58,996 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:58,997 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:59,000 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:59,004 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,004 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,004 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,005 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,005 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:59,008 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:59,010 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:59,012 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:59,014 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-09 05:35:59,015 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-09 05:35:59,015 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:59,016 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:59,019 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:59,023 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,023 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,023 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,023 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,023 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:59,026 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:59,028 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:59,031 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:59,032 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-09 05:35:59,033 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-09 05:35:59,033 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:59,034 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:59,038 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:59,041 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,041 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,042 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,042 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,042 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:59,045 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:59,047 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:59,049 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:59,051 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-09 05:35:59,051 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-09 05:35:59,052 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:59,053 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:59,056 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:59,060 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,060 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,060 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,060 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,060 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:59,063 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:59,065 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:59,068 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:59,070 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-09 05:35:59,070 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-09 05:35:59,070 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:59,071 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:59,075 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:59,079 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,079 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,079 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,079 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,079 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:59,082 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:59,084 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:59,086 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:59,088 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-09 05:35:59,088 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-09 05:35:59,088 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:59,090 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:59,093 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:59,094 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,094 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,094 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,094 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,094 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:59,097 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:59,100 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:59,102 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:59,104 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-09 05:35:59,105 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-09 05:35:59,105 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:59,106 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:59,107 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:59,107 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,107 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,107 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,107 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,107 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:59,108 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:59,108 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:59,108 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:59,108 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:59,108 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:59,108 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:59,109 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:59,109 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:59,109 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,110 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,110 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,110 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,110 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:59,120 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:59,128 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:59,136 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:59,145 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:35:59,145 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:35:59,145 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:59,150 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:59,150 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:59,151 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:59,151 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,151 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:59,151 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,151 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:59,151 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:59,151 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:59,152 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:59,152 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:59,152 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:59,152 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:59,152 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:59,153 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:59,157 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 20]), 19)
2023-10-09 05:35:59,157 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,157 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 20]), 19)
2023-10-09 05:35:59,157 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,157 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:59,157 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:59,158 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:59,158 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:59,158 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:59,158 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:59,158 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:59,159 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:59,162 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:59,165 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,165 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,166 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,166 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,166 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:59,169 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:59,171 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:59,173 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:59,175 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-09 05:35:59,175 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-09 05:35:59,176 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:59,177 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:59,181 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:59,184 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,184 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,184 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,184 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,185 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:59,188 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:59,190 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:59,191 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:59,193 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-09 05:35:59,193 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-09 05:35:59,194 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:59,195 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:59,198 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:59,202 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,202 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,202 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,202 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,202 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:59,206 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:59,207 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:59,209 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:59,211 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-09 05:35:59,211 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-09 05:35:59,211 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:59,213 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:59,216 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:59,220 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,220 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,220 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,220 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,220 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:59,224 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:59,226 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:59,227 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:59,229 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-09 05:35:59,230 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-09 05:35:59,230 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:59,231 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:59,235 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:59,238 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,239 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,239 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,239 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,239 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:59,242 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:59,243 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:59,246 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:59,247 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-09 05:35:59,248 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-09 05:35:59,248 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:59,249 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:59,252 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:59,256 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,256 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,256 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,256 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,256 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:59,260 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:59,262 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:59,263 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:59,265 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-09 05:35:59,265 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-09 05:35:59,266 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:59,267 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:59,270 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:59,274 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,274 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,274 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,274 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,274 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:59,277 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:59,279 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:59,281 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:59,283 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-09 05:35:59,283 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-09 05:35:59,284 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:59,285 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:59,288 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:59,292 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,292 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,292 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,292 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,292 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:59,295 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:59,297 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:59,299 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:59,301 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-09 05:35:59,302 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-09 05:35:59,302 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:59,303 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:59,306 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:59,310 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,310 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,310 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,310 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,310 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:59,314 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:59,316 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:59,319 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:59,320 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-09 05:35:59,321 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-09 05:35:59,321 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:59,323 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:59,326 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:59,329 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,330 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,330 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,330 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,330 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:59,333 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:59,335 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:59,337 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:59,340 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-09 05:35:59,340 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-09 05:35:59,340 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:59,342 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:59,345 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:59,348 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,349 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,349 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,349 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,349 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:59,352 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:59,355 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:59,357 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:59,358 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-09 05:35:59,359 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-09 05:35:59,359 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:59,360 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:59,363 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:59,364 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,364 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,364 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,364 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,365 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:59,368 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:59,370 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:59,372 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:59,373 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-09 05:35:59,374 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-09 05:35:59,374 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:59,375 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:59,376 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:59,376 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,376 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,376 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,376 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,376 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:59,377 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:59,377 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:59,377 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:59,377 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:59,377 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:59,378 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:59,378 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:59,378 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:59,379 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,379 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,379 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,379 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,379 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:59,391 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:59,398 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:59,406 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:59,416 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:35:59,419 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:35:59,419 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:59,424 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:59,425 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:59,425 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:59,425 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,425 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:59,425 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,425 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:59,426 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:59,426 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:59,426 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:59,426 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:59,426 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:59,426 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:59,427 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:59,427 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:59,431 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 21]), 20)
2023-10-09 05:35:59,431 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,431 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 21]), 20)
2023-10-09 05:35:59,431 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,431 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:59,432 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:59,432 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:59,432 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:59,432 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:59,432 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:59,433 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:59,433 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:59,436 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:59,439 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,440 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,440 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,440 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,440 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:59,443 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:59,446 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:59,448 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:59,449 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-09 05:35:59,450 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-09 05:35:59,450 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:59,452 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:59,455 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:59,458 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,458 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,459 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,459 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,459 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:59,462 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:59,464 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:59,466 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:59,468 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-09 05:35:59,468 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-09 05:35:59,468 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:59,470 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:59,473 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:59,476 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,477 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,477 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,477 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,477 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:59,480 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:59,482 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:59,485 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:59,487 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-09 05:35:59,488 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-09 05:35:59,488 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:59,490 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:59,493 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:59,496 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,496 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,497 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,497 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,497 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:59,500 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:59,502 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:59,504 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:59,506 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-09 05:35:59,507 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-09 05:35:59,507 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:59,508 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:59,511 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:59,515 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,515 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,515 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,515 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,516 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:59,518 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:59,520 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:59,523 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:59,524 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-09 05:35:59,525 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-09 05:35:59,525 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:59,527 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:59,530 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:59,533 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,533 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,534 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,534 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,534 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:59,538 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:59,540 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:59,541 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:59,543 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-09 05:35:59,544 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-09 05:35:59,544 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:59,545 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:59,549 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:59,552 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,552 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,553 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,553 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,553 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:59,556 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:59,558 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:59,560 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:59,562 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-09 05:35:59,562 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-09 05:35:59,563 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:59,564 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:59,567 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:59,571 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,571 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,571 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,571 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,571 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:59,575 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:59,577 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:59,579 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:59,580 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-09 05:35:59,581 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-09 05:35:59,581 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:59,582 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:59,585 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:59,589 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,589 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,590 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,590 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,590 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:59,593 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:59,595 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:59,597 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:59,598 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-09 05:35:59,599 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-09 05:35:59,599 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:59,600 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:59,604 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:59,607 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,607 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,607 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,608 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,608 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:59,611 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:59,614 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:59,615 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:59,617 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-09 05:35:59,618 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-09 05:35:59,618 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:59,619 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:59,622 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:59,626 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,626 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,626 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,626 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,626 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:59,629 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:59,631 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:59,633 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:59,635 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-09 05:35:59,636 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-09 05:35:59,636 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:59,637 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:59,640 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:59,641 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,641 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,641 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,642 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,642 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:59,645 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:59,648 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:59,650 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:59,651 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-09 05:35:59,652 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-09 05:35:59,652 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:59,654 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:59,654 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:59,655 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,655 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,655 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,655 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,655 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:59,655 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:59,656 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:59,656 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:59,656 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:59,656 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:59,656 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:59,657 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:59,657 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:59,658 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,658 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,658 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,658 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,658 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:59,669 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:59,679 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:59,687 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:59,695 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:35:59,696 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:35:59,697 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:59,701 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:59,702 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:59,702 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:59,702 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,702 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:59,702 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,702 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:59,703 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:59,703 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:59,703 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:59,703 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:59,703 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:59,703 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:59,704 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:59,704 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:59,708 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 22]), 21)
2023-10-09 05:35:59,708 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,708 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 22]), 21)
2023-10-09 05:35:59,708 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,708 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:59,709 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:59,709 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:59,709 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:59,710 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:59,710 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:59,710 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:59,710 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:59,713 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:59,717 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,717 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,717 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,717 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,717 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:35:59,721 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:35:59,723 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:35:59,725 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:35:59,727 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-09 05:35:59,727 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-09 05:35:59,727 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:35:59,729 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:35:59,732 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:59,736 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,736 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,736 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,736 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,736 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:35:59,739 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:35:59,741 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:35:59,743 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:35:59,745 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-09 05:35:59,746 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-09 05:35:59,746 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:35:59,747 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:35:59,751 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:59,754 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,754 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,754 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,755 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,755 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:35:59,758 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:35:59,759 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:35:59,762 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:35:59,764 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-09 05:35:59,764 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-09 05:35:59,764 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:35:59,766 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:35:59,769 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:59,772 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,773 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,773 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,773 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,773 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:35:59,776 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:35:59,778 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:35:59,780 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:35:59,782 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-09 05:35:59,783 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-09 05:35:59,783 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:35:59,784 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:35:59,788 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:59,791 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,791 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,792 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,792 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,792 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:35:59,795 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:35:59,797 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:35:59,799 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:35:59,801 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-09 05:35:59,802 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-09 05:35:59,802 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:35:59,803 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:35:59,806 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:59,810 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,811 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,811 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,811 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,811 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:35:59,814 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:35:59,817 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:35:59,819 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:35:59,821 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-09 05:35:59,821 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-09 05:35:59,821 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:35:59,823 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:35:59,826 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:59,830 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,830 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,830 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,830 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,830 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:35:59,834 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:35:59,836 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:35:59,838 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:35:59,840 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-09 05:35:59,840 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-09 05:35:59,841 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:35:59,843 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:35:59,846 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:59,850 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,850 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,850 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,850 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,850 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:35:59,854 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:35:59,856 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:35:59,857 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:35:59,859 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-09 05:35:59,866 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-09 05:35:59,866 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:35:59,867 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:35:59,871 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:59,874 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,875 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,875 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,875 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,875 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:35:59,878 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:35:59,881 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:35:59,883 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:35:59,885 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-09 05:35:59,885 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-09 05:35:59,886 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:35:59,887 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:35:59,890 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:59,894 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,894 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,894 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,894 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,895 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:35:59,898 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:35:59,900 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:35:59,902 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:35:59,904 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-09 05:35:59,905 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-09 05:35:59,905 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:35:59,906 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:35:59,909 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:59,913 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,913 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,913 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,913 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,913 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:35:59,917 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:35:59,919 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:35:59,920 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:35:59,923 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-09 05:35:59,924 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-09 05:35:59,924 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:35:59,926 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:35:59,929 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:59,930 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,930 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,930 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,930 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:35:59,930 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:35:59,933 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:35:59,935 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:35:59,938 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:35:59,940 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-09 05:35:59,940 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-09 05:35:59,940 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:35:59,942 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:35:59,943 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:59,943 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,943 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,944 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,944 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,944 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:35:59,944 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:35:59,944 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:35:59,944 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:35:59,944 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:59,945 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:59,945 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:35:59,945 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:35:59,945 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:59,946 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:35:59,946 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,946 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:35:59,946 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,946 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:35:59,955 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:35:59,963 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:35:59,970 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:35:59,978 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:35:59,979 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:35:59,979 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:35:59,983 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:35:59,984 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:59,984 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:35:59,985 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,985 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:35:59,985 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,985 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:35:59,985 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:35:59,985 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:35:59,986 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:35:59,986 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:59,986 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:59,986 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:35:59,987 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:35:59,987 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:59,991 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 23]), 22)
2023-10-09 05:35:59,991 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:35:59,991 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 23]), 22)
2023-10-09 05:35:59,991 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:35:59,991 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:35:59,991 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:35:59,992 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:35:59,992 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:35:59,992 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:35:59,992 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:35:59,993 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:35:59,993 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:35:59,996 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:00,003 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,003 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,004 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,004 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,004 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:00,026 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:00,031 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:00,036 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:00,039 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-09 05:36:00,040 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-09 05:36:00,040 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:00,041 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:00,045 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:00,049 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,049 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,049 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,049 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,049 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:00,054 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:00,056 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:00,059 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:00,062 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-09 05:36:00,062 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-09 05:36:00,063 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:00,064 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:00,067 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:00,071 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,071 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,071 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,071 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,072 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:00,077 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:00,080 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:00,082 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:00,086 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-09 05:36:00,087 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-09 05:36:00,087 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:00,088 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:00,091 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:00,095 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,095 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,095 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,095 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,096 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:00,100 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:00,102 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:00,104 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:00,107 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-09 05:36:00,107 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-09 05:36:00,107 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:00,109 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:00,112 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:00,116 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,116 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,116 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,116 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,117 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:00,121 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:00,123 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:00,125 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:00,127 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-09 05:36:00,127 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-09 05:36:00,127 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:00,129 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:00,132 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:00,136 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,136 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,136 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,136 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,136 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:00,139 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:00,142 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:00,144 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:00,146 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-09 05:36:00,147 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-09 05:36:00,147 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:00,148 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:00,152 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:00,155 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,156 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,156 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,156 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,156 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:00,160 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:00,163 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:00,165 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:00,167 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-09 05:36:00,168 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-09 05:36:00,168 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:00,169 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:00,173 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:00,176 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,177 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,177 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,177 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,177 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:00,180 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:00,183 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:00,185 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:00,187 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-09 05:36:00,187 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-09 05:36:00,188 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:00,189 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:00,192 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:00,196 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,196 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,196 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,196 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,196 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:00,200 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:00,203 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:00,205 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:00,207 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-09 05:36:00,208 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-09 05:36:00,208 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:00,210 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:00,213 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:00,216 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,216 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,217 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,217 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,217 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:00,221 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:00,223 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:00,225 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:00,227 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-09 05:36:00,228 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-09 05:36:00,228 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:00,229 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:00,232 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:00,236 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,236 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,236 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,236 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,237 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:00,243 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:00,246 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:00,247 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:00,250 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-09 05:36:00,250 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-09 05:36:00,250 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:00,252 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:00,255 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:00,256 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,256 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,256 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,256 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,257 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:00,261 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:00,263 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:00,265 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:00,267 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-09 05:36:00,268 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-09 05:36:00,268 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:00,269 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:00,270 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:00,271 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,271 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:00,271 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,271 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:00,271 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:00,271 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:00,271 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:00,272 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:00,272 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:00,272 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:00,272 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:00,273 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:00,273 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:00,273 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,274 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:00,274 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,274 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:00,274 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:00,284 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:00,293 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:00,301 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:00,309 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:00,311 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:00,311 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:00,318 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:00,318 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:00,319 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:00,319 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:00,319 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:00,320 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:00,320 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:00,320 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:00,320 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:00,321 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:00,321 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:00,321 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:00,322 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:00,322 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:00,323 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:00,327 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 24]), 23)
2023-10-09 05:36:00,327 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:00,328 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 24]), 23)
2023-10-09 05:36:00,328 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:00,328 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:00,329 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:00,329 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:00,330 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:00,330 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:00,330 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:00,330 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:00,331 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:00,335 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:00,339 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,339 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,339 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,339 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,339 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:00,343 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:00,345 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:00,347 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:00,349 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-09 05:36:00,350 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-09 05:36:00,350 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:00,352 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:00,355 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:00,359 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,359 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,359 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,359 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,359 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:00,363 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:00,365 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:00,367 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:00,369 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-09 05:36:00,370 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-09 05:36:00,370 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:00,371 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:00,375 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:00,378 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,378 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,378 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,379 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,379 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:00,382 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:00,384 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:00,386 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:00,387 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-09 05:36:00,388 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-09 05:36:00,388 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:00,390 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:00,393 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:00,397 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,397 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,397 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,397 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,397 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:00,401 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:00,403 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:00,404 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:00,406 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-09 05:36:00,407 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-09 05:36:00,408 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:00,409 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:00,412 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:00,416 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,416 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,416 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,416 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,416 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:00,420 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:00,422 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:00,424 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:00,425 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-09 05:36:00,426 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-09 05:36:00,426 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:00,428 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:00,431 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:00,434 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,435 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,435 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,435 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,435 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:00,438 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:00,444 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:00,446 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:00,447 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-09 05:36:00,448 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-09 05:36:00,448 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:00,449 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:00,452 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:00,456 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,456 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,456 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,456 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,456 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:00,467 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:00,470 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:00,471 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:00,474 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-09 05:36:00,474 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-09 05:36:00,474 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:00,476 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:00,479 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:00,483 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,483 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,483 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,483 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,484 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:00,487 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:00,490 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:00,492 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:00,499 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-09 05:36:00,500 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-09 05:36:00,500 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:00,501 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:00,505 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:00,508 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,509 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,509 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,509 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,509 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:00,512 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:00,514 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:00,516 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:00,518 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-09 05:36:00,518 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-09 05:36:00,519 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:00,520 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:00,523 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:00,527 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,527 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,527 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,528 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,528 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:00,531 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:00,533 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:00,535 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:00,537 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-09 05:36:00,538 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-09 05:36:00,538 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:00,539 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:00,542 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:00,546 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,546 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,547 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,547 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,547 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:00,550 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:00,552 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:00,554 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:00,557 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-09 05:36:00,557 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-09 05:36:00,557 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:00,559 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:00,562 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:00,563 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,563 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,563 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,563 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,563 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:00,567 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:00,569 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:00,571 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:00,573 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-09 05:36:00,575 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-09 05:36:00,575 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:00,576 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:00,577 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:00,577 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,577 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:00,578 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,578 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:00,578 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:00,578 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:00,578 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:00,579 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:00,579 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:00,579 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:00,579 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:00,579 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:00,580 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:00,580 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,580 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:00,580 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,581 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:00,581 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:00,592 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:00,602 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:00,612 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:00,622 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:00,623 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:00,624 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:00,628 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:00,629 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:00,629 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:00,629 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:00,629 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:00,629 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:00,630 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:00,630 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:00,630 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:00,630 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:00,630 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:00,630 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:00,631 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:00,631 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:00,631 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:00,635 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 25]), 24)
2023-10-09 05:36:00,635 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:00,635 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 25]), 24)
2023-10-09 05:36:00,635 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:00,635 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:00,636 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:00,636 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:00,636 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:00,636 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:00,637 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:00,637 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:00,637 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:00,640 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:00,644 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,644 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,644 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,644 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,644 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:00,647 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:00,650 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:00,652 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:00,654 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-09 05:36:00,655 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-09 05:36:00,655 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:00,657 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:00,660 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:00,664 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,664 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,664 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,664 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,664 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:00,667 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:00,669 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:00,671 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:00,673 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-09 05:36:00,673 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-09 05:36:00,673 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:00,675 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:00,678 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:00,682 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,682 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,682 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,682 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,683 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:00,686 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:00,687 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:00,690 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:00,691 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-09 05:36:00,692 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-09 05:36:00,692 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:00,694 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:00,697 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:00,701 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,701 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,701 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,701 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,701 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:00,712 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:00,716 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:00,718 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:00,720 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-09 05:36:00,721 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-09 05:36:00,721 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:00,722 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:00,726 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:00,729 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,730 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,730 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,730 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,730 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:00,734 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:00,736 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:00,739 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:00,740 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-09 05:36:00,741 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-09 05:36:00,741 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:00,743 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:00,746 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:00,750 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,750 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,750 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,750 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,750 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:00,753 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:00,756 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:00,757 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:00,760 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-09 05:36:00,760 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-09 05:36:00,760 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:00,762 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:00,765 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:00,769 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,769 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,769 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,769 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,769 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:00,774 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:00,777 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:00,778 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:00,780 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-09 05:36:00,781 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-09 05:36:00,781 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:00,783 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:00,786 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:00,789 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,790 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,790 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,790 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,790 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:00,796 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:00,799 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:00,801 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:00,803 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-09 05:36:00,803 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-09 05:36:00,803 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:00,805 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:00,808 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:00,812 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,812 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,812 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,812 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,812 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:00,816 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:00,818 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:00,820 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:00,822 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-09 05:36:00,823 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-09 05:36:00,823 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:00,824 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:00,828 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:00,831 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,831 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,832 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,832 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,832 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:00,835 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:00,838 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:00,840 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:00,842 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-09 05:36:00,843 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-09 05:36:00,843 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:00,844 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:00,848 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:00,851 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,852 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,852 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,852 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,852 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:00,855 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:00,857 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:00,859 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:00,861 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-09 05:36:00,861 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-09 05:36:00,862 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:00,863 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:00,866 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:00,867 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,867 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,867 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,867 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,868 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:00,871 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:00,874 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:00,876 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:00,879 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-09 05:36:00,879 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-09 05:36:00,880 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:00,881 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:00,881 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:00,882 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,882 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:00,882 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,882 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:00,882 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:00,885 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:00,886 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:00,886 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:00,886 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:00,886 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:00,887 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:00,887 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:00,888 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:00,888 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,889 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:00,889 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,889 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:00,889 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:00,901 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:00,911 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:00,921 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:00,929 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:00,931 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:00,931 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:00,936 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:00,937 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:00,937 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:00,938 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:00,938 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:00,938 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:00,938 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:00,938 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:00,938 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:00,939 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:00,939 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:00,939 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:00,939 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:00,940 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:00,940 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:00,944 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 26]), 25)
2023-10-09 05:36:00,944 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:00,945 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 26]), 25)
2023-10-09 05:36:00,945 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:00,945 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:00,945 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:00,945 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:00,946 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:00,946 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:00,946 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:00,946 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:00,947 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:00,950 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:00,955 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,955 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,955 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,956 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,956 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:00,960 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:00,963 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:00,965 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:00,967 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-09 05:36:00,967 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-09 05:36:00,968 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:00,969 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:00,973 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:00,976 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,976 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,976 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,976 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,976 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:00,979 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:00,981 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:00,983 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:00,984 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-09 05:36:00,985 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-09 05:36:00,985 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:00,987 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:00,990 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:00,994 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:00,994 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,994 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:00,994 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:00,994 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:00,998 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:00,999 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:01,001 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:01,003 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-09 05:36:01,003 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-09 05:36:01,003 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:01,005 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:01,008 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:01,012 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,012 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,012 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,012 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,012 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:01,015 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:01,017 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:01,019 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:01,020 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-09 05:36:01,021 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-09 05:36:01,021 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:01,023 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:01,026 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:01,030 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,030 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,030 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,030 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,030 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:01,034 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:01,035 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:01,038 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:01,039 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-09 05:36:01,040 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-09 05:36:01,040 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:01,041 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:01,045 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:01,048 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,048 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,048 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,049 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,049 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:01,052 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:01,054 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:01,056 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:01,058 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-09 05:36:01,059 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-09 05:36:01,059 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:01,060 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:01,064 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:01,067 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,068 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,068 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,068 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,068 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:01,073 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:01,075 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:01,077 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:01,079 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-09 05:36:01,079 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-09 05:36:01,080 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:01,081 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:01,085 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:01,088 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,088 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,088 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,088 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,089 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:01,091 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:01,093 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:01,095 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:01,097 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-09 05:36:01,098 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-09 05:36:01,098 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:01,099 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:01,102 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:01,106 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,106 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,106 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,107 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,107 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:01,110 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:01,112 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:01,114 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:01,115 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-09 05:36:01,116 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-09 05:36:01,116 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:01,118 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:01,121 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:01,125 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,125 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,125 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,125 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,125 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:01,128 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:01,130 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:01,132 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:01,134 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-09 05:36:01,136 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-09 05:36:01,136 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:01,137 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:01,141 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:01,145 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,145 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,145 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,146 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,146 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:01,150 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:01,153 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:01,155 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:01,157 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-09 05:36:01,158 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-09 05:36:01,158 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:01,160 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:01,163 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:01,164 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,164 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,164 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,164 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,164 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:01,167 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:01,170 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:01,172 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:01,174 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-09 05:36:01,174 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-09 05:36:01,174 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:01,176 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:01,177 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:01,177 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,177 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:01,177 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,178 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:01,178 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:01,178 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:01,178 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:01,178 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:01,178 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:01,179 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:01,179 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:01,179 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:01,180 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:01,180 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,180 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:01,180 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,181 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:01,181 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:01,189 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:01,197 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:01,204 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:01,211 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:01,212 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:01,212 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:01,216 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:01,217 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:01,217 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:01,217 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:01,218 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:01,218 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:01,218 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:01,218 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:01,218 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:01,218 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:01,219 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:01,219 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:01,219 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:01,219 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:01,220 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:01,224 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 27]), 26)
2023-10-09 05:36:01,224 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:01,225 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 27]), 26)
2023-10-09 05:36:01,225 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:01,225 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:01,225 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:01,225 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:01,226 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:01,226 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:01,226 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:01,226 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:01,227 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:01,231 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:01,235 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,235 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,235 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,235 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,236 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:01,239 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:01,242 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:01,245 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:01,247 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-09 05:36:01,247 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-09 05:36:01,247 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:01,249 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:01,253 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:01,257 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,257 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,257 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,258 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,258 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:01,262 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:01,264 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:01,266 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:01,269 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-09 05:36:01,269 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-09 05:36:01,269 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:01,271 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:01,275 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:01,279 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,279 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,279 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,279 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,279 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:01,283 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:01,285 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:01,287 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:01,289 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-09 05:36:01,290 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-09 05:36:01,290 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:01,292 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:01,296 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:01,299 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,300 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,300 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,300 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,300 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:01,304 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:01,306 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:01,309 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:01,311 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-09 05:36:01,312 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-09 05:36:01,312 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:01,314 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:01,317 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:01,322 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,322 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,322 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,322 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,322 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:01,326 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:01,328 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:01,331 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:01,333 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-09 05:36:01,334 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-09 05:36:01,334 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:01,336 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:01,339 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:01,343 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,343 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,344 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,344 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,344 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:01,347 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:01,350 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:01,352 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:01,355 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-09 05:36:01,355 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-09 05:36:01,355 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:01,357 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:01,361 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:01,365 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,365 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,365 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,365 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,365 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:01,369 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:01,372 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:01,374 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:01,378 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-09 05:36:01,378 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-09 05:36:01,379 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:01,381 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:01,385 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:01,388 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,389 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,389 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,389 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,389 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:01,394 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:01,397 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:01,400 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:01,402 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-09 05:36:01,403 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-09 05:36:01,403 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:01,405 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:01,409 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:01,413 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,413 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,413 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,413 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,413 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:01,417 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:01,420 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:01,422 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:01,425 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-09 05:36:01,425 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-09 05:36:01,425 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:01,427 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:01,431 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:01,435 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,435 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,435 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,435 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,435 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:01,440 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:01,442 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:01,445 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:01,448 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-09 05:36:01,449 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-09 05:36:01,449 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:01,450 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:01,456 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:01,462 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,462 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,463 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,463 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,463 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:01,467 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:01,470 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:01,473 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:01,476 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-09 05:36:01,478 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-09 05:36:01,478 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:01,479 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:01,483 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:01,484 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,484 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,484 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,484 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,484 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:01,488 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:01,491 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:01,494 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:01,497 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-09 05:36:01,498 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-09 05:36:01,498 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:01,499 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:01,500 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:01,500 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,501 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:01,501 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,501 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:01,501 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:01,501 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:01,502 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:01,502 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:01,502 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:01,502 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:01,502 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:01,503 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:01,503 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:01,504 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,504 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:01,504 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,504 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:01,504 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:01,517 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:01,528 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:01,537 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:01,547 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:01,548 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:01,548 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:01,553 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:01,554 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:01,554 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:01,554 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:01,554 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:01,555 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:01,555 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:01,555 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:01,555 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:01,555 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:01,556 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:01,556 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:01,556 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:01,556 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:01,557 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:01,561 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 28]), 27)
2023-10-09 05:36:01,561 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:01,561 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 28]), 27)
2023-10-09 05:36:01,561 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:01,561 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:01,562 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:01,562 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:01,562 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:01,563 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:01,563 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:01,563 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:01,563 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:01,567 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:01,571 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,571 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,571 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,571 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,571 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:01,575 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:01,578 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:01,580 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:01,582 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-09 05:36:01,583 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-09 05:36:01,583 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:01,585 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:01,588 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:01,592 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,593 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,593 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,593 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,593 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:01,598 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:01,601 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:01,603 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:01,606 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-09 05:36:01,606 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-09 05:36:01,606 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:01,608 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:01,612 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:01,616 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,616 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,616 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,616 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,616 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:01,620 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:01,623 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:01,625 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:01,628 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-09 05:36:01,629 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-09 05:36:01,629 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:01,631 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:01,635 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:01,638 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,639 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,639 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,639 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,639 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:01,644 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:01,647 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:01,649 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:01,652 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-09 05:36:01,653 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-09 05:36:01,653 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:01,655 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:01,658 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:01,663 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,663 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,663 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,663 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,663 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:01,666 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:01,669 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:01,671 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:01,673 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-09 05:36:01,673 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-09 05:36:01,673 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:01,675 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:01,679 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:01,683 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,683 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,683 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,683 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,683 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:01,687 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:01,690 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:01,692 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:01,695 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-09 05:36:01,695 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-09 05:36:01,695 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:01,697 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:01,700 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:01,704 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,705 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,705 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,705 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,705 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:01,708 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:01,711 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:01,714 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:01,716 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-09 05:36:01,717 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-09 05:36:01,717 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:01,719 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:01,723 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:01,726 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,726 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,726 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,727 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,727 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:01,730 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:01,732 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:01,734 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:01,736 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-09 05:36:01,737 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-09 05:36:01,737 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:01,739 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:01,742 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:01,746 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,747 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,747 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,747 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,747 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:01,751 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:01,754 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:01,756 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:01,758 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-09 05:36:01,759 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-09 05:36:01,759 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:01,761 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:01,765 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:01,769 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,769 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,769 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,769 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,769 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:01,774 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:01,777 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:01,779 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:01,782 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-09 05:36:01,783 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-09 05:36:01,783 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:01,784 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:01,788 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:01,792 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,792 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,793 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,793 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,793 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:01,797 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:01,800 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:01,802 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:01,805 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-09 05:36:01,806 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-09 05:36:01,806 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:01,808 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:01,811 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:01,812 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,812 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,812 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,813 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,813 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:01,817 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:01,820 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:01,822 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:01,825 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-09 05:36:01,825 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-09 05:36:01,825 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:01,827 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:01,828 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:01,828 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,828 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:01,828 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,828 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:01,829 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:01,829 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:01,829 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:01,829 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:01,829 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:01,830 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:01,830 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:01,830 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:01,830 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:01,831 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,831 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:01,831 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,831 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:01,832 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:01,842 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:01,852 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:01,862 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:01,871 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:01,873 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:01,873 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:01,878 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:01,878 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:01,879 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:01,879 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:01,879 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:01,879 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:01,879 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:01,880 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:01,880 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:01,880 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:01,880 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:01,880 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:01,880 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:01,881 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:01,881 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:01,885 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 29]), 28)
2023-10-09 05:36:01,886 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:01,886 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 29]), 28)
2023-10-09 05:36:01,886 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:01,886 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:01,886 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:01,887 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:01,887 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:01,887 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:01,887 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:01,888 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:01,888 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:01,892 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:01,895 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,896 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,896 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,896 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,896 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:01,900 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:01,902 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:01,904 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:01,907 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-09 05:36:01,908 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-09 05:36:01,908 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:01,910 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:01,913 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:01,917 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,918 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,918 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,918 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,918 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:01,927 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:01,930 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:01,932 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:01,935 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-09 05:36:01,935 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-09 05:36:01,935 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:01,937 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:01,941 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:01,945 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,945 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,945 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,946 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,946 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:01,950 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:01,952 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:01,954 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:01,956 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-09 05:36:01,957 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-09 05:36:01,957 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:01,959 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:01,963 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:01,967 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,967 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,967 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,967 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,967 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:01,971 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:01,973 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:01,975 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:01,976 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-09 05:36:01,978 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-09 05:36:01,978 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:01,980 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:01,984 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:01,988 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:01,988 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,988 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:01,989 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:01,989 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:01,993 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:01,996 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:01,998 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:01,999 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-09 05:36:02,000 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-09 05:36:02,000 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:02,002 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:02,006 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:02,010 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,010 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,010 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,010 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,010 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:02,014 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:02,016 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:02,018 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:02,020 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-09 05:36:02,020 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-09 05:36:02,020 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:02,022 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:02,026 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:02,030 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,030 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,030 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,031 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,031 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:02,034 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:02,036 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:02,038 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:02,040 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-09 05:36:02,040 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-09 05:36:02,040 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:02,042 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:02,046 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:02,050 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,050 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,050 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,050 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,050 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:02,053 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:02,056 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:02,059 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:02,060 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-09 05:36:02,061 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-09 05:36:02,061 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:02,063 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:02,066 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:02,071 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,071 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,071 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,071 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,071 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:02,075 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:02,077 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:02,079 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:02,083 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-09 05:36:02,083 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-09 05:36:02,083 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:02,085 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:02,089 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:02,093 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,093 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,093 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,094 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,094 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:02,097 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:02,099 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:02,101 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:02,103 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-09 05:36:02,103 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-09 05:36:02,103 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:02,104 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:02,108 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:02,112 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,112 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,112 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,112 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,112 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:02,115 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:02,117 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:02,120 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:02,122 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-09 05:36:02,122 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-09 05:36:02,122 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:02,124 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:02,127 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:02,128 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,128 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,128 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,128 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,128 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:02,131 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:02,134 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:02,136 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:02,137 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-09 05:36:02,138 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-09 05:36:02,138 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:02,139 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:02,140 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:02,140 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,140 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:02,140 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,141 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:02,141 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:02,141 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:02,141 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:02,141 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:02,142 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:02,142 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:02,142 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:02,142 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:02,142 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:02,143 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,143 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:02,143 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,143 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:02,143 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:02,153 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:02,161 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:02,168 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:02,175 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:02,177 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:02,177 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:02,181 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:02,182 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:02,182 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:02,182 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:02,182 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:02,182 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:02,183 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:02,183 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:02,183 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:02,183 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:02,183 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:02,183 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:02,184 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:02,184 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:02,184 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:02,188 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 30]), 29)
2023-10-09 05:36:02,188 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:02,188 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 30]), 29)
2023-10-09 05:36:02,188 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:02,188 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:02,189 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:02,189 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:02,189 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:02,189 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:02,190 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:02,190 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:02,190 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:02,193 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:02,197 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,197 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,197 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,197 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,197 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:02,201 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:02,203 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:02,205 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:02,207 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-09 05:36:02,208 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-09 05:36:02,208 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:02,210 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:02,213 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:02,216 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,217 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,217 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,217 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,217 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:02,220 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:02,223 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:02,225 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:02,226 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-09 05:36:02,227 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-09 05:36:02,227 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:02,229 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:02,232 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:02,235 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,235 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,236 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,236 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,236 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:02,241 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:02,243 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:02,245 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:02,247 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-09 05:36:02,248 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-09 05:36:02,248 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:02,250 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:02,253 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:02,257 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,257 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,257 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,257 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,257 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:02,262 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:02,264 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:02,266 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:02,267 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-09 05:36:02,268 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-09 05:36:02,268 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:02,270 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:02,274 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:02,278 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,278 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,278 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,278 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,278 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:02,282 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:02,284 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:02,286 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:02,287 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-09 05:36:02,288 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-09 05:36:02,288 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:02,289 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:02,293 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:02,296 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,297 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,297 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,297 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,297 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:02,302 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:02,304 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:02,306 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:02,308 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-09 05:36:02,310 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-09 05:36:02,310 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:02,311 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:02,315 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:02,318 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,319 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,319 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,319 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,319 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:02,322 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:02,324 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:02,326 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:02,328 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-09 05:36:02,328 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-09 05:36:02,328 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:02,330 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:02,333 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:02,337 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,337 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,337 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,337 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,337 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:02,341 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:02,343 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:02,344 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:02,346 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-09 05:36:02,347 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-09 05:36:02,347 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:02,348 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:02,352 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:02,356 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,356 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,356 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,356 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,356 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:02,359 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:02,363 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:02,366 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:02,368 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-09 05:36:02,369 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-09 05:36:02,369 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:02,371 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:02,374 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:02,377 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,378 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,378 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,378 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,378 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:02,381 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:02,384 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:02,387 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:02,389 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-09 05:36:02,390 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-09 05:36:02,390 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:02,391 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:02,394 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:02,398 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,398 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,398 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,399 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,399 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:02,402 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:02,404 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:02,406 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:02,408 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-09 05:36:02,408 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-09 05:36:02,409 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:02,410 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:02,413 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:02,414 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,414 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,414 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,414 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,414 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:02,420 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:02,435 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:02,438 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:02,440 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-09 05:36:02,441 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-09 05:36:02,441 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:02,442 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:02,443 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:02,444 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,444 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:02,444 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,444 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:02,444 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:02,445 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:02,446 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:02,446 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:02,446 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:02,446 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:02,446 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:02,447 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:02,447 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:02,448 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,448 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:02,448 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,448 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:02,448 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:02,458 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:02,466 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:02,475 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:02,483 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:02,484 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:02,484 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:02,490 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:02,491 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:02,492 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:02,492 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:02,492 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:02,492 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:02,493 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:02,493 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:02,493 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:02,494 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:02,494 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:02,494 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:02,495 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:02,496 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:02,497 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:02,500 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 31]), 30)
2023-10-09 05:36:02,501 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:02,501 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 31]), 30)
2023-10-09 05:36:02,501 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:02,502 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:02,502 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:02,502 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:02,503 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:02,503 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:02,503 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:02,504 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:02,504 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:02,507 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:02,511 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,511 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,511 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,511 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,511 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:02,515 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:02,517 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:02,520 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:02,522 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-09 05:36:02,523 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-09 05:36:02,523 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:02,525 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:02,528 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:02,532 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,532 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,532 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,532 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,532 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:02,536 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:02,538 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:02,540 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:02,542 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-09 05:36:02,543 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-09 05:36:02,543 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:02,544 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:02,548 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:02,551 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,551 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,552 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,552 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,552 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:02,555 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:02,557 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:02,559 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:02,562 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-09 05:36:02,562 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-09 05:36:02,562 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:02,564 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:02,567 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:02,571 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,571 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,571 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,571 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,571 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:02,587 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:02,591 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:02,594 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:02,596 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-09 05:36:02,597 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-09 05:36:02,597 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:02,599 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:02,602 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:02,607 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,607 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,607 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,607 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,607 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:02,611 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:02,613 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:02,615 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:02,618 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-09 05:36:02,619 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-09 05:36:02,619 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:02,621 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:02,624 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:02,628 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,628 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,628 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,628 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,628 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:02,632 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:02,634 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:02,636 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:02,637 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-09 05:36:02,638 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-09 05:36:02,638 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:02,639 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:02,643 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:02,647 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,647 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,647 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,647 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,648 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:02,651 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:02,652 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:02,655 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:02,656 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-09 05:36:02,657 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-09 05:36:02,657 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:02,659 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:02,662 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:02,666 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,666 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,666 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,666 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,666 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:02,670 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:02,672 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:02,674 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:02,676 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-09 05:36:02,677 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-09 05:36:02,677 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:02,678 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:02,682 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:02,686 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,686 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,686 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,686 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,686 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:02,690 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:02,692 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:02,694 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:02,696 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-09 05:36:02,696 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-09 05:36:02,697 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:02,698 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:02,702 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:02,705 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,706 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,706 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,706 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,706 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:02,710 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:02,713 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:02,715 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:02,717 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-09 05:36:02,718 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-09 05:36:02,719 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:02,720 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:02,724 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:02,728 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,728 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,728 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,729 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,729 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:02,734 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:02,736 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:02,738 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:02,741 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-09 05:36:02,742 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-09 05:36:02,742 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:02,744 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:02,748 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:02,748 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,748 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,749 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,749 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,749 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:02,752 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:02,755 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:02,757 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:02,760 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-09 05:36:02,760 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-09 05:36:02,760 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:02,762 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:02,763 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:02,763 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,763 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:02,763 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,763 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:02,764 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:02,764 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:02,764 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:02,764 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:02,764 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:02,765 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:02,765 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:02,765 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:02,766 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:02,766 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,766 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:02,766 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,767 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:02,767 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:02,777 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:02,788 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:02,796 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:02,806 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:02,807 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:02,808 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:02,812 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:02,813 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:02,814 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:02,814 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:02,814 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:02,814 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:02,814 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:02,815 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:02,815 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:02,815 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:02,815 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:02,815 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:02,816 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:02,816 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:02,816 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:02,820 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 32]), 31)
2023-10-09 05:36:02,820 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:02,821 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 32]), 31)
2023-10-09 05:36:02,821 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:02,821 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:02,821 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:02,821 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:02,822 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:02,822 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:02,822 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:02,822 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:02,823 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:02,826 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:02,830 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,830 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,830 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,830 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,830 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:02,834 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:02,837 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:02,840 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:02,843 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-09 05:36:02,844 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-09 05:36:02,844 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:02,846 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:02,849 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:02,853 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,853 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,853 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,853 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,853 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:02,856 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:02,858 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:02,861 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:02,863 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-09 05:36:02,863 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-09 05:36:02,863 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:02,865 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:02,868 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:02,872 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,872 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,872 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,873 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,873 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:02,876 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:02,878 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:02,881 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:02,884 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-09 05:36:02,884 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-09 05:36:02,884 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:02,886 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:02,889 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:02,893 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,893 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,893 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,893 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,893 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:02,897 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:02,900 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:02,902 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:02,904 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-09 05:36:02,905 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-09 05:36:02,905 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:02,906 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:02,910 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:02,914 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,914 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,914 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,914 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,914 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:02,917 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:02,919 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:02,921 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:02,923 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-09 05:36:02,924 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-09 05:36:02,924 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:02,925 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:02,929 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:02,933 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,934 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,934 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,935 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,935 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:02,964 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:02,968 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:02,972 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:02,975 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-09 05:36:02,976 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-09 05:36:02,976 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:02,977 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:02,981 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:02,984 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:02,985 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,985 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:02,985 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:02,985 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:02,990 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:02,992 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:02,994 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:02,996 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-09 05:36:02,997 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-09 05:36:02,997 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:02,999 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:03,002 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:03,006 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,006 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,006 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,006 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,006 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:03,010 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:03,012 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:03,014 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:03,016 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-09 05:36:03,017 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-09 05:36:03,017 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:03,019 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:03,022 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:03,026 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,026 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,026 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,027 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,027 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:03,031 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:03,033 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:03,035 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:03,038 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-09 05:36:03,038 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-09 05:36:03,038 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:03,040 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:03,043 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:03,047 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,047 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,048 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,048 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,048 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:03,052 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:03,054 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:03,056 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:03,059 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-09 05:36:03,060 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-09 05:36:03,060 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:03,061 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:03,065 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:03,069 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,070 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,070 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,070 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,070 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:03,075 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:03,078 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:03,080 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:03,082 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-09 05:36:03,083 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-09 05:36:03,083 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:03,085 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:03,089 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:03,089 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,090 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,090 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,090 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,090 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:03,095 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:03,098 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:03,099 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:03,101 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-09 05:36:03,102 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-09 05:36:03,102 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:03,103 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:03,103 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:03,104 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,104 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:03,104 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,104 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:03,104 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:03,105 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:03,105 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:03,106 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:03,106 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:03,106 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:03,107 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:03,107 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:03,108 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:03,108 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,108 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:03,108 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,108 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:03,108 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:03,120 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:03,130 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:03,139 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:03,161 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:03,183 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:03,185 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:03,192 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:03,194 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:03,195 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:03,195 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:03,195 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:03,195 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:03,196 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:03,196 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:03,196 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:03,196 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:03,197 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:03,197 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:03,197 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:03,198 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:03,198 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:03,202 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 33]), 32)
2023-10-09 05:36:03,202 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:03,202 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 33]), 32)
2023-10-09 05:36:03,202 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:03,203 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:03,203 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:03,203 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:03,203 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:03,204 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:03,204 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:03,204 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:03,204 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:03,207 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:03,211 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,211 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,211 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,211 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,212 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:03,280 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:03,339 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:03,343 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:03,346 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-09 05:36:03,372 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-09 05:36:03,373 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:03,376 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:03,380 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:03,383 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,384 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,384 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,384 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,384 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:03,411 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:03,414 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:03,415 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:03,418 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-09 05:36:03,418 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-09 05:36:03,418 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:03,420 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:03,424 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:03,427 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,427 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,428 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,428 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,428 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:03,431 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:03,433 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:03,434 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:03,436 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-09 05:36:03,436 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-09 05:36:03,436 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:03,438 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:03,441 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:03,445 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,445 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,445 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,445 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,445 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:03,454 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:03,456 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:03,458 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:03,460 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-09 05:36:03,461 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-09 05:36:03,462 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:03,463 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:03,467 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:03,471 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,471 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,471 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,471 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,471 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:03,475 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:03,477 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:03,479 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:03,481 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-09 05:36:03,482 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-09 05:36:03,482 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:03,484 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:03,487 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:03,491 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,491 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,491 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,491 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,491 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:03,495 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:03,497 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:03,499 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:03,500 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-09 05:36:03,501 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-09 05:36:03,501 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:03,503 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:03,506 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:03,510 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,510 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,510 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,510 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,510 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:03,513 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:03,516 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:03,518 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:03,519 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-09 05:36:03,520 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-09 05:36:03,520 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:03,522 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:03,525 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:03,529 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,529 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,529 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,529 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,529 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:03,532 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:03,536 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:03,537 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:03,540 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-09 05:36:03,540 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-09 05:36:03,540 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:03,542 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:03,545 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:03,549 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,549 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,549 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,549 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,549 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:03,552 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:03,554 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:03,556 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:03,558 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-09 05:36:03,558 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-09 05:36:03,558 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:03,560 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:03,563 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:03,567 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,567 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,567 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,567 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,567 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:03,571 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:03,573 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:03,574 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:03,576 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-09 05:36:03,576 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-09 05:36:03,576 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:03,578 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:03,581 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:03,585 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,585 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,585 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,585 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,585 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:03,588 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:03,590 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:03,592 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:03,594 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-09 05:36:03,594 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-09 05:36:03,595 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:03,596 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:03,599 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:03,600 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,600 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,600 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,600 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,600 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:03,604 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:03,605 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:03,607 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:03,608 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-09 05:36:03,609 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-09 05:36:03,609 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:03,610 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:03,611 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:03,611 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,611 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:03,612 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,612 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:03,612 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:03,612 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:03,612 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:03,612 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:03,612 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:03,613 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:03,613 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:03,613 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:03,613 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:03,614 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,614 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:03,614 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,614 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:03,614 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:03,623 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:03,630 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:03,638 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:03,645 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:03,646 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:03,646 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:03,650 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:03,651 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:03,651 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:03,652 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:03,652 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:03,652 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:03,652 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:03,653 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:03,653 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:03,653 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:03,653 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:03,654 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:03,654 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:03,654 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:03,655 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:03,658 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 34]), 33)
2023-10-09 05:36:03,659 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:03,659 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 34]), 33)
2023-10-09 05:36:03,659 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:03,659 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:03,659 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:03,660 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:03,660 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:03,660 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:03,661 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:03,661 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:03,661 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:03,664 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:03,668 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,668 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,668 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,669 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,669 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:03,672 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:03,674 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:03,677 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:03,680 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-09 05:36:03,681 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-09 05:36:03,682 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:03,683 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:03,687 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:03,690 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,690 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,691 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,691 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,691 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:03,694 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:03,696 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:03,698 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:03,700 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-09 05:36:03,700 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-09 05:36:03,700 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:03,702 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:03,705 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:03,709 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,709 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,709 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,709 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,710 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:03,713 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:03,714 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:03,716 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:03,718 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-09 05:36:03,718 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-09 05:36:03,718 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:03,720 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:03,723 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:03,727 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,727 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,727 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,727 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,727 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:03,730 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:03,732 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:03,734 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:03,736 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-09 05:36:03,736 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-09 05:36:03,736 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:03,738 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:03,741 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:03,745 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,745 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,745 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,745 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,745 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:03,748 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:03,750 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:03,753 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:03,755 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-09 05:36:03,755 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-09 05:36:03,756 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:03,757 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:03,760 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:03,764 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,764 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,764 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,764 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,764 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:03,768 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:03,770 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:03,771 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:03,773 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-09 05:36:03,774 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-09 05:36:03,774 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:03,775 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:03,778 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:03,782 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,782 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,783 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,783 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,783 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:03,787 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:03,789 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:03,791 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:03,793 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-09 05:36:03,794 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-09 05:36:03,794 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:03,796 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:03,799 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:03,802 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,802 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,803 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,803 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,803 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:03,806 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:03,808 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:03,810 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:03,812 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-09 05:36:03,813 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-09 05:36:03,813 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:03,814 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:03,818 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:03,821 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,822 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,822 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,822 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,822 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:03,825 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:03,827 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:03,829 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:03,830 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-09 05:36:03,831 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-09 05:36:03,831 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:03,833 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:03,836 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:03,840 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,840 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,840 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,840 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,840 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:03,843 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:03,845 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:03,847 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:03,849 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-09 05:36:03,850 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-09 05:36:03,850 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:03,852 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:03,855 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:03,859 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,859 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,859 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,859 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,859 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:03,863 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:03,866 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:03,868 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:03,870 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-09 05:36:03,871 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-09 05:36:03,871 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:03,872 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:03,876 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:03,876 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,876 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,877 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,877 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,877 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:03,880 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:03,883 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:03,886 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:03,888 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-09 05:36:03,888 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-09 05:36:03,888 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:03,890 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:03,890 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:03,891 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,891 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:03,891 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,891 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:03,891 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:03,891 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:03,891 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:03,892 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:03,892 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:03,892 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:03,892 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:03,892 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:03,893 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:03,893 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,893 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:03,893 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,893 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:03,893 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:03,904 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:03,914 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:03,923 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:03,932 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:03,933 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:03,933 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:03,937 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:03,938 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:03,938 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:03,938 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:03,938 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:03,939 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:03,939 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:03,939 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:03,939 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:03,940 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:03,940 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:03,940 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:03,940 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:03,941 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:03,941 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:03,945 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 35]), 34)
2023-10-09 05:36:03,945 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:03,945 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 35]), 34)
2023-10-09 05:36:03,946 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:03,946 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:03,946 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:03,946 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:03,946 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:03,947 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:03,947 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:03,947 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:03,947 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:03,950 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:03,954 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,954 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,954 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,954 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,955 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:03,958 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:03,961 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:03,963 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:03,965 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-09 05:36:03,966 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-09 05:36:03,966 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:03,968 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:03,971 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:03,974 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:03,974 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,975 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:03,975 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:03,975 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:04,010 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:04,064 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:04,116 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:04,160 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-09 05:36:04,190 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-09 05:36:04,190 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:04,192 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:04,196 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:04,200 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,200 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,201 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,202 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,202 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:04,257 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:04,265 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:04,267 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:04,269 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-09 05:36:04,270 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-09 05:36:04,270 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:04,272 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:04,275 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:04,278 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,279 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,279 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,279 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,279 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:04,282 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:04,285 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:04,287 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:04,289 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-09 05:36:04,289 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-09 05:36:04,289 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:04,291 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:04,294 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:04,298 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,298 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,298 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,298 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,299 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:04,302 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:04,305 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:04,308 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:04,311 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-09 05:36:04,311 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-09 05:36:04,311 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:04,314 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:04,319 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:04,325 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,325 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,325 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,326 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,326 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:04,334 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:04,337 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:04,339 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:04,342 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-09 05:36:04,343 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-09 05:36:04,343 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:04,345 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:04,350 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:04,356 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,357 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,357 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,357 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,357 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:04,361 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:04,365 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:04,368 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:04,371 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-09 05:36:04,372 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-09 05:36:04,372 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:04,375 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:04,379 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:04,383 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,384 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,384 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,384 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,384 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:04,388 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:04,391 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:04,393 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:04,396 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-09 05:36:04,397 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-09 05:36:04,398 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:04,400 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:04,405 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:04,410 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,411 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,411 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,411 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,411 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:04,415 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:04,418 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:04,420 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:04,421 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-09 05:36:04,422 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-09 05:36:04,422 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:04,424 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:04,427 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:04,430 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,430 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,431 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,431 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,431 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:04,434 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:04,441 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:04,454 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:04,456 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-09 05:36:04,456 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-09 05:36:04,457 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:04,458 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:04,461 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:04,465 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,465 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,465 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,465 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,466 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:04,469 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:04,471 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:04,473 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:04,475 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-09 05:36:04,476 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-09 05:36:04,476 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:04,477 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:04,481 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:04,481 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,481 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,481 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,482 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,482 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:04,485 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:04,488 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:04,489 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:04,491 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-09 05:36:04,491 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-09 05:36:04,492 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:04,493 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:04,493 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:04,494 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,494 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:04,494 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,494 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:04,494 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:04,494 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:04,495 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:04,495 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:04,495 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:04,495 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:04,495 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:04,496 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:04,496 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:04,496 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,496 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:04,497 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,497 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:04,497 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:04,507 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:04,515 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:04,524 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:04,533 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:04,535 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:04,535 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:04,540 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:04,541 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:04,542 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:04,542 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:04,542 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:04,542 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:04,542 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:04,543 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:04,543 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:04,543 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:04,543 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:04,544 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:04,544 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:04,544 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:04,545 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:04,549 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 36]), 35)
2023-10-09 05:36:04,549 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:04,549 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 36]), 35)
2023-10-09 05:36:04,549 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:04,549 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:04,550 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:04,550 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:04,550 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:04,550 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:04,550 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:04,551 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:04,551 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:04,554 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:04,558 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,558 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,558 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,558 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,558 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:04,563 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:04,566 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:04,568 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:04,572 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-09 05:36:04,572 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-09 05:36:04,572 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:04,574 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:04,578 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:04,581 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,581 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,582 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,582 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,582 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:04,585 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:04,587 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:04,589 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:04,590 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-09 05:36:04,591 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-09 05:36:04,591 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:04,593 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:04,596 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:04,600 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,600 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,600 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,600 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,600 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:04,603 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:04,605 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:04,614 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:04,616 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-09 05:36:04,616 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-09 05:36:04,616 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:04,618 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:04,621 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:04,625 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,625 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,625 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,625 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,625 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:04,629 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:04,631 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:04,632 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:04,634 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-09 05:36:04,635 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-09 05:36:04,635 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:04,637 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:04,640 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:04,644 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,644 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,644 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,644 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,645 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:04,648 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:04,650 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:04,651 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:04,653 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-09 05:36:04,654 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-09 05:36:04,654 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:04,656 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:04,659 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:04,662 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,662 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,663 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,663 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,663 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:04,666 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:04,668 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:04,670 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:04,671 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-09 05:36:04,672 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-09 05:36:04,672 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:04,674 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:04,677 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:04,681 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,681 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,681 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,681 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,681 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:04,684 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:04,686 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:04,688 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:04,690 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-09 05:36:04,690 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-09 05:36:04,690 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:04,692 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:04,695 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:04,699 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,699 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,699 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,699 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,699 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:04,702 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:04,704 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:04,706 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:04,708 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-09 05:36:04,709 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-09 05:36:04,709 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:04,710 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:04,713 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:04,717 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,717 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,717 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,718 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,718 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:04,721 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:04,723 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:04,726 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:04,730 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-09 05:36:04,730 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-09 05:36:04,730 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:04,732 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:04,735 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:04,738 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,739 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,739 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,739 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,739 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:04,742 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:04,744 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:04,745 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:04,747 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-09 05:36:04,748 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-09 05:36:04,748 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:04,749 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:04,752 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:04,756 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,756 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,756 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,756 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,756 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:04,760 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:04,762 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:04,764 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:04,766 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-09 05:36:04,766 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-09 05:36:04,766 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:04,768 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:04,771 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:04,772 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,772 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,772 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,772 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,772 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:04,775 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:04,777 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:04,779 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:04,781 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-09 05:36:04,782 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-09 05:36:04,782 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:04,783 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:04,784 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:04,784 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,784 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:04,784 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,785 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:04,785 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:04,785 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:04,786 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:04,786 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:04,786 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:04,787 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:04,787 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:04,787 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:04,787 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:04,788 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,788 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:04,788 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,788 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:04,788 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:04,798 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:04,807 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:04,816 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:04,824 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:04,826 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:04,826 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:04,831 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:04,831 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:04,832 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:04,832 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:04,832 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:04,832 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:04,832 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:04,833 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:04,833 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:04,833 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:04,833 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:04,833 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:04,833 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:04,834 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:04,834 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:04,838 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 37]), 36)
2023-10-09 05:36:04,838 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:04,838 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 37]), 36)
2023-10-09 05:36:04,839 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:04,839 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:04,839 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:04,839 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:04,839 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:04,840 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:04,840 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:04,840 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:04,840 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:04,844 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:04,848 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,848 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,848 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,848 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,848 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:04,855 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:04,858 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:04,860 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:04,863 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-09 05:36:04,864 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-09 05:36:04,864 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:04,866 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:04,869 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:04,873 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,873 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,873 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,873 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,873 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:04,878 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:04,881 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:04,884 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:04,886 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-09 05:36:04,887 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-09 05:36:04,887 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:04,889 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:04,893 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:04,896 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,896 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,897 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,897 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,897 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:04,900 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:04,903 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:04,905 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:04,908 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-09 05:36:04,908 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-09 05:36:04,908 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:04,910 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:04,914 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:04,918 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,918 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,918 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,918 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,918 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:04,922 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:04,924 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:04,926 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:04,929 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-09 05:36:04,929 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-09 05:36:04,930 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:04,931 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:04,935 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:04,939 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,939 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,939 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,940 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,940 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:04,944 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:04,947 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:04,949 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:04,952 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-09 05:36:04,953 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-09 05:36:04,953 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:04,955 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:04,958 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:04,962 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,962 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,963 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,963 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,963 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:04,966 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:04,969 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:04,971 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:04,974 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-09 05:36:04,976 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-09 05:36:04,976 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:04,977 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:04,981 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:04,985 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:04,985 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,985 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:04,986 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:04,986 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:04,990 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:04,993 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:04,995 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:04,997 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-09 05:36:04,998 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-09 05:36:04,998 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:05,000 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:05,003 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:05,007 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,007 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,008 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,008 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,008 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:05,015 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:05,018 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:05,019 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:05,022 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-09 05:36:05,022 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-09 05:36:05,022 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:05,024 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:05,027 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:05,031 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,031 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,032 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,032 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,032 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:05,036 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:05,039 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:05,044 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:05,047 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-09 05:36:05,047 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-09 05:36:05,047 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:05,049 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:05,053 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:05,056 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,057 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,057 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,057 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,057 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:05,062 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:05,066 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:05,068 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:05,071 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-09 05:36:05,071 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-09 05:36:05,071 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:05,073 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:05,076 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:05,080 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,080 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,080 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,080 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,080 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:05,084 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:05,086 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:05,088 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:05,090 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-09 05:36:05,091 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-09 05:36:05,091 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:05,092 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:05,096 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:05,096 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,097 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,097 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,097 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,097 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:05,102 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:05,105 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:05,107 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:05,110 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-09 05:36:05,110 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-09 05:36:05,111 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:05,112 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:05,112 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:05,113 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,113 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:05,113 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,113 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:05,113 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:05,113 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:05,114 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:05,114 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:05,114 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:05,114 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:05,114 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:05,115 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:05,115 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:05,115 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,115 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:05,115 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,116 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:05,116 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:05,127 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:05,138 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:05,148 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:05,159 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:05,160 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:05,160 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:05,164 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:05,165 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:05,166 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-09 05:36:05,166 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:05,166 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-09 05:36:05,166 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:05,166 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-09 05:36:05,167 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-09 05:36:05,167 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-09 05:36:05,167 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-09 05:36:05,167 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:05,167 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:05,167 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-09 05:36:05,168 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-09 05:36:05,168 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:05,172 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 38]), 37)
2023-10-09 05:36:05,172 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:05,172 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 38]), 37)
2023-10-09 05:36:05,172 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:05,172 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-09 05:36:05,172 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-09 05:36:05,173 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-09 05:36:05,173 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-09 05:36:05,173 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:05,173 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:05,173 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-09 05:36:05,174 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-09 05:36:05,177 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:05,180 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,180 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,181 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,181 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,181 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-09 05:36:05,185 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-09 05:36:05,192 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-09 05:36:05,194 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-09 05:36:05,197 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-09 05:36:05,197 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-09 05:36:05,197 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-09 05:36:05,199 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-09 05:36:05,203 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:05,208 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,208 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,208 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,208 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,208 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-09 05:36:05,212 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-09 05:36:05,215 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-09 05:36:05,217 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-09 05:36:05,219 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-09 05:36:05,220 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-09 05:36:05,220 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-09 05:36:05,222 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-09 05:36:05,225 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:05,229 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,229 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,229 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,229 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,230 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-09 05:36:05,234 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-09 05:36:05,236 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-09 05:36:05,240 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-09 05:36:05,243 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-09 05:36:05,244 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-09 05:36:05,244 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-09 05:36:05,246 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-09 05:36:05,249 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:05,253 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,254 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,254 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,254 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,254 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-09 05:36:05,259 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-09 05:36:05,261 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-09 05:36:05,263 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-09 05:36:05,265 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-09 05:36:05,265 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-09 05:36:05,265 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-09 05:36:05,267 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-09 05:36:05,271 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:05,275 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,275 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,275 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,275 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,275 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-09 05:36:05,278 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-09 05:36:05,280 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-09 05:36:05,283 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-09 05:36:05,286 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-09 05:36:05,286 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-09 05:36:05,286 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-09 05:36:05,288 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-09 05:36:05,292 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:05,296 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,296 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,296 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,297 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,297 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-09 05:36:05,301 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-09 05:36:05,303 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-09 05:36:05,305 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-09 05:36:05,307 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-09 05:36:05,308 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-09 05:36:05,308 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-09 05:36:05,309 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-09 05:36:05,313 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:05,317 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,317 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,317 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,318 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,318 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-09 05:36:05,321 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-09 05:36:05,324 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-09 05:36:05,326 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-09 05:36:05,328 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-09 05:36:05,329 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-09 05:36:05,329 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-09 05:36:05,331 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-09 05:36:05,334 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:05,338 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,338 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,338 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,338 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,339 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-09 05:36:05,342 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-09 05:36:05,345 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-09 05:36:05,347 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-09 05:36:05,350 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-09 05:36:05,351 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-09 05:36:05,351 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-09 05:36:05,352 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-09 05:36:05,356 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:05,360 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,360 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,360 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,360 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,360 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-09 05:36:05,365 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-09 05:36:05,368 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-09 05:36:05,370 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-09 05:36:05,373 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-09 05:36:05,373 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-09 05:36:05,373 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-09 05:36:05,375 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-09 05:36:05,379 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:05,383 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,383 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,383 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,384 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,384 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-09 05:36:05,388 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-09 05:36:05,390 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-09 05:36:05,392 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-09 05:36:05,395 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-09 05:36:05,396 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-09 05:36:05,396 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-09 05:36:05,397 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-09 05:36:05,400 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:05,405 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,405 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,405 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,406 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,406 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-09 05:36:05,409 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-09 05:36:05,412 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-09 05:36:05,414 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-09 05:36:05,416 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-09 05:36:05,417 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-09 05:36:05,417 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-09 05:36:05,419 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-09 05:36:05,422 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:05,423 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,423 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,423 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,424 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-09 05:36:05,424 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-09 05:36:05,427 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-09 05:36:05,430 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-09 05:36:05,431 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-09 05:36:05,433 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-09 05:36:05,434 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-09 05:36:05,434 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-09 05:36:05,435 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-09 05:36:05,436 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:05,436 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,436 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:05,436 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,437 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:05,437 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-09 05:36:05,437 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-09 05:36:05,437 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-09 05:36:05,437 [layer_forward.py:94 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-09 05:36:05,437 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-09 05:36:05,438 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-09 05:36:05,438 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-09 05:36:05,438 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-09 05:36:05,438 [model_loader.py:257 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-09 05:36:05,439 [layer_forward.py:80 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-09 05:36:05,439 [layer_forward.py:81 in new_forward] DEBUG - kwargs: {}
2023-10-09 05:36:05,439 [layer_forward.py:87 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-09 05:36:05,439 [layer_forward.py:88 in new_forward] DEBUG - kwargs_0: {}
2023-10-09 05:36:05,439 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-09 05:36:05,448 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-09 05:36:05,456 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-09 05:36:05,465 [layer_forward.py:94 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-09 05:36:05,473 [layer_forward.py:106 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-09 05:36:05,473 [layer_forward.py:108 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-09 05:36:05,474 [model_loader.py:267 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-09 05:36:05,479 [generate_test.py:40 in test_hf_gen] INFO - for i in range(10):                               
2023-10-09 05:36:05,479 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-09 05:36:05,479 [generate_test.py:40 in test_hf_gen] INFO - Who are you? Are you conscious?
I'm a woman. I'm not conscious.
I'm not conscious. I'm not conscious.
I'm not conscious. I'm
2023-10-09 05:36:05,479 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-09 05:36:05,479 [generate_test.py:40 in test_hf_gen] INFO - Where is Deutschland?
I'm in Germany.
2023-10-09 05:36:05,479 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-09 05:36:05,480 [generate_test.py:40 in test_hf_gen] INFO - How is Huawei Mate 60 Pro?
Huawei Mate 60 Pro is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone
2023-10-09 05:36:05,480 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-09 05:36:05,480 [generate_test.py:40 in test_hf_gen] INFO - for i in range(10):                               
2023-10-09 05:36:05,480 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-09 05:36:05,480 [generate_test.py:40 in test_hf_gen] INFO - Who are you? Are you conscious?
I'm a woman. I'm not conscious.
I'm not conscious. I'm not conscious.
I'm not conscious. I'm
2023-10-09 05:36:05,480 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-09 05:36:05,480 [generate_test.py:40 in test_hf_gen] INFO - Where is Deutschland?
I'm in Germany.
2023-10-09 05:36:05,480 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-09 05:36:05,480 [generate_test.py:40 in test_hf_gen] INFO - How is Huawei Mate 60 Pro?
Huawei Mate 60 Pro is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone
2023-10-09 05:36:05,480 [generate_test.py:41 in test_hf_gen] INFO - ----------
2023-10-09 05:36:05,490 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.embed_tokens from flexgen to old.
2023-10-09 05:36:05,490 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.embed_positions from flexgen to old.
2023-10-09 05:36:05,491 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.layers.0 from flexgen to old.
2023-10-09 05:36:05,491 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.layers.1 from flexgen to old.
2023-10-09 05:36:05,491 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.layers.2 from flexgen to old.
2023-10-09 05:36:05,491 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.layers.3 from flexgen to old.
2023-10-09 05:36:05,491 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.layers.4 from flexgen to old.
2023-10-09 05:36:05,491 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.layers.5 from flexgen to old.
2023-10-09 05:36:05,491 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.layers.6 from flexgen to old.
2023-10-09 05:36:05,492 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.layers.7 from flexgen to old.
2023-10-09 05:36:05,492 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.layers.8 from flexgen to old.
2023-10-09 05:36:05,492 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.layers.9 from flexgen to old.
2023-10-09 05:36:05,492 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.layers.10 from flexgen to old.
2023-10-09 05:36:05,492 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.layers.11 from flexgen to old.
2023-10-09 05:36:05,492 [layer_forward.py:19 in reset_forward] DEBUG - model.decoder.final_layer_norm from flexgen to old.
2023-10-09 05:36:05,492 [layer_forward.py:19 in reset_forward] DEBUG - lm_head from flexgen to old.
