2023-10-07 07:57:15,360 [instantiator.py:21 in <module>] INFO - Created a temporary directory at /tmp/tmp5315bsqj
2023-10-07 07:57:15,362 [instantiator.py:76 in _write] INFO - Writing /tmp/tmp5315bsqj/_remote_module_non_scriptable.py
2023-10-07 07:57:16,054 [connectionpool.py:1003 in _new_conn] DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2023-10-07 07:57:16,120 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1" 200 0
2023-10-07 07:57:20,071 [tpu_cluster_resolver.py:32 in <module>] DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2023-10-07 07:57:21,041 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5
2023-10-07 07:57:21,043 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7
2023-10-07 07:57:21,044 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5
2023-10-07 07:57:21,045 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7
2023-10-07 07:57:22,881 [flexgen_init.py:201 in get_policy_weight_map] INFO - device_map is prepared!
2023-10-07 07:57:22,885 [flexgen_init.py:207 in get_policy_weight_map] INFO - CausalLM facebook/opt-125m is to be loaded on: 
GPU Mem 0.00 GiB (0.00%), CPU Mem 0.07 GiB (30.19%), Disk Mem 0.16 Gib (69.81%)
2023-10-07 07:57:22,935 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1" 200 0
2023-10-07 07:57:23,066 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1" 200 0
2023-10-07 07:57:23,157 [flexgen_init.py:67 in policy_init] INFO - The whole model has been downloaded an processed to offload_folder: 'offload_dir/facebook.opt-125m'
2023-10-07 07:57:23,238 [flexgen_init.py:79 in policy_init] INFO - model has been loaded by policy.
2023-10-07 07:57:23,262 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.embed_tokens to flexgen forward
2023-10-07 07:57:23,263 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.embed_positions to flexgen forward
2023-10-07 07:57:23,264 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.final_layer_norm to flexgen forward
2023-10-07 07:57:23,265 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.0 to flexgen forward
2023-10-07 07:57:23,266 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.1 to flexgen forward
2023-10-07 07:57:23,267 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.2 to flexgen forward
2023-10-07 07:57:23,268 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.3 to flexgen forward
2023-10-07 07:57:23,269 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.4 to flexgen forward
2023-10-07 07:57:23,270 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.5 to flexgen forward
2023-10-07 07:57:23,271 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.6 to flexgen forward
2023-10-07 07:57:23,272 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.7 to flexgen forward
2023-10-07 07:57:23,273 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.8 to flexgen forward
2023-10-07 07:57:23,273 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.9 to flexgen forward
2023-10-07 07:57:23,275 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.10 to flexgen forward
2023-10-07 07:57:23,276 [457060047.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.11 to flexgen forward
2023-10-07 07:57:23,276 [457060047.py:36 in to_flexgen_forward] DEBUG - lm_head to flexgen forward
2023-10-07 07:57:23,333 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2023-10-07 07:57:23,620 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:23,622 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:23,623 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10]),)
2023-10-07 07:57:23,624 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:23,625 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10]),)
2023-10-07 07:57:23,625 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:23,626 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:23,644 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:23,651 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:23,652 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:23,653 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])
2023-10-07 07:57:23,657 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])
2023-10-07 07:57:23,657 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:23,673 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:23,674 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:23,676 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10]), 0)
2023-10-07 07:57:23,677 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:23,678 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10]), 0)
2023-10-07 07:57:23,679 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:23,680 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:23,685 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:23,687 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:23,688 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:23,689 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])
2023-10-07 07:57:23,690 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])
2023-10-07 07:57:23,690 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:23,692 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:23,701 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:23,708 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:23,709 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:23,710 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:23,710 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:23,711 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:23,854 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:23,863 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:23,868 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:23,874 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 07:57:23,875 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 07:57:23,876 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:23,880 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:23,888 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:23,897 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:23,898 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:23,899 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:23,900 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:23,901 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:24,009 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:24,015 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:24,021 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:24,026 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 07:57:24,028 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 07:57:24,029 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:24,032 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:24,040 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:24,048 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:24,049 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,051 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:24,052 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,053 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:24,112 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:24,119 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:24,124 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:24,130 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 07:57:24,132 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 07:57:24,133 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:24,136 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:24,145 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:24,152 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:24,153 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,154 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:24,154 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,155 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:24,215 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:24,223 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:24,229 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:24,235 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 07:57:24,237 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 07:57:24,238 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:24,241 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:24,249 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:24,256 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:24,257 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,258 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:24,260 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,261 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:24,324 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:24,330 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:24,335 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:24,339 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 07:57:24,341 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 07:57:24,342 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:24,344 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:24,352 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:24,360 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:24,361 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,362 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:24,363 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,364 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:24,431 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:24,480 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:24,486 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:24,490 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 07:57:24,492 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 07:57:24,493 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:24,495 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:24,503 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:24,511 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:24,511 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,512 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:24,513 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,514 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:24,582 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:24,592 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:24,612 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:24,620 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 07:57:24,621 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 07:57:24,622 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:24,625 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:24,633 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:24,640 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:24,641 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,642 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:24,643 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,643 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:24,711 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:24,719 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:24,727 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:24,761 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 07:57:24,763 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 07:57:24,764 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:24,767 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:24,774 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:24,782 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:24,783 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,784 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:24,785 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,786 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:24,854 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:24,860 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:24,864 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:24,868 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 07:57:24,870 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 07:57:24,871 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:24,873 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:24,881 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:24,888 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:24,889 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,890 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:24,891 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:24,892 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:24,973 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:24,979 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:24,987 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:24,997 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 07:57:24,999 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 07:57:25,000 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:25,002 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:25,011 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:25,019 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:25,020 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,021 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:25,022 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,023 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:25,100 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:25,106 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:25,111 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:25,125 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 07:57:25,127 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 07:57:25,128 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:25,130 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:25,138 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:25,140 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:25,141 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,142 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:25,143 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,144 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:25,242 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:25,253 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:25,258 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:25,276 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 07:57:25,279 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 07:57:25,279 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:25,282 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:25,284 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:25,292 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:25,292 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:25,293 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:25,294 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:25,295 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:25,297 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:25,299 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:25,300 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:25,302 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])
2023-10-07 07:57:25,303 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])
2023-10-07 07:57:25,304 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:25,306 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:25,307 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:25,309 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 07:57:25,310 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:25,310 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 07:57:25,311 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:25,312 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:25,452 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:25,467 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:25,488 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:25,502 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 50272])
2023-10-07 07:57:25,507 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 50272])
2023-10-07 07:57:25,508 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:25,548 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:25,551 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:25,553 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:25,553 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:25,554 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:25,555 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:25,556 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:25,557 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:25,558 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:25,559 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:25,560 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:25,560 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:25,561 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:25,562 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:25,564 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:25,565 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 11]), 10)
2023-10-07 07:57:25,566 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:25,567 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 11]), 10)
2023-10-07 07:57:25,567 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:25,568 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:25,570 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:25,571 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:25,572 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:25,573 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:25,574 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:25,574 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:25,576 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:25,583 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:25,591 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:25,592 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,593 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:25,594 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,595 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:25,609 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:25,618 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:25,623 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:25,627 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 07:57:25,629 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 07:57:25,629 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:25,633 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:25,640 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:25,651 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:25,652 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,653 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:25,654 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,655 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:25,662 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:25,669 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:25,680 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:25,686 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 07:57:25,687 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 07:57:25,688 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:25,691 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:25,699 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:25,707 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:25,708 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,709 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:25,710 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,711 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:25,719 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:25,725 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:25,729 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:25,748 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 07:57:25,750 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 07:57:25,750 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:25,754 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:25,762 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:25,770 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:25,770 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,772 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:25,772 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,774 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:25,777 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:25,787 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:25,790 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:25,794 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 07:57:25,796 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 07:57:25,796 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:25,801 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:25,808 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:25,817 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:25,818 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,819 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:25,820 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,821 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:25,825 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:25,838 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:25,841 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:25,845 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 07:57:25,847 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 07:57:25,847 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:25,850 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:25,857 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:25,865 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:25,865 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,866 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:25,867 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,868 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:25,872 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:25,874 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:25,877 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:25,881 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 07:57:25,882 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 07:57:25,883 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:25,886 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:25,893 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:25,900 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:25,901 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,902 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:25,903 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,904 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:25,907 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:25,910 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:25,912 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:25,915 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 07:57:25,916 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 07:57:25,917 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:25,920 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:25,927 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:25,935 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:25,935 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,936 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:25,937 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,938 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:25,950 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:25,955 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:25,959 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:25,963 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 07:57:25,964 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 07:57:25,965 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:25,968 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:25,975 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:25,983 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:25,984 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,985 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:25,986 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:25,986 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:25,993 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:26,002 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:26,005 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:26,009 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 07:57:26,010 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 07:57:26,011 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:26,014 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:26,022 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:26,030 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,031 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,032 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,032 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,033 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:26,037 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:26,041 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:26,044 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:26,047 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 07:57:26,048 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 07:57:26,049 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:26,051 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:26,059 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:26,067 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,068 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,069 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,070 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,071 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:26,077 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:26,081 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:26,084 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:26,087 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 07:57:26,089 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 07:57:26,089 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:26,093 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:26,100 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:26,102 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,103 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,103 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,104 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,105 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:26,109 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:26,112 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:26,115 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:26,117 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 07:57:26,118 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 07:57:26,119 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:26,122 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:26,123 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:26,131 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,132 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:26,133 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,134 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:26,135 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:26,137 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:26,141 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:26,144 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:26,148 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:26,149 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:26,149 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:26,151 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:26,152 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:26,154 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,154 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:26,155 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,156 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:26,157 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:26,170 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:26,177 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:26,185 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:26,196 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:26,198 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:26,199 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:26,215 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:26,217 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:26,218 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:26,219 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:26,220 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:26,221 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:26,221 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:26,222 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:26,223 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:26,224 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:26,225 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:26,226 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:26,227 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:26,228 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:26,230 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:26,231 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 12]), 11)
2023-10-07 07:57:26,233 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:26,233 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 12]), 11)
2023-10-07 07:57:26,234 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:26,235 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:26,237 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:26,238 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:26,239 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:26,240 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:26,241 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:26,241 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:26,243 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:26,250 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:26,258 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,259 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,260 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,260 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,261 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:26,271 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:26,277 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:26,282 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:26,285 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 07:57:26,287 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 07:57:26,288 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:26,290 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:26,297 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:26,306 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,306 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,307 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,308 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,308 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:26,313 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:26,321 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:26,325 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:26,328 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 07:57:26,329 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 07:57:26,330 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:26,333 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:26,341 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:26,350 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,351 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,351 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,353 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,353 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:26,361 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:26,371 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:26,374 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:26,376 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 07:57:26,377 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 07:57:26,378 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:26,381 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:26,388 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:26,396 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,397 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,398 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,399 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,400 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:26,405 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:26,408 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:26,412 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:26,416 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 07:57:26,417 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 07:57:26,418 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:26,421 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:26,431 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:26,445 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,446 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,448 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,449 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,450 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:26,456 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:26,460 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:26,470 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:26,491 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 07:57:26,493 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 07:57:26,494 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:26,496 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:26,503 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:26,512 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,513 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,513 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,514 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,515 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:26,519 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:26,522 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:26,525 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:26,529 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 07:57:26,531 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 07:57:26,532 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:26,534 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:26,542 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:26,551 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,552 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,553 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,554 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,555 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:26,564 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:26,568 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:26,571 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:26,574 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 07:57:26,576 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 07:57:26,576 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:26,579 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:26,586 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:26,595 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,596 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,596 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,597 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,598 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:26,619 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:26,623 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:26,632 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:26,636 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 07:57:26,638 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 07:57:26,639 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:26,641 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:26,649 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:26,657 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,658 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,659 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,660 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,660 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:26,665 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:26,669 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:26,673 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:26,676 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 07:57:26,678 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 07:57:26,679 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:26,681 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:26,689 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:26,697 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,698 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,699 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,700 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,701 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:26,705 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:26,709 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:26,712 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:26,715 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 07:57:26,716 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 07:57:26,717 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:26,720 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:26,727 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:26,736 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,737 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,738 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,739 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,740 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:26,748 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:26,751 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:26,754 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:26,757 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 07:57:26,758 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 07:57:26,758 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:26,761 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:26,769 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:26,770 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,771 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,772 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,773 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,774 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:26,781 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:26,789 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:26,793 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:26,796 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 07:57:26,798 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 07:57:26,799 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:26,801 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:26,803 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:26,810 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,811 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:26,812 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,813 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:26,814 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:26,816 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:26,818 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:26,819 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:26,823 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:26,824 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:26,825 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:26,827 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:26,829 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:26,830 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,831 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:26,832 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,832 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:26,833 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:26,844 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:26,854 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:26,862 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:26,870 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:26,873 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:26,873 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:26,883 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:26,885 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:26,886 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:26,887 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:26,888 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:26,889 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:26,890 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:26,891 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:26,892 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:26,893 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:26,894 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:26,894 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:26,895 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:26,896 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:26,898 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:26,899 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 13]), 12)
2023-10-07 07:57:26,900 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:26,901 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 13]), 12)
2023-10-07 07:57:26,902 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:26,902 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:26,905 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:26,906 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:26,907 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:26,908 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:26,908 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:26,909 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:26,911 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:26,919 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:26,927 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,928 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,929 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,929 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,930 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:26,949 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:26,953 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:26,957 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:26,960 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 07:57:26,962 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 07:57:26,963 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:26,966 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:26,974 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:26,983 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:26,984 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,985 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:26,985 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:26,986 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:26,993 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:26,996 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:27,000 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:27,006 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 07:57:27,008 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 07:57:27,009 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:27,012 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:27,024 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:27,033 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,033 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,034 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,035 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,036 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:27,044 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:27,048 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:27,051 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:27,055 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 07:57:27,057 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 07:57:27,057 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:27,060 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:27,068 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:27,076 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,076 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,077 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,078 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,078 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:27,083 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:27,087 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:27,091 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:27,095 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 07:57:27,097 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 07:57:27,098 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:27,100 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:27,108 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:27,116 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,117 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,118 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,118 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,119 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:27,125 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:27,130 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:27,133 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:27,137 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 07:57:27,139 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 07:57:27,139 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:27,142 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:27,155 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:27,168 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,177 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,178 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,179 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,180 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:27,207 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:27,217 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:27,222 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:27,227 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 07:57:27,230 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 07:57:27,231 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:27,234 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:27,247 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:27,260 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,262 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,262 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,263 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,264 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:27,274 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:27,282 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:27,286 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:27,289 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 07:57:27,291 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 07:57:27,292 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:27,295 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:27,306 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:27,314 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,315 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,316 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,318 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,318 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:27,333 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:27,336 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:27,339 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:27,342 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 07:57:27,344 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 07:57:27,345 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:27,347 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:27,355 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:27,363 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,364 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,365 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,366 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,367 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:27,373 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:27,376 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:27,383 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:27,387 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 07:57:27,389 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 07:57:27,390 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:27,392 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:27,400 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:27,408 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,409 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,410 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,411 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,411 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:27,419 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:27,423 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:27,427 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:27,430 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 07:57:27,432 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 07:57:27,433 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:27,435 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:27,442 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:27,450 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,451 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,452 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,453 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,454 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:27,460 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:27,464 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:27,468 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:27,478 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 07:57:27,480 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 07:57:27,481 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:27,484 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:27,492 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:27,493 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,494 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,495 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,496 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,497 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:27,503 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:27,508 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:27,512 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:27,515 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 07:57:27,517 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 07:57:27,518 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:27,520 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:27,522 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:27,531 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,532 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:27,532 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,533 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:27,534 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:27,537 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:27,539 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:27,543 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:27,547 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:27,548 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:27,550 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:27,552 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:27,554 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:27,555 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,556 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:27,557 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,558 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:27,558 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:27,573 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:27,582 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:27,593 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:27,606 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:27,608 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:27,610 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:27,622 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:27,624 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:27,626 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:27,626 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:27,627 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:27,628 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:27,628 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:27,630 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:27,631 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:27,632 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:27,633 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:27,634 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:27,635 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:27,637 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:27,638 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:27,641 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 14]), 13)
2023-10-07 07:57:27,641 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:27,642 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 14]), 13)
2023-10-07 07:57:27,643 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:27,644 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:27,646 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:27,647 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:27,648 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:27,649 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:27,649 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:27,650 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:27,652 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:27,660 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:27,668 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,668 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,669 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,670 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,671 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:27,678 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:27,683 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:27,687 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:27,691 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 07:57:27,692 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 07:57:27,693 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:27,695 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:27,703 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:27,711 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,712 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,712 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,713 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,714 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:27,721 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:27,730 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:27,735 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:27,738 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 07:57:27,740 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 07:57:27,741 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:27,743 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:27,752 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:27,760 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,761 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,762 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,762 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,763 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:27,768 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:27,772 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:27,775 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:27,778 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 07:57:27,779 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 07:57:27,780 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:27,783 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:27,791 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:27,799 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,800 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,801 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,802 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,803 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:27,809 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:27,814 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:27,818 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:27,822 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 07:57:27,824 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 07:57:27,825 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:27,828 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:27,836 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:27,845 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,845 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,847 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,848 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,849 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:27,853 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:27,857 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:27,863 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:27,867 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 07:57:27,868 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 07:57:27,869 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:27,872 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:27,880 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:27,888 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,889 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,889 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,890 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,891 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:27,898 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:27,912 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:27,916 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:27,919 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 07:57:27,920 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 07:57:27,922 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:27,924 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:27,931 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:27,940 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,941 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,941 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,942 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,943 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:27,952 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:27,957 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:27,959 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:27,962 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 07:57:27,963 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 07:57:27,964 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:27,966 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:27,974 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:27,983 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:27,983 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,984 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:27,985 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:27,986 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:27,997 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:28,000 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:28,005 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:28,011 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 07:57:28,012 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 07:57:28,013 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:28,016 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:28,023 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:28,033 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,034 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,035 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,036 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,037 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:28,045 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:28,048 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:28,053 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:28,072 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 07:57:28,074 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 07:57:28,075 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:28,078 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:28,086 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:28,096 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,096 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,097 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,098 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,099 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:28,112 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:28,116 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:28,119 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:28,136 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 07:57:28,138 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 07:57:28,139 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:28,141 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:28,149 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:28,157 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,158 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,159 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,159 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,160 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:28,166 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:28,176 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:28,179 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:28,182 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 07:57:28,183 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 07:57:28,184 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:28,187 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:28,195 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:28,196 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,197 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,198 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,198 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,199 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:28,205 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:28,216 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:28,219 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:28,222 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 07:57:28,223 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 07:57:28,224 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:28,227 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:28,229 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:28,237 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,238 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:28,239 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,240 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:28,241 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:28,243 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:28,248 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:28,254 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:28,259 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:28,259 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:28,260 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:28,261 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:28,263 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:28,264 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,264 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:28,266 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,266 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:28,267 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:28,277 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:28,287 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:28,295 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:28,304 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:28,307 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:28,308 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:28,317 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:28,319 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:28,321 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:28,321 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:28,322 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:28,323 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:28,324 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:28,325 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:28,326 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:28,327 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:28,328 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:28,329 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:28,330 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:28,332 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:28,334 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:28,336 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 15]), 14)
2023-10-07 07:57:28,337 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:28,337 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 15]), 14)
2023-10-07 07:57:28,338 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:28,339 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:28,340 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:28,341 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:28,342 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:28,344 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:28,344 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:28,345 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:28,346 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:28,354 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:28,363 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,364 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,365 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,366 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,367 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:28,373 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:28,380 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:28,386 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:28,397 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 07:57:28,398 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 07:57:28,399 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:28,402 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:28,410 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:28,418 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,420 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,420 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,421 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,422 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:28,429 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:28,437 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:28,440 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:28,444 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 07:57:28,445 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 07:57:28,445 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:28,449 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:28,456 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:28,464 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,465 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,466 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,467 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,468 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:28,472 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:28,475 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:28,478 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:28,484 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 07:57:28,486 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 07:57:28,487 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:28,489 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:28,497 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:28,505 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,506 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,507 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,507 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,508 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:28,518 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:28,526 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:28,530 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:28,533 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 07:57:28,535 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 07:57:28,536 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:28,538 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:28,546 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:28,554 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,556 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,556 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,557 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,558 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:28,565 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:28,570 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:28,574 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:28,577 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 07:57:28,579 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 07:57:28,579 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:28,582 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:28,590 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:28,598 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,599 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,600 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,601 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,601 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:28,606 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:28,609 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:28,614 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:28,618 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 07:57:28,620 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 07:57:28,621 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:28,623 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:28,631 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:28,640 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,641 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,642 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,642 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,643 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:28,649 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:28,653 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:28,656 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:28,659 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 07:57:28,660 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 07:57:28,661 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:28,664 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:28,672 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:28,681 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,683 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,683 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,684 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,685 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:28,694 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:28,697 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:28,700 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:28,703 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 07:57:28,704 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 07:57:28,705 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:28,707 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:28,716 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:28,725 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,726 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,727 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,728 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,728 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:28,734 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:28,739 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:28,742 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:28,744 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 07:57:28,745 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 07:57:28,746 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:28,749 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:28,757 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:28,765 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,766 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,767 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,768 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,769 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:28,775 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:28,783 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:28,793 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:28,796 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 07:57:28,797 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 07:57:28,798 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:28,800 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:28,808 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:28,816 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,817 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,818 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,819 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,820 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:28,824 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:28,829 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:28,847 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:28,851 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 07:57:28,853 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 07:57:28,854 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:28,857 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:28,864 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:28,866 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,867 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,867 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,868 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:28,869 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:28,877 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:28,881 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:28,884 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:28,886 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 07:57:28,887 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 07:57:28,888 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:28,891 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:28,893 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:28,900 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,901 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:28,902 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,903 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:28,904 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:28,907 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:28,910 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:28,914 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:28,917 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:28,918 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:28,919 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:28,921 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:28,922 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:28,924 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:28,924 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:28,925 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:28,926 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:28,927 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:28,936 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:28,945 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:28,959 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:28,975 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:28,992 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:28,993 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:29,009 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:29,011 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:29,012 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:29,013 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:29,014 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:29,015 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:29,016 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:29,017 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:29,017 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:29,019 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:29,019 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:29,020 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:29,021 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:29,023 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:29,024 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:29,026 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 16]), 15)
2023-10-07 07:57:29,026 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:29,027 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 16]), 15)
2023-10-07 07:57:29,028 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:29,029 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:29,030 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:29,031 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:29,032 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:29,033 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:29,034 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:29,035 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:29,036 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:29,044 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:29,052 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,053 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,053 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,054 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,055 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:29,062 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:29,067 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:29,073 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:29,082 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 07:57:29,084 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 07:57:29,085 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:29,087 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:29,094 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:29,102 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,103 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,104 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,105 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,105 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:29,110 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:29,113 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:29,123 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:29,126 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 07:57:29,128 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 07:57:29,129 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:29,131 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:29,138 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:29,146 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,147 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,148 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,148 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,149 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:29,156 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:29,159 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:29,161 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:29,166 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 07:57:29,168 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 07:57:29,168 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:29,171 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:29,179 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:29,187 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,187 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,188 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,189 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,189 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:29,193 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:29,203 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:29,207 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:29,210 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 07:57:29,211 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 07:57:29,212 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:29,215 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:29,222 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:29,230 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,231 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,232 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,233 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,234 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:29,240 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:29,249 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:29,252 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:29,255 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 07:57:29,256 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 07:57:29,257 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:29,259 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:29,267 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:29,274 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,275 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,276 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,277 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,277 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:29,288 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:29,292 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:29,296 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:29,300 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 07:57:29,301 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 07:57:29,302 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:29,305 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:29,314 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:29,323 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,325 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,326 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,327 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,328 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:29,334 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:29,338 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:29,347 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:29,351 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 07:57:29,352 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 07:57:29,353 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:29,355 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:29,363 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:29,372 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,373 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,374 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,374 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,375 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:29,384 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:29,410 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:29,413 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:29,416 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 07:57:29,417 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 07:57:29,418 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:29,421 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:29,430 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:29,438 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,439 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,439 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,440 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,441 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:29,457 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:29,460 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:29,463 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:29,465 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 07:57:29,466 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 07:57:29,467 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:29,470 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:29,478 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:29,487 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,488 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,489 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,490 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,491 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:29,497 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:29,500 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:29,504 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:29,508 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 07:57:29,509 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 07:57:29,510 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:29,513 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:29,520 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:29,529 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,529 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,530 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,531 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,531 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:29,538 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:29,542 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:29,546 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:29,549 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 07:57:29,550 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 07:57:29,551 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:29,553 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:29,561 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:29,562 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,563 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,564 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,565 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,565 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:29,569 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:29,572 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:29,575 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:29,585 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 07:57:29,586 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 07:57:29,587 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:29,590 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:29,592 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:29,600 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,600 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:29,601 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,602 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:29,603 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:29,605 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:29,606 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:29,612 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:29,614 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:29,615 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:29,616 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:29,617 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:29,619 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:29,620 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,621 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:29,622 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,623 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:29,624 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:29,636 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:29,648 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:29,657 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:29,665 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:29,667 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:29,668 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:29,727 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:29,729 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:29,731 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:29,732 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:29,733 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:29,734 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:29,734 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:29,736 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:29,737 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:29,738 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:29,739 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:29,740 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:29,741 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:29,742 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:29,744 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:29,745 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 17]), 16)
2023-10-07 07:57:29,746 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:29,747 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 17]), 16)
2023-10-07 07:57:29,748 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:29,748 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:29,750 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:29,751 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:29,752 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:29,754 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:29,754 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:29,755 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:29,757 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:29,765 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:29,774 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,775 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,775 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,776 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,777 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:29,796 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:29,804 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:29,809 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:29,813 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 07:57:29,814 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 07:57:29,815 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:29,817 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:29,825 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:29,834 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,835 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,835 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,837 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,838 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:29,849 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:29,853 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:29,856 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:29,863 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 07:57:29,864 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 07:57:29,865 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:29,868 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:29,876 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:29,885 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,886 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,887 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,888 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,888 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:29,905 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:29,909 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:29,912 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:29,916 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 07:57:29,917 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 07:57:29,918 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:29,922 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:29,935 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:29,948 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:29,949 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,950 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:29,952 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:29,953 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:29,958 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:29,965 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:29,971 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:29,978 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 07:57:29,981 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 07:57:29,982 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:29,984 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:29,992 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:30,000 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,001 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,002 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,003 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,003 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:30,010 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:30,017 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:30,023 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:30,030 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 07:57:30,032 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 07:57:30,033 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:30,036 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:30,044 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:30,052 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,053 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,054 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,055 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,056 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:30,065 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:30,070 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:30,073 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:30,076 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 07:57:30,077 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 07:57:30,078 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:30,080 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:30,088 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:30,096 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,097 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,098 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,099 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,099 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:30,109 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:30,112 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:30,116 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:30,120 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 07:57:30,122 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 07:57:30,122 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:30,125 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:30,134 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:30,144 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,145 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,146 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,147 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,148 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:30,155 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:30,162 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:30,168 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:30,171 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 07:57:30,173 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 07:57:30,174 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:30,176 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:30,184 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:30,192 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,193 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,194 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,195 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,196 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:30,202 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:30,205 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:30,208 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:30,211 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 07:57:30,212 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 07:57:30,213 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:30,215 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:30,223 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:30,232 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,232 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,234 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,235 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,235 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:30,242 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:30,253 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:30,256 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:30,258 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 07:57:30,260 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 07:57:30,261 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:30,264 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:30,271 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:30,279 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,280 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,281 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,282 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,283 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:30,290 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:30,297 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:30,305 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:30,308 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 07:57:30,309 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 07:57:30,310 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:30,313 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:30,321 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:30,323 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,326 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,327 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,328 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,328 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:30,384 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:30,414 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:30,418 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:30,421 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 07:57:30,423 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 07:57:30,424 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:30,426 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:30,429 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:30,437 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,437 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:30,438 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,440 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:30,441 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:30,443 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:30,447 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:30,450 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:30,453 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:30,454 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:30,456 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:30,458 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:30,459 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:30,461 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,461 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:30,462 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,463 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:30,464 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:30,473 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:30,481 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:30,490 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:30,499 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:30,502 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:30,503 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:30,511 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:30,513 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:30,515 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:30,516 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:30,517 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:30,517 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:30,518 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:30,520 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:30,521 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:30,522 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:30,523 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:30,524 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:30,525 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:30,527 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:30,529 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:30,532 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 18]), 17)
2023-10-07 07:57:30,532 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:30,533 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 18]), 17)
2023-10-07 07:57:30,534 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:30,535 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:30,537 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:30,538 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:30,539 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:30,540 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:30,541 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:30,542 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:30,544 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:30,554 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:30,561 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,562 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,564 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,564 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,565 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:30,571 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:30,578 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:30,587 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:30,590 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 07:57:30,592 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 07:57:30,593 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:30,596 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:30,604 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:30,615 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,616 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,617 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,618 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,619 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:30,649 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:30,668 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:30,689 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:30,692 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 07:57:30,695 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 07:57:30,696 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:30,700 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:30,709 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:30,717 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,718 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,719 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,720 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,722 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:30,728 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:30,734 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:30,746 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:30,750 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 07:57:30,751 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 07:57:30,752 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:30,755 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:30,768 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:30,780 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,782 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,783 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,784 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,784 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:30,793 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:30,803 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:30,808 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:30,813 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 07:57:30,815 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 07:57:30,816 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:30,820 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:30,832 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:30,841 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,842 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,843 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,844 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,845 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:30,858 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:30,919 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:30,948 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:30,954 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 07:57:30,955 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 07:57:30,957 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:30,959 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:30,967 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:30,975 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:30,976 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,977 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:30,978 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:30,978 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:30,989 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:30,995 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:30,999 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:31,013 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 07:57:31,015 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 07:57:31,016 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:31,019 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:31,027 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:31,036 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,036 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,037 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,038 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,039 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:31,045 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:31,051 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:31,054 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:31,056 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 07:57:31,058 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 07:57:31,058 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:31,061 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:31,069 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:31,077 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,078 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,079 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,079 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,080 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:31,089 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:31,095 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:31,098 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:31,102 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 07:57:31,103 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 07:57:31,104 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:31,106 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:31,114 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:31,122 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,123 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,124 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,124 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,125 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:31,129 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:31,133 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:31,136 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:31,139 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 07:57:31,140 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 07:57:31,141 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:31,144 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:31,152 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:31,161 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,162 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,163 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,164 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,165 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:31,205 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:31,222 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:31,226 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:31,232 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 07:57:31,234 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 07:57:31,235 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:31,237 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:31,245 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:31,254 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,254 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,256 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,257 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,258 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:31,261 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:31,264 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:31,267 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:31,269 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 07:57:31,270 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 07:57:31,271 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:31,274 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:31,282 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:31,284 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,284 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,285 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,286 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,287 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:31,291 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:31,301 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:31,313 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:31,318 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 07:57:31,319 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 07:57:31,320 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:31,323 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:31,325 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:31,333 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,334 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:31,335 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,335 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:31,336 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:31,338 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:31,342 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:31,346 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:31,350 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:31,351 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:31,352 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:31,355 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:31,356 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:31,358 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,358 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:31,359 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,360 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:31,361 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:31,372 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:31,380 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:31,389 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:31,397 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:31,400 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:31,402 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:31,409 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:31,411 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:31,413 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:31,413 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:31,414 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:31,415 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:31,416 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:31,417 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:31,418 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:31,419 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:31,420 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:31,421 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:31,422 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:31,423 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:31,425 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:31,428 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 19]), 18)
2023-10-07 07:57:31,429 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:31,430 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 19]), 18)
2023-10-07 07:57:31,430 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:31,431 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:31,432 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:31,433 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:31,434 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:31,435 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:31,436 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:31,437 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:31,438 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:31,445 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:31,453 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,454 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,455 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,456 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,457 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:31,478 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:31,484 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:31,488 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:31,491 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 07:57:31,493 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 07:57:31,494 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:31,496 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:31,504 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:31,512 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,513 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,514 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,515 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,516 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:31,529 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:31,532 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:31,536 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:31,539 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 07:57:31,540 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 07:57:31,540 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:31,543 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:31,551 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:31,559 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,560 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,560 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,562 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,562 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:31,568 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:31,582 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:31,585 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:31,589 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 07:57:31,590 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 07:57:31,591 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:31,594 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:31,601 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:31,609 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,610 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,611 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,612 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,613 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:31,656 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:31,660 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:31,663 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:31,691 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 07:57:31,693 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 07:57:31,694 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:31,696 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:31,704 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:31,715 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,716 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,717 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,718 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,719 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:31,727 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:31,730 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:31,734 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:31,745 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 07:57:31,747 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 07:57:31,748 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:31,750 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:31,758 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:31,766 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,767 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,768 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,783 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,784 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:31,788 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:31,820 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:31,824 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:31,827 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 07:57:31,831 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 07:57:31,832 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:31,835 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:31,843 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:31,851 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,852 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,853 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,854 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,855 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:31,863 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:31,867 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:31,875 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:31,879 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 07:57:31,880 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 07:57:31,881 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:31,883 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:31,892 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:31,900 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,901 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,902 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,903 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,904 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:31,909 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:31,913 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:31,916 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:31,919 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 07:57:31,920 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 07:57:31,921 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:31,924 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:31,933 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:31,942 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,943 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,944 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,945 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,946 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:31,953 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:31,959 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:31,961 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:31,964 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 07:57:31,965 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 07:57:31,965 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:31,968 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:31,976 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:31,984 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:31,985 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,985 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:31,986 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:31,988 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:32,047 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:32,052 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:32,069 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:32,077 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 07:57:32,078 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 07:57:32,079 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:32,082 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:32,091 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:32,100 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,101 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,102 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,104 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,104 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:32,110 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:32,115 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:32,118 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:32,124 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 07:57:32,127 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 07:57:32,128 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:32,131 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:32,139 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:32,141 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,141 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,142 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,143 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,144 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:32,151 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:32,157 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:32,161 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:32,173 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 07:57:32,175 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 07:57:32,176 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:32,178 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:32,180 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:32,188 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,188 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:32,189 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,190 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:32,191 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:32,194 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:32,197 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:32,200 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:32,203 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:32,204 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:32,205 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:32,207 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:32,208 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:32,210 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,211 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:32,212 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,213 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:32,214 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:32,225 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:32,234 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:32,243 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:32,252 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:32,253 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:32,254 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:32,263 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:32,265 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:32,266 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:32,267 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:32,268 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:32,268 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:32,269 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:32,270 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:32,271 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:32,272 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:32,273 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:32,274 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:32,275 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:32,276 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:32,277 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:32,279 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 20]), 19)
2023-10-07 07:57:32,280 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:32,281 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 20]), 19)
2023-10-07 07:57:32,281 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:32,282 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:32,284 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:32,285 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:32,296 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:32,299 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:32,300 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:32,301 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:32,302 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:32,310 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:32,318 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,319 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,320 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,321 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,321 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:32,340 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:32,370 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:32,375 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:32,380 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 07:57:32,382 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 07:57:32,383 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:32,386 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:32,395 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:32,403 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,404 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,405 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,407 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,408 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:32,417 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:32,424 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:32,428 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:32,432 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 07:57:32,433 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 07:57:32,435 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:32,438 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:32,446 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:32,455 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,456 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,457 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,458 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,459 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:32,466 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:32,479 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:32,485 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:32,490 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 07:57:32,491 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 07:57:32,492 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:32,495 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:32,503 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:32,512 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,513 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,513 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,514 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,515 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:32,519 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:32,526 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:32,530 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:32,534 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 07:57:32,535 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 07:57:32,536 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:32,539 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:32,548 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:32,556 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,557 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,558 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,559 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,560 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:32,565 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:32,568 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:32,571 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:32,575 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 07:57:32,576 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 07:57:32,577 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:32,580 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:32,593 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:32,607 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,608 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,610 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,618 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,619 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:32,624 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:32,628 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:32,631 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:32,634 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 07:57:32,636 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 07:57:32,637 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:32,640 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:32,649 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:32,658 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,659 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,660 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,661 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,662 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:32,713 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:32,745 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:32,749 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:32,753 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 07:57:32,755 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 07:57:32,756 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:32,759 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:32,767 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:32,775 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,776 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,777 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,778 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,779 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:32,785 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:32,791 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:32,794 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:32,797 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 07:57:32,799 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 07:57:32,800 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:32,803 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:32,814 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:32,826 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,827 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,828 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,829 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,829 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:32,834 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:32,840 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:32,846 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:32,850 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 07:57:32,852 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 07:57:32,852 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:32,855 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:32,862 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:32,870 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,871 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,872 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,873 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,874 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:32,882 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:32,887 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:32,892 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:32,897 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 07:57:32,898 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 07:57:32,899 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:32,902 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:32,910 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:32,920 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,921 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,921 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,922 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,923 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:32,928 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:32,931 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:32,934 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:32,939 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 07:57:32,940 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 07:57:32,941 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:32,943 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:32,951 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:32,953 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,953 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,954 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,955 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:32,956 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:32,963 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:32,966 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:32,969 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:32,971 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 07:57:32,972 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 07:57:32,973 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:32,976 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:32,978 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:32,986 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:32,987 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:32,988 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:32,989 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:32,990 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:32,993 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:32,994 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:32,994 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:32,995 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:32,996 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:32,997 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:32,999 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:33,000 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:33,002 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,003 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:33,004 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,005 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:33,007 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:33,019 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:33,027 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:33,036 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:33,043 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:33,047 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:33,048 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:33,060 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:33,062 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:33,064 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:33,064 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:33,065 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:33,066 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:33,067 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:33,068 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:33,069 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:33,070 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:33,071 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:33,072 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:33,073 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:33,074 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:33,076 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:33,078 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 21]), 20)
2023-10-07 07:57:33,078 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:33,079 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 21]), 20)
2023-10-07 07:57:33,080 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:33,081 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:33,083 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:33,084 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:33,085 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:33,086 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:33,087 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:33,088 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:33,089 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:33,097 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:33,107 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,112 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,113 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,114 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,115 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:33,149 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:33,153 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:33,156 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:33,158 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 07:57:33,160 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 07:57:33,161 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:33,163 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:33,171 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:33,179 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,180 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,181 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,182 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,183 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:33,195 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:33,200 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:33,211 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:33,217 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 07:57:33,219 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 07:57:33,220 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:33,222 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:33,230 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:33,239 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,240 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,241 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,242 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,243 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:33,250 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:33,256 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:33,261 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:33,264 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 07:57:33,266 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 07:57:33,267 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:33,270 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:33,277 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:33,286 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,287 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,288 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,289 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,289 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:33,298 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:33,301 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:33,304 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:33,314 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 07:57:33,317 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 07:57:33,318 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:33,321 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:33,331 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:33,342 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,343 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,344 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,345 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,346 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:33,352 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:33,367 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:33,382 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:33,386 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 07:57:33,389 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 07:57:33,390 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:33,393 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:33,402 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:33,412 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,413 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,414 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,415 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,416 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:33,422 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:33,427 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:33,435 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:33,449 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 07:57:33,451 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 07:57:33,451 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:33,454 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:33,462 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:33,470 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,471 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,472 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,473 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,474 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:33,485 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:33,488 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:33,491 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:33,494 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 07:57:33,496 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 07:57:33,496 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:33,499 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:33,507 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:33,516 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,517 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,518 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,519 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,519 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:33,526 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:33,529 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:33,533 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:33,536 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 07:57:33,538 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 07:57:33,539 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:33,541 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:33,549 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:33,557 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,558 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,558 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,559 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,560 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:33,570 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:33,574 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:33,577 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:33,583 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 07:57:33,584 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 07:57:33,585 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:33,588 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:33,595 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:33,603 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,604 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,605 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,606 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,606 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:33,612 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:33,616 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:33,619 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:33,622 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 07:57:33,623 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 07:57:33,624 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:33,626 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:33,635 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:33,644 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,645 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,646 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,647 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,647 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:33,653 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:33,660 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:33,665 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:33,671 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 07:57:33,672 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 07:57:33,673 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:33,676 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:33,684 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:33,685 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,686 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,687 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,688 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,688 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:33,697 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:33,701 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:33,704 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:33,707 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 07:57:33,708 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 07:57:33,709 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:33,712 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:33,713 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:33,721 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,722 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:33,723 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,724 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:33,724 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:33,726 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:33,729 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:33,731 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:33,732 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:33,733 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:33,734 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:33,735 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:33,737 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:33,738 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,739 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:33,740 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,741 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:33,742 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:33,755 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:33,764 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:33,773 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:33,784 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:33,795 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:33,796 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:33,804 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:33,806 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:33,808 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:33,809 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:33,809 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:33,811 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:33,811 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:33,813 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:33,814 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:33,814 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:33,816 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:33,816 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:33,817 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:33,819 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:33,820 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:33,822 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 22]), 21)
2023-10-07 07:57:33,823 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:33,824 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 22]), 21)
2023-10-07 07:57:33,824 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:33,825 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:33,827 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:33,828 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:33,829 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:33,831 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:33,832 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:33,832 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:33,834 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:33,847 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:33,860 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,862 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,864 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,865 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,866 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:33,874 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:33,880 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:33,883 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:33,887 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 07:57:33,890 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 07:57:33,891 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:33,894 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:33,902 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:33,912 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,913 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,914 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,914 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,915 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:33,925 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:33,934 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:33,939 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:33,943 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 07:57:33,955 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 07:57:33,956 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:33,959 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:33,966 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:33,974 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:33,975 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,976 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:33,977 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:33,977 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:33,983 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:33,989 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:34,006 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:34,009 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 07:57:34,011 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 07:57:34,012 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:34,014 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:34,022 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:34,029 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,030 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,031 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,032 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,033 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:34,045 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:34,052 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:34,055 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:34,058 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 07:57:34,061 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 07:57:34,062 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:34,065 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:34,073 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:34,082 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,083 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,083 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,084 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,085 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:34,090 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:34,105 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:34,108 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:34,111 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 07:57:34,112 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 07:57:34,113 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:34,115 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:34,123 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:34,132 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,133 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,134 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,134 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,135 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:34,140 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:34,147 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:34,150 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:34,155 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 07:57:34,157 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 07:57:34,158 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:34,160 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:34,168 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:34,176 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,177 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,177 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,178 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,179 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:34,196 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:34,200 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:34,204 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:34,207 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 07:57:34,208 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 07:57:34,209 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:34,212 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:34,219 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:34,227 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,228 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,229 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,230 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,231 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:34,236 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:34,239 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:34,242 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:34,246 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 07:57:34,247 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 07:57:34,248 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:34,250 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:34,258 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:34,266 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,267 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,268 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,269 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,269 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:34,274 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:34,277 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:34,280 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:34,287 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 07:57:34,289 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 07:57:34,290 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:34,292 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:34,300 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:34,308 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,309 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,310 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,311 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,312 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:34,318 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:34,329 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:34,333 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:34,337 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 07:57:34,338 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 07:57:34,339 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:34,341 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:34,354 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:34,367 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,368 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,370 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,371 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,372 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:34,378 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:34,384 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:34,388 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:34,392 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 07:57:34,394 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 07:57:34,395 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:34,399 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:34,412 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:34,414 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,415 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,416 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,416 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,418 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:34,428 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:34,433 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:34,437 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:34,441 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 07:57:34,443 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 07:57:34,444 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:34,446 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:34,449 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:34,457 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,458 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:34,459 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,460 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:34,460 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:34,461 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:34,467 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:34,470 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:34,473 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:34,473 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:34,474 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:34,476 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:34,477 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:34,479 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,480 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:34,480 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,481 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:34,482 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:34,493 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:34,500 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:34,508 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:34,516 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:34,518 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:34,519 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:34,527 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:34,528 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:34,530 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:34,531 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:34,531 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:34,532 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:34,533 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:34,534 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:34,535 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:34,536 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:34,536 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:34,537 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:34,538 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:34,539 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:34,541 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:34,544 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 23]), 22)
2023-10-07 07:57:34,545 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:34,546 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 23]), 22)
2023-10-07 07:57:34,547 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:34,547 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:34,549 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:34,550 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:34,551 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:34,552 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:34,553 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:34,553 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:34,555 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:34,562 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:34,570 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,571 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,572 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,572 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,573 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:34,579 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:34,585 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:34,593 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:34,596 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 07:57:34,598 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 07:57:34,598 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:34,601 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:34,608 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:34,617 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,617 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,618 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,619 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,620 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:34,624 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:34,629 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:34,635 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:34,639 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 07:57:34,641 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 07:57:34,641 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:34,644 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:34,653 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:34,662 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,662 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,663 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,664 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,665 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:34,673 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:34,677 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:34,681 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:34,684 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 07:57:34,685 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 07:57:34,686 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:34,688 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:34,697 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:34,705 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,706 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,707 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,707 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,708 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:34,713 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:34,717 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:34,721 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:34,724 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 07:57:34,726 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 07:57:34,726 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:34,729 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:34,738 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:34,746 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,747 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,748 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,749 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,749 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:34,757 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:34,761 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:34,764 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:34,767 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 07:57:34,769 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 07:57:34,769 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:34,773 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:34,780 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:34,788 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,789 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,790 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,791 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,791 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:34,798 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:34,801 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:34,805 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:34,808 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 07:57:34,810 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 07:57:34,811 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:34,814 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:34,822 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:34,831 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,832 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,833 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,834 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,835 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:34,843 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:34,850 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:34,854 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:34,857 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 07:57:34,858 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 07:57:34,859 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:34,861 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:34,870 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:34,878 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,879 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,880 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,880 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,881 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:34,886 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:34,895 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:34,904 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:34,908 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 07:57:34,910 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 07:57:34,911 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:34,913 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:34,921 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:34,931 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,932 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,933 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,934 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,935 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:34,947 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:34,952 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:34,958 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:34,961 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 07:57:34,963 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 07:57:34,964 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:34,966 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:34,974 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:34,982 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:34,983 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,984 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:34,985 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:34,985 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:34,992 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:34,996 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:35,001 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:35,017 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 07:57:35,020 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 07:57:35,021 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:35,024 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:35,032 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:35,040 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,041 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,042 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,043 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,044 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:35,050 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:35,053 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:35,057 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:35,061 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 07:57:35,063 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 07:57:35,064 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:35,067 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:35,076 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:35,077 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,078 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,078 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,079 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,080 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:35,084 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:35,088 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:35,091 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:35,094 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 07:57:35,096 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 07:57:35,096 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:35,099 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:35,100 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:35,109 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,109 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:35,111 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,111 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:35,112 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:35,115 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:35,118 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:35,122 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:35,125 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:35,126 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:35,127 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:35,129 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:35,130 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:35,131 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,132 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:35,133 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,134 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:35,135 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:35,149 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:35,156 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:35,165 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:35,172 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:35,175 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:35,176 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:35,183 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:35,185 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:35,186 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:35,187 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:35,188 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:35,189 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:35,189 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:35,191 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:35,192 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:35,193 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:35,194 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:35,195 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:35,196 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:35,198 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:35,200 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:35,202 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 24]), 23)
2023-10-07 07:57:35,203 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:35,204 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 24]), 23)
2023-10-07 07:57:35,205 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:35,206 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:35,208 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:35,209 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:35,210 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:35,212 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:35,212 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:35,213 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:35,215 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:35,227 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:35,236 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,237 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,238 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,239 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,240 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:35,245 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:35,253 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:35,261 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:35,266 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 07:57:35,268 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 07:57:35,269 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:35,272 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:35,280 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:35,289 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,290 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,290 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,292 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,293 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:35,299 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:35,309 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:35,312 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:35,317 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 07:57:35,322 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 07:57:35,323 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:35,326 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:35,334 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:35,343 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,343 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,344 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,345 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,346 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:35,355 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:35,358 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:35,361 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:35,376 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 07:57:35,418 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 07:57:35,419 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:35,421 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:35,430 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:35,438 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,440 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,441 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,442 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,443 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:35,451 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:35,454 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:35,457 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:35,476 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 07:57:35,483 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 07:57:35,484 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:35,486 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:35,494 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:35,502 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,503 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,504 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,505 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,506 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:35,511 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:35,515 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:35,518 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:35,520 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 07:57:35,522 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 07:57:35,523 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:35,525 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:35,533 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:35,541 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,541 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,542 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,543 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,544 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:35,551 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:35,554 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:35,556 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:35,559 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 07:57:35,603 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 07:57:35,605 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:35,607 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:35,615 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:35,624 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,626 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,627 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,628 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,629 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:35,638 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:35,641 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:35,652 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:35,658 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 07:57:35,659 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 07:57:35,660 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:35,662 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:35,670 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:35,679 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,679 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,680 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,681 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,682 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:35,688 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:35,691 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:35,695 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:35,703 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 07:57:35,705 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 07:57:35,705 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:35,708 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:35,715 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:35,724 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,725 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,726 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,727 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,728 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:35,733 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:35,736 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:35,742 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:35,772 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 07:57:35,774 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 07:57:35,774 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:35,777 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:35,785 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:35,792 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,793 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,794 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,795 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,795 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:35,800 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:35,804 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:35,807 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:35,810 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 07:57:35,813 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 07:57:35,814 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:35,817 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:35,825 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:35,833 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,834 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,835 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,835 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,836 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:35,840 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:35,847 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:35,860 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:35,863 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 07:57:35,864 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 07:57:35,865 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:35,867 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:35,875 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:35,876 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,877 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,878 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,879 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:35,880 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:35,891 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:35,894 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:35,897 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:35,901 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 07:57:35,902 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 07:57:35,903 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:35,906 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:35,908 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:35,920 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,921 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:35,921 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,922 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:35,923 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:35,925 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:35,930 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:35,934 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:35,937 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:35,938 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:35,939 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:35,940 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:35,942 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:35,943 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:35,944 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:35,944 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:35,945 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:35,946 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:35,956 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:35,964 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:35,973 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:35,981 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:35,982 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:35,983 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:35,991 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:35,993 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:35,994 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:35,995 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:35,996 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:35,997 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:35,998 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:35,999 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:36,000 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:36,001 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:36,002 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:36,004 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:36,005 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:36,007 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:36,009 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:36,011 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 25]), 24)
2023-10-07 07:57:36,012 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:36,013 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 25]), 24)
2023-10-07 07:57:36,013 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:36,015 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:36,016 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:36,017 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:36,018 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:36,019 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:36,020 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:36,021 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:36,022 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:36,030 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:36,039 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,040 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,041 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,042 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,042 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:36,051 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:36,057 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:36,060 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:36,063 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 07:57:36,065 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 07:57:36,065 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:36,068 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:36,075 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:36,083 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,084 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,084 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,085 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,086 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:36,089 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:36,092 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:36,099 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:36,115 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 07:57:36,117 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 07:57:36,118 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:36,122 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:36,129 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:36,138 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,138 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,139 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,140 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,141 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:36,145 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:36,153 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:36,161 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:36,164 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 07:57:36,166 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 07:57:36,167 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:36,170 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:36,177 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:36,185 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,186 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,187 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,187 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,188 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:36,197 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:36,209 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:36,214 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:36,219 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 07:57:36,221 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 07:57:36,222 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:36,224 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:36,233 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:36,241 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,242 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,243 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,244 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,245 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:36,252 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:36,256 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:36,260 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:36,267 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 07:57:36,271 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 07:57:36,272 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:36,275 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:36,282 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:36,291 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,291 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,292 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,301 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,302 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:36,361 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:36,369 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:36,373 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:36,377 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 07:57:36,379 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 07:57:36,380 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:36,382 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:36,390 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:36,398 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,399 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,400 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,401 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,402 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:36,406 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:36,410 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:36,415 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:36,419 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 07:57:36,420 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 07:57:36,421 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:36,424 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:36,431 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:36,439 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,440 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,441 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,442 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,443 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:36,448 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:36,452 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:36,457 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:36,537 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 07:57:36,571 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 07:57:36,573 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:36,576 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:36,585 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:36,594 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,595 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,596 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,598 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,599 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:36,614 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:36,646 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:36,657 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:36,661 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 07:57:36,696 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 07:57:36,697 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:36,700 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:36,711 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:36,719 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,720 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,723 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,724 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,725 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:36,737 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:36,741 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:36,744 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:36,747 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 07:57:36,749 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 07:57:36,749 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:36,751 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:36,759 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:36,767 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,768 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,769 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,769 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,770 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:36,775 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:36,778 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:36,783 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:36,786 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 07:57:36,787 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 07:57:36,788 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:36,790 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:36,798 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:36,799 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,800 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,801 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,802 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,803 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:36,807 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:36,811 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:36,815 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:36,819 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 07:57:36,820 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 07:57:36,821 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:36,824 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:36,825 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:36,833 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,833 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:36,834 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,835 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:36,836 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:36,839 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:36,841 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:36,844 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:36,846 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:36,846 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:36,847 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:36,848 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:36,850 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:36,851 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,852 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:36,852 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,853 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:36,854 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:36,868 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:36,875 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:36,887 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:36,894 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:36,900 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:36,900 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:36,908 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:36,910 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:36,911 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:36,912 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:36,913 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:36,914 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:36,915 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:36,917 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:36,918 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:36,919 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:36,920 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:36,921 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:36,923 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:36,924 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:36,926 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:36,927 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 26]), 25)
2023-10-07 07:57:36,928 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:36,929 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 26]), 25)
2023-10-07 07:57:36,929 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:36,930 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:36,931 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:36,932 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:36,933 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:36,934 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:36,935 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:36,936 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:36,937 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:36,944 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:36,952 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:36,953 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,954 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:36,955 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:36,955 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:36,960 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:36,967 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:36,973 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:36,980 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 07:57:36,983 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 07:57:36,984 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:36,986 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:36,994 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:37,004 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,005 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,006 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,007 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,007 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:37,015 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:37,023 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:37,029 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:37,033 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 07:57:37,034 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 07:57:37,036 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:37,039 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:37,046 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:37,054 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,054 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,056 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,057 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,058 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:37,065 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:37,069 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:37,072 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:37,096 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 07:57:37,099 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 07:57:37,100 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:37,104 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:37,114 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:37,123 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,124 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,126 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,127 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,127 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:37,134 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:37,143 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:37,146 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:37,160 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 07:57:37,164 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 07:57:37,165 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:37,168 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:37,176 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:37,186 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,187 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,188 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,188 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,189 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:37,198 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:37,201 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:37,205 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:37,268 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 07:57:37,279 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 07:57:37,280 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:37,283 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:37,292 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:37,301 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,302 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,303 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,304 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,305 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:37,309 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:37,312 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:37,315 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:37,318 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 07:57:37,320 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 07:57:37,320 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:37,323 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:37,331 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:37,339 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,340 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,341 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,342 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,343 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:37,387 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:37,390 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:37,393 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:37,410 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 07:57:37,412 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 07:57:37,413 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:37,415 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:37,423 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:37,431 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,432 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,433 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,434 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,435 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:37,440 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:37,443 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:37,446 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:37,456 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 07:57:37,457 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 07:57:37,458 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:37,460 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:37,467 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:37,476 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,477 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,478 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,479 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,479 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:37,483 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:37,486 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:37,489 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:37,501 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 07:57:37,503 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 07:57:37,504 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:37,507 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:37,515 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:37,523 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,524 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,524 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,525 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,526 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:37,530 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:37,536 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:37,541 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:37,544 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 07:57:37,546 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 07:57:37,547 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:37,549 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:37,557 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:37,566 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,567 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,567 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,568 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,569 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:37,578 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:37,585 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:37,588 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:37,593 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 07:57:37,598 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 07:57:37,600 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:37,602 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:37,610 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:37,612 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,612 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,613 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,614 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,615 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:37,619 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:37,623 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:37,626 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:37,629 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 07:57:37,631 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 07:57:37,632 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:37,635 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:37,637 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:37,645 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,646 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:37,647 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,647 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:37,648 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:37,650 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:37,654 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:37,655 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:37,658 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:37,659 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:37,660 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:37,662 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:37,663 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:37,665 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,666 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:37,666 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,667 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:37,668 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:37,677 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:37,687 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:37,700 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:37,709 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:37,711 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:37,712 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:37,720 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:37,722 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:37,723 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:37,724 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:37,724 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:37,725 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:37,726 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:37,727 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:37,728 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:37,729 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:37,730 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:37,730 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:37,731 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:37,733 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:37,734 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:37,736 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 27]), 26)
2023-10-07 07:57:37,737 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:37,737 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 27]), 26)
2023-10-07 07:57:37,738 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:37,739 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:37,740 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:37,742 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:37,743 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:37,744 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:37,744 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:37,745 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:37,746 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:37,755 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:37,763 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,764 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,765 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,765 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,767 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:37,773 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:37,778 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:37,786 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:37,792 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 07:57:37,794 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 07:57:37,795 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:37,797 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:37,805 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:37,813 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,814 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,815 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,816 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,817 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:37,822 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:37,832 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:37,836 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:37,842 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 07:57:37,844 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 07:57:37,844 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:37,847 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:37,855 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:37,863 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,864 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,865 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,865 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,866 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:37,870 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:37,873 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:37,879 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:37,889 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 07:57:37,890 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 07:57:37,892 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:37,894 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:37,901 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:37,909 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,910 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,911 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,911 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,912 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:37,916 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:37,921 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:37,924 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:37,927 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 07:57:37,929 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 07:57:37,930 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:37,932 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:37,940 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:37,949 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,950 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,951 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:37,951 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,953 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:37,965 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:37,968 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:37,971 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:37,974 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 07:57:37,976 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 07:57:37,976 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:37,980 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:37,987 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:37,998 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:37,998 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:37,999 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,000 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,001 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:38,009 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:38,012 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:38,015 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:38,018 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 07:57:38,019 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 07:57:38,020 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:38,022 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:38,030 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:38,039 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,039 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,040 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,041 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,041 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:38,047 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:38,051 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:38,060 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:38,063 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 07:57:38,068 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 07:57:38,069 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:38,071 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:38,079 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:38,087 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,088 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,089 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,089 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,090 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:38,099 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:38,103 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:38,107 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:38,111 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 07:57:38,112 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 07:57:38,113 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:38,115 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:38,124 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:38,132 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,134 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,134 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,135 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,136 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:38,141 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:38,144 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:38,148 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:38,162 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 07:57:38,171 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 07:57:38,172 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:38,174 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:38,183 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:38,191 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,192 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,192 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,193 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,194 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:38,202 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:38,208 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:38,236 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:38,239 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 07:57:38,241 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 07:57:38,242 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:38,244 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:38,252 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:38,261 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,261 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,262 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,263 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,264 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:38,270 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:38,277 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:38,280 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:38,282 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 07:57:38,285 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 07:57:38,286 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:38,288 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:38,297 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:38,299 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,300 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,300 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,301 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,302 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:38,309 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:38,312 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:38,315 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:38,317 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 07:57:38,319 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 07:57:38,319 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:38,321 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:38,323 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:38,331 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,332 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:38,333 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,333 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:38,334 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:38,336 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:38,338 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:38,339 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:38,340 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:38,341 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:38,342 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:38,344 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:38,345 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:38,347 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,348 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:38,348 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,349 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:38,350 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:38,361 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:38,369 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:38,378 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:38,386 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:38,388 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:38,390 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:38,397 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:38,398 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:38,400 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:38,400 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:38,401 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:38,402 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:38,403 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:38,405 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:38,406 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:38,407 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:38,408 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:38,409 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:38,410 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:38,412 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:38,413 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:38,415 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 28]), 27)
2023-10-07 07:57:38,416 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:38,417 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 28]), 27)
2023-10-07 07:57:38,418 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:38,419 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:38,420 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:38,421 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:38,423 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:38,424 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:38,425 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:38,426 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:38,427 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:38,435 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:38,444 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,444 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,445 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,446 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,447 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:38,458 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:38,461 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:38,464 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:38,466 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 07:57:38,469 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 07:57:38,470 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:38,473 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:38,481 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:38,489 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,490 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,490 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,491 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,492 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:38,496 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:38,498 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:38,501 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:38,512 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 07:57:38,514 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 07:57:38,515 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:38,518 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:38,526 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:38,534 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,535 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,536 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,536 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,537 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:38,561 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:38,564 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:38,570 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:38,577 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 07:57:38,579 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 07:57:38,579 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:38,582 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:38,591 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:38,600 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,601 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,601 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,603 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,603 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:38,609 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:38,617 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:38,620 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:38,623 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 07:57:38,624 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 07:57:38,625 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:38,628 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:38,637 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:38,646 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,647 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,647 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,648 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,649 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:38,658 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:38,661 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:38,664 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:38,666 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 07:57:38,673 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 07:57:38,674 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:38,676 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:38,684 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:38,692 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,693 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,693 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,695 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,695 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:38,705 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:38,708 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:38,711 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:38,721 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 07:57:38,723 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 07:57:38,723 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:38,725 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:38,733 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:38,742 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,743 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,744 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,745 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,745 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:38,758 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:38,761 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:38,764 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:38,767 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 07:57:38,773 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 07:57:38,774 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:38,777 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:38,785 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:38,793 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,794 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,794 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,795 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,796 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:38,801 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:38,805 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:38,809 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:38,812 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 07:57:38,814 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 07:57:38,815 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:38,817 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:38,825 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:38,833 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,834 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,834 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,835 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,836 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:38,842 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:38,846 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:38,853 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:38,856 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 07:57:38,857 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 07:57:38,858 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:38,860 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:38,868 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:38,876 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,877 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,878 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,879 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,879 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:38,883 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:38,886 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:38,935 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:38,953 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 07:57:38,955 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 07:57:38,957 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:38,959 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:38,967 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:38,977 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:38,977 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,979 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:38,980 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:38,981 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:38,989 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:38,993 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:38,997 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:39,000 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 07:57:39,002 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 07:57:39,003 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:39,006 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:39,014 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:39,016 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,016 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,017 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,018 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,019 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:39,024 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:39,028 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:39,073 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:39,107 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 07:57:39,110 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 07:57:39,111 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:39,113 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:39,115 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:39,124 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,124 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:39,125 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,126 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:39,127 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:39,128 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:39,131 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:39,132 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:39,133 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:39,133 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:39,134 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:39,136 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:39,137 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:39,138 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,139 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:39,140 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,141 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:39,141 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:39,152 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:39,162 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:39,171 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:39,181 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:39,182 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:39,183 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:39,192 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:39,194 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:39,196 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:39,196 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:39,197 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:39,198 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:39,199 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:39,200 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:39,201 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:39,202 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:39,203 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:39,204 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:39,205 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:39,207 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:39,208 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:39,210 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 29]), 28)
2023-10-07 07:57:39,211 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:39,212 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 29]), 28)
2023-10-07 07:57:39,213 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:39,213 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:39,215 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:39,216 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:39,218 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:39,219 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:39,220 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:39,220 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:39,222 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:39,230 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:39,237 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,238 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,239 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,239 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,240 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:39,257 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:39,261 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:39,264 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:39,278 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 07:57:39,280 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 07:57:39,281 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:39,283 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:39,291 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:39,300 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,301 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,302 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,304 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,305 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:39,321 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:39,325 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:39,384 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:39,389 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 07:57:39,391 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 07:57:39,392 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:39,395 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:39,404 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:39,413 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,414 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,415 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,416 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,417 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:39,422 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:39,426 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:39,439 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:39,443 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 07:57:39,444 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 07:57:39,445 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:39,448 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:39,456 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:39,464 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,464 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,465 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,466 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,467 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:39,474 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:39,482 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:39,489 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:39,499 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 07:57:39,501 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 07:57:39,502 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:39,505 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:39,513 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:39,522 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,522 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,524 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,525 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,526 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:39,532 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:39,535 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:39,539 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:39,545 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 07:57:39,547 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 07:57:39,548 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:39,551 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:39,558 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:39,566 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,567 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,568 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,569 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,570 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:39,575 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:39,578 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:39,582 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:39,587 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 07:57:39,590 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 07:57:39,591 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:39,594 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:39,602 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:39,611 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,612 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,613 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,614 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,615 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:39,622 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:39,642 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:39,657 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:39,662 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 07:57:39,665 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 07:57:39,666 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:39,668 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:39,678 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:39,686 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,687 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,687 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,688 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,689 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:39,699 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:39,706 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:39,710 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:39,713 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 07:57:39,715 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 07:57:39,717 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:39,719 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:39,727 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:39,735 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,736 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,737 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,738 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,738 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:39,747 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:39,753 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:39,756 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:39,761 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 07:57:39,763 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 07:57:39,763 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:39,766 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:39,774 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:39,782 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,783 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,784 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,785 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,786 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:39,793 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:39,797 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:39,801 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:39,807 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 07:57:39,808 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 07:57:39,809 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:39,811 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:39,821 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:39,830 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,830 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,831 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,832 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,832 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:39,893 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:39,903 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:39,906 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:39,909 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 07:57:39,911 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 07:57:39,912 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:39,915 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:39,923 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:39,924 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,925 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,926 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,927 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:39,927 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:39,938 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:39,943 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:39,946 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:39,950 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 07:57:39,952 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 07:57:39,953 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:39,955 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:39,957 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:39,965 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,965 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:39,966 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,967 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:39,968 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:39,971 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:39,972 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:39,973 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:39,975 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:39,976 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:39,977 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:39,978 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:39,980 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:39,981 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:39,982 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:39,983 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:39,984 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:39,985 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:40,000 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:40,011 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:40,022 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:40,032 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:40,040 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:40,042 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:40,049 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:40,050 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:40,052 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:40,053 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:40,054 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:40,054 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:40,055 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:40,057 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:40,058 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:40,059 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:40,060 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:40,061 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:40,062 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:40,064 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:40,065 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:40,067 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 30]), 29)
2023-10-07 07:57:40,067 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:40,068 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 30]), 29)
2023-10-07 07:57:40,069 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:40,069 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:40,072 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:40,074 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:40,075 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:40,076 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:40,077 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:40,078 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:40,079 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:40,087 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:40,095 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,096 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,097 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,097 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,098 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:40,106 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:40,172 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:40,189 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:40,197 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 07:57:40,215 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 07:57:40,216 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:40,219 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:40,228 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:40,236 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,237 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,238 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,239 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,240 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:40,245 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:40,249 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:40,252 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:40,255 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 07:57:40,256 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 07:57:40,257 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:40,260 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:40,268 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:40,277 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,278 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,278 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,279 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,280 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:40,285 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:40,291 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:40,295 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:40,299 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 07:57:40,301 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 07:57:40,302 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:40,305 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:40,314 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:40,322 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,323 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,324 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,325 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,325 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:40,396 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:40,405 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:40,409 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:40,413 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 07:57:40,417 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 07:57:40,418 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:40,421 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:40,428 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:40,436 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,437 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,438 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,439 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,440 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:40,448 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:40,452 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:40,454 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:40,458 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 07:57:40,460 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 07:57:40,461 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:40,463 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:40,471 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:40,478 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,479 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,480 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,481 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,482 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:40,486 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:40,489 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:40,492 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:40,523 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 07:57:40,546 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 07:57:40,547 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:40,550 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:40,558 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:40,566 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,567 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,567 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,568 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,569 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:40,580 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:40,583 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:40,586 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:40,592 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 07:57:40,594 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 07:57:40,594 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:40,597 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:40,605 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:40,612 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,613 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,614 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,615 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,615 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:40,622 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:40,625 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:40,630 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:40,633 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 07:57:40,635 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 07:57:40,636 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:40,638 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:40,646 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:40,654 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,655 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,656 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,657 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,658 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:40,663 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:40,666 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:40,669 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:40,729 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 07:57:40,739 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 07:57:40,740 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:40,744 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:40,752 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:40,759 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,760 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,761 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,762 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,763 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:40,773 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:40,781 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:40,784 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:40,787 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 07:57:40,796 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 07:57:40,796 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:40,799 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:40,807 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:40,816 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,817 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,818 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,819 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,820 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:40,828 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:40,832 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:40,834 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:40,837 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 07:57:40,839 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 07:57:40,840 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:40,842 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:40,850 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:40,851 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,852 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,853 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,854 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:40,855 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:40,861 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:40,864 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:40,867 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:40,869 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 07:57:40,871 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 07:57:40,872 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:40,874 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:40,876 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:40,884 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,885 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:40,885 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,886 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:40,887 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:40,893 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:40,903 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:40,911 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:40,916 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:40,917 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:40,918 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:40,920 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:40,922 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:40,924 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:40,925 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:40,926 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:40,927 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:40,928 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:40,946 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:40,959 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:40,971 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:40,979 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:40,982 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:40,983 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:40,991 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:40,992 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:40,994 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:40,995 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:40,995 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:40,996 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:40,997 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:40,998 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:41,000 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:41,000 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:41,002 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:41,002 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:41,003 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:41,004 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:41,006 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:41,008 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 31]), 30)
2023-10-07 07:57:41,008 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:41,009 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 31]), 30)
2023-10-07 07:57:41,010 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:41,011 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:41,012 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:41,013 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:41,015 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:41,016 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:41,016 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:41,017 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:41,018 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:41,026 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:41,034 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,035 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,035 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,036 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,037 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:41,044 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:41,048 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:41,052 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:41,055 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 07:57:41,056 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 07:57:41,057 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:41,060 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:41,068 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:41,076 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,077 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,078 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,079 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,080 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:41,085 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:41,087 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:41,090 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:41,094 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 07:57:41,096 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 07:57:41,096 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:41,099 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:41,107 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:41,116 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,116 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,117 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,118 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,119 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:41,123 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:41,126 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:41,128 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:41,131 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 07:57:41,137 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 07:57:41,138 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:41,141 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:41,149 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:41,157 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,158 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,159 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,160 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,160 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:41,166 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:41,169 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:41,172 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:41,177 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 07:57:41,179 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 07:57:41,180 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:41,182 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:41,191 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:41,202 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,203 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,204 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,205 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,206 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:41,211 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:41,217 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:41,223 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:41,231 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 07:57:41,233 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 07:57:41,234 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:41,237 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:41,244 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:41,252 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,253 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,254 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,255 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,256 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:41,265 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:41,268 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:41,276 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:41,286 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 07:57:41,288 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 07:57:41,289 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:41,291 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:41,299 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:41,309 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,310 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,310 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,311 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,312 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:41,317 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:41,321 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:41,326 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:41,330 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 07:57:41,333 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 07:57:41,334 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:41,336 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:41,344 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:41,353 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,353 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,354 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,355 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,356 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:41,365 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:41,369 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:41,412 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:41,451 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 07:57:41,454 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 07:57:41,455 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:41,460 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:41,471 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:41,483 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,485 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,487 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,488 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,488 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:41,495 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:41,498 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:41,502 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:41,504 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 07:57:41,506 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 07:57:41,506 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:41,509 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:41,517 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:41,526 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,527 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,528 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,529 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,529 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:41,534 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:41,549 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:41,553 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:41,556 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 07:57:41,559 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 07:57:41,560 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:41,564 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:41,572 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:41,580 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,581 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,581 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,582 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,583 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:41,590 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:41,599 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:41,604 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:41,613 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 07:57:41,614 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 07:57:41,616 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:41,618 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:41,626 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:41,627 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,628 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,628 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,629 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,630 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:41,635 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:41,638 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:41,641 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:41,645 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 07:57:41,652 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 07:57:41,653 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:41,656 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:41,658 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:41,666 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,667 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:41,668 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,669 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:41,670 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:41,672 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:41,676 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:41,678 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:41,683 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:41,684 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:41,685 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:41,686 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:41,688 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:41,689 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,690 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:41,690 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,691 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:41,692 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:41,701 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:41,713 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:41,721 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:41,730 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:41,733 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:41,734 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:41,745 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:41,747 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:41,749 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:41,750 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:41,751 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:41,752 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:41,752 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:41,754 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:41,755 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:41,756 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:41,757 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:41,759 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:41,759 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:41,761 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:41,763 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:41,765 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 32]), 31)
2023-10-07 07:57:41,765 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:41,766 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 32]), 31)
2023-10-07 07:57:41,767 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:41,768 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:41,770 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:41,771 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:41,772 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:41,773 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:41,774 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:41,774 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:41,776 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:41,784 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:41,792 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,793 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,794 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,795 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,796 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:41,828 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:41,832 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:41,835 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:41,838 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 07:57:41,843 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 07:57:41,844 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:41,847 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:41,856 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:41,864 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,864 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,866 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,867 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,867 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:41,875 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:41,878 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:41,885 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:41,889 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 07:57:41,890 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 07:57:41,891 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:41,895 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:41,904 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:41,912 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,913 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,914 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,915 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,915 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:41,925 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:41,928 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:41,930 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:41,932 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 07:57:41,934 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 07:57:41,935 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:41,939 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:41,947 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:41,955 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:41,956 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,957 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:41,958 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:41,958 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:41,964 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:41,967 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:41,970 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:41,976 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 07:57:41,981 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 07:57:41,982 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:41,985 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:41,993 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:42,001 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,002 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,004 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,005 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,005 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:42,011 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:42,022 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:42,030 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:42,034 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 07:57:42,039 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 07:57:42,041 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:42,043 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:42,051 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:42,059 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,060 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,061 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,062 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,063 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:42,070 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:42,073 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:42,076 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:42,081 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 07:57:42,084 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 07:57:42,085 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:42,088 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:42,096 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:42,104 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,105 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,105 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,106 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,107 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:42,111 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:42,124 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:42,128 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:42,135 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 07:57:42,194 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 07:57:42,196 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:42,199 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:42,207 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:42,215 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,215 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,216 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,218 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,218 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:42,233 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:42,236 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:42,239 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:42,247 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 07:57:42,250 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 07:57:42,251 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:42,254 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:42,261 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:42,269 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,270 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,271 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,272 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,273 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:42,278 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:42,283 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:42,295 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:42,299 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 07:57:42,301 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 07:57:42,302 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:42,305 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:42,314 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:42,322 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,323 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,324 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,325 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,325 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:42,330 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:42,332 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:42,335 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:42,338 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 07:57:42,342 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 07:57:42,344 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:42,347 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:42,355 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:42,363 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,363 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,365 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,366 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,366 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:42,374 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:42,380 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:42,384 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:42,387 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 07:57:42,388 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 07:57:42,389 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:42,391 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:42,400 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:42,401 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,402 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,403 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,403 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,404 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:42,410 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:42,413 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:42,420 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:42,431 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 07:57:42,433 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 07:57:42,434 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:42,437 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:42,438 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:42,446 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,447 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:42,448 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,449 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:42,450 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:42,453 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:42,455 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:42,459 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:42,462 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:42,463 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:42,464 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:42,466 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:42,468 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:42,469 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,470 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:42,471 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,472 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:42,473 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:42,488 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:42,496 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:42,504 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:42,512 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:42,515 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:42,517 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:42,537 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:42,540 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:42,541 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:42,542 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:42,543 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:42,543 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:42,544 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:42,546 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:42,547 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:42,548 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:42,549 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:42,549 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:42,550 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:42,552 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:42,553 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:42,555 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 33]), 32)
2023-10-07 07:57:42,555 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:42,556 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 33]), 32)
2023-10-07 07:57:42,557 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:42,558 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:42,559 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:42,560 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:42,561 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:42,562 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:42,563 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:42,564 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:42,565 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:42,573 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:42,581 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,582 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,583 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,584 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,585 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:42,596 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:42,601 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:42,604 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:42,608 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 07:57:42,610 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 07:57:42,611 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:42,614 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:42,622 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:42,630 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,631 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,632 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,633 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,634 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:42,640 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:42,651 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:42,655 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:42,658 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 07:57:42,660 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 07:57:42,661 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:42,665 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:42,677 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:42,688 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,689 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,691 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,691 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,692 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:42,699 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:42,702 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:42,715 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:42,719 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 07:57:42,720 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 07:57:42,721 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:42,724 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:42,731 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:42,739 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,740 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,741 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,741 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,742 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:42,746 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:42,749 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:42,752 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:42,754 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 07:57:42,758 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 07:57:42,760 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:42,762 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:42,770 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:42,779 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,790 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,791 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,792 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,793 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:42,881 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:42,934 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:42,944 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:42,948 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 07:57:42,950 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 07:57:42,951 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:42,953 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:42,961 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:42,969 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:42,970 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,971 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:42,972 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:42,973 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:42,977 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:42,980 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:42,983 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:42,985 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 07:57:42,987 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 07:57:42,988 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:42,990 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:42,998 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:43,006 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,007 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,008 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,008 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,009 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:43,057 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:43,060 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:43,063 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:43,089 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 07:57:43,092 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 07:57:43,093 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:43,095 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:43,103 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:43,111 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,112 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,113 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,114 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,115 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:43,119 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:43,121 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:43,124 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:43,129 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 07:57:43,131 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 07:57:43,131 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:43,134 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:43,141 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:43,150 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,151 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,152 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,153 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,154 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:43,162 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:43,166 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:43,169 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:43,172 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 07:57:43,174 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 07:57:43,175 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:43,177 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:43,186 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:43,195 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,196 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,197 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,198 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,199 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:43,204 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:43,207 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:43,210 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:43,217 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 07:57:43,219 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 07:57:43,220 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:43,222 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:43,232 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:43,241 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,245 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,246 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,247 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,248 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:43,306 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:43,313 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:43,316 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:43,319 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 07:57:43,320 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 07:57:43,321 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:43,324 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:43,332 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:43,334 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,335 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,336 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,337 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,338 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:43,342 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:43,344 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:43,347 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:43,350 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 07:57:43,355 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 07:57:43,356 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:43,358 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:43,360 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:43,369 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,369 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:43,370 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,371 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:43,372 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:43,375 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:43,376 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:43,377 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:43,378 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:43,379 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:43,380 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:43,382 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:43,383 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:43,385 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,385 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:43,386 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,387 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:43,388 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:43,399 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:43,409 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:43,417 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:43,426 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:43,429 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:43,430 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:43,440 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:43,442 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:43,444 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:43,444 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:43,445 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:43,446 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:43,447 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:43,449 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:43,450 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:43,451 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:43,452 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:43,453 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:43,454 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:43,456 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:43,457 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:43,459 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 34]), 33)
2023-10-07 07:57:43,460 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:43,461 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 34]), 33)
2023-10-07 07:57:43,462 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:43,462 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:43,465 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:43,466 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:43,467 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:43,468 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:43,469 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:43,470 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:43,472 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:43,479 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:43,488 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,489 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,490 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,491 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,491 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:43,498 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:43,530 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:43,623 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:43,638 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 07:57:43,667 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 07:57:43,669 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:43,672 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:43,680 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:43,689 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,690 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,691 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,692 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,692 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:43,700 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:43,704 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:43,707 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:43,711 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 07:57:43,712 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 07:57:43,714 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:43,716 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:43,725 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:43,735 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,736 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,737 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,738 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,738 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:43,748 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:43,751 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:43,755 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:43,758 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 07:57:43,759 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 07:57:43,760 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:43,763 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:43,770 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:43,778 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,779 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,780 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,781 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,782 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:43,792 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:43,811 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:43,822 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:43,827 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 07:57:43,831 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 07:57:43,833 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:43,835 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:43,843 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:43,851 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,851 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,852 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,853 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,854 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:43,862 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:43,866 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:43,870 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:43,874 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 07:57:43,876 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 07:57:43,877 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:43,879 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:43,887 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:43,895 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,896 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,896 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,898 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,898 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:43,906 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:43,916 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:43,921 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:43,925 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 07:57:43,928 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 07:57:43,929 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:43,932 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:43,940 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:43,949 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,950 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,951 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:43,952 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:43,953 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:43,962 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:43,968 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:43,972 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:43,976 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 07:57:43,979 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 07:57:43,980 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:43,983 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:43,991 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:43,999 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:43,999 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,000 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,001 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,002 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:44,008 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:44,012 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:44,016 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:44,020 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 07:57:44,022 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 07:57:44,023 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:44,026 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:44,033 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:44,042 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,042 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,044 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,045 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,046 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:44,051 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:44,055 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:44,058 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:44,062 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 07:57:44,063 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 07:57:44,064 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:44,067 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:44,075 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:44,084 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,085 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,086 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,087 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,087 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:44,096 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:44,100 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:44,104 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:44,108 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 07:57:44,110 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 07:57:44,111 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:44,114 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:44,122 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:44,131 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,132 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,133 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,134 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,135 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:44,143 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:44,149 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:44,152 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:44,156 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 07:57:44,158 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 07:57:44,159 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:44,161 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:44,169 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:44,170 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,171 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,172 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,173 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,175 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:44,182 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:44,198 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:44,201 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:44,204 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 07:57:44,205 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 07:57:44,206 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:44,208 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:44,210 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:44,227 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,228 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:44,229 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,231 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:44,232 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:44,236 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:44,239 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:44,244 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:44,248 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:44,249 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:44,249 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:44,251 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:44,252 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:44,261 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,262 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:44,263 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,264 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:44,265 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:44,279 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:44,304 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:44,317 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:44,335 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:44,369 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:44,371 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:44,444 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:44,446 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:44,448 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:44,449 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:44,450 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:44,451 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:44,452 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:44,453 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:44,454 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:44,456 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:44,457 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:44,458 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:44,459 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:44,461 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:44,463 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:44,464 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 35]), 34)
2023-10-07 07:57:44,465 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:44,466 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 35]), 34)
2023-10-07 07:57:44,466 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:44,467 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:44,469 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:44,470 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:44,471 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:44,472 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:44,472 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:44,473 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:44,475 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:44,481 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:44,488 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,489 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,490 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,491 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,492 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:44,498 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:44,505 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:44,569 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:44,574 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 07:57:44,577 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 07:57:44,578 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:44,581 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:44,589 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:44,598 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,599 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,600 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,601 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,602 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:44,608 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:44,612 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:44,617 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:44,621 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 07:57:44,623 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 07:57:44,624 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:44,626 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:44,636 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:44,645 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,646 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,647 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,647 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,648 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:44,656 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:44,661 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:44,668 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:44,672 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 07:57:44,673 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 07:57:44,675 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:44,679 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:44,687 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:44,695 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,696 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,697 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,698 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,699 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:44,714 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:44,764 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:44,768 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:44,771 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 07:57:44,772 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 07:57:44,773 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:44,777 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:44,787 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:44,796 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,797 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,798 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,799 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,799 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:44,803 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:44,806 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:44,809 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:44,825 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 07:57:44,827 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 07:57:44,827 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:44,830 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:44,838 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:44,845 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,846 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,847 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,848 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,848 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:44,852 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:44,855 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:44,857 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:44,895 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 07:57:44,903 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 07:57:44,904 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:44,907 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:44,914 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:44,922 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,924 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,925 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,926 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,927 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:44,945 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:44,948 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:44,951 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:44,953 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 07:57:44,954 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 07:57:44,955 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:44,958 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:44,965 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:44,973 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:44,973 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,974 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:44,976 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:44,976 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:44,981 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:44,983 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:44,986 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:44,989 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 07:57:44,991 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 07:57:44,991 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:44,994 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:45,001 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:45,009 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,010 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,012 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,012 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,013 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:45,018 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:45,020 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:45,023 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:45,026 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 07:57:45,068 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 07:57:45,069 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:45,072 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:45,080 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:45,087 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,088 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,089 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,090 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,090 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:45,151 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:45,162 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:45,167 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:45,171 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 07:57:45,173 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 07:57:45,173 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:45,176 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:45,183 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:45,191 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,192 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,193 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,194 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,194 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:45,199 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:45,202 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:45,205 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:45,215 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 07:57:45,218 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 07:57:45,219 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:45,222 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:45,229 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:45,231 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,231 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,232 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,233 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,233 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:45,265 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:45,269 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:45,273 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:45,276 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 07:57:45,278 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 07:57:45,279 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:45,281 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:45,283 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:45,291 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,292 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:45,293 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,293 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:45,294 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:45,297 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:45,299 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:45,303 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:45,306 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:45,307 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:45,308 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:45,310 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:45,311 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:45,312 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,313 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:45,314 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,315 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:45,316 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:45,329 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:45,337 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:45,345 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:45,353 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:45,355 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:45,356 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:45,365 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:45,367 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:45,368 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:45,369 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:45,370 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:45,371 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:45,371 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:45,373 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:45,374 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:45,375 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:45,376 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:45,377 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:45,377 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:45,379 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:45,380 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:45,382 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 36]), 35)
2023-10-07 07:57:45,383 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:45,384 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 36]), 35)
2023-10-07 07:57:45,385 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:45,385 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:45,387 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:45,388 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:45,389 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:45,390 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:45,391 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:45,392 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:45,393 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:45,401 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:45,409 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,409 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,410 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,411 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,412 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:45,420 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:45,425 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:45,429 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:45,435 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 07:57:45,437 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 07:57:45,438 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:45,440 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:45,449 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:45,461 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,462 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,464 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,465 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,467 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:45,482 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:45,550 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:45,554 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:45,557 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 07:57:45,559 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 07:57:45,560 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:45,562 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:45,571 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:45,580 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,581 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,582 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,583 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,584 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:45,594 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:45,597 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:45,600 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:45,602 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 07:57:45,623 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 07:57:45,624 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:45,627 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:45,635 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:45,644 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,644 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,645 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,646 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,647 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:45,694 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:45,736 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:45,740 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:45,743 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 07:57:45,744 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 07:57:45,745 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:45,748 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:45,755 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:45,763 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,764 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,766 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,766 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,767 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:45,772 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:45,775 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:45,778 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:45,781 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 07:57:45,782 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 07:57:45,783 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:45,786 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:45,793 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:45,801 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,802 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,803 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,804 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,805 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:45,812 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:45,815 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:45,818 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:45,821 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 07:57:45,831 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 07:57:45,833 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:45,835 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:45,843 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:45,851 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,852 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,853 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,854 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,855 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:45,867 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:45,873 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:45,876 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:45,879 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 07:57:45,881 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 07:57:45,882 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:45,885 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:45,893 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:45,901 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,901 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,903 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,903 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,904 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:45,912 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:45,919 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:45,922 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:45,936 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 07:57:45,954 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 07:57:45,955 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:45,957 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:45,965 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:45,973 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:45,974 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,975 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:45,976 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:45,976 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:45,980 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:45,983 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:45,986 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:45,990 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 07:57:45,991 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 07:57:45,992 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:45,995 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:46,002 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:46,010 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,011 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,012 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,012 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,013 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:46,019 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:46,022 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:46,024 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:46,027 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 07:57:46,036 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 07:57:46,037 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:46,040 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:46,048 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:46,060 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,061 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,062 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,063 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,064 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:46,072 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:46,074 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:46,077 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:46,079 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 07:57:46,081 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 07:57:46,082 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:46,085 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:46,093 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:46,095 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,095 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,096 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,097 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,098 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:46,106 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:46,109 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:46,114 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:46,117 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 07:57:46,119 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 07:57:46,120 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:46,122 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:46,124 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:46,132 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,136 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:46,137 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,138 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:46,139 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:46,153 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:46,159 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:46,164 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:46,167 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:46,169 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:46,170 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:46,171 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:46,175 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:46,177 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,179 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:46,181 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,182 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:46,183 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:46,196 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:46,214 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:46,224 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:46,235 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:46,237 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:46,239 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:46,250 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:46,252 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:46,254 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:46,255 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:46,256 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:46,256 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:46,257 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:46,259 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:46,260 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:46,261 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:46,262 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:46,263 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:46,264 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:46,265 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:46,267 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:46,268 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 37]), 36)
2023-10-07 07:57:46,269 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:46,270 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 37]), 36)
2023-10-07 07:57:46,271 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:46,272 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:46,273 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:46,274 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:46,275 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:46,276 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:46,277 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:46,278 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:46,279 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:46,287 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:46,294 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,295 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,296 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,297 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,297 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:46,308 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:46,311 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:46,314 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:46,322 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 07:57:46,325 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 07:57:46,326 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:46,329 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:46,338 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:46,346 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,347 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,348 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,349 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,350 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:46,354 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:46,386 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:46,426 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:46,442 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 07:57:46,444 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 07:57:46,445 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:46,447 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:46,455 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:46,464 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,465 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,466 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,467 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,467 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:46,472 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:46,476 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:46,478 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:46,486 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 07:57:46,489 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 07:57:46,490 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:46,493 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:46,502 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:46,510 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,511 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,512 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,512 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,513 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:46,518 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:46,522 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:46,530 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:46,534 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 07:57:46,536 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 07:57:46,537 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:46,539 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:46,547 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:46,556 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,557 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,558 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,563 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,564 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:46,601 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:46,608 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:46,622 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:46,629 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 07:57:46,632 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 07:57:46,634 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:46,637 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:46,645 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:46,654 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,656 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,656 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,657 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,658 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:46,667 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:46,675 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:46,679 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:46,683 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 07:57:46,686 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 07:57:46,686 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:46,689 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:46,697 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:46,706 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,707 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,708 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,709 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,709 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:46,714 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:46,720 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:46,724 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:46,729 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 07:57:46,731 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 07:57:46,732 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:46,736 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:46,745 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:46,753 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,754 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,755 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,756 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,757 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:46,761 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:46,767 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:46,776 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:46,784 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 07:57:46,791 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 07:57:46,792 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:46,795 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:46,803 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:46,812 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,812 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,813 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,814 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,815 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:46,820 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:46,823 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:46,827 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:46,837 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 07:57:46,841 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 07:57:46,842 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:46,845 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:46,853 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:46,861 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,862 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,863 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,864 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,864 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:46,870 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:46,873 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:46,876 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:46,879 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 07:57:46,891 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 07:57:46,892 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:46,894 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:46,902 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:46,911 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,912 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,913 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,914 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,915 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:46,921 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:46,931 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:46,934 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:46,952 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 07:57:46,954 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 07:57:46,955 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:46,957 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:46,965 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:46,966 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:46,967 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,968 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:46,969 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:46,971 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:47,041 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:47,047 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:47,051 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:47,055 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 07:57:47,057 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 07:57:47,057 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:47,060 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:47,062 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:47,071 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,072 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:47,073 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,074 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:47,075 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:47,076 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:47,082 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:47,087 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:47,091 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:47,092 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:47,093 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:47,094 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:47,095 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:47,097 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,098 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:47,099 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,100 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:47,100 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:47,115 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:47,127 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:47,137 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:47,145 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:47,151 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:47,152 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:47,160 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:47,162 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:47,163 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:47,164 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:47,165 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:47,166 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:47,167 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:47,168 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:47,169 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:47,171 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:47,173 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:47,173 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:47,174 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:47,176 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:47,177 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:47,179 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 38]), 37)
2023-10-07 07:57:47,180 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:47,180 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 38]), 37)
2023-10-07 07:57:47,181 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:47,182 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:47,184 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:47,185 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:47,186 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:47,187 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:47,188 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:47,189 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:47,190 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:47,198 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:47,206 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,207 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,208 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,209 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,210 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:47,241 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:47,244 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:47,247 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:47,250 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 07:57:47,252 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 07:57:47,253 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:47,255 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:47,264 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:47,271 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,272 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,273 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,274 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,275 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:47,280 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:47,284 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:47,287 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:47,292 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 07:57:47,295 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 07:57:47,296 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:47,299 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:47,307 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:47,315 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,316 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,317 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,318 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,319 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:47,331 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:47,335 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:47,402 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:47,419 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 07:57:47,427 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 07:57:47,428 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:47,431 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:47,439 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:47,447 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,448 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,449 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,450 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,450 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:47,455 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:47,458 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:47,463 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:47,467 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 07:57:47,468 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 07:57:47,469 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:47,472 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:47,480 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:47,488 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,489 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,490 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,491 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,491 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:47,498 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:47,501 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:47,504 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:47,507 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 07:57:47,510 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 07:57:47,512 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:47,514 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:47,523 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:47,531 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,532 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,533 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,534 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,534 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:47,541 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:47,544 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:47,547 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:47,552 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 07:57:47,554 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 07:57:47,555 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:47,558 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:47,567 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:47,575 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,575 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,576 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,577 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,578 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:47,587 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:47,589 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:47,592 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:47,594 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 07:57:47,599 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 07:57:47,600 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:47,602 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:47,611 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:47,619 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,620 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,621 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,622 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,622 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:47,628 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:47,632 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:47,637 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:47,640 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 07:57:47,641 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 07:57:47,642 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:47,645 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:47,652 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:47,662 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,663 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,664 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,665 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,666 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:47,677 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:47,680 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:47,683 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:47,687 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 07:57:47,689 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 07:57:47,690 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:47,692 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:47,700 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:47,708 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,708 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,710 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,710 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,711 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:47,717 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:47,721 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:47,733 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:47,737 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 07:57:47,740 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 07:57:47,741 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:47,744 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:47,752 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:47,761 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,762 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,763 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,764 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,764 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:47,775 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:47,779 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:47,781 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:47,785 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 07:57:47,787 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 07:57:47,787 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:47,790 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:47,798 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:47,800 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,801 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,802 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,802 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,803 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:47,808 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:47,813 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:47,816 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:47,820 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 07:57:47,822 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 07:57:47,823 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:47,825 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:47,827 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:47,836 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,836 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:47,837 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,838 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:47,839 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:47,841 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:47,843 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:47,847 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:47,849 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:47,851 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:47,852 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:47,854 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:47,855 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:47,857 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,857 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:47,858 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,859 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:47,860 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:47,873 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:47,884 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:47,896 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:47,908 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:47,910 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:47,911 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:47,923 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:47,925 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:47,926 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 07:57:47,927 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:47,928 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 07:57:47,929 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:47,930 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 07:57:47,931 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 07:57:47,932 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 07:57:47,933 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 07:57:47,934 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:47,935 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:47,936 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 07:57:47,937 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 07:57:47,939 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:47,941 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 39]), 38)
2023-10-07 07:57:47,941 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:47,942 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 39]), 38)
2023-10-07 07:57:47,943 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:47,944 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 07:57:47,945 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 07:57:47,946 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 07:57:47,947 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 07:57:47,948 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:47,949 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:47,950 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 07:57:47,951 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:47,959 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:47,968 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:47,968 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,969 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:47,970 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:47,971 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 07:57:47,981 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 07:57:47,987 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 07:57:47,990 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 07:57:47,993 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 07:57:47,994 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 07:57:47,995 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 07:57:47,998 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 07:57:48,006 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:48,021 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:48,022 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,023 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:48,024 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,025 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 07:57:48,029 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 07:57:48,034 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 07:57:48,050 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 07:57:48,078 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 07:57:48,081 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 07:57:48,082 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 07:57:48,085 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 07:57:48,096 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:48,107 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:48,108 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,109 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:48,110 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,111 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 07:57:48,117 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 07:57:48,120 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 07:57:48,123 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 07:57:48,129 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 07:57:48,131 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 07:57:48,132 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 07:57:48,134 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 07:57:48,142 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:48,151 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:48,151 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,152 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:48,153 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,154 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 07:57:48,210 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 07:57:48,214 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 07:57:48,261 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 07:57:48,266 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 07:57:48,268 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 07:57:48,269 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 07:57:48,271 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 07:57:48,281 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:48,289 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:48,290 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,291 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:48,292 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,293 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 07:57:48,298 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 07:57:48,302 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 07:57:48,305 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 07:57:48,311 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 07:57:48,313 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 07:57:48,314 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 07:57:48,316 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 07:57:48,325 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:48,334 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:48,335 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,336 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:48,337 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,337 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 07:57:48,350 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 07:57:48,353 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 07:57:48,356 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 07:57:48,359 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 07:57:48,361 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 07:57:48,362 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 07:57:48,364 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 07:57:48,373 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:48,382 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:48,383 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,384 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:48,385 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,386 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 07:57:48,390 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 07:57:48,394 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 07:57:48,398 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 07:57:48,402 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 07:57:48,404 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 07:57:48,405 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 07:57:48,408 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 07:57:48,416 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:48,424 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:48,425 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,426 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:48,426 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,427 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 07:57:48,432 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 07:57:48,435 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 07:57:48,438 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 07:57:48,442 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 07:57:48,444 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 07:57:48,444 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 07:57:48,447 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 07:57:48,454 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:48,462 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:48,463 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,464 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:48,464 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,465 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 07:57:48,469 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 07:57:48,472 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 07:57:48,475 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 07:57:48,478 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 07:57:48,481 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 07:57:48,482 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 07:57:48,484 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 07:57:48,492 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:48,500 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:48,501 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,502 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:48,502 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,503 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 07:57:48,556 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 07:57:48,599 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 07:57:48,603 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 07:57:48,606 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 07:57:48,608 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 07:57:48,609 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 07:57:48,611 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 07:57:48,619 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:48,627 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:48,628 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,629 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:48,630 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,631 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 07:57:48,635 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 07:57:48,638 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 07:57:48,640 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 07:57:48,642 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 07:57:48,650 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 07:57:48,651 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 07:57:48,653 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 07:57:48,661 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:48,663 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:48,663 [457060047.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,664 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:48,665 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 07:57:48,666 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 07:57:48,731 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 07:57:48,737 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 07:57:48,741 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 07:57:48,744 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 07:57:48,746 [457060047.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 07:57:48,747 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 07:57:48,749 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 07:57:48,751 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 07:57:48,759 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:48,760 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:48,761 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:48,762 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:48,763 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 07:57:48,765 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 07:57:48,767 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 07:57:48,768 [457060047.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 07:57:48,769 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 07:57:48,770 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 07:57:48,771 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 07:57:48,772 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 07:57:48,774 [457060047.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 07:57:48,775 [457060047.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 07:57:48,776 [457060047.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 07:57:48,777 [457060047.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 07:57:48,777 [457060047.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 07:57:48,778 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 07:57:48,789 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 07:57:48,800 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 07:57:48,809 [457060047.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 07:57:48,818 [457060047.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 07:57:48,831 [457060047.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 07:57:48,832 [457060047.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 07:57:48,842 [3316428403.py:28 in <module>] INFO - Who are you? Are you conscious?�Hey it's me and I just want to check in with ya... I was having a terrible morning and I woke up to all this horrible silence
2023-10-07 07:57:48,843 [3316428403.py:29 in <module>] INFO - ----------
2023-10-07 07:57:48,844 [3316428403.py:28 in <module>] INFO - Where is Deutschland?, and who is that?
It is one of the best countries in all of North Europe and it is home to the very best music companies around
2023-10-07 07:57:48,845 [3316428403.py:29 in <module>] INFO - ----------
2023-10-07 07:57:48,846 [3316428403.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?
Huawei Mate 60 Pro is a little bit different, as the phone comes complete with all the features but includes all the extra modules for the Mate
2023-10-07 07:57:48,847 [3316428403.py:29 in <module>] INFO - ----------
2023-10-07 07:57:48,848 [3316428403.py:28 in <module>] INFO - Who are you? Are you conscious?�
Im thinking of a girl who's pretty and I live in a town with a lot of homeless/emotional kids in town. I'd
2023-10-07 07:57:48,848 [3316428403.py:29 in <module>] INFO - ----------
2023-10-07 07:57:48,850 [3316428403.py:28 in <module>] INFO - Where is Deutschland?- German: “It’s not about the words, but the whole idea of Europe that is about the words.”
Yeah
2023-10-07 07:57:48,850 [3316428403.py:29 in <module>] INFO - ----------
2023-10-07 07:57:48,851 [3316428403.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?
There seems to be a lot of interest from the Huawei lovers for the Huawei Mate 60 Pro smartphone (at the latest rumors), but it has to
2023-10-07 07:57:48,852 [3316428403.py:29 in <module>] INFO - ----------
2023-10-07 07:57:48,852 [3316428403.py:28 in <module>] INFO - Who are you? Are you conscious?
Haha. Oh shit. Thanks for the reply!
2023-10-07 07:57:48,853 [3316428403.py:29 in <module>] INFO - ----------
2023-10-07 07:57:48,855 [3316428403.py:28 in <module>] INFO - Where is Deutschland?awn on tumblr
He just got killed by a horde of people who were trying to kill him. :P
2023-10-07 07:57:48,856 [3316428403.py:29 in <module>] INFO - ----------
