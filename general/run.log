2023-10-07 08:47:39,384 [instantiator.py:21 in <module>] INFO - Created a temporary directory at /tmp/tmphw68ooxh
2023-10-07 08:47:39,386 [instantiator.py:76 in _write] INFO - Writing /tmp/tmphw68ooxh/_remote_module_non_scriptable.py
2023-10-07 08:47:45,662 [connectionpool.py:1003 in _new_conn] DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2023-10-07 08:47:45,722 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1" 200 0
2023-10-07 08:47:47,349 [tpu_cluster_resolver.py:32 in <module>] DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2023-10-07 08:47:47,518 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5
2023-10-07 08:47:47,519 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7
2023-10-07 08:47:47,520 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5
2023-10-07 08:47:47,522 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7
2023-10-07 08:47:48,575 [flexgen_init.py:202 in get_policy_weight_map] INFO - device_map is prepared!
2023-10-07 08:47:48,582 [flexgen_init.py:208 in get_policy_weight_map] INFO - CausalLM facebook/opt-125m is to be loaded on: 
GPU Mem 0.00 GiB (0.00%), CPU Mem 0.07 GiB (30.19%), Disk Mem 0.16 Gib (69.81%)
2023-10-07 08:47:48,626 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1" 200 0
2023-10-07 08:47:48,844 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1" 200 0
2023-10-07 08:47:48,940 [flexgen_init.py:67 in policy_init] INFO - The whole model has been downloaded an processed to offload_folder: 'offload_dir/facebook.opt-125m'
2023-10-07 08:47:49,028 [flexgen_init.py:79 in policy_init] INFO - model has been loaded by policy.
2023-10-07 08:50:04,521 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.embed_tokens to test forward
2023-10-07 08:50:04,523 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.embed_positions to test forward
2023-10-07 08:50:04,524 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.final_layer_norm to test forward
2023-10-07 08:50:04,525 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.layers.0 to test forward
2023-10-07 08:50:04,526 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.layers.1 to test forward
2023-10-07 08:50:04,527 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.layers.2 to test forward
2023-10-07 08:50:04,528 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.layers.3 to test forward
2023-10-07 08:50:04,528 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.layers.4 to test forward
2023-10-07 08:50:04,530 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.layers.5 to test forward
2023-10-07 08:50:04,531 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.layers.6 to test forward
2023-10-07 08:50:04,532 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.layers.7 to test forward
2023-10-07 08:50:04,532 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.layers.8 to test forward
2023-10-07 08:50:04,534 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.layers.9 to test forward
2023-10-07 08:50:04,535 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.layers.10 to test forward
2023-10-07 08:50:04,536 [3293904854.py:36 in to_test_forward] DEBUG - model.decoder.layers.11 to test forward
2023-10-07 08:50:04,537 [3293904854.py:36 in to_test_forward] DEBUG - lm_head to test forward
2023-10-07 08:50:04,579 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2023-10-07 08:50:04,782 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:50:04,785 [3293904854.py:45 in new_forward] DEBUG - model.decoder.embed_tokens forward pass:
2023-10-07 08:50:04,785 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2]),)
2023-10-07 08:50:04,787 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:04,788 [3293904854.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:50:04,789 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:50:04,793 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:50:04,795 [3293904854.py:45 in new_forward] DEBUG - model.decoder.embed_positions forward pass:
2023-10-07 08:50:04,796 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2]), 0)
2023-10-07 08:50:04,797 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:04,798 [3293904854.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:50:04,799 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:50:04,801 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:50:04,809 [3293904854.py:45 in new_forward] DEBUG - model.decoder.layers.0 forward pass:
2023-10-07 08:50:04,810 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:04,811 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:04,825 [3293904854.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:04,826 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:50:04,829 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:50:04,837 [3293904854.py:45 in new_forward] DEBUG - model.decoder.layers.1 forward pass:
2023-10-07 08:50:04,838 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:04,840 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:04,846 [3293904854.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:04,847 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:50:04,850 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:50:04,860 [3293904854.py:45 in new_forward] DEBUG - model.decoder.layers.2 forward pass:
2023-10-07 08:50:04,861 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:04,862 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:04,878 [3293904854.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:04,879 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:50:04,882 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:50:04,891 [3293904854.py:45 in new_forward] DEBUG - model.decoder.layers.3 forward pass:
2023-10-07 08:50:04,892 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:04,893 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:04,924 [3293904854.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:04,925 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:50:04,929 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:50:04,937 [3293904854.py:45 in new_forward] DEBUG - model.decoder.layers.4 forward pass:
2023-10-07 08:50:04,938 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:04,939 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:04,946 [3293904854.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:04,947 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:50:04,950 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:50:04,958 [3293904854.py:45 in new_forward] DEBUG - model.decoder.layers.5 forward pass:
2023-10-07 08:50:04,959 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:04,960 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:04,966 [3293904854.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:04,967 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:50:04,970 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:50:04,978 [3293904854.py:45 in new_forward] DEBUG - model.decoder.layers.6 forward pass:
2023-10-07 08:50:04,979 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:04,980 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:04,986 [3293904854.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:04,988 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:50:04,991 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:50:04,999 [3293904854.py:45 in new_forward] DEBUG - model.decoder.layers.7 forward pass:
2023-10-07 08:50:05,000 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:05,001 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:05,007 [3293904854.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:05,009 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:50:05,012 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:50:05,025 [3293904854.py:45 in new_forward] DEBUG - model.decoder.layers.8 forward pass:
2023-10-07 08:50:05,026 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:05,027 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:05,032 [3293904854.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:05,034 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:50:05,038 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:50:05,046 [3293904854.py:45 in new_forward] DEBUG - model.decoder.layers.9 forward pass:
2023-10-07 08:50:05,047 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:05,048 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:05,054 [3293904854.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:05,056 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:50:05,059 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:50:05,067 [3293904854.py:45 in new_forward] DEBUG - model.decoder.layers.10 forward pass:
2023-10-07 08:50:05,068 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:05,068 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:05,073 [3293904854.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:05,074 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:50:05,078 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:50:05,086 [3293904854.py:45 in new_forward] DEBUG - model.decoder.layers.11 forward pass:
2023-10-07 08:50:05,087 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:05,088 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:05,094 [3293904854.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:05,097 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:50:05,099 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:50:05,101 [3293904854.py:45 in new_forward] DEBUG - model.decoder.final_layer_norm forward pass:
2023-10-07 08:50:05,102 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:05,103 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:05,105 [3293904854.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:50:05,107 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:50:05,109 [3293904854.py:9 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:50:05,110 [3293904854.py:45 in new_forward] DEBUG - lm_head forward pass:
2023-10-07 08:50:05,111 [3293904854.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:05,112 [3293904854.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:05,125 [3293904854.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 50272])
2023-10-07 08:50:05,127 [3293904854.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:50:05,135 [flexgen_test.py:28 in test_gen] INFO - 0)
2023-10-07 08:50:05,137 [flexgen_test.py:29 in test_gen] INFO - ----------
2023-10-07 08:50:05,146 [3293904854.py:88 in <module>] DEBUG - layer order: ['model.decoder.embed_tokens', 'model.decoder.embed_positions', 'model.decoder.layers.0', 'model.decoder.layers.1', 'model.decoder.layers.2', 'model.decoder.layers.3', 'model.decoder.layers.4', 'model.decoder.layers.5', 'model.decoder.layers.6', 'model.decoder.layers.7', 'model.decoder.layers.8', 'model.decoder.layers.9', 'model.decoder.layers.10', 'model.decoder.layers.11', 'model.decoder.final_layer_norm', 'lm_head']
2023-10-07 08:50:18,171 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.embed_tokens from test to old.
2023-10-07 08:50:18,173 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.embed_positions from test to old.
2023-10-07 08:50:18,174 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.final_layer_norm from test to old.
2023-10-07 08:50:18,175 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.layers.0 from test to old.
2023-10-07 08:50:18,176 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.layers.1 from test to old.
2023-10-07 08:50:18,177 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.layers.2 from test to old.
2023-10-07 08:50:18,178 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.layers.3 from test to old.
2023-10-07 08:50:18,179 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.layers.4 from test to old.
2023-10-07 08:50:18,180 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.layers.5 from test to old.
2023-10-07 08:50:18,181 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.layers.6 from test to old.
2023-10-07 08:50:18,182 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.layers.7 from test to old.
2023-10-07 08:50:18,183 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.layers.8 from test to old.
2023-10-07 08:50:18,184 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.layers.9 from test to old.
2023-10-07 08:50:18,185 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.layers.10 from test to old.
2023-10-07 08:50:18,187 [3457246667.py:70 in to_old_forward] DEBUG - model.decoder.layers.11 from test to old.
2023-10-07 08:50:18,189 [3457246667.py:70 in to_old_forward] DEBUG - lm_head from test to old.
2023-10-07 08:50:18,191 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.embed_tokens to test forward
2023-10-07 08:50:18,194 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.embed_positions to test forward
2023-10-07 08:50:18,197 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.final_layer_norm to test forward
2023-10-07 08:50:18,198 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.layers.0 to test forward
2023-10-07 08:50:18,199 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.layers.1 to test forward
2023-10-07 08:50:18,200 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.layers.2 to test forward
2023-10-07 08:50:18,201 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.layers.3 to test forward
2023-10-07 08:50:18,202 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.layers.4 to test forward
2023-10-07 08:50:18,204 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.layers.5 to test forward
2023-10-07 08:50:18,205 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.layers.6 to test forward
2023-10-07 08:50:18,206 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.layers.7 to test forward
2023-10-07 08:50:18,207 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.layers.8 to test forward
2023-10-07 08:50:18,208 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.layers.9 to test forward
2023-10-07 08:50:18,209 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.layers.10 to test forward
2023-10-07 08:50:18,210 [3457246667.py:36 in to_test_forward] DEBUG - model.decoder.layers.11 to test forward
2023-10-07 08:50:18,211 [3457246667.py:36 in to_test_forward] DEBUG - lm_head to test forward
2023-10-07 08:50:18,259 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2023-10-07 08:50:18,450 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:50:18,453 [3457246667.py:45 in new_forward] DEBUG - model.decoder.embed_tokens forward pass:
2023-10-07 08:50:18,454 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2]),)
2023-10-07 08:50:18,455 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:18,456 [3457246667.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:50:18,457 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:50:18,459 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:50:18,460 [3457246667.py:45 in new_forward] DEBUG - model.decoder.embed_positions forward pass:
2023-10-07 08:50:18,461 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2]), 0)
2023-10-07 08:50:18,462 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:18,463 [3457246667.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:50:18,465 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:50:18,466 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:50:18,474 [3457246667.py:45 in new_forward] DEBUG - model.decoder.layers.0 forward pass:
2023-10-07 08:50:18,475 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,476 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:18,489 [3457246667.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:18,490 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:50:18,493 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:50:18,503 [3457246667.py:45 in new_forward] DEBUG - model.decoder.layers.1 forward pass:
2023-10-07 08:50:18,504 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,504 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:18,511 [3457246667.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:18,512 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:50:18,515 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:50:18,524 [3457246667.py:45 in new_forward] DEBUG - model.decoder.layers.2 forward pass:
2023-10-07 08:50:18,525 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,526 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:18,563 [3457246667.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:18,564 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:50:18,567 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:50:18,575 [3457246667.py:45 in new_forward] DEBUG - model.decoder.layers.3 forward pass:
2023-10-07 08:50:18,576 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,577 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:18,581 [3457246667.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:18,582 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:50:18,585 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:50:18,592 [3457246667.py:45 in new_forward] DEBUG - model.decoder.layers.4 forward pass:
2023-10-07 08:50:18,593 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,594 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:18,600 [3457246667.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:18,601 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:50:18,604 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:50:18,612 [3457246667.py:45 in new_forward] DEBUG - model.decoder.layers.5 forward pass:
2023-10-07 08:50:18,612 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,613 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:18,623 [3457246667.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:18,624 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:50:18,627 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:50:18,635 [3457246667.py:45 in new_forward] DEBUG - model.decoder.layers.6 forward pass:
2023-10-07 08:50:18,635 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,636 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:18,641 [3457246667.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:18,642 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:50:18,645 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:50:18,653 [3457246667.py:45 in new_forward] DEBUG - model.decoder.layers.7 forward pass:
2023-10-07 08:50:18,654 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,655 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:18,660 [3457246667.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:18,661 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:50:18,663 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:50:18,672 [3457246667.py:45 in new_forward] DEBUG - model.decoder.layers.8 forward pass:
2023-10-07 08:50:18,672 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,673 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:18,678 [3457246667.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:18,679 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:50:18,682 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:50:18,690 [3457246667.py:45 in new_forward] DEBUG - model.decoder.layers.9 forward pass:
2023-10-07 08:50:18,691 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,692 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:18,698 [3457246667.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:18,699 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:50:18,702 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:50:18,710 [3457246667.py:45 in new_forward] DEBUG - model.decoder.layers.10 forward pass:
2023-10-07 08:50:18,711 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,711 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:18,716 [3457246667.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:18,718 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:50:18,720 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:50:18,728 [3457246667.py:45 in new_forward] DEBUG - model.decoder.layers.11 forward pass:
2023-10-07 08:50:18,729 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,730 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:18,741 [3457246667.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:18,743 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:50:18,746 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:50:18,748 [3457246667.py:45 in new_forward] DEBUG - model.decoder.final_layer_norm forward pass:
2023-10-07 08:50:18,749 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,749 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:18,752 [3457246667.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:50:18,754 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:50:18,756 [3457246667.py:9 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:50:18,757 [3457246667.py:45 in new_forward] DEBUG - lm_head forward pass:
2023-10-07 08:50:18,758 [3457246667.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:18,759 [3457246667.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:18,775 [3457246667.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 50272])
2023-10-07 08:50:18,777 [3457246667.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:50:18,789 [flexgen_test.py:28 in test_gen] INFO - 0 Shares
2023-10-07 08:50:18,795 [flexgen_test.py:29 in test_gen] INFO - ----------
2023-10-07 08:50:18,812 [3457246667.py:88 in <module>] DEBUG - layer order: ['model.decoder.embed_tokens', 'model.decoder.embed_positions', 'model.decoder.layers.0', 'model.decoder.layers.1', 'model.decoder.layers.2', 'model.decoder.layers.3', 'model.decoder.layers.4', 'model.decoder.layers.5', 'model.decoder.layers.6', 'model.decoder.layers.7', 'model.decoder.layers.8', 'model.decoder.layers.9', 'model.decoder.layers.10', 'model.decoder.layers.11', 'model.decoder.final_layer_norm', 'lm_head']
2023-10-07 08:50:26,863 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.embed_tokens from test to old.
2023-10-07 08:50:26,865 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.embed_positions from test to old.
2023-10-07 08:50:26,866 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.final_layer_norm from test to old.
2023-10-07 08:50:26,867 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.layers.0 from test to old.
2023-10-07 08:50:26,869 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.layers.1 from test to old.
2023-10-07 08:50:26,870 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.layers.2 from test to old.
2023-10-07 08:50:26,871 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.layers.3 from test to old.
2023-10-07 08:50:26,872 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.layers.4 from test to old.
2023-10-07 08:50:26,873 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.layers.5 from test to old.
2023-10-07 08:50:26,873 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.layers.6 from test to old.
2023-10-07 08:50:26,875 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.layers.7 from test to old.
2023-10-07 08:50:26,876 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.layers.8 from test to old.
2023-10-07 08:50:26,877 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.layers.9 from test to old.
2023-10-07 08:50:26,879 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.layers.10 from test to old.
2023-10-07 08:50:26,879 [2491198285.py:70 in to_old_forward] DEBUG - model.decoder.layers.11 from test to old.
2023-10-07 08:50:26,880 [2491198285.py:70 in to_old_forward] DEBUG - lm_head from test to old.
2023-10-07 08:50:26,882 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.embed_tokens to test forward
2023-10-07 08:50:26,883 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.embed_positions to test forward
2023-10-07 08:50:26,884 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.final_layer_norm to test forward
2023-10-07 08:50:26,885 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.layers.0 to test forward
2023-10-07 08:50:26,886 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.layers.1 to test forward
2023-10-07 08:50:26,892 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.layers.2 to test forward
2023-10-07 08:50:26,893 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.layers.3 to test forward
2023-10-07 08:50:26,894 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.layers.4 to test forward
2023-10-07 08:50:26,895 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.layers.5 to test forward
2023-10-07 08:50:26,896 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.layers.6 to test forward
2023-10-07 08:50:26,896 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.layers.7 to test forward
2023-10-07 08:50:26,898 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.layers.8 to test forward
2023-10-07 08:50:26,899 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.layers.9 to test forward
2023-10-07 08:50:26,900 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.layers.10 to test forward
2023-10-07 08:50:26,901 [2491198285.py:36 in to_test_forward] DEBUG - model.decoder.layers.11 to test forward
2023-10-07 08:50:26,903 [2491198285.py:36 in to_test_forward] DEBUG - lm_head to test forward
2023-10-07 08:50:26,947 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2023-10-07 08:50:27,113 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:50:27,115 [2491198285.py:45 in new_forward] DEBUG - model.decoder.embed_tokens forward pass:
2023-10-07 08:50:27,116 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2]),)
2023-10-07 08:50:27,116 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:27,117 [2491198285.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:50:27,118 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:50:27,120 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:50:27,122 [2491198285.py:45 in new_forward] DEBUG - model.decoder.embed_positions forward pass:
2023-10-07 08:50:27,122 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2]), 0)
2023-10-07 08:50:27,123 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:27,125 [2491198285.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:50:27,126 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:50:27,127 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:50:27,135 [2491198285.py:45 in new_forward] DEBUG - model.decoder.layers.0 forward pass:
2023-10-07 08:50:27,136 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,137 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:27,144 [2491198285.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:27,146 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:50:27,148 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:50:27,157 [2491198285.py:45 in new_forward] DEBUG - model.decoder.layers.1 forward pass:
2023-10-07 08:50:27,158 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,159 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:27,165 [2491198285.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:27,167 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:50:27,170 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:50:27,178 [2491198285.py:45 in new_forward] DEBUG - model.decoder.layers.2 forward pass:
2023-10-07 08:50:27,179 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,181 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:27,184 [2491198285.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:27,186 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:50:27,189 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:50:27,198 [2491198285.py:45 in new_forward] DEBUG - model.decoder.layers.3 forward pass:
2023-10-07 08:50:27,199 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,199 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:27,209 [2491198285.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:27,210 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:50:27,213 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:50:27,221 [2491198285.py:45 in new_forward] DEBUG - model.decoder.layers.4 forward pass:
2023-10-07 08:50:27,222 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,223 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:27,228 [2491198285.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:27,230 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:50:27,232 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:50:27,241 [2491198285.py:45 in new_forward] DEBUG - model.decoder.layers.5 forward pass:
2023-10-07 08:50:27,242 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,242 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:27,247 [2491198285.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:27,248 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:50:27,251 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:50:27,258 [2491198285.py:45 in new_forward] DEBUG - model.decoder.layers.6 forward pass:
2023-10-07 08:50:27,259 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,260 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:27,268 [2491198285.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:27,269 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:50:27,272 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:50:27,280 [2491198285.py:45 in new_forward] DEBUG - model.decoder.layers.7 forward pass:
2023-10-07 08:50:27,281 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,282 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:27,288 [2491198285.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:27,289 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:50:27,292 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:50:27,300 [2491198285.py:45 in new_forward] DEBUG - model.decoder.layers.8 forward pass:
2023-10-07 08:50:27,301 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,302 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:27,306 [2491198285.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:27,307 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:50:27,310 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:50:27,319 [2491198285.py:45 in new_forward] DEBUG - model.decoder.layers.9 forward pass:
2023-10-07 08:50:27,319 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,320 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:27,326 [2491198285.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:27,327 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:50:27,330 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:50:27,338 [2491198285.py:45 in new_forward] DEBUG - model.decoder.layers.10 forward pass:
2023-10-07 08:50:27,339 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,340 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:27,347 [2491198285.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:27,350 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:50:27,353 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:50:27,362 [2491198285.py:45 in new_forward] DEBUG - model.decoder.layers.11 forward pass:
2023-10-07 08:50:27,363 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,364 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:27,369 [2491198285.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:27,371 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:50:27,373 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:50:27,376 [2491198285.py:45 in new_forward] DEBUG - model.decoder.final_layer_norm forward pass:
2023-10-07 08:50:27,376 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,377 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:27,380 [2491198285.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:50:27,382 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:50:27,384 [2491198285.py:9 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:50:27,385 [2491198285.py:45 in new_forward] DEBUG - lm_head forward pass:
2023-10-07 08:50:27,386 [2491198285.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:27,387 [2491198285.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:27,400 [2491198285.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 50272])
2023-10-07 08:50:27,402 [2491198285.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:50:27,412 [flexgen_test.py:28 in test_gen] INFO - 0.
2023-10-07 08:50:27,414 [flexgen_test.py:29 in test_gen] INFO - ----------
2023-10-07 08:50:27,427 [2491198285.py:88 in <module>] DEBUG - layer order: ['model.decoder.embed_tokens', 'model.decoder.embed_positions', 'model.decoder.layers.0', 'model.decoder.layers.1', 'model.decoder.layers.2', 'model.decoder.layers.3', 'model.decoder.layers.4', 'model.decoder.layers.5', 'model.decoder.layers.6', 'model.decoder.layers.7', 'model.decoder.layers.8', 'model.decoder.layers.9', 'model.decoder.layers.10', 'model.decoder.layers.11', 'model.decoder.final_layer_norm', 'lm_head']
2023-10-07 08:50:36,098 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.embed_tokens from test to old.
2023-10-07 08:50:36,099 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.embed_positions from test to old.
2023-10-07 08:50:36,100 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.final_layer_norm from test to old.
2023-10-07 08:50:36,102 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.layers.0 from test to old.
2023-10-07 08:50:36,103 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.layers.1 from test to old.
2023-10-07 08:50:36,104 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.layers.2 from test to old.
2023-10-07 08:50:36,105 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.layers.3 from test to old.
2023-10-07 08:50:36,107 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.layers.4 from test to old.
2023-10-07 08:50:36,108 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.layers.5 from test to old.
2023-10-07 08:50:36,109 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.layers.6 from test to old.
2023-10-07 08:50:36,109 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.layers.7 from test to old.
2023-10-07 08:50:36,110 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.layers.8 from test to old.
2023-10-07 08:50:36,111 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.layers.9 from test to old.
2023-10-07 08:50:36,112 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.layers.10 from test to old.
2023-10-07 08:50:36,113 [1194143434.py:70 in to_old_forward] DEBUG - model.decoder.layers.11 from test to old.
2023-10-07 08:50:36,114 [1194143434.py:70 in to_old_forward] DEBUG - lm_head from test to old.
2023-10-07 08:50:36,115 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.embed_tokens to test forward
2023-10-07 08:50:36,116 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.embed_positions to test forward
2023-10-07 08:50:36,117 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.final_layer_norm to test forward
2023-10-07 08:50:36,118 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.layers.0 to test forward
2023-10-07 08:50:36,119 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.layers.1 to test forward
2023-10-07 08:50:36,120 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.layers.2 to test forward
2023-10-07 08:50:36,121 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.layers.3 to test forward
2023-10-07 08:50:36,122 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.layers.4 to test forward
2023-10-07 08:50:36,123 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.layers.5 to test forward
2023-10-07 08:50:36,124 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.layers.6 to test forward
2023-10-07 08:50:36,125 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.layers.7 to test forward
2023-10-07 08:50:36,127 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.layers.8 to test forward
2023-10-07 08:50:36,127 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.layers.9 to test forward
2023-10-07 08:50:36,128 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.layers.10 to test forward
2023-10-07 08:50:36,129 [1194143434.py:36 in to_test_forward] DEBUG - model.decoder.layers.11 to test forward
2023-10-07 08:50:36,130 [1194143434.py:36 in to_test_forward] DEBUG - lm_head to test forward
2023-10-07 08:50:36,171 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2023-10-07 08:50:36,319 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:50:36,321 [1194143434.py:45 in new_forward] DEBUG - model.decoder.embed_tokens forward pass:
2023-10-07 08:50:36,322 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2]),)
2023-10-07 08:50:36,323 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:36,324 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:50:36,325 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:50:36,326 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:50:36,328 [1194143434.py:45 in new_forward] DEBUG - model.decoder.embed_positions forward pass:
2023-10-07 08:50:36,329 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2]), 0)
2023-10-07 08:50:36,329 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:36,331 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:50:36,332 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:50:36,334 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:50:36,342 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.0 forward pass:
2023-10-07 08:50:36,343 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,343 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,357 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:36,359 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:50:36,363 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:50:36,371 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.1 forward pass:
2023-10-07 08:50:36,372 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,373 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,379 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:36,380 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:50:36,384 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:50:36,392 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.2 forward pass:
2023-10-07 08:50:36,393 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,394 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,399 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:36,401 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:50:36,403 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:50:36,411 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.3 forward pass:
2023-10-07 08:50:36,412 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,413 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,419 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:36,420 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:50:36,422 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:50:36,430 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.4 forward pass:
2023-10-07 08:50:36,431 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,432 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,436 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:36,438 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:50:36,441 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:50:36,449 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.5 forward pass:
2023-10-07 08:50:36,449 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,451 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,456 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:36,458 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:50:36,460 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:50:36,467 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.6 forward pass:
2023-10-07 08:50:36,468 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,469 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,477 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:36,478 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:50:36,481 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:50:36,489 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.7 forward pass:
2023-10-07 08:50:36,489 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,491 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,497 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:36,498 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:50:36,500 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:50:36,508 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.8 forward pass:
2023-10-07 08:50:36,509 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,510 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,514 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:36,515 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:50:36,517 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:50:36,526 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.9 forward pass:
2023-10-07 08:50:36,527 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,529 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,564 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:36,567 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:50:36,570 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:50:36,581 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.10 forward pass:
2023-10-07 08:50:36,582 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,583 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,602 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:36,605 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:50:36,607 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:50:36,616 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.11 forward pass:
2023-10-07 08:50:36,617 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,618 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,624 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:50:36,626 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:50:36,629 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:50:36,631 [1194143434.py:45 in new_forward] DEBUG - model.decoder.final_layer_norm forward pass:
2023-10-07 08:50:36,632 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,633 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:36,635 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:50:36,635 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:50:36,638 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:50:36,639 [1194143434.py:45 in new_forward] DEBUG - lm_head forward pass:
2023-10-07 08:50:36,640 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:50:36,641 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:36,650 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 50272])
2023-10-07 08:50:36,651 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:50:36,658 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:50:36,660 [1194143434.py:45 in new_forward] DEBUG - model.decoder.embed_tokens forward pass:
2023-10-07 08:50:36,661 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1]),)
2023-10-07 08:50:36,662 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:36,663 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:50:36,664 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:50:36,665 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:50:36,667 [1194143434.py:45 in new_forward] DEBUG - model.decoder.embed_positions forward pass:
2023-10-07 08:50:36,668 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 3]), 2)
2023-10-07 08:50:36,669 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:36,670 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:50:36,671 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:50:36,672 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:50:36,680 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.0 forward pass:
2023-10-07 08:50:36,681 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,682 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,689 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:50:36,692 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:50:36,694 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:50:36,702 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.1 forward pass:
2023-10-07 08:50:36,703 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,704 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,708 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:50:36,711 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:50:36,713 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:50:36,723 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.2 forward pass:
2023-10-07 08:50:36,724 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,725 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,731 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:50:36,732 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:50:36,736 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:50:36,744 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.3 forward pass:
2023-10-07 08:50:36,745 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,746 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,752 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:50:36,754 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:50:36,756 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:50:36,764 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.4 forward pass:
2023-10-07 08:50:36,765 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,766 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,770 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:50:36,772 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:50:36,775 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:50:36,783 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.5 forward pass:
2023-10-07 08:50:36,784 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,786 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,793 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:50:36,794 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:50:36,796 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:50:36,805 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.6 forward pass:
2023-10-07 08:50:36,805 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,806 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,846 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:50:36,848 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:50:36,850 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:50:36,858 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.7 forward pass:
2023-10-07 08:50:36,859 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,860 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,890 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:50:36,892 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:50:36,895 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:50:36,905 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.8 forward pass:
2023-10-07 08:50:36,907 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,907 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,913 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:50:36,914 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:50:36,916 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:50:36,924 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.9 forward pass:
2023-10-07 08:50:36,925 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,926 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,930 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:50:36,931 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:50:36,933 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:50:36,942 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.10 forward pass:
2023-10-07 08:50:36,943 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,944 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,949 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:50:36,949 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:50:36,952 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:50:36,960 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.11 forward pass:
2023-10-07 08:50:36,961 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,963 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:36,976 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:50:36,977 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:50:36,979 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:50:36,981 [1194143434.py:45 in new_forward] DEBUG - model.decoder.final_layer_norm forward pass:
2023-10-07 08:50:36,982 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,982 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:36,984 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:50:36,984 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:50:36,986 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:50:36,987 [1194143434.py:45 in new_forward] DEBUG - lm_head forward pass:
2023-10-07 08:50:36,988 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:36,989 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:36,997 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 50272])
2023-10-07 08:50:36,999 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:50:37,007 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:50:37,009 [1194143434.py:45 in new_forward] DEBUG - model.decoder.embed_tokens forward pass:
2023-10-07 08:50:37,010 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1]),)
2023-10-07 08:50:37,011 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:37,012 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:50:37,013 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:50:37,015 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:50:37,016 [1194143434.py:45 in new_forward] DEBUG - model.decoder.embed_positions forward pass:
2023-10-07 08:50:37,017 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 4]), 3)
2023-10-07 08:50:37,018 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:37,019 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:50:37,020 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:50:37,021 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:50:37,029 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.0 forward pass:
2023-10-07 08:50:37,030 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,031 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,035 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:50:37,037 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:50:37,040 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:50:37,048 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.1 forward pass:
2023-10-07 08:50:37,049 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,050 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,054 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:50:37,056 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:50:37,059 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:50:37,068 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.2 forward pass:
2023-10-07 08:50:37,068 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,069 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,073 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:50:37,075 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:50:37,077 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:50:37,086 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.3 forward pass:
2023-10-07 08:50:37,087 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,087 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,094 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:50:37,096 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:50:37,099 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:50:37,107 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.4 forward pass:
2023-10-07 08:50:37,108 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,109 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,117 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:50:37,119 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:50:37,122 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:50:37,132 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.5 forward pass:
2023-10-07 08:50:37,133 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,133 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,139 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:50:37,142 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:50:37,144 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:50:37,153 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.6 forward pass:
2023-10-07 08:50:37,154 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,155 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,161 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:50:37,163 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:50:37,166 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:50:37,173 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.7 forward pass:
2023-10-07 08:50:37,174 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,175 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,180 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:50:37,182 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:50:37,184 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:50:37,192 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.8 forward pass:
2023-10-07 08:50:37,193 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,194 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,200 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:50:37,203 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:50:37,205 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:50:37,213 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.9 forward pass:
2023-10-07 08:50:37,214 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,215 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,221 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:50:37,223 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:50:37,225 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:50:37,234 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.10 forward pass:
2023-10-07 08:50:37,235 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,236 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,241 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:50:37,243 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:50:37,246 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:50:37,254 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.11 forward pass:
2023-10-07 08:50:37,255 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,256 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,259 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:50:37,262 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:50:37,264 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:50:37,266 [1194143434.py:45 in new_forward] DEBUG - model.decoder.final_layer_norm forward pass:
2023-10-07 08:50:37,267 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,268 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:37,269 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:50:37,270 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:50:37,271 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:50:37,273 [1194143434.py:45 in new_forward] DEBUG - lm_head forward pass:
2023-10-07 08:50:37,273 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,274 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:37,284 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 50272])
2023-10-07 08:50:37,286 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:50:37,293 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:50:37,295 [1194143434.py:45 in new_forward] DEBUG - model.decoder.embed_tokens forward pass:
2023-10-07 08:50:37,296 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1]),)
2023-10-07 08:50:37,297 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:37,298 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:50:37,299 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:50:37,300 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:50:37,302 [1194143434.py:45 in new_forward] DEBUG - model.decoder.embed_positions forward pass:
2023-10-07 08:50:37,303 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 5]), 4)
2023-10-07 08:50:37,303 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:37,305 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:50:37,306 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:50:37,307 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:50:37,316 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.0 forward pass:
2023-10-07 08:50:37,317 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,318 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,328 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:50:37,330 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:50:37,333 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:50:37,341 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.1 forward pass:
2023-10-07 08:50:37,342 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,343 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,359 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:50:37,360 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:50:37,363 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:50:37,371 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.2 forward pass:
2023-10-07 08:50:37,372 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,373 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,377 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:50:37,377 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:50:37,380 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:50:37,389 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.3 forward pass:
2023-10-07 08:50:37,389 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,391 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,398 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:50:37,399 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:50:37,402 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:50:37,410 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.4 forward pass:
2023-10-07 08:50:37,411 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,413 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,432 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:50:37,433 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:50:37,436 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:50:37,444 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.5 forward pass:
2023-10-07 08:50:37,445 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,446 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,453 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:50:37,454 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:50:37,456 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:50:37,465 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.6 forward pass:
2023-10-07 08:50:37,466 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,466 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,472 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:50:37,473 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:50:37,476 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:50:37,484 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.7 forward pass:
2023-10-07 08:50:37,485 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,486 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,492 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:50:37,494 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:50:37,496 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:50:37,505 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.8 forward pass:
2023-10-07 08:50:37,506 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,507 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,513 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:50:37,513 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:50:37,516 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:50:37,524 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.9 forward pass:
2023-10-07 08:50:37,525 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,526 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,539 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:50:37,540 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:50:37,543 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:50:37,552 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.10 forward pass:
2023-10-07 08:50:37,553 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,554 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,563 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:50:37,564 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:50:37,567 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:50:37,575 [1194143434.py:45 in new_forward] DEBUG - model.decoder.layers.11 forward pass:
2023-10-07 08:50:37,575 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,576 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:50:37,582 [1194143434.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:50:37,583 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:50:37,585 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:50:37,587 [1194143434.py:45 in new_forward] DEBUG - model.decoder.final_layer_norm forward pass:
2023-10-07 08:50:37,588 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,588 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:37,590 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:50:37,591 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:50:37,592 [1194143434.py:9 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:50:37,594 [1194143434.py:45 in new_forward] DEBUG - lm_head forward pass:
2023-10-07 08:50:37,594 [1194143434.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:50:37,595 [1194143434.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:50:37,604 [1194143434.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 50272])
2023-10-07 08:50:37,607 [1194143434.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:50:37,645 [flexgen_test.py:28 in test_gen] INFO - 0.3
Let
2023-10-07 08:50:37,647 [flexgen_test.py:29 in test_gen] INFO - ----------
2023-10-07 08:50:37,657 [1194143434.py:88 in <module>] DEBUG - layer order: ['model.decoder.embed_tokens', 'model.decoder.embed_positions', 'model.decoder.layers.0', 'model.decoder.layers.1', 'model.decoder.layers.2', 'model.decoder.layers.3', 'model.decoder.layers.4', 'model.decoder.layers.5', 'model.decoder.layers.6', 'model.decoder.layers.7', 'model.decoder.layers.8', 'model.decoder.layers.9', 'model.decoder.layers.10', 'model.decoder.layers.11', 'model.decoder.final_layer_norm', 'lm_head', 'model.decoder.embed_tokens', 'model.decoder.embed_positions', 'model.decoder.layers.0', 'model.decoder.layers.1', 'model.decoder.layers.2', 'model.decoder.layers.3', 'model.decoder.layers.4', 'model.decoder.layers.5', 'model.decoder.layers.6', 'model.decoder.layers.7', 'model.decoder.layers.8', 'model.decoder.layers.9', 'model.decoder.layers.10', 'model.decoder.layers.11', 'model.decoder.final_layer_norm', 'lm_head', 'model.decoder.embed_tokens', 'model.decoder.embed_positions', 'model.decoder.layers.0', 'model.decoder.layers.1', 'model.decoder.layers.2', 'model.decoder.layers.3', 'model.decoder.layers.4', 'model.decoder.layers.5', 'model.decoder.layers.6', 'model.decoder.layers.7', 'model.decoder.layers.8', 'model.decoder.layers.9', 'model.decoder.layers.10', 'model.decoder.layers.11', 'model.decoder.final_layer_norm', 'lm_head', 'model.decoder.embed_tokens', 'model.decoder.embed_positions', 'model.decoder.layers.0', 'model.decoder.layers.1', 'model.decoder.layers.2', 'model.decoder.layers.3', 'model.decoder.layers.4', 'model.decoder.layers.5', 'model.decoder.layers.6', 'model.decoder.layers.7', 'model.decoder.layers.8', 'model.decoder.layers.9', 'model.decoder.layers.10', 'model.decoder.layers.11', 'model.decoder.final_layer_norm', 'lm_head']
2023-10-07 08:51:02,753 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.embed_tokens from test to old.
2023-10-07 08:51:02,754 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.embed_positions from test to old.
2023-10-07 08:51:02,755 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.final_layer_norm from test to old.
2023-10-07 08:51:02,756 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.layers.0 from test to old.
2023-10-07 08:51:02,757 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.layers.1 from test to old.
2023-10-07 08:51:02,758 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.layers.2 from test to old.
2023-10-07 08:51:02,759 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.layers.3 from test to old.
2023-10-07 08:51:02,759 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.layers.4 from test to old.
2023-10-07 08:51:02,760 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.layers.5 from test to old.
2023-10-07 08:51:02,761 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.layers.6 from test to old.
2023-10-07 08:51:02,762 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.layers.7 from test to old.
2023-10-07 08:51:02,763 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.layers.8 from test to old.
2023-10-07 08:51:02,764 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.layers.9 from test to old.
2023-10-07 08:51:02,766 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.layers.10 from test to old.
2023-10-07 08:51:02,767 [3638497074.py:70 in to_old_forward] DEBUG - model.decoder.layers.11 from test to old.
2023-10-07 08:51:02,767 [3638497074.py:70 in to_old_forward] DEBUG - lm_head from test to old.
2023-10-07 08:51:02,768 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.embed_tokens to test forward
2023-10-07 08:51:02,769 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.embed_positions to test forward
2023-10-07 08:51:02,770 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.final_layer_norm to test forward
2023-10-07 08:51:02,772 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.layers.0 to test forward
2023-10-07 08:51:02,772 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.layers.1 to test forward
2023-10-07 08:51:02,774 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.layers.2 to test forward
2023-10-07 08:51:02,775 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.layers.3 to test forward
2023-10-07 08:51:02,776 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.layers.4 to test forward
2023-10-07 08:51:02,776 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.layers.5 to test forward
2023-10-07 08:51:02,777 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.layers.6 to test forward
2023-10-07 08:51:02,778 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.layers.7 to test forward
2023-10-07 08:51:02,779 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.layers.8 to test forward
2023-10-07 08:51:02,780 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.layers.9 to test forward
2023-10-07 08:51:02,780 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.layers.10 to test forward
2023-10-07 08:51:02,782 [3638497074.py:36 in to_test_forward] DEBUG - model.decoder.layers.11 to test forward
2023-10-07 08:51:02,782 [3638497074.py:36 in to_test_forward] DEBUG - lm_head to test forward
2023-10-07 08:51:02,826 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2023-10-07 08:51:02,980 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:51:02,981 [3638497074.py:45 in new_forward] DEBUG - model.decoder.embed_tokens forward pass:
2023-10-07 08:51:02,982 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2]),)
2023-10-07 08:51:02,983 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:02,984 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:51:02,985 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:51:02,987 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:51:02,988 [3638497074.py:45 in new_forward] DEBUG - model.decoder.embed_positions forward pass:
2023-10-07 08:51:02,989 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2]), 0)
2023-10-07 08:51:02,990 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:02,992 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:51:02,992 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:51:02,994 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:51:03,002 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.0 forward pass:
2023-10-07 08:51:03,003 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,004 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,010 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:03,012 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:51:03,014 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:51:03,022 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.1 forward pass:
2023-10-07 08:51:03,023 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,024 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,028 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:03,031 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:51:03,033 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:51:03,045 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.2 forward pass:
2023-10-07 08:51:03,046 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,047 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,053 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:03,054 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:51:03,057 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:51:03,064 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.3 forward pass:
2023-10-07 08:51:03,065 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,066 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,073 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:03,074 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:51:03,076 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:51:03,084 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.4 forward pass:
2023-10-07 08:51:03,085 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,086 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,091 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:03,092 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:51:03,094 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:51:03,102 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.5 forward pass:
2023-10-07 08:51:03,103 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,104 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,108 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:03,110 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:51:03,112 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:51:03,120 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.6 forward pass:
2023-10-07 08:51:03,121 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,122 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,133 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:03,136 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:51:03,138 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:51:03,147 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.7 forward pass:
2023-10-07 08:51:03,148 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,149 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,154 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:03,155 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:51:03,158 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:51:03,166 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.8 forward pass:
2023-10-07 08:51:03,167 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,168 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,173 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:03,174 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:51:03,176 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:51:03,184 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.9 forward pass:
2023-10-07 08:51:03,185 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,186 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,193 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:03,195 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:51:03,198 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:51:03,207 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.10 forward pass:
2023-10-07 08:51:03,208 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,209 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,214 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:03,216 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:51:03,219 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:51:03,227 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.11 forward pass:
2023-10-07 08:51:03,228 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,228 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,235 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:03,236 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:51:03,238 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:51:03,241 [3638497074.py:45 in new_forward] DEBUG - model.decoder.final_layer_norm forward pass:
2023-10-07 08:51:03,241 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,242 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:03,245 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:51:03,247 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:51:03,248 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:51:03,250 [3638497074.py:45 in new_forward] DEBUG - lm_head forward pass:
2023-10-07 08:51:03,251 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:03,251 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:03,263 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 50272])
2023-10-07 08:51:03,264 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:51:03,271 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:51:03,272 [3638497074.py:45 in new_forward] DEBUG - model.decoder.embed_tokens forward pass:
2023-10-07 08:51:03,273 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1]),)
2023-10-07 08:51:03,274 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:03,275 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:51:03,276 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:51:03,278 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:51:03,279 [3638497074.py:45 in new_forward] DEBUG - model.decoder.embed_positions forward pass:
2023-10-07 08:51:03,280 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 3]), 2)
2023-10-07 08:51:03,281 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:03,282 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:51:03,283 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:51:03,284 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:51:03,292 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.0 forward pass:
2023-10-07 08:51:03,293 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,294 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,299 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:51:03,302 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:51:03,304 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:51:03,312 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.1 forward pass:
2023-10-07 08:51:03,313 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,313 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,320 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:51:03,322 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:51:03,324 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:51:03,332 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.2 forward pass:
2023-10-07 08:51:03,333 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,334 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,340 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:51:03,342 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:51:03,344 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:51:03,353 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.3 forward pass:
2023-10-07 08:51:03,354 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,355 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,362 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:51:03,364 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:51:03,367 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:51:03,375 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.4 forward pass:
2023-10-07 08:51:03,376 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,377 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,390 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:51:03,391 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:51:03,393 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:51:03,401 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.5 forward pass:
2023-10-07 08:51:03,402 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,404 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,412 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:51:03,413 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:51:03,415 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:51:03,423 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.6 forward pass:
2023-10-07 08:51:03,424 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,425 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,431 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:51:03,432 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:51:03,435 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:51:03,444 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.7 forward pass:
2023-10-07 08:51:03,445 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,446 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,449 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:51:03,450 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:51:03,452 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:51:03,460 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.8 forward pass:
2023-10-07 08:51:03,461 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,462 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,468 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:51:03,469 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:51:03,471 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:51:03,479 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.9 forward pass:
2023-10-07 08:51:03,480 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,481 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,486 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:51:03,488 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:51:03,490 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:51:03,498 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.10 forward pass:
2023-10-07 08:51:03,499 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,500 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,507 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:51:03,509 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:51:03,511 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:51:03,519 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.11 forward pass:
2023-10-07 08:51:03,520 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,521 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 3]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,526 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])))
2023-10-07 08:51:03,529 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:51:03,531 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:51:03,533 [3638497074.py:45 in new_forward] DEBUG - model.decoder.final_layer_norm forward pass:
2023-10-07 08:51:03,533 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,535 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:03,536 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:51:03,536 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:51:03,538 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:51:03,539 [3638497074.py:45 in new_forward] DEBUG - lm_head forward pass:
2023-10-07 08:51:03,540 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,541 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:03,551 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 50272])
2023-10-07 08:51:03,553 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:51:03,559 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:51:03,562 [3638497074.py:45 in new_forward] DEBUG - model.decoder.embed_tokens forward pass:
2023-10-07 08:51:03,563 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1]),)
2023-10-07 08:51:03,564 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:03,565 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:51:03,565 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:51:03,567 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:51:03,568 [3638497074.py:45 in new_forward] DEBUG - model.decoder.embed_positions forward pass:
2023-10-07 08:51:03,569 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 4]), 3)
2023-10-07 08:51:03,570 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:03,571 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:51:03,572 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:51:03,573 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:51:03,582 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.0 forward pass:
2023-10-07 08:51:03,582 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,583 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,590 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:51:03,592 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:51:03,595 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:51:03,603 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.1 forward pass:
2023-10-07 08:51:03,604 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,605 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,619 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:51:03,620 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:51:03,623 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:51:03,632 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.2 forward pass:
2023-10-07 08:51:03,633 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,633 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,637 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:51:03,638 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:51:03,642 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:51:03,650 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.3 forward pass:
2023-10-07 08:51:03,651 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,652 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,656 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:51:03,658 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:51:03,661 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:51:03,669 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.4 forward pass:
2023-10-07 08:51:03,669 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,670 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,674 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:51:03,676 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:51:03,679 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:51:03,687 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.5 forward pass:
2023-10-07 08:51:03,688 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,689 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,695 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:51:03,697 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:51:03,699 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:51:03,707 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.6 forward pass:
2023-10-07 08:51:03,708 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,709 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,714 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:51:03,717 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:51:03,719 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:51:03,728 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.7 forward pass:
2023-10-07 08:51:03,729 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,730 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,737 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:51:03,739 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:51:03,741 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:51:03,750 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.8 forward pass:
2023-10-07 08:51:03,751 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,752 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,755 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:51:03,758 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:51:03,760 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:51:03,769 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.9 forward pass:
2023-10-07 08:51:03,770 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,770 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,779 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:51:03,780 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:51:03,782 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:51:03,790 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.10 forward pass:
2023-10-07 08:51:03,791 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,793 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,797 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:51:03,800 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:51:03,802 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:51:03,811 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.11 forward pass:
2023-10-07 08:51:03,812 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,813 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 4]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 3, 64]), torch.Size([1, 12, 3, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,819 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])))
2023-10-07 08:51:03,821 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:51:03,824 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:51:03,826 [3638497074.py:45 in new_forward] DEBUG - model.decoder.final_layer_norm forward pass:
2023-10-07 08:51:03,826 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,827 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:03,828 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:51:03,829 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:51:03,831 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:51:03,833 [3638497074.py:45 in new_forward] DEBUG - lm_head forward pass:
2023-10-07 08:51:03,834 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,835 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:03,843 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 50272])
2023-10-07 08:51:03,845 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:51:03,860 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:51:03,863 [3638497074.py:45 in new_forward] DEBUG - model.decoder.embed_tokens forward pass:
2023-10-07 08:51:03,863 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1]),)
2023-10-07 08:51:03,865 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:03,866 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:51:03,866 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:51:03,868 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:51:03,869 [3638497074.py:45 in new_forward] DEBUG - model.decoder.embed_positions forward pass:
2023-10-07 08:51:03,871 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 5]), 4)
2023-10-07 08:51:03,871 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:03,873 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:51:03,874 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:51:03,875 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:51:03,884 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.0 forward pass:
2023-10-07 08:51:03,885 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,886 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,892 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:51:03,894 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:51:03,896 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:51:03,906 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.1 forward pass:
2023-10-07 08:51:03,907 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,908 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,915 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:51:03,916 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:51:03,919 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:51:03,927 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.2 forward pass:
2023-10-07 08:51:03,928 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,929 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,933 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:51:03,935 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:51:03,938 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:51:03,946 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.3 forward pass:
2023-10-07 08:51:03,947 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,948 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,953 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:51:03,955 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:51:03,958 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:51:03,967 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.4 forward pass:
2023-10-07 08:51:03,968 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,969 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,975 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:51:03,977 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:51:03,980 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:51:03,988 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.5 forward pass:
2023-10-07 08:51:03,989 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:03,990 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:03,996 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:51:03,998 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:51:04,001 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:51:04,009 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.6 forward pass:
2023-10-07 08:51:04,010 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:04,011 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:04,017 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:51:04,020 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:51:04,022 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:51:04,033 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.7 forward pass:
2023-10-07 08:51:04,033 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:04,034 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:04,072 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:51:04,074 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:51:04,076 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:51:04,085 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.8 forward pass:
2023-10-07 08:51:04,086 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:04,086 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:04,109 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:51:04,112 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:51:04,114 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:51:04,123 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.9 forward pass:
2023-10-07 08:51:04,124 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:04,124 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:04,128 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:51:04,129 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:51:04,132 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:51:04,140 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.10 forward pass:
2023-10-07 08:51:04,141 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:04,142 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:04,145 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:51:04,146 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:51:04,149 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:51:04,157 [3638497074.py:45 in new_forward] DEBUG - model.decoder.layers.11 forward pass:
2023-10-07 08:51:04,158 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:04,160 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 1, 5]), 'layer_head_mask': None, 'past_key_value': (torch.Size([1, 12, 4, 64]), torch.Size([1, 12, 4, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:04,163 [3638497074.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 1, 768]), (torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 5, 64])))
2023-10-07 08:51:04,165 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:51:04,168 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:51:04,170 [3638497074.py:45 in new_forward] DEBUG - model.decoder.final_layer_norm forward pass:
2023-10-07 08:51:04,170 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:04,171 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:04,172 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 768])
2023-10-07 08:51:04,173 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:51:04,175 [3638497074.py:9 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:51:04,176 [3638497074.py:45 in new_forward] DEBUG - lm_head forward pass:
2023-10-07 08:51:04,176 [3638497074.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 1, 768]),)
2023-10-07 08:51:04,177 [3638497074.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:04,187 [3638497074.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 1, 50272])
2023-10-07 08:51:04,188 [3638497074.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:51:04,203 [flexgen_test.py:28 in test_gen] INFO - 0

0

2023-10-07 08:51:04,203 [flexgen_test.py:29 in test_gen] INFO - ----------
2023-10-07 08:51:04,213 [3638497074.py:88 in <module>] DEBUG - layer order: ['model.decoder.embed_tokens', 'model.decoder.embed_positions', 'model.decoder.layers.0', 'model.decoder.layers.1', 'model.decoder.layers.2', 'model.decoder.layers.3', 'model.decoder.layers.4', 'model.decoder.layers.5', 'model.decoder.layers.6', 'model.decoder.layers.7', 'model.decoder.layers.8', 'model.decoder.layers.9', 'model.decoder.layers.10', 'model.decoder.layers.11', 'model.decoder.final_layer_norm', 'lm_head', 'model.decoder.embed_tokens', 'model.decoder.embed_positions', 'model.decoder.layers.0', 'model.decoder.layers.1', 'model.decoder.layers.2', 'model.decoder.layers.3', 'model.decoder.layers.4', 'model.decoder.layers.5', 'model.decoder.layers.6', 'model.decoder.layers.7', 'model.decoder.layers.8', 'model.decoder.layers.9', 'model.decoder.layers.10', 'model.decoder.layers.11', 'model.decoder.final_layer_norm', 'lm_head', 'model.decoder.embed_tokens', 'model.decoder.embed_positions', 'model.decoder.layers.0', 'model.decoder.layers.1', 'model.decoder.layers.2', 'model.decoder.layers.3', 'model.decoder.layers.4', 'model.decoder.layers.5', 'model.decoder.layers.6', 'model.decoder.layers.7', 'model.decoder.layers.8', 'model.decoder.layers.9', 'model.decoder.layers.10', 'model.decoder.layers.11', 'model.decoder.final_layer_norm', 'lm_head', 'model.decoder.embed_tokens', 'model.decoder.embed_positions', 'model.decoder.layers.0', 'model.decoder.layers.1', 'model.decoder.layers.2', 'model.decoder.layers.3', 'model.decoder.layers.4', 'model.decoder.layers.5', 'model.decoder.layers.6', 'model.decoder.layers.7', 'model.decoder.layers.8', 'model.decoder.layers.9', 'model.decoder.layers.10', 'model.decoder.layers.11', 'model.decoder.final_layer_norm', 'lm_head']
2023-10-07 08:51:34,578 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.embed_tokens from test to old.
2023-10-07 08:51:34,580 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.embed_positions from test to old.
2023-10-07 08:51:34,581 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.final_layer_norm from test to old.
2023-10-07 08:51:34,582 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.0 from test to old.
2023-10-07 08:51:34,583 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.1 from test to old.
2023-10-07 08:51:34,584 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.2 from test to old.
2023-10-07 08:51:34,585 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.3 from test to old.
2023-10-07 08:51:34,586 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.4 from test to old.
2023-10-07 08:51:34,587 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.5 from test to old.
2023-10-07 08:51:34,588 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.6 from test to old.
2023-10-07 08:51:34,590 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.7 from test to old.
2023-10-07 08:51:34,591 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.8 from test to old.
2023-10-07 08:51:34,592 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.9 from test to old.
2023-10-07 08:51:34,593 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.10 from test to old.
2023-10-07 08:51:34,594 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.11 from test to old.
2023-10-07 08:51:34,595 [4100687501.py:70 in to_old_forward] DEBUG - lm_head from test to old.
2023-10-07 08:51:34,596 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.embed_tokens to test forward
2023-10-07 08:51:34,597 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.embed_positions to test forward
2023-10-07 08:51:34,599 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.final_layer_norm to test forward
2023-10-07 08:51:34,599 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.layers.0 to test forward
2023-10-07 08:51:34,600 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.layers.1 to test forward
2023-10-07 08:51:34,601 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.layers.2 to test forward
2023-10-07 08:51:34,602 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.layers.3 to test forward
2023-10-07 08:51:34,604 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.layers.4 to test forward
2023-10-07 08:51:34,605 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.layers.5 to test forward
2023-10-07 08:51:34,606 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.layers.6 to test forward
2023-10-07 08:51:34,607 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.layers.7 to test forward
2023-10-07 08:51:34,608 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.layers.8 to test forward
2023-10-07 08:51:34,609 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.layers.9 to test forward
2023-10-07 08:51:34,611 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.layers.10 to test forward
2023-10-07 08:51:34,612 [4100687501.py:36 in to_test_forward] DEBUG - model.decoder.layers.11 to test forward
2023-10-07 08:51:34,613 [4100687501.py:36 in to_test_forward] DEBUG - lm_head to test forward
2023-10-07 08:51:34,651 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2023-10-07 08:51:34,823 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:51:34,826 [4100687501.py:45 in new_forward] DEBUG - model.decoder.embed_tokens forward pass:
2023-10-07 08:51:34,827 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2]),)
2023-10-07 08:51:34,828 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:34,829 [4100687501.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:51:34,830 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:51:34,832 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:51:34,834 [4100687501.py:45 in new_forward] DEBUG - model.decoder.embed_positions forward pass:
2023-10-07 08:51:34,835 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2]), 0)
2023-10-07 08:51:34,835 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:34,837 [4100687501.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:51:34,837 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:51:34,839 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:51:34,847 [4100687501.py:45 in new_forward] DEBUG - model.decoder.layers.0 forward pass:
2023-10-07 08:51:34,848 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:34,848 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:34,860 [4100687501.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:34,862 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:51:34,865 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:51:34,873 [4100687501.py:45 in new_forward] DEBUG - model.decoder.layers.1 forward pass:
2023-10-07 08:51:34,874 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:34,875 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:34,881 [4100687501.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:34,883 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:51:34,885 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:51:34,894 [4100687501.py:45 in new_forward] DEBUG - model.decoder.layers.2 forward pass:
2023-10-07 08:51:34,895 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:34,896 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:34,901 [4100687501.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:34,902 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:51:34,905 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:51:34,913 [4100687501.py:45 in new_forward] DEBUG - model.decoder.layers.3 forward pass:
2023-10-07 08:51:34,914 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:34,915 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:34,925 [4100687501.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:34,926 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:51:34,929 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:51:34,937 [4100687501.py:45 in new_forward] DEBUG - model.decoder.layers.4 forward pass:
2023-10-07 08:51:34,938 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:34,939 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:34,948 [4100687501.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:34,950 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:51:34,952 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:51:34,960 [4100687501.py:45 in new_forward] DEBUG - model.decoder.layers.5 forward pass:
2023-10-07 08:51:34,961 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:34,962 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:34,968 [4100687501.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:34,969 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:51:34,971 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:51:34,983 [4100687501.py:45 in new_forward] DEBUG - model.decoder.layers.6 forward pass:
2023-10-07 08:51:34,985 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:34,987 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:35,008 [4100687501.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:35,009 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:51:35,012 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:51:35,021 [4100687501.py:45 in new_forward] DEBUG - model.decoder.layers.7 forward pass:
2023-10-07 08:51:35,022 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:35,023 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:35,028 [4100687501.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:35,029 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:51:35,032 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:51:35,041 [4100687501.py:45 in new_forward] DEBUG - model.decoder.layers.8 forward pass:
2023-10-07 08:51:35,042 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:35,043 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:35,048 [4100687501.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:35,049 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:51:35,052 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:51:35,062 [4100687501.py:45 in new_forward] DEBUG - model.decoder.layers.9 forward pass:
2023-10-07 08:51:35,063 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:35,064 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:35,071 [4100687501.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:35,072 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:51:35,075 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:51:35,085 [4100687501.py:45 in new_forward] DEBUG - model.decoder.layers.10 forward pass:
2023-10-07 08:51:35,089 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:35,089 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:35,096 [4100687501.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:35,097 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:51:35,100 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:51:35,108 [4100687501.py:45 in new_forward] DEBUG - model.decoder.layers.11 forward pass:
2023-10-07 08:51:35,109 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:35,110 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {'attention_mask': torch.Size([1, 1, 2, 2]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:51:35,118 [4100687501.py:49 in new_forward] DEBUG - 	output: (torch.Size([1, 2, 768]), (torch.Size([1, 12, 2, 64]), torch.Size([1, 12, 2, 64])))
2023-10-07 08:51:35,120 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:51:35,124 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:51:35,126 [4100687501.py:45 in new_forward] DEBUG - model.decoder.final_layer_norm forward pass:
2023-10-07 08:51:35,127 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:35,128 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:35,130 [4100687501.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 768])
2023-10-07 08:51:35,132 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:51:35,134 [4100687501.py:9 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:51:35,135 [4100687501.py:45 in new_forward] DEBUG - lm_head forward pass:
2023-10-07 08:51:35,136 [4100687501.py:46 in new_forward] DEBUG - 	args: (torch.Size([1, 2, 768]),)
2023-10-07 08:51:35,137 [4100687501.py:47 in new_forward] DEBUG - 	kwargs: {}
2023-10-07 08:51:35,148 [4100687501.py:49 in new_forward] DEBUG - 	output: torch.Size([1, 2, 50272])
2023-10-07 08:51:35,151 [4100687501.py:20 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:51:35,160 [flexgen_test.py:28 in test_gen] INFO - 0.
2023-10-07 08:51:35,161 [flexgen_test.py:29 in test_gen] INFO - ----------
2023-10-07 08:51:35,170 [4100687501.py:88 in <module>] DEBUG - layer order: ['model.decoder.embed_tokens', 'model.decoder.embed_positions', 'model.decoder.layers.0', 'model.decoder.layers.1', 'model.decoder.layers.2', 'model.decoder.layers.3', 'model.decoder.layers.4', 'model.decoder.layers.5', 'model.decoder.layers.6', 'model.decoder.layers.7', 'model.decoder.layers.8', 'model.decoder.layers.9', 'model.decoder.layers.10', 'model.decoder.layers.11', 'model.decoder.final_layer_norm', 'lm_head']
2023-10-07 08:51:47,259 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.embed_tokens from test to old.
2023-10-07 08:51:47,260 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.embed_positions from test to old.
2023-10-07 08:51:47,261 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.0 from test to old.
2023-10-07 08:51:47,262 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.1 from test to old.
2023-10-07 08:51:47,263 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.2 from test to old.
2023-10-07 08:51:47,264 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.3 from test to old.
2023-10-07 08:51:47,265 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.4 from test to old.
2023-10-07 08:51:47,266 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.5 from test to old.
2023-10-07 08:51:47,267 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.6 from test to old.
2023-10-07 08:51:47,268 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.7 from test to old.
2023-10-07 08:51:47,269 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.8 from test to old.
2023-10-07 08:51:47,270 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.9 from test to old.
2023-10-07 08:51:47,271 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.10 from test to old.
2023-10-07 08:51:47,272 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.layers.11 from test to old.
2023-10-07 08:51:47,273 [4100687501.py:70 in to_old_forward] DEBUG - model.decoder.final_layer_norm from test to old.
2023-10-07 08:51:47,274 [4100687501.py:70 in to_old_forward] DEBUG - lm_head from test to old.
2023-10-07 08:51:47,274 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.embed_tokens to flexgen forward
2023-10-07 08:51:47,276 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.embed_positions to flexgen forward
2023-10-07 08:51:47,277 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.0 to flexgen forward
2023-10-07 08:51:47,277 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.1 to flexgen forward
2023-10-07 08:51:47,278 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.2 to flexgen forward
2023-10-07 08:51:47,279 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.3 to flexgen forward
2023-10-07 08:51:47,280 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.4 to flexgen forward
2023-10-07 08:51:47,282 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.5 to flexgen forward
2023-10-07 08:51:47,282 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.6 to flexgen forward
2023-10-07 08:51:47,283 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.7 to flexgen forward
2023-10-07 08:51:47,284 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.8 to flexgen forward
2023-10-07 08:51:47,285 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.9 to flexgen forward
2023-10-07 08:51:47,286 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.10 to flexgen forward
2023-10-07 08:51:47,288 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.11 to flexgen forward
2023-10-07 08:51:47,289 [1091436659.py:36 in to_flexgen_forward] DEBUG - model.decoder.final_layer_norm to flexgen forward
2023-10-07 08:51:47,290 [1091436659.py:36 in to_flexgen_forward] DEBUG - lm_head to flexgen forward
2023-10-07 08:52:28,574 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 "HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2023-10-07 08:52:28,759 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:28,762 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:28,763 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10]),)
2023-10-07 08:52:28,764 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:28,765 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10]),)
2023-10-07 08:52:28,765 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:28,767 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:28,768 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:28,769 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:28,770 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:28,771 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])
2023-10-07 08:52:28,772 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])
2023-10-07 08:52:28,773 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:28,775 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:28,776 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:28,784 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10]), 0)
2023-10-07 08:52:28,785 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:28,786 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10]), 0)
2023-10-07 08:52:28,787 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:28,788 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:28,790 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:28,791 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:28,792 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:28,793 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])
2023-10-07 08:52:28,795 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])
2023-10-07 08:52:28,796 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:28,799 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:28,810 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:28,818 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:28,819 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:28,820 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:28,821 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:28,821 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:28,834 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:28,844 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:28,853 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:28,860 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 08:52:28,862 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 08:52:28,863 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:28,865 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:28,873 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:28,880 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:28,881 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:28,882 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:28,883 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:28,883 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:28,895 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:28,901 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:28,906 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:28,913 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 08:52:28,915 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 08:52:28,916 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:28,919 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:28,927 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:28,936 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:28,937 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:28,938 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:28,939 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:28,940 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:28,946 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:28,950 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:28,955 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:28,961 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 08:52:28,963 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 08:52:28,963 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:28,966 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:28,974 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:28,982 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:28,982 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:28,984 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:28,984 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:28,985 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:28,996 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:29,015 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:29,022 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:29,027 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 08:52:29,030 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 08:52:29,031 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:29,033 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:29,042 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:29,051 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:29,051 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,053 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:29,053 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,054 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:29,061 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:29,065 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:29,070 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:29,075 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 08:52:29,076 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 08:52:29,077 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:29,079 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:29,087 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:29,096 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:29,097 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,098 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:29,099 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,100 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:29,109 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:29,129 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:29,133 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:29,137 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 08:52:29,138 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 08:52:29,139 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:29,141 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:29,150 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:29,158 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:29,159 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,160 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:29,161 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,161 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:29,172 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:29,176 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:29,182 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:29,187 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 08:52:29,189 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 08:52:29,190 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:29,192 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:29,202 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:29,214 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:29,215 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,217 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:29,217 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,219 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:29,230 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:29,237 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:29,242 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:29,251 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 08:52:29,254 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 08:52:29,254 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:29,257 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:29,265 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:29,274 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:29,275 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,276 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:29,277 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,277 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:29,287 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:29,291 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:29,297 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:29,306 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 08:52:29,308 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 08:52:29,309 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:29,313 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:29,322 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:29,330 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:29,331 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,332 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:29,332 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,334 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:29,340 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:29,344 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:29,350 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:29,357 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 08:52:29,359 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 08:52:29,360 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:29,362 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:29,371 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:29,379 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:29,380 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,381 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:29,382 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,383 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:29,391 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:29,395 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:29,399 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:29,407 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 08:52:29,409 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 08:52:29,410 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:29,413 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:29,421 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:29,423 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:29,424 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,425 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:29,426 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,426 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:29,434 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:29,437 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:29,441 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:29,452 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))
2023-10-07 08:52:29,453 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))
2023-10-07 08:52:29,454 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:29,457 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:29,459 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:29,461 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:29,461 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:29,462 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:29,463 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:29,463 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:29,466 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:29,470 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:29,473 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:29,477 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])
2023-10-07 08:52:29,477 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])
2023-10-07 08:52:29,478 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:29,480 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:29,481 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:29,483 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)
2023-10-07 08:52:29,484 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:29,485 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)
2023-10-07 08:52:29,486 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:29,487 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:29,505 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:29,517 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:29,533 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:29,547 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 50272])
2023-10-07 08:52:29,553 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 50272])
2023-10-07 08:52:29,555 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:29,564 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:29,566 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:29,567 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:29,568 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:29,569 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:29,570 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:29,571 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:29,572 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:29,573 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:29,575 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:29,576 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:29,577 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:29,578 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:29,580 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:29,581 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:29,590 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 11]), 10)
2023-10-07 08:52:29,590 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:29,592 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 11]), 10)
2023-10-07 08:52:29,592 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:29,593 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:29,595 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:29,596 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:29,597 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:29,598 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:29,599 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:29,600 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:29,602 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:29,613 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:29,622 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:29,623 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,624 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:29,625 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,627 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:29,632 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:29,654 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:29,658 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:29,662 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 08:52:29,665 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 08:52:29,666 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:29,668 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:29,676 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:29,684 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:29,685 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,686 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:29,687 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,688 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:29,698 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:29,701 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:29,713 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:29,741 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 08:52:29,743 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 08:52:29,744 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:29,747 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:29,755 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:29,764 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:29,765 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,766 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:29,767 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,767 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:29,773 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:29,780 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:29,790 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:29,798 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 08:52:29,800 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 08:52:29,801 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:29,804 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:29,825 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:29,833 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:29,835 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,836 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:29,837 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,838 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:29,885 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:29,892 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:29,896 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:29,905 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 08:52:29,907 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 08:52:29,908 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:29,910 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:29,918 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:29,926 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:29,927 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,928 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:29,929 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,930 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:29,940 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:29,944 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:29,946 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:29,949 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 08:52:29,951 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 08:52:29,952 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:29,954 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:29,962 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:29,971 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:29,972 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,973 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:29,974 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:29,975 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:29,982 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:29,990 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:29,993 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:30,008 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 08:52:30,009 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 08:52:30,010 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:30,013 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:30,021 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:30,030 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,031 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,032 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,033 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,034 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:30,038 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:30,043 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:30,046 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:30,050 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 08:52:30,052 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 08:52:30,052 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:30,055 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:30,062 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:30,070 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,071 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,072 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,073 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,074 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:30,082 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:30,085 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:30,088 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:30,093 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 08:52:30,098 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 08:52:30,099 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:30,104 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:30,115 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:30,129 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,131 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,132 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,133 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,135 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:30,149 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:30,157 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:30,173 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:30,177 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 08:52:30,179 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 08:52:30,180 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:30,182 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:30,191 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:30,199 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,200 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,201 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,202 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,203 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:30,210 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:30,220 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:30,229 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:30,239 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 08:52:30,241 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 08:52:30,242 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:30,244 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:30,252 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:30,261 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,262 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,263 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,264 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,266 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:30,271 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:30,284 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:30,289 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:30,294 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 08:52:30,295 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 08:52:30,297 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:30,300 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:30,309 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:30,312 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,313 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,314 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,316 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,317 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:30,324 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:30,335 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:30,340 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:30,345 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))
2023-10-07 08:52:30,347 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))
2023-10-07 08:52:30,348 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:30,351 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:30,353 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:30,355 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,356 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:30,357 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,358 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:30,360 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:30,363 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:30,367 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:30,370 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:30,372 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:30,375 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:30,376 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:30,378 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:30,380 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:30,381 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,382 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:30,383 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,384 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:30,385 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:30,399 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:30,406 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:30,418 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:30,429 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:30,435 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:30,436 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:30,445 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:30,447 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:30,448 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:30,449 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:30,450 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:30,451 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:30,452 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:30,453 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:30,455 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:30,456 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:30,457 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:30,457 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:30,458 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:30,460 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:30,462 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:30,470 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 12]), 11)
2023-10-07 08:52:30,471 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:30,472 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 12]), 11)
2023-10-07 08:52:30,472 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:30,474 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:30,475 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:30,477 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:30,478 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:30,479 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:30,480 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:30,481 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:30,482 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:30,490 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:30,499 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,500 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,501 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,501 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,502 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:30,510 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:30,520 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:30,524 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:30,527 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 08:52:30,529 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 08:52:30,530 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:30,533 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:30,541 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:30,550 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,551 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,552 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,553 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,554 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:30,563 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:30,566 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:30,568 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:30,574 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 08:52:30,576 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 08:52:30,577 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:30,579 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:30,587 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:30,595 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,596 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,597 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,598 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,600 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:30,618 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:30,632 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:30,635 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:30,638 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 08:52:30,639 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 08:52:30,640 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:30,644 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:30,653 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:30,662 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,663 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,664 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,664 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,665 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:30,681 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:30,685 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:30,691 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:30,694 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 08:52:30,696 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 08:52:30,697 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:30,700 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:30,708 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:30,718 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,719 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,719 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,721 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,721 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:30,731 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:30,737 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:30,749 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:30,753 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 08:52:30,755 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 08:52:30,756 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:30,758 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:30,767 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:30,775 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,776 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,777 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,778 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,779 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:30,785 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:30,789 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:30,792 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:30,796 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 08:52:30,799 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 08:52:30,799 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:30,803 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:30,815 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:30,828 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,829 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,830 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,831 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,832 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:30,839 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:30,844 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:30,848 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:30,852 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 08:52:30,853 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 08:52:30,854 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:30,857 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:30,865 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:30,873 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,874 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,875 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:30,876 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,877 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:30,944 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:30,966 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:30,971 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:30,974 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 08:52:30,976 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 08:52:30,977 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:30,980 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:30,988 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:30,997 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:30,998 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:30,999 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,000 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,002 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:31,009 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:31,015 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:31,022 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:31,030 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 08:52:31,032 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 08:52:31,033 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:31,036 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:31,044 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:31,052 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,053 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,054 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,055 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,056 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:31,061 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:31,065 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:31,070 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:31,074 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 08:52:31,076 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 08:52:31,077 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:31,079 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:31,087 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:31,096 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,097 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,098 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,099 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,100 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:31,107 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:31,110 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:31,116 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:31,120 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 08:52:31,121 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 08:52:31,122 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:31,124 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:31,132 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:31,135 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,135 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,136 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,137 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,139 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:31,145 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:31,148 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:31,153 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:31,157 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))
2023-10-07 08:52:31,158 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))
2023-10-07 08:52:31,159 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:31,162 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:31,164 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:31,165 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,166 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:31,167 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,168 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:31,169 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:31,171 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:31,172 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:31,174 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:31,178 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:31,179 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:31,180 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:31,182 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:31,184 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:31,185 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,186 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:31,187 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,188 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:31,189 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:31,200 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:31,210 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:31,220 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:31,230 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:31,233 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:31,234 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:31,250 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:31,252 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:31,254 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:31,254 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:31,255 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:31,256 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:31,257 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:31,258 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:31,259 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:31,260 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:31,261 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:31,262 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:31,263 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:31,264 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:31,266 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:31,274 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 13]), 12)
2023-10-07 08:52:31,275 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:31,276 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 13]), 12)
2023-10-07 08:52:31,277 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:31,277 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:31,279 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:31,280 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:31,281 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:31,282 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:31,283 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:31,285 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:31,286 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:31,296 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:31,305 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,307 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,308 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,309 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,310 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:31,317 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:31,320 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:31,324 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:31,326 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 08:52:31,328 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 08:52:31,329 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:31,332 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:31,340 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:31,349 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,350 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,351 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,352 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,353 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:31,366 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:31,373 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:31,383 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:31,388 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 08:52:31,392 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 08:52:31,393 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:31,396 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:31,405 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:31,414 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,414 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,415 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,416 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,417 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:31,427 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:31,433 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:31,437 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:31,444 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 08:52:31,446 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 08:52:31,447 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:31,450 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:31,459 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:31,467 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,468 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,469 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,470 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,471 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:31,482 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:31,489 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:31,493 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:31,505 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 08:52:31,506 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 08:52:31,507 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:31,510 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:31,522 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:31,532 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,533 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,533 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,534 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,535 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:31,569 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:31,600 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:31,609 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:31,617 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 08:52:31,619 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 08:52:31,620 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:31,623 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:31,633 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:31,643 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,644 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,645 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,645 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,647 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:31,653 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:31,657 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:31,661 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:31,676 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 08:52:31,677 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 08:52:31,678 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:31,681 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:31,689 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:31,698 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,699 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,700 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,701 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,702 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:31,711 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:31,716 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:31,722 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:31,727 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 08:52:31,729 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 08:52:31,730 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:31,733 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:31,743 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:31,752 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,753 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,755 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,755 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,757 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:31,762 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:31,765 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:31,768 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:31,773 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 08:52:31,774 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 08:52:31,775 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:31,777 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:31,785 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:31,793 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,794 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,795 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,796 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,796 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:31,850 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:31,876 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:31,881 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:31,886 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 08:52:31,887 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 08:52:31,888 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:31,891 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:31,899 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:31,909 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,910 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,911 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,912 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,914 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:31,919 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:31,924 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:31,929 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:31,939 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 08:52:31,941 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 08:52:31,942 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:31,944 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:31,953 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:31,962 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,963 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,964 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:31,965 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:31,965 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:31,971 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:31,976 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:31,979 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:31,982 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 08:52:31,984 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 08:52:31,985 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:31,988 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:31,996 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:31,997 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:31,998 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,000 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,000 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,001 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:32,005 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:32,008 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:32,012 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:32,015 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))
2023-10-07 08:52:32,016 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))
2023-10-07 08:52:32,017 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:32,019 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:32,021 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:32,023 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,023 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:32,024 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,025 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:32,026 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:32,029 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:32,032 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:32,035 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:32,039 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:32,040 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:32,041 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:32,042 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:32,043 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:32,045 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,046 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:32,047 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,048 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:32,049 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:32,063 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:32,071 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:32,081 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:32,091 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:32,095 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:32,096 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:32,107 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:32,109 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:32,112 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:32,113 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:32,114 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:32,115 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:32,116 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:32,117 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:32,118 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:32,119 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:32,120 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:32,121 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:32,122 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:32,124 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:32,125 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:32,136 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 14]), 13)
2023-10-07 08:52:32,137 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:32,138 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 14]), 13)
2023-10-07 08:52:32,139 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:32,140 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:32,142 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:32,143 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:32,144 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:32,146 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:32,147 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:32,147 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:32,149 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:32,157 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:32,166 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,167 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,168 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,169 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,170 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:32,178 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:32,183 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:32,186 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:32,189 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 08:52:32,190 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 08:52:32,191 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:32,198 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:32,214 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:32,231 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,234 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,235 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,236 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,237 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:32,247 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:32,254 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:32,262 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:32,265 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 08:52:32,268 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 08:52:32,270 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:32,273 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:32,283 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:32,292 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,293 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,294 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,295 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,296 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:32,305 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:32,313 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:32,317 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:32,323 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 08:52:32,325 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 08:52:32,326 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:32,328 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:32,336 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:32,344 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,345 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,346 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,348 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,348 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:32,355 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:32,358 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:32,360 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:32,364 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 08:52:32,366 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 08:52:32,366 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:32,369 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:32,377 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:32,385 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,386 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,387 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,388 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,388 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:32,402 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:32,406 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:32,409 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:32,417 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 08:52:32,419 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 08:52:32,420 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:32,422 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:32,430 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:32,438 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,439 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,440 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,441 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,442 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:32,449 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:32,462 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:32,513 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:32,560 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 08:52:32,563 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 08:52:32,564 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:32,566 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:32,574 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:32,583 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,584 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,585 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,586 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,587 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:32,624 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:32,659 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:32,670 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:32,688 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 08:52:32,691 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 08:52:32,692 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:32,694 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:32,702 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:32,710 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,710 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,711 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,712 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,713 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:32,719 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:32,723 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:32,727 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:32,731 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 08:52:32,733 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 08:52:32,734 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:32,736 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:32,744 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:32,752 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,753 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,754 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,755 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,756 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:32,763 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:32,768 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:32,772 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:32,777 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 08:52:32,779 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 08:52:32,780 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:32,782 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:32,790 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:32,798 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,799 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,800 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,801 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,802 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:32,814 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:32,821 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:32,824 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:32,828 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 08:52:32,829 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 08:52:32,830 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:32,833 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:32,841 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:32,849 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,850 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,851 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,851 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,853 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:32,862 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:32,864 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:32,869 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:32,883 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 08:52:32,884 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 08:52:32,885 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:32,888 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:32,896 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:32,899 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,899 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,901 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,901 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:32,902 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:32,908 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:32,911 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:32,914 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:32,920 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))
2023-10-07 08:52:32,922 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))
2023-10-07 08:52:32,923 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:32,925 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:32,927 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:32,929 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,930 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:32,931 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,932 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:32,933 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:32,937 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:32,940 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:32,941 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:32,945 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:32,946 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:32,948 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:32,950 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:32,952 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:32,953 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:32,954 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:32,955 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:32,956 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:32,958 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:32,968 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:32,979 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:32,993 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:33,006 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:33,020 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:33,025 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:33,074 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:33,076 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:33,078 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:33,079 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:33,080 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:33,081 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:33,082 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:33,083 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:33,085 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:33,086 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:33,087 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:33,088 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:33,089 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:33,090 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:33,092 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:33,101 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 15]), 14)
2023-10-07 08:52:33,102 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:33,103 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 15]), 14)
2023-10-07 08:52:33,103 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:33,104 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:33,106 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:33,107 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:33,108 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:33,109 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:33,110 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:33,111 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:33,113 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:33,121 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:33,129 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,130 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,131 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,132 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,133 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:33,156 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:33,161 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:33,165 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:33,169 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 08:52:33,171 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 08:52:33,172 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:33,175 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:33,183 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:33,192 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,193 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,194 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,194 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,196 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:33,201 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:33,206 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:33,210 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:33,215 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 08:52:33,217 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 08:52:33,218 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:33,220 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:33,229 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:33,237 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,238 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,239 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,240 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,241 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:33,249 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:33,257 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:33,287 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:33,308 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 08:52:33,310 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 08:52:33,312 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:33,315 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:33,325 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:33,335 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,336 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,338 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,338 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,339 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:33,345 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:33,350 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:33,364 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:33,380 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 08:52:33,382 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 08:52:33,383 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:33,387 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:33,397 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:33,406 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,408 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,409 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,410 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,411 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:33,425 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:33,430 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:33,436 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:33,439 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 08:52:33,441 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 08:52:33,442 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:33,444 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:33,453 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:33,461 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,463 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,464 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,464 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,465 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:33,472 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:33,476 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:33,479 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:33,481 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 08:52:33,483 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 08:52:33,484 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:33,487 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:33,496 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:33,505 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,505 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,506 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,508 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,508 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:33,554 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:33,584 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:33,590 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:33,593 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 08:52:33,595 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 08:52:33,596 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:33,599 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:33,607 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:33,615 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,616 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,617 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,618 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,620 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:33,627 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:33,636 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:33,640 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:33,645 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 08:52:33,647 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 08:52:33,648 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:33,650 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:33,659 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:33,667 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,668 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,669 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,670 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,672 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:33,680 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:33,683 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:33,686 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:33,690 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 08:52:33,692 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 08:52:33,693 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:33,695 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:33,703 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:33,712 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,712 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,713 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,715 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,716 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:33,723 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:33,737 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:33,749 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:33,754 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 08:52:33,755 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 08:52:33,756 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:33,758 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:33,766 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:33,775 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,776 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,777 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,777 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,778 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:33,784 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:33,788 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:33,791 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:33,797 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 08:52:33,799 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 08:52:33,800 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:33,802 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:33,810 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:33,812 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,813 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,814 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,825 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:33,826 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:33,853 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:33,876 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:33,888 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:33,892 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))
2023-10-07 08:52:33,893 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))
2023-10-07 08:52:33,894 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:33,898 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:33,901 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:33,903 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,904 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:33,905 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,906 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:33,907 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:33,909 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:33,911 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:33,913 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:33,915 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:33,918 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:33,919 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:33,921 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:33,923 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:33,925 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:33,926 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:33,927 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:33,928 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:33,930 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:33,946 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:33,955 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:33,964 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:33,973 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:33,983 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:33,984 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:33,992 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:33,994 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:33,996 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:33,997 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:33,998 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:33,999 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:34,000 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:34,001 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:34,003 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:34,004 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:34,005 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:34,006 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:34,007 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:34,010 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:34,013 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:34,023 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 16]), 15)
2023-10-07 08:52:34,024 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:34,025 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 16]), 15)
2023-10-07 08:52:34,026 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:34,027 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:34,029 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:34,031 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:34,032 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:34,033 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:34,034 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:34,035 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:34,037 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:34,047 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:34,058 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,059 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,060 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,061 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,062 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:34,077 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:34,080 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:34,090 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:34,096 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 08:52:34,098 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 08:52:34,099 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:34,102 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:34,110 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:34,118 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,119 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,120 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,121 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,122 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:34,130 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:34,140 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:34,145 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:34,149 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 08:52:34,151 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 08:52:34,152 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:34,155 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:34,165 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:34,175 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,176 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,178 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,179 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,179 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:34,192 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:34,196 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:34,199 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:34,202 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 08:52:34,203 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 08:52:34,204 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:34,207 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:34,217 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:34,225 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,226 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,227 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,228 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,229 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:34,268 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:34,271 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:34,274 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:34,277 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 08:52:34,279 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 08:52:34,279 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:34,282 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:34,289 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:34,298 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,299 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,299 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,300 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,301 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:34,307 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:34,317 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:34,324 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:34,328 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 08:52:34,329 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 08:52:34,330 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:34,332 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:34,341 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:34,350 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,351 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,352 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,353 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,353 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:34,365 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:34,369 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:34,375 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:34,378 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 08:52:34,380 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 08:52:34,381 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:34,383 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:34,392 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:34,401 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,402 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,403 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,404 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,404 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:34,410 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:34,413 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:34,416 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:34,421 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 08:52:34,423 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 08:52:34,424 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:34,426 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:34,435 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:34,445 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,445 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,446 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,447 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,448 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:34,456 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:34,492 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:34,503 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:34,507 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 08:52:34,509 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 08:52:34,510 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:34,513 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:34,521 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:34,530 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,531 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,532 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,533 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,535 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:34,541 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:34,549 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:34,552 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:34,555 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 08:52:34,557 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 08:52:34,558 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:34,560 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:34,569 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:34,577 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,578 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,579 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,580 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,580 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:34,589 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:34,595 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:34,598 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:34,601 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 08:52:34,603 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 08:52:34,604 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:34,606 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:34,615 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:34,623 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,624 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,625 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,626 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,627 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:34,640 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:34,645 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:34,653 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:34,707 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 08:52:34,709 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 08:52:34,710 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:34,713 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:34,722 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:34,724 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,725 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,726 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,727 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,728 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:34,733 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:34,738 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:34,742 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:34,745 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))
2023-10-07 08:52:34,747 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))
2023-10-07 08:52:34,748 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:34,750 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:34,753 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:34,755 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,756 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:34,757 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,758 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:34,759 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:34,764 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:34,767 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:34,770 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:34,771 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:34,772 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:34,774 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:34,775 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:34,777 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:34,779 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,780 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:34,781 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,781 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:34,782 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:34,795 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:34,805 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:34,815 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:34,827 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:34,829 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:34,830 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:34,841 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:34,843 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:34,845 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:34,845 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:34,846 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:34,847 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:34,848 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:34,849 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:34,850 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:34,851 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:34,853 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:34,854 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:34,854 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:34,856 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:34,857 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:34,865 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 17]), 16)
2023-10-07 08:52:34,866 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:34,867 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 17]), 16)
2023-10-07 08:52:34,868 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:34,868 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:34,870 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:34,871 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:34,872 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:34,873 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:34,874 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:34,875 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:34,877 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:34,884 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:34,893 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,893 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,894 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,895 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,896 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:34,911 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:34,924 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:34,928 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:34,931 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 08:52:34,932 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 08:52:34,933 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:34,936 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:34,944 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:34,953 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:34,953 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,954 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:34,955 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:34,957 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:34,962 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:34,968 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:34,976 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:34,982 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 08:52:34,984 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 08:52:34,985 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:34,987 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:34,995 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:35,003 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,004 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,005 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,006 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,007 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:35,013 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:35,021 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:35,025 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:35,028 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 08:52:35,029 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 08:52:35,030 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:35,033 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:35,042 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:35,051 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,052 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,053 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,054 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,055 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:35,065 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:35,073 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:35,077 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:35,080 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 08:52:35,082 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 08:52:35,083 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:35,085 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:35,093 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:35,101 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,102 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,103 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,104 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,105 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:35,122 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:35,127 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:35,131 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:35,134 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 08:52:35,135 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 08:52:35,136 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:35,139 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:35,147 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:35,155 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,156 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,157 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,158 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,159 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:35,169 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:35,172 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:35,175 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:35,178 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 08:52:35,179 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 08:52:35,180 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:35,183 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:35,191 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:35,200 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,201 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,202 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,203 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,204 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:35,210 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:35,216 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:35,225 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:35,229 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 08:52:35,230 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 08:52:35,231 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:35,234 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:35,242 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:35,250 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,251 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,252 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,252 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,254 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:35,259 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:35,265 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:35,268 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:35,270 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 08:52:35,272 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 08:52:35,273 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:35,275 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:35,286 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:35,296 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,297 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,298 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,299 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,300 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:35,304 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:35,312 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:35,315 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:35,318 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 08:52:35,319 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 08:52:35,320 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:35,322 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:35,330 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:35,339 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,340 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,341 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,342 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,342 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:35,376 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:35,379 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:35,382 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:35,385 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 08:52:35,386 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 08:52:35,387 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:35,389 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:35,397 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:35,406 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,407 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,408 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,409 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,410 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:35,417 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:35,420 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:35,423 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:35,441 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 08:52:35,442 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 08:52:35,444 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:35,446 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:35,455 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:35,456 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,457 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,458 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,459 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,460 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:35,470 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:35,474 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:35,477 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:35,483 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))
2023-10-07 08:52:35,485 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))
2023-10-07 08:52:35,485 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:35,488 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:35,490 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:35,491 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,492 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:35,493 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,494 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:35,495 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:35,496 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:35,499 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:35,501 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:35,502 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:35,504 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:35,505 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:35,506 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:35,508 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:35,509 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,510 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:35,511 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,511 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:35,512 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:35,524 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:35,535 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:35,545 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:35,554 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:35,557 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:35,558 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:35,565 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:35,567 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:35,569 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:35,570 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:35,570 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:35,571 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:35,572 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:35,573 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:35,574 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:35,575 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:35,576 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:35,578 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:35,579 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:35,581 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:35,582 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:35,592 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 18]), 17)
2023-10-07 08:52:35,592 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:35,593 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 18]), 17)
2023-10-07 08:52:35,594 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:35,595 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:35,597 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:35,598 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:35,599 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:35,601 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:35,602 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:35,602 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:35,604 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:35,612 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:35,623 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,627 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,628 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,629 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,630 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:35,660 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:35,666 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:35,670 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:35,688 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 08:52:35,690 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 08:52:35,691 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:35,695 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:35,704 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:35,713 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,714 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,715 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,716 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,717 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:35,732 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:35,735 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:35,741 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:35,748 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 08:52:35,749 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 08:52:35,750 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:35,753 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:35,760 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:35,769 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,770 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,771 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,772 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,773 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:35,789 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:35,793 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:35,797 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:35,802 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 08:52:35,803 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 08:52:35,804 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:35,808 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:35,821 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:35,834 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,835 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,837 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,838 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,839 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:35,846 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:35,850 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:35,854 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:35,858 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 08:52:35,859 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 08:52:35,860 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:35,862 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:35,870 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:35,879 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,880 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,881 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,882 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,882 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:35,888 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:35,892 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:35,895 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:35,898 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 08:52:35,899 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 08:52:35,900 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:35,903 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:35,911 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:35,920 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:35,921 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,922 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:35,923 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:35,923 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:35,928 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:35,932 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:35,979 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:35,985 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 08:52:35,987 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 08:52:35,987 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:35,990 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:35,999 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:36,009 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,010 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,011 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,012 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,013 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:36,017 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:36,020 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:36,024 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:36,029 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 08:52:36,031 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 08:52:36,032 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:36,034 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:36,042 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:36,051 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,051 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,052 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,053 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,054 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:36,060 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:36,072 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:36,081 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:36,085 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 08:52:36,087 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 08:52:36,088 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:36,091 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:36,100 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:36,110 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,111 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,112 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,113 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,114 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:36,121 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:36,125 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:36,133 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:36,140 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 08:52:36,142 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 08:52:36,142 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:36,146 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:36,158 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:36,170 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,171 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,171 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,173 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,174 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:36,199 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:36,205 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:36,211 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:36,215 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 08:52:36,217 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 08:52:36,218 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:36,221 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:36,233 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:36,240 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,241 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,242 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,243 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,244 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:36,254 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:36,257 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:36,262 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:36,267 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 08:52:36,268 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 08:52:36,269 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:36,272 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:36,280 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:36,282 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,283 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,284 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,284 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,285 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:36,293 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:36,296 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:36,299 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:36,304 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))
2023-10-07 08:52:36,306 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))
2023-10-07 08:52:36,307 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:36,309 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:36,311 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:36,312 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,313 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:36,314 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,315 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:36,316 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:36,318 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:36,323 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:36,324 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:36,325 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:36,326 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:36,327 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:36,329 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:36,330 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:36,331 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,332 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:36,333 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,334 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:36,335 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:36,348 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:36,356 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:36,364 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:36,372 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:36,374 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:36,375 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:36,383 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:36,385 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:36,386 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:36,387 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:36,388 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:36,389 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:36,390 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:36,391 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:36,392 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:36,395 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:36,396 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:36,397 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:36,397 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:36,399 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:36,400 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:36,409 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 19]), 18)
2023-10-07 08:52:36,410 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:36,411 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 19]), 18)
2023-10-07 08:52:36,412 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:36,412 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:36,414 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:36,428 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:36,429 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:36,430 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:36,431 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:36,432 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:36,434 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:36,442 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:36,451 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,452 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,453 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,454 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,455 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:36,460 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:36,468 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:36,474 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:36,497 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 08:52:36,499 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 08:52:36,500 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:36,504 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:36,517 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:36,529 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,530 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,531 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,532 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,533 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:36,545 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:36,560 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:36,576 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:36,617 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 08:52:36,619 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 08:52:36,620 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:36,623 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:36,637 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:36,646 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,647 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,649 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,649 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,650 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:36,656 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:36,660 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:36,663 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:36,667 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 08:52:36,669 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 08:52:36,670 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:36,672 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:36,681 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:36,690 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,691 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,692 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,692 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,693 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:36,704 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:36,708 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:36,712 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:36,715 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 08:52:36,717 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 08:52:36,718 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:36,721 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:36,729 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:36,738 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,739 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,739 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,740 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,741 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:36,747 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:36,751 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:36,755 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:36,759 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 08:52:36,760 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 08:52:36,761 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:36,764 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:36,772 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:36,780 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,781 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,782 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,783 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,784 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:36,793 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:36,804 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:36,808 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:36,811 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 08:52:36,812 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 08:52:36,813 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:36,815 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:36,824 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:36,832 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,833 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,834 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,834 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,835 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:36,844 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:36,848 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:36,851 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:36,854 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 08:52:36,856 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 08:52:36,857 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:36,860 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:36,868 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:36,879 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,880 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,881 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,882 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,883 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:36,891 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:36,897 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:36,903 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:36,909 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 08:52:36,911 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 08:52:36,912 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:36,915 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:36,927 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:36,939 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,940 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,941 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,942 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,943 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:36,949 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:36,953 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:36,957 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:36,960 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 08:52:36,962 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 08:52:36,963 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:36,965 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:36,974 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:36,982 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:36,983 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,984 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:36,985 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:36,986 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:36,990 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:36,993 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:36,996 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:37,005 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 08:52:37,007 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 08:52:37,008 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:37,010 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:37,017 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:37,031 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,032 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,033 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,033 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,034 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:37,049 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:37,052 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:37,057 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:37,073 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 08:52:37,075 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 08:52:37,076 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:37,078 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:37,087 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:37,089 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,090 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,091 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,092 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,093 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:37,097 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:37,100 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:37,103 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:37,106 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))
2023-10-07 08:52:37,107 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))
2023-10-07 08:52:37,108 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:37,111 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:37,113 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:37,115 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,116 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:37,117 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,117 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:37,119 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:37,121 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:37,125 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:37,128 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:37,133 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:37,135 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:37,136 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:37,138 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:37,141 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:37,145 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,147 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:37,148 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,150 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:37,154 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:37,168 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:37,180 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:37,191 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:37,198 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:37,200 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:37,200 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:37,213 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:37,214 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:37,216 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:37,217 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:37,218 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:37,219 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:37,220 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:37,220 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:37,222 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:37,223 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:37,224 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:37,225 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:37,231 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:37,233 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:37,235 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:37,243 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 20]), 19)
2023-10-07 08:52:37,244 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:37,245 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 20]), 19)
2023-10-07 08:52:37,246 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:37,247 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:37,248 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:37,249 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:37,250 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:37,251 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:37,252 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:37,253 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:37,255 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:37,263 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:37,272 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,273 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,274 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,275 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,276 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:37,281 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:37,288 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:37,292 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:37,294 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 08:52:37,296 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 08:52:37,297 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:37,300 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:37,309 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:37,317 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,318 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,319 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,319 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,320 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:37,333 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:37,344 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:37,347 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:37,349 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 08:52:37,351 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 08:52:37,352 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:37,354 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:37,363 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:37,371 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,371 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,373 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,373 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,374 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:37,386 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:37,389 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:37,392 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:37,401 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 08:52:37,403 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 08:52:37,403 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:37,406 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:37,414 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:37,425 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,426 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,427 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,428 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,429 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:37,435 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:37,441 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:37,445 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:37,449 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 08:52:37,451 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 08:52:37,452 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:37,454 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:37,463 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:37,471 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,472 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,473 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,474 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,474 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:37,482 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:37,487 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:37,490 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:37,493 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 08:52:37,495 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 08:52:37,496 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:37,498 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:37,506 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:37,513 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,514 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,515 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,516 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,517 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:37,524 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:37,527 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:37,530 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:37,533 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 08:52:37,534 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 08:52:37,535 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:37,537 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:37,545 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:37,554 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,555 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,556 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,557 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,557 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:37,564 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:37,567 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:37,570 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:37,574 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 08:52:37,576 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 08:52:37,577 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:37,579 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:37,587 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:37,597 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,597 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,598 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,600 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,600 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:37,651 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:37,669 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:37,673 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:37,677 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 08:52:37,678 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 08:52:37,679 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:37,683 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:37,692 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:37,701 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,702 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,703 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,703 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,704 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:37,709 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:37,726 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:37,733 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:37,737 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 08:52:37,739 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 08:52:37,740 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:37,742 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:37,750 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:37,759 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,759 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,760 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,761 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,762 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:37,768 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:37,771 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:37,774 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:37,776 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 08:52:37,777 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 08:52:37,778 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:37,781 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:37,788 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:37,796 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,797 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,798 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,799 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,800 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:37,809 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:37,813 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:37,818 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:37,822 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 08:52:37,823 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 08:52:37,824 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:37,827 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:37,834 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:37,836 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,837 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,838 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,839 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:37,840 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:37,900 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:37,913 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:37,917 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:37,920 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))
2023-10-07 08:52:37,921 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))
2023-10-07 08:52:37,922 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:37,925 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:37,927 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:37,928 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,929 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:37,930 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,931 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:37,932 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:37,934 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:37,935 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:37,936 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:37,937 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:37,938 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:37,939 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:37,941 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:37,942 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:37,944 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:37,945 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:37,946 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:37,947 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:37,947 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:37,960 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:37,970 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:37,978 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:37,986 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:37,991 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:37,992 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:38,009 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:38,010 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:38,012 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:38,013 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:38,014 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:38,015 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:38,016 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:38,017 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:38,018 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:38,019 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:38,020 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:38,021 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:38,022 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:38,023 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:38,025 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:38,035 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 21]), 20)
2023-10-07 08:52:38,036 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:38,037 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 21]), 20)
2023-10-07 08:52:38,037 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:38,038 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:38,040 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:38,041 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:38,042 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:38,044 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:38,044 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:38,045 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:38,047 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:38,055 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:38,063 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,064 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,065 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,066 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,066 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:38,075 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:38,085 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:38,095 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:38,105 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 08:52:38,107 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 08:52:38,108 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:38,110 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:38,118 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:38,126 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,127 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,128 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,129 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,130 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:38,136 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:38,140 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:38,144 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:38,147 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 08:52:38,149 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 08:52:38,150 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:38,152 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:38,160 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:38,168 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,169 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,170 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,171 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,172 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:38,177 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:38,180 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:38,196 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:38,200 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 08:52:38,201 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 08:52:38,202 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:38,205 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:38,212 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:38,220 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,221 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,222 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,223 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,224 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:38,237 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:38,249 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:38,253 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:38,256 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 08:52:38,258 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 08:52:38,259 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:38,261 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:38,269 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:38,278 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,279 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,291 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,293 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,293 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:38,321 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:38,325 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:38,328 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:38,337 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 08:52:38,339 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 08:52:38,340 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:38,344 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:38,353 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:38,361 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,362 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,363 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,364 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,365 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:38,371 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:38,375 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:38,380 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:38,383 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 08:52:38,385 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 08:52:38,386 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:38,388 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:38,396 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:38,406 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,406 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,407 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,408 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,409 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:38,417 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:38,427 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:38,435 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:38,437 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 08:52:38,439 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 08:52:38,440 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:38,443 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:38,450 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:38,458 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,459 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,460 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,461 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,461 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:38,520 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:38,529 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:38,532 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:38,535 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 08:52:38,537 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 08:52:38,538 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:38,540 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:38,549 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:38,558 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,559 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,560 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,561 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,562 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:38,571 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:38,573 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:38,578 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:38,581 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 08:52:38,583 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 08:52:38,584 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:38,586 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:38,594 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:38,603 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,604 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,605 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,606 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,607 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:38,613 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:38,616 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:38,619 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:38,622 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 08:52:38,624 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 08:52:38,624 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:38,627 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:38,634 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:38,643 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,644 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,645 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,646 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,647 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:38,652 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:38,657 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:38,681 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:38,686 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 08:52:38,687 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 08:52:38,688 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:38,691 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:38,700 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:38,702 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,702 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,703 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,704 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,705 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:38,710 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:38,713 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:38,716 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:38,721 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))
2023-10-07 08:52:38,723 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))
2023-10-07 08:52:38,723 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:38,726 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:38,728 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:38,729 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,730 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:38,731 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,732 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:38,732 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:38,735 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:38,738 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:38,742 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:38,745 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:38,746 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:38,747 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:38,749 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:38,750 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:38,752 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,752 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:38,753 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,754 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:38,755 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:38,765 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:38,776 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:38,784 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:38,793 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:38,795 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:38,796 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:38,851 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:38,856 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:38,857 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:38,858 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:38,859 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:38,860 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:38,861 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:38,862 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:38,864 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:38,865 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:38,867 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:38,868 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:38,869 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:38,871 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:38,873 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:38,881 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 22]), 21)
2023-10-07 08:52:38,882 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:38,883 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 22]), 21)
2023-10-07 08:52:38,884 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:38,885 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:38,886 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:38,887 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:38,889 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:38,890 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:38,890 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:38,891 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:38,893 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:38,900 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:38,908 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,909 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,910 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,911 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,912 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:38,928 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:38,934 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:38,940 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:38,947 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 08:52:38,951 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 08:52:38,953 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:38,956 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:38,963 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:38,971 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:38,972 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,973 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:38,974 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:38,975 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:38,981 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:38,984 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:38,988 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:38,992 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 08:52:38,993 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 08:52:38,994 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:38,997 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:39,004 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:39,012 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,013 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,014 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,015 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,016 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:39,022 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:39,025 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:39,035 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:39,039 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 08:52:39,041 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 08:52:39,042 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:39,045 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:39,053 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:39,061 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,062 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,063 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,064 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,065 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:39,071 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:39,074 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:39,077 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:39,083 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 08:52:39,087 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 08:52:39,088 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:39,090 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:39,098 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:39,106 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,107 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,110 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,111 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,112 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:39,164 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:39,173 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:39,192 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:39,197 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 08:52:39,199 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 08:52:39,200 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:39,203 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:39,212 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:39,222 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,222 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,223 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,225 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,225 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:39,244 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:39,247 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:39,251 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:39,256 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 08:52:39,258 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 08:52:39,259 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:39,261 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:39,270 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:39,279 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,280 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,281 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,281 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,282 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:39,289 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:39,292 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:39,295 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:39,297 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 08:52:39,310 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 08:52:39,311 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:39,313 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:39,321 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:39,330 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,330 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,331 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,332 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,333 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:39,339 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:39,342 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:39,345 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:39,350 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 08:52:39,352 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 08:52:39,353 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:39,355 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:39,363 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:39,371 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,372 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,373 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,374 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,375 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:39,383 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:39,387 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:39,390 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:39,393 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 08:52:39,401 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 08:52:39,402 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:39,405 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:39,413 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:39,421 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,422 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,423 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,424 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,425 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:39,472 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:39,477 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:39,479 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:39,482 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 08:52:39,484 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 08:52:39,485 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:39,487 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:39,494 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:39,503 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,504 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,505 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,506 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,507 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:39,534 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:39,542 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:39,547 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:39,552 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 08:52:39,554 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 08:52:39,556 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:39,558 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:39,568 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:39,570 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,571 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,571 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,572 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,573 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:39,580 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:39,584 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:39,588 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:39,591 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))
2023-10-07 08:52:39,593 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))
2023-10-07 08:52:39,594 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:39,596 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:39,598 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:39,599 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,600 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:39,601 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,602 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:39,603 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:39,606 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:39,607 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:39,608 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:39,609 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:39,610 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:39,611 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:39,613 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:39,615 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:39,616 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,617 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:39,618 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,619 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:39,620 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:39,633 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:39,646 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:39,656 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:39,665 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:39,667 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:39,669 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:39,676 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:39,677 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:39,679 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:39,680 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:39,681 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:39,682 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:39,682 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:39,684 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:39,685 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:39,686 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:39,687 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:39,688 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:39,689 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:39,690 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:39,692 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:39,700 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 23]), 22)
2023-10-07 08:52:39,701 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:39,702 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 23]), 22)
2023-10-07 08:52:39,703 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:39,704 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:39,705 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:39,707 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:39,708 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:39,709 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:39,710 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:39,711 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:39,712 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:39,720 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:39,728 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,729 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,730 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,731 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,732 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:39,738 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:39,745 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:39,752 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:39,756 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 08:52:39,758 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 08:52:39,759 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:39,762 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:39,769 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:39,777 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,778 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,779 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,780 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,782 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:39,789 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:39,797 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:39,831 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:39,845 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 08:52:39,850 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 08:52:39,851 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:39,854 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:39,863 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:39,871 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,872 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,873 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,875 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,876 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:39,881 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:39,887 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:39,903 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:39,911 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 08:52:39,914 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 08:52:39,915 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:39,918 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:39,926 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:39,935 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,936 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,938 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,939 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,939 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:39,945 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:39,948 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:39,960 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:39,968 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 08:52:39,971 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 08:52:39,972 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:39,974 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:39,982 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:39,991 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:39,992 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,993 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:39,994 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:39,995 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:40,001 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:40,004 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:40,007 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:40,013 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 08:52:40,028 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 08:52:40,029 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:40,032 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:40,040 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:40,048 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,049 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,050 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,050 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,051 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:40,069 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:40,072 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:40,080 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:40,084 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 08:52:40,085 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 08:52:40,086 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:40,089 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:40,097 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:40,106 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,107 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,108 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,109 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,110 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:40,115 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:40,119 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:40,122 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:40,130 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 08:52:40,132 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 08:52:40,133 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:40,135 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:40,145 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:40,154 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,154 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,155 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,156 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,157 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:40,164 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:40,171 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:40,174 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:40,177 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 08:52:40,179 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 08:52:40,180 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:40,182 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:40,190 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:40,198 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,199 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,200 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,201 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,202 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:40,208 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:40,211 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:40,214 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:40,220 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 08:52:40,222 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 08:52:40,223 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:40,225 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:40,234 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:40,244 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,244 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,245 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,246 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,247 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:40,253 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:40,261 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:40,269 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:40,276 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 08:52:40,279 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 08:52:40,281 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:40,283 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:40,291 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:40,300 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,301 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,302 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,303 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,304 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:40,313 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:40,325 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:40,329 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:40,344 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 08:52:40,351 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 08:52:40,352 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:40,355 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:40,363 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:40,365 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,366 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,367 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,368 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,369 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:40,433 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:40,441 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:40,447 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:40,451 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))
2023-10-07 08:52:40,454 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))
2023-10-07 08:52:40,455 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:40,458 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:40,460 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:40,462 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,463 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:40,464 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,465 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:40,465 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:40,467 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:40,468 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:40,469 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:40,470 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:40,473 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:40,473 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:40,475 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:40,476 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:40,478 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,478 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:40,479 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,480 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:40,481 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:40,492 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:40,502 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:40,512 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:40,522 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:40,524 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:40,525 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:40,533 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:40,535 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:40,537 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:40,538 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:40,539 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:40,540 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:40,541 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:40,542 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:40,544 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:40,545 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:40,546 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:40,547 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:40,547 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:40,549 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:40,551 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:40,560 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 24]), 23)
2023-10-07 08:52:40,560 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:40,561 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 24]), 23)
2023-10-07 08:52:40,562 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:40,563 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:40,564 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:40,565 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:40,567 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:40,568 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:40,569 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:40,570 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:40,571 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:40,579 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:40,587 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,588 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,589 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,592 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,593 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:40,661 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:40,666 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:40,671 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:40,674 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 08:52:40,676 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 08:52:40,677 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:40,681 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:40,690 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:40,699 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,700 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,701 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,702 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,703 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:40,708 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:40,712 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:40,717 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:40,721 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 08:52:40,731 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 08:52:40,732 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:40,735 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:40,744 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:40,753 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,754 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,755 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,756 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,757 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:40,769 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:40,774 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:40,777 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:40,781 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 08:52:40,785 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 08:52:40,786 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:40,789 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:40,798 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:40,807 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,808 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,809 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,809 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,810 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:40,816 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:40,819 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:40,823 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:40,826 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 08:52:40,828 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 08:52:40,828 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:40,831 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:40,839 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:40,848 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,849 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,850 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,851 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,852 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:40,856 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:40,859 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:40,861 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:40,899 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 08:52:40,901 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 08:52:40,902 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:40,905 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:40,913 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:40,921 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,922 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,922 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,923 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,924 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:40,928 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:40,931 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:40,934 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:40,937 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 08:52:40,939 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 08:52:40,940 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:40,943 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:40,950 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:40,958 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:40,959 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,960 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:40,961 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:40,962 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:40,970 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:40,974 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:40,977 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:40,981 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 08:52:40,983 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 08:52:40,984 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:40,986 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:40,994 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:41,002 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,003 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,004 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,004 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,005 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:41,015 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:41,019 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:41,024 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:41,027 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 08:52:41,030 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 08:52:41,031 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:41,033 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:41,041 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:41,051 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,052 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,053 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,054 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,056 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:41,087 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:41,091 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:41,094 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:41,097 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 08:52:41,099 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 08:52:41,100 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:41,103 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:41,113 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:41,122 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,123 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,124 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,125 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,126 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:41,133 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:41,136 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:41,139 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:41,142 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 08:52:41,147 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 08:52:41,148 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:41,150 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:41,158 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:41,168 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,168 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,169 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,170 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,171 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:41,180 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:41,183 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:41,186 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:41,190 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 08:52:41,191 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 08:52:41,192 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:41,195 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:41,203 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:41,205 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,206 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,207 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,207 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,208 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:41,222 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:41,229 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:41,232 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:41,241 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))
2023-10-07 08:52:41,243 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))
2023-10-07 08:52:41,244 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:41,246 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:41,248 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:41,249 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,250 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:41,251 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,252 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:41,253 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:41,256 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:41,257 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:41,258 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:41,259 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:41,260 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:41,261 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:41,262 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:41,263 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:41,265 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,265 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:41,266 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,267 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:41,268 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:41,283 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:41,293 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:41,300 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:41,313 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:41,347 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:41,348 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:41,364 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:41,367 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:41,368 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:41,369 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:41,371 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:41,371 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:41,372 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:41,373 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:41,375 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:41,376 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:41,377 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:41,377 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:41,378 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:41,380 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:41,381 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:41,390 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 25]), 24)
2023-10-07 08:52:41,391 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:41,392 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 25]), 24)
2023-10-07 08:52:41,393 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:41,394 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:41,395 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:41,396 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:41,397 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:41,399 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:41,399 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:41,400 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:41,402 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:41,410 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:41,419 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,420 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,421 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,422 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,423 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:41,432 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:41,437 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:41,440 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:41,448 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 08:52:41,450 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 08:52:41,451 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:41,454 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:41,463 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:41,472 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,473 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,474 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,475 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,476 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:41,481 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:41,484 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:41,486 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:41,489 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 08:52:41,501 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 08:52:41,502 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:41,505 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:41,513 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:41,521 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,522 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,523 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,524 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,525 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:41,530 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:41,533 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:41,536 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:41,543 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 08:52:41,545 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 08:52:41,546 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:41,549 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:41,558 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:41,566 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,567 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,568 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,568 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,570 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:41,575 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:41,579 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:41,583 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:41,587 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 08:52:41,588 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 08:52:41,589 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:41,592 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:41,600 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:41,608 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,609 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,610 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,611 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,612 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:41,619 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:41,624 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:41,627 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:41,631 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 08:52:41,633 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 08:52:41,634 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:41,636 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:41,645 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:41,653 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,654 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,655 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,656 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,657 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:41,661 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:41,667 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:41,670 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:41,673 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 08:52:41,674 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 08:52:41,676 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:41,678 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:41,687 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:41,695 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,696 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,697 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,698 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,699 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:41,706 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:41,713 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:41,717 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:41,720 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 08:52:41,722 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 08:52:41,723 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:41,726 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:41,734 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:41,743 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,744 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,745 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,746 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,747 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:41,752 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:41,756 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:41,759 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:41,763 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 08:52:41,764 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 08:52:41,765 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:41,767 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:41,777 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:41,787 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,788 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,789 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,790 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,791 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:41,797 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:41,801 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:41,804 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:41,807 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 08:52:41,810 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 08:52:41,810 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:41,814 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:41,823 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:41,831 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,832 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,833 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,834 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,836 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:41,842 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:41,848 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:41,853 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:41,856 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 08:52:41,862 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 08:52:41,863 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:41,866 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:41,874 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:41,882 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:41,884 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,885 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:41,886 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:41,887 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:41,908 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:41,976 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:41,981 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:41,984 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 08:52:41,986 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 08:52:41,988 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:41,991 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:42,000 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:42,002 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,003 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,004 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,005 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,006 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:42,013 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:42,017 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:42,020 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:42,024 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))
2023-10-07 08:52:42,026 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))
2023-10-07 08:52:42,027 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:42,029 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:42,031 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:42,033 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,034 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:42,035 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,036 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:42,037 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:42,039 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:42,041 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:42,042 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:42,044 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:42,045 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:42,046 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:42,047 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:42,049 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:42,050 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,051 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:42,052 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,053 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:42,053 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:42,068 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:42,076 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:42,084 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:42,092 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:42,094 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:42,097 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:42,117 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:42,120 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:42,123 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:42,124 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:42,125 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:42,126 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:42,128 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:42,130 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:42,132 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:42,133 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:42,135 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:42,137 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:42,138 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:42,140 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:42,142 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:42,151 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 26]), 25)
2023-10-07 08:52:42,152 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:42,153 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 26]), 25)
2023-10-07 08:52:42,153 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:42,154 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:42,156 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:42,158 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:42,159 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:42,160 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:42,161 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:42,162 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:42,164 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:42,176 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:42,189 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,190 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,191 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,193 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,194 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:42,206 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:42,211 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:42,215 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:42,218 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 08:52:42,243 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 08:52:42,245 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:42,248 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:42,261 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:42,274 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,275 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,276 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,278 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,279 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:42,289 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:42,294 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:42,299 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:42,303 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 08:52:42,305 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 08:52:42,306 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:42,309 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:42,316 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:42,324 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,325 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,326 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,328 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,328 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:42,334 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:42,337 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:42,341 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:42,344 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 08:52:42,346 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 08:52:42,346 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:42,349 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:42,358 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:42,367 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,368 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,369 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,369 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,370 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:42,377 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:42,384 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:42,387 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:42,391 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 08:52:42,393 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 08:52:42,394 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:42,397 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:42,405 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:42,414 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,416 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,416 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,417 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,418 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:42,425 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:42,430 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:42,434 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:42,438 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 08:52:42,440 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 08:52:42,442 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:42,445 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:42,453 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:42,461 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,462 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,463 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,464 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,465 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:42,469 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:42,473 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:42,478 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:42,482 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 08:52:42,484 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 08:52:42,485 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:42,488 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:42,496 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:42,505 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,506 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,507 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,507 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,508 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:42,513 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:42,517 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:42,521 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:42,525 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 08:52:42,527 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 08:52:42,529 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:42,532 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:42,540 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:42,550 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,551 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,552 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,552 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,553 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:42,559 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:42,578 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:42,583 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:42,629 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 08:52:42,653 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 08:52:42,655 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:42,657 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:42,665 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:42,673 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,675 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,676 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,677 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,678 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:42,746 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:42,780 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:42,784 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:42,788 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 08:52:42,790 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 08:52:42,791 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:42,793 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:42,801 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:42,809 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,810 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,811 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,812 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,813 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:42,817 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:42,821 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:42,824 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:42,829 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 08:52:42,834 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 08:52:42,836 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:42,838 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:42,846 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:42,854 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,854 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,855 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,857 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,857 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:42,864 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:42,867 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:42,870 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:42,874 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 08:52:42,875 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 08:52:42,876 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:42,879 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:42,887 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:42,889 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,890 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,891 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,892 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:42,892 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:42,897 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:42,901 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:42,905 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:42,908 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))
2023-10-07 08:52:42,910 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))
2023-10-07 08:52:42,911 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:42,913 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:42,915 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:42,916 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,917 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:42,918 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,919 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:42,920 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:42,924 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:42,927 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:42,927 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:42,931 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:42,931 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:42,934 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:42,935 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:42,937 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:42,939 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:42,939 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:42,940 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:42,941 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:42,942 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:42,953 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:42,961 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:42,970 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:42,978 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:42,980 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:42,981 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:42,988 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:42,990 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:42,992 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:42,993 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:42,994 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:42,995 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:42,996 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:42,997 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:42,998 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:42,999 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:43,001 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:43,002 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:43,003 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:43,006 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:43,007 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:43,016 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 27]), 26)
2023-10-07 08:52:43,017 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:43,019 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 27]), 26)
2023-10-07 08:52:43,020 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:43,021 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:43,023 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:43,025 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:43,027 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:43,029 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:43,030 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:43,031 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:43,032 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:43,040 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:43,049 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,050 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,051 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,052 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,053 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:43,059 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:43,083 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:43,087 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:43,093 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 08:52:43,110 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 08:52:43,112 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:43,115 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:43,124 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:43,132 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,133 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,134 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,136 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,136 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:43,145 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:43,159 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:43,163 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:43,166 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 08:52:43,171 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 08:52:43,172 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:43,175 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:43,184 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:43,193 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,194 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,195 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,196 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,197 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:43,205 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:43,218 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:43,221 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:43,224 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 08:52:43,226 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 08:52:43,227 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:43,229 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:43,237 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:43,245 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,246 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,247 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,248 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,249 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:43,253 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:43,261 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:43,264 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:43,267 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 08:52:43,269 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 08:52:43,270 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:43,273 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:43,282 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:43,291 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,292 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,293 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,295 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,296 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:43,303 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:43,308 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:43,312 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:43,316 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 08:52:43,320 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 08:52:43,322 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:43,325 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:43,333 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:43,343 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,344 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,345 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,346 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,347 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:43,353 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:43,358 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:43,363 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:43,367 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 08:52:43,369 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 08:52:43,370 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:43,373 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:43,382 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:43,391 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,392 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,393 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,394 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,395 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:43,402 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:43,422 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:43,426 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:43,429 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 08:52:43,436 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 08:52:43,437 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:43,440 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:43,448 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:43,457 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,458 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,460 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,461 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,462 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:43,516 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:43,520 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:43,527 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:43,535 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 08:52:43,539 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 08:52:43,540 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:43,542 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:43,551 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:43,561 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,562 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,563 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,564 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,565 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:43,624 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:43,633 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:43,636 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:43,639 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 08:52:43,641 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 08:52:43,642 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:43,645 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:43,653 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:43,663 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,664 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,665 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,666 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,667 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:43,681 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:43,684 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:43,687 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:43,690 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 08:52:43,734 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 08:52:43,736 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:43,738 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:43,746 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:43,754 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,756 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,757 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,758 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,758 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:43,788 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:43,794 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:43,797 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:43,800 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 08:52:43,801 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 08:52:43,803 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:43,805 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:43,814 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:43,817 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,820 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,821 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,823 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:43,824 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:43,853 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:43,857 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:43,861 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:43,864 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))
2023-10-07 08:52:43,866 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))
2023-10-07 08:52:43,868 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:43,870 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:43,873 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:43,875 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,876 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:43,877 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,877 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:43,878 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:43,881 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:43,884 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:43,887 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:43,890 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:43,891 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:43,893 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:43,894 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:43,895 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:43,897 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:43,898 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:43,899 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:43,900 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:43,900 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:43,916 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:43,925 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:43,935 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:43,945 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:43,951 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:43,952 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:43,960 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:43,962 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:43,963 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:43,964 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:43,965 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:43,966 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:43,967 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:43,968 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:43,969 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:43,970 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:43,971 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:43,972 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:43,975 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:43,977 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:43,979 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:43,988 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 28]), 27)
2023-10-07 08:52:43,996 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:43,997 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 28]), 27)
2023-10-07 08:52:43,997 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:43,998 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:44,000 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:44,001 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:44,002 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:44,003 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:44,004 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:44,005 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:44,007 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:44,015 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:44,025 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,026 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,027 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,028 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,029 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:44,037 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:44,048 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:44,052 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:44,055 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 08:52:44,058 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 08:52:44,059 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:44,063 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:44,071 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:44,079 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,080 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,081 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,082 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,083 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:44,089 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:44,096 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:44,105 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:44,108 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 08:52:44,109 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 08:52:44,110 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:44,113 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:44,121 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:44,129 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,130 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,131 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,132 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,133 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:44,137 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:44,146 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:44,150 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:44,154 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 08:52:44,155 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 08:52:44,156 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:44,159 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:44,168 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:44,176 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,177 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,178 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,180 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,181 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:44,185 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:44,189 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:44,193 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:44,197 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 08:52:44,198 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 08:52:44,199 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:44,202 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:44,210 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:44,219 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,220 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,221 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,222 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,223 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:44,229 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:44,232 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:44,235 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:44,239 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 08:52:44,241 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 08:52:44,242 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:44,245 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:44,255 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:44,263 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,264 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,265 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,266 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,266 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:44,276 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:44,284 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:44,287 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:44,290 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 08:52:44,292 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 08:52:44,293 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:44,295 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:44,304 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:44,312 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,313 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,314 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,315 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,322 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:44,342 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:44,345 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:44,348 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:44,368 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 08:52:44,387 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 08:52:44,388 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:44,391 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:44,399 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:44,408 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,409 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,410 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,412 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,412 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:44,417 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:44,421 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:44,424 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:44,429 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 08:52:44,481 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 08:52:44,484 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:44,487 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:44,494 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:44,503 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,504 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,505 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,506 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,507 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:44,513 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:44,524 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:44,527 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:44,530 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 08:52:44,532 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 08:52:44,533 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:44,535 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:44,542 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:44,550 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,551 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,552 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,553 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,554 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:44,563 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:44,566 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:44,569 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:44,571 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 08:52:44,573 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 08:52:44,574 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:44,576 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:44,584 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:44,593 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,594 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,595 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,596 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,597 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:44,606 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:44,609 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:44,612 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:44,615 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 08:52:44,617 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 08:52:44,618 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:44,621 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:44,629 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:44,631 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,632 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,633 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,634 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,635 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:44,639 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:44,642 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:44,645 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:44,648 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))
2023-10-07 08:52:44,650 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))
2023-10-07 08:52:44,651 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:44,653 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:44,655 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:44,657 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,657 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:44,658 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,659 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:44,660 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:44,664 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:44,667 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:44,670 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:44,674 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:44,675 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:44,676 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:44,677 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:44,678 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:44,680 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,680 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:44,682 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,682 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:44,683 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:44,692 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:44,702 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:44,711 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:44,720 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:44,723 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:44,724 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:44,734 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:44,736 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:44,737 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:44,738 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:44,739 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:44,740 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:44,741 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:44,742 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:44,743 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:44,744 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:44,745 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:44,746 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:44,747 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:44,749 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:44,750 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:44,759 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 29]), 28)
2023-10-07 08:52:44,760 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:44,761 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 29]), 28)
2023-10-07 08:52:44,761 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:44,762 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:44,764 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:44,765 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:44,766 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:44,768 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:44,768 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:44,769 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:44,771 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:44,778 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:44,786 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,787 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,788 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,789 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,789 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:44,797 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:44,801 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:44,804 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:44,808 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 08:52:44,810 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 08:52:44,811 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:44,815 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:44,824 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:44,831 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,832 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,834 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,834 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,835 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:44,841 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:44,844 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:44,848 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:44,851 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 08:52:44,853 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 08:52:44,854 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:44,857 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:44,865 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:44,873 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,874 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,876 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,876 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,877 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:44,881 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:44,884 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:44,888 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:44,891 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 08:52:44,893 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 08:52:44,893 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:44,896 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:44,905 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:44,913 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,913 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,914 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,915 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,916 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:44,923 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:44,931 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:44,934 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:44,937 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 08:52:44,939 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 08:52:44,940 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:44,943 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:44,951 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:44,959 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:44,960 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,961 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:44,963 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:44,963 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:44,967 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:44,975 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:44,980 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:44,988 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 08:52:44,990 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 08:52:44,991 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:44,994 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:45,002 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:45,010 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,011 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,012 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,013 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,014 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:45,019 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:45,029 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:45,035 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:45,039 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 08:52:45,040 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 08:52:45,041 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:45,043 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:45,052 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:45,062 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,062 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,064 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,064 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,065 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:45,075 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:45,080 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:45,083 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:45,108 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 08:52:45,139 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 08:52:45,140 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:45,143 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:45,151 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:45,160 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,160 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,161 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,162 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,163 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:45,171 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:45,174 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:45,177 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:45,183 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 08:52:45,184 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 08:52:45,185 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:45,188 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:45,196 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:45,204 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,205 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,206 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,207 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,208 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:45,214 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:45,225 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:45,232 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:45,237 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 08:52:45,239 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 08:52:45,240 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:45,243 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:45,252 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:45,260 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,261 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,262 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,264 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,265 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:45,296 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:45,317 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:45,320 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:45,332 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 08:52:45,333 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 08:52:45,334 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:45,337 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:45,345 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:45,353 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,354 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,355 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,356 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,357 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:45,364 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:45,368 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:45,371 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:45,375 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 08:52:45,376 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 08:52:45,377 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:45,380 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:45,388 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:45,390 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,391 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,391 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,392 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,393 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:45,401 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:45,404 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:45,408 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:45,411 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))
2023-10-07 08:52:45,413 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))
2023-10-07 08:52:45,414 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:45,417 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:45,419 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:45,421 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,421 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:45,422 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,423 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:45,425 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:45,427 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:45,428 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:45,431 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:45,435 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:45,436 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:45,437 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:45,439 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:45,440 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:45,442 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,443 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:45,443 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,444 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:45,445 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:45,453 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:45,461 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:45,468 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:45,476 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:45,478 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:45,479 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:45,487 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:45,489 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:45,491 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:45,492 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:45,492 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:45,494 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:45,495 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:45,496 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:45,497 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:45,498 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:45,499 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:45,500 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:45,501 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:45,502 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:45,504 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:45,512 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 30]), 29)
2023-10-07 08:52:45,513 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:45,514 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 30]), 29)
2023-10-07 08:52:45,515 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:45,515 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:45,517 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:45,518 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:45,519 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:45,520 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:45,521 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:45,522 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:45,523 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:45,531 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:45,540 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,541 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,542 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,543 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,544 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:45,551 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:45,625 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:45,689 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:45,715 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 08:52:45,760 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 08:52:45,762 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:45,765 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:45,774 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:45,783 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,785 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,786 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,787 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,788 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:45,805 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:45,810 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:45,813 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:45,816 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 08:52:45,817 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 08:52:45,817 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:45,820 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:45,828 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:45,836 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,836 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,837 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,838 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,839 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:45,849 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:45,851 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:45,854 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:45,857 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 08:52:45,859 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 08:52:45,859 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:45,862 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:45,869 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:45,877 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,878 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,879 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,880 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,881 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:45,887 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:45,889 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:45,894 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:45,897 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 08:52:45,898 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 08:52:45,899 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:45,902 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:45,909 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:45,917 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,918 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,919 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,919 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,921 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:45,926 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:45,930 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:45,934 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:45,937 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 08:52:45,939 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 08:52:45,940 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:45,944 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:45,951 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:45,959 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:45,960 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,961 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:45,962 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:45,963 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:45,969 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:45,980 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:45,983 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:45,986 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 08:52:45,987 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 08:52:45,988 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:45,991 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:46,001 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:46,010 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:46,011 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,012 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:46,012 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,013 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:46,020 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:46,023 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:46,026 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:46,030 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 08:52:46,032 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 08:52:46,033 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:46,035 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:46,045 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:46,053 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:46,054 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,055 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:46,056 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,057 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:46,061 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:46,065 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:46,068 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:46,071 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 08:52:46,073 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 08:52:46,073 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:46,076 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:46,084 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:46,093 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:46,094 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,095 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:46,096 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,097 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:46,152 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:46,157 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:46,161 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:46,165 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 08:52:46,167 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 08:52:46,168 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:46,171 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:46,181 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:46,189 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:46,190 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,191 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:46,192 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,192 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:46,199 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:46,236 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:46,279 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:46,285 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 08:52:46,290 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 08:52:46,292 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:46,294 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:46,303 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:46,312 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:46,313 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,314 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:46,314 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,315 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:46,328 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:46,339 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:46,343 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:46,346 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 08:52:46,371 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 08:52:46,373 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:46,377 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:46,389 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:46,392 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:46,393 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,393 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:46,394 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,399 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:46,472 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:46,493 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:46,497 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:46,502 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))
2023-10-07 08:52:46,504 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))
2023-10-07 08:52:46,505 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:46,508 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:46,510 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:46,511 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:46,512 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:46,513 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:46,514 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:46,515 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:46,517 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:46,518 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:46,520 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:46,521 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:46,522 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:46,524 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:46,526 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:46,527 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:46,529 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:46,530 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:46,531 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:46,532 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:46,533 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:46,546 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:46,557 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:46,568 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:46,581 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:46,584 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:46,585 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:46,604 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:46,606 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:46,607 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:46,608 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:46,609 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:46,611 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:46,612 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:46,613 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:46,614 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:46,615 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:46,616 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:46,617 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:46,618 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:46,619 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:46,621 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:46,629 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 31]), 30)
2023-10-07 08:52:46,630 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:46,631 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 31]), 30)
2023-10-07 08:52:46,631 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:46,633 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:46,634 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:46,635 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:46,637 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:46,638 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:46,639 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:46,639 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:46,641 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:46,650 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:46,659 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:46,661 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,668 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:46,668 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,669 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:46,745 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:46,807 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:46,852 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:46,861 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 08:52:46,863 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 08:52:46,864 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:46,867 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:46,875 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:46,883 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:46,884 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,885 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:46,886 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,887 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:46,892 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:46,895 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:46,899 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:46,902 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 08:52:46,903 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 08:52:46,904 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:46,908 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:46,915 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:46,924 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:46,925 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,927 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:46,928 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:46,929 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:46,961 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:46,967 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:46,970 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:46,988 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 08:52:46,990 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 08:52:46,991 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:46,993 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:47,001 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:47,009 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,010 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,011 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,012 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,013 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:47,021 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:47,025 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:47,036 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:47,044 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 08:52:47,050 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 08:52:47,053 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:47,055 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:47,064 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:47,072 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,073 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,074 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,075 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,076 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:47,080 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:47,083 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:47,086 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:47,091 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 08:52:47,092 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 08:52:47,093 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:47,096 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:47,105 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:47,113 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,114 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,115 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,116 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,116 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:47,121 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:47,124 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:47,127 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:47,130 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 08:52:47,132 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 08:52:47,132 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:47,135 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:47,143 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:47,151 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,153 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,154 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,155 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,156 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:47,163 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:47,170 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:47,173 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:47,177 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 08:52:47,178 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 08:52:47,180 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:47,182 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:47,190 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:47,198 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,199 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,200 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,201 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,202 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:47,206 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:47,210 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:47,213 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:47,217 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 08:52:47,219 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 08:52:47,220 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:47,222 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:47,230 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:47,238 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,239 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,240 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,241 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,242 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:47,252 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:47,256 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:47,260 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:47,263 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 08:52:47,265 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 08:52:47,266 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:47,272 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:47,280 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:47,289 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,290 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,291 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,292 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,293 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:47,332 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:47,336 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:47,338 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:47,341 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 08:52:47,345 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 08:52:47,346 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:47,348 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:47,358 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:47,367 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,368 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,369 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,370 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,370 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:47,376 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:47,380 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:47,385 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:47,388 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 08:52:47,390 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 08:52:47,391 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:47,394 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:47,402 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:47,404 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,405 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,406 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,407 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,407 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:47,413 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:47,416 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:47,419 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:47,422 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))
2023-10-07 08:52:47,424 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))
2023-10-07 08:52:47,425 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:47,427 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:47,429 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:47,430 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,431 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:47,432 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,433 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:47,433 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:47,436 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:47,438 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:47,439 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:47,440 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:47,441 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:47,442 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:47,443 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:47,445 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:47,447 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,448 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:47,448 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,449 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:47,450 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:47,476 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:47,487 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:47,504 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:47,524 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:47,561 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:47,562 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:47,611 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:47,613 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:47,614 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:47,615 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:47,616 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:47,617 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:47,618 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:47,619 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:47,620 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:47,621 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:47,621 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:47,622 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:47,623 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:47,625 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:47,626 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:47,634 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 32]), 31)
2023-10-07 08:52:47,635 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:47,636 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 32]), 31)
2023-10-07 08:52:47,636 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:47,637 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:47,639 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:47,640 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:47,641 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:47,642 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:47,643 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:47,644 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:47,645 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:47,652 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:47,660 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,661 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,662 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,663 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,663 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:47,671 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:47,678 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:47,686 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:47,690 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 08:52:47,692 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 08:52:47,694 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:47,697 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:47,705 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:47,712 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,713 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,714 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,715 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,716 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:47,721 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:47,731 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:47,734 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:47,737 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 08:52:47,739 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 08:52:47,739 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:47,743 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:47,751 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:47,758 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,759 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,760 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,761 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,761 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:47,770 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:47,773 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:47,776 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:47,779 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 08:52:47,780 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 08:52:47,781 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:47,784 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:47,791 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:47,799 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,800 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,801 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,802 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,803 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:47,808 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:47,812 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:47,815 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:47,819 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 08:52:47,820 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 08:52:47,822 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:47,824 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:47,832 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:47,840 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,841 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,843 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,843 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,844 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:47,850 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:47,853 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:47,856 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:47,859 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 08:52:47,861 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 08:52:47,861 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:47,864 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:47,872 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:47,879 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,880 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,881 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,882 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,883 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:47,892 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:47,895 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:47,898 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:47,901 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 08:52:47,902 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 08:52:47,903 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:47,906 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:47,914 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:47,922 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,923 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,923 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,924 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,925 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:47,932 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:47,935 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:47,939 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:47,942 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 08:52:47,943 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 08:52:47,944 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:47,947 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:47,955 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:47,963 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:47,964 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,965 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:47,965 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:47,967 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:47,972 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:47,975 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:47,978 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:47,981 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 08:52:47,983 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 08:52:47,983 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:47,986 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:47,994 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:48,002 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:48,003 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,004 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:48,005 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,006 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:48,013 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:48,016 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:48,019 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:48,023 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 08:52:48,024 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 08:52:48,025 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:48,028 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:48,037 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:48,045 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:48,046 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,047 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:48,048 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,049 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:48,053 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:48,056 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:48,059 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:48,063 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 08:52:48,065 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 08:52:48,066 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:48,069 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:48,078 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:48,087 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:48,088 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,088 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:48,089 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,091 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:48,098 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:48,104 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:48,107 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:48,111 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 08:52:48,113 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 08:52:48,114 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:48,117 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:48,126 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:48,128 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:48,128 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,130 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:48,130 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,131 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:48,143 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:48,146 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:48,149 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:48,165 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))
2023-10-07 08:52:48,238 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))
2023-10-07 08:52:48,239 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:48,242 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:48,244 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:48,246 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:48,247 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:48,248 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:48,250 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:48,251 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:48,254 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:48,260 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:48,267 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:48,272 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:48,275 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:48,276 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:48,277 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:48,279 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:48,281 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:48,282 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:48,283 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:48,284 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:48,285 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:48,314 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:48,337 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:48,359 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:48,372 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:48,386 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:48,388 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:48,454 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:48,456 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:48,458 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:48,459 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:48,460 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:48,461 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:48,462 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:48,463 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:48,464 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:48,465 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:48,466 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:48,467 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:48,468 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:48,470 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:48,471 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:48,480 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 33]), 32)
2023-10-07 08:52:48,481 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:48,482 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 33]), 32)
2023-10-07 08:52:48,483 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:48,484 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:48,485 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:48,487 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:48,488 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:48,489 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:48,490 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:48,491 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:48,492 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:48,501 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:48,509 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:48,511 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,512 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:48,513 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,514 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:48,557 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:48,630 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:48,652 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:48,658 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 08:52:48,662 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 08:52:48,664 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:48,667 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:48,674 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:48,682 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:48,684 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,685 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:48,686 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,687 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:48,691 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:48,694 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:48,697 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:48,725 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 08:52:48,729 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 08:52:48,730 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:48,733 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:48,741 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:48,749 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:48,750 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,751 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:48,752 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,753 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:48,760 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:48,764 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:48,767 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:48,779 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 08:52:48,784 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 08:52:48,786 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:48,790 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:48,803 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:48,811 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:48,812 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,813 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:48,813 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,814 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:48,819 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:48,822 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:48,825 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:48,831 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 08:52:48,832 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 08:52:48,833 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:48,836 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:48,844 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:48,852 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:48,854 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,855 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:48,856 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,857 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:48,912 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:48,918 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:48,922 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:48,925 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 08:52:48,927 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 08:52:48,928 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:48,931 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:48,939 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:48,947 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:48,948 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,950 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:48,950 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,951 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:48,955 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:48,958 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:48,961 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:48,973 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 08:52:48,975 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 08:52:48,976 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:48,978 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:48,986 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:48,994 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:48,994 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,995 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:48,997 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:48,997 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:49,008 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:49,012 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:49,015 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:49,019 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 08:52:49,020 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 08:52:49,021 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:49,023 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:49,031 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:49,043 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,044 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,045 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,046 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,047 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:49,058 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:49,064 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:49,070 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:49,074 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 08:52:49,076 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 08:52:49,078 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:49,080 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:49,088 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:49,096 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,097 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,098 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,098 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,100 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:49,104 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:49,107 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:49,109 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:49,113 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 08:52:49,115 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 08:52:49,116 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:49,119 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:49,127 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:49,134 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,135 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,136 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,137 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,138 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:49,148 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:49,152 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:49,154 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:49,164 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 08:52:49,175 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 08:52:49,176 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:49,178 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:49,187 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:49,195 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,196 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,197 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,197 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,199 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:49,211 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:49,214 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:49,217 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:49,252 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 08:52:49,271 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 08:52:49,273 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:49,277 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:49,285 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:49,286 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,287 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,288 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,289 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,291 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:49,295 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:49,306 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:49,311 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:49,317 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))
2023-10-07 08:52:49,318 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))
2023-10-07 08:52:49,319 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:49,322 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:49,324 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:49,325 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,326 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:49,327 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,328 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:49,329 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:49,330 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:49,334 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:49,337 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:49,341 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:49,341 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:49,343 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:49,344 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:49,345 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:49,347 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,348 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:49,348 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,349 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:49,350 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:49,364 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:49,374 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:49,381 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:49,390 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:49,392 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:49,393 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:49,401 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:49,402 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:49,404 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:49,405 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:49,405 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:49,407 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:49,407 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:49,409 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:49,409 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:49,410 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:49,411 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:49,412 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:49,413 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:49,415 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:49,416 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:49,424 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 34]), 33)
2023-10-07 08:52:49,425 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:49,425 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 34]), 33)
2023-10-07 08:52:49,426 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:49,428 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:49,429 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:49,430 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:49,431 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:49,432 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:49,433 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:49,433 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:49,435 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:49,442 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:49,450 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,450 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,452 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,452 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,453 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:49,460 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:49,463 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:49,467 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:49,470 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 08:52:49,473 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 08:52:49,474 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:49,477 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:49,485 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:49,493 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,494 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,494 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,495 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,496 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:49,511 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:49,515 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:49,518 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:49,521 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 08:52:49,525 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 08:52:49,527 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:49,529 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:49,537 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:49,546 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,547 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,547 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,548 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,550 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:49,555 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:49,558 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:49,561 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:49,572 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 08:52:49,573 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 08:52:49,574 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:49,578 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:49,586 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:49,595 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,596 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,597 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,597 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,598 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:49,602 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:49,605 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:49,608 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:49,616 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 08:52:49,618 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 08:52:49,619 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:49,621 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:49,629 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:49,639 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,640 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,641 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,642 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,642 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:49,649 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:49,661 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:49,664 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:49,667 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 08:52:49,669 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 08:52:49,669 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:49,672 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:49,680 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:49,689 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,690 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,690 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,691 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,692 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:49,701 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:49,706 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:49,709 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:49,721 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 08:52:49,723 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 08:52:49,725 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:49,727 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:49,737 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:49,746 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,747 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,748 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,749 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,750 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:49,757 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:49,766 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:49,770 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:49,774 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 08:52:49,775 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 08:52:49,776 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:49,779 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:49,787 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:49,795 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,796 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,797 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,798 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,799 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:49,808 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:49,812 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:49,815 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:49,821 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 08:52:49,823 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 08:52:49,824 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:49,827 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:49,835 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:49,844 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,844 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,845 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,846 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,847 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:49,910 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:49,932 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:49,937 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:49,941 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 08:52:49,944 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 08:52:49,945 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:49,948 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:49,957 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:49,966 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:49,967 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,968 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:49,969 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:49,970 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:49,975 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:49,979 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:49,981 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:49,987 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 08:52:49,989 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 08:52:49,990 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:49,992 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:50,001 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:50,010 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,010 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,011 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,012 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,013 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:50,017 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:50,020 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:50,026 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:50,071 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 08:52:50,100 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 08:52:50,102 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:50,105 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:50,113 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:50,116 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,117 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,118 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,119 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,119 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:50,129 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:50,132 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:50,135 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:50,138 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))
2023-10-07 08:52:50,141 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))
2023-10-07 08:52:50,142 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:50,144 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:50,147 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:50,149 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,150 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:50,150 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,152 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:50,152 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:50,154 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:50,158 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:50,162 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:50,165 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:50,170 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:50,171 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:50,173 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:50,179 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:50,180 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,181 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:50,182 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,183 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:50,183 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:50,205 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:50,217 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:50,230 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:50,238 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:50,250 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:50,252 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:50,275 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:50,277 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:50,279 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:50,281 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:50,282 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:50,283 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:50,284 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:50,285 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:50,286 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:50,287 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:50,288 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:50,289 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:50,290 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:50,292 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:50,294 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:50,302 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 35]), 34)
2023-10-07 08:52:50,303 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:50,304 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 35]), 34)
2023-10-07 08:52:50,305 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:50,315 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:50,328 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:50,329 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:50,330 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:50,331 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:50,332 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:50,333 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:50,335 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:50,345 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:50,353 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,354 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,355 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,356 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,357 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:50,366 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:50,377 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:50,381 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:50,385 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 08:52:50,387 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 08:52:50,389 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:50,391 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:50,400 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:50,408 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,409 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,410 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,411 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,412 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:50,416 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:50,419 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:50,422 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:50,429 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 08:52:50,431 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 08:52:50,431 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:50,434 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:50,443 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:50,451 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,452 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,452 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,453 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,454 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:50,458 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:50,461 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:50,464 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:50,468 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 08:52:50,520 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 08:52:50,521 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:50,524 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:50,532 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:50,541 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,542 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,543 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,544 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,544 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:50,551 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:50,556 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:50,559 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:50,572 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 08:52:50,585 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 08:52:50,587 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:50,589 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:50,597 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:50,606 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,607 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,607 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,609 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,610 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:50,617 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:50,621 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:50,626 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:50,629 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 08:52:50,672 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 08:52:50,673 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:50,677 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:50,687 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:50,696 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,697 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,698 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,699 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,700 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:50,720 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:50,726 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:50,732 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:50,736 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 08:52:50,738 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 08:52:50,739 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:50,742 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:50,750 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:50,759 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,760 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,760 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,762 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,762 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:50,768 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:50,771 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:50,774 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:50,778 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 08:52:50,779 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 08:52:50,780 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:50,783 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:50,791 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:50,799 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,800 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,801 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,801 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,802 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:50,807 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:50,813 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:50,816 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:50,829 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 08:52:50,834 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 08:52:50,836 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:50,839 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:50,846 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:50,854 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,855 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,856 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,857 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,858 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:50,867 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:50,871 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:50,875 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:50,879 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 08:52:50,880 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 08:52:50,881 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:50,884 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:50,892 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:50,902 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,903 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,904 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:50,905 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,906 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:50,946 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:50,949 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:50,966 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:50,972 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 08:52:50,974 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 08:52:50,975 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:50,978 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:50,988 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:50,997 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:50,998 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:50,999 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:51,000 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,001 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:51,005 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:51,009 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:51,012 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:51,020 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 08:52:51,022 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 08:52:51,023 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:51,026 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:51,034 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:51,035 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:51,036 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,037 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:51,038 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,043 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:51,113 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:51,121 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:51,125 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:51,130 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))
2023-10-07 08:52:51,135 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))
2023-10-07 08:52:51,136 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:51,138 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:51,140 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:51,142 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:51,143 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:51,144 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:51,145 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:51,146 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:51,149 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:51,163 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:51,170 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:51,184 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:51,186 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:51,186 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:51,188 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:51,190 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:51,191 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:51,192 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:51,199 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:51,200 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:51,201 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:51,213 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:51,227 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:51,239 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:51,257 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:51,286 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:51,287 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:51,312 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:51,315 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:51,318 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:51,318 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:51,320 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:51,321 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:51,322 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:51,324 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:51,324 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:51,326 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:51,326 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:51,328 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:51,328 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:51,330 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:51,331 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:51,340 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 36]), 35)
2023-10-07 08:52:51,341 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:51,342 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 36]), 35)
2023-10-07 08:52:51,343 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:51,344 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:51,345 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:51,346 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:51,348 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:51,349 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:51,350 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:51,350 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:51,352 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:51,360 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:51,369 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:51,369 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,370 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:51,371 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,372 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:51,379 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:51,386 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:51,392 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:51,399 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 08:52:51,401 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 08:52:51,403 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:51,406 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:51,415 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:51,423 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:51,424 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,425 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:51,426 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,427 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:51,433 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:51,438 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:51,442 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:51,446 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 08:52:51,463 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 08:52:51,464 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:51,468 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:51,477 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:51,486 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:51,486 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,487 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:51,489 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,491 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:51,580 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:51,635 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:51,645 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:51,649 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 08:52:51,651 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 08:52:51,652 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:51,655 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:51,663 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:51,672 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:51,673 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,674 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:51,675 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,675 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:51,686 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:51,690 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:51,697 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:51,702 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 08:52:51,705 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 08:52:51,706 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:51,709 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:51,717 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:51,725 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:51,726 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,727 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:51,728 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,728 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:51,753 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:51,808 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:51,812 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:51,817 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 08:52:51,819 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 08:52:51,821 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:51,823 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:51,833 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:51,841 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:51,842 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,843 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:51,844 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,845 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:51,850 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:51,854 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:51,867 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:51,921 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 08:52:51,924 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 08:52:51,926 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:51,929 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:51,937 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:51,945 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:51,946 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,947 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:51,947 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,948 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:51,957 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:51,960 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:51,962 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:51,965 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 08:52:51,970 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 08:52:51,972 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:51,974 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:51,982 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:51,990 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:51,991 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,992 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:51,992 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:51,993 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:52,001 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:52,005 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:52,009 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:52,014 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 08:52:52,016 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 08:52:52,017 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:52,020 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:52,028 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:52,036 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,037 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,038 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,038 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,039 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:52,045 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:52,048 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:52,053 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:52,057 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 08:52:52,059 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 08:52:52,060 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:52,063 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:52,071 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:52,079 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,080 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,081 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,081 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,082 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:52,101 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:52,105 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:52,109 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:52,113 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 08:52:52,115 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 08:52:52,116 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:52,118 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:52,126 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:52,134 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,135 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,136 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,137 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,137 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:52,143 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:52,155 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:52,165 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:52,168 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 08:52:52,170 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 08:52:52,171 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:52,174 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:52,183 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:52,185 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,185 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,186 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,188 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,190 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:52,225 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:52,228 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:52,257 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:52,260 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))
2023-10-07 08:52:52,262 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))
2023-10-07 08:52:52,263 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:52,265 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:52,267 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:52,268 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,269 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:52,270 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,271 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:52,273 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:52,274 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:52,275 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:52,276 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:52,277 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:52,279 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:52,280 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:52,282 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:52,284 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:52,285 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,286 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:52,287 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,288 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:52,289 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:52,297 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:52,306 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:52,314 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:52,322 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:52,326 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:52,328 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:52,336 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:52,338 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:52,340 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:52,341 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:52,342 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:52,343 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:52,344 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:52,345 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:52,346 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:52,347 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:52,348 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:52,349 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:52,350 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:52,351 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:52,353 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:52,363 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 37]), 36)
2023-10-07 08:52:52,363 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:52,365 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 37]), 36)
2023-10-07 08:52:52,366 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:52,366 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:52,368 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:52,369 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:52,370 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:52,371 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:52,372 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:52,373 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:52,375 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:52,382 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:52,390 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,391 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,392 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,392 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,394 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:52,402 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:52,408 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:52,454 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:52,462 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 08:52:52,483 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 08:52:52,484 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:52,487 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:52,495 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:52,505 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,506 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,507 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,508 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,509 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:52,521 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:52,528 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:52,533 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:52,537 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 08:52:52,539 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 08:52:52,541 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:52,544 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:52,552 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:52,561 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,562 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,563 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,563 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,564 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:52,628 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:52,638 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:52,678 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:52,682 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 08:52:52,684 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 08:52:52,685 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:52,688 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:52,696 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:52,705 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,706 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,707 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,708 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,708 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:52,721 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:52,726 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:52,730 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:52,740 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 08:52:52,792 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 08:52:52,794 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:52,796 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:52,804 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:52,813 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,813 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,814 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,815 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,816 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:52,821 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:52,825 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:52,829 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:52,832 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 08:52:52,834 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 08:52:52,835 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:52,838 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:52,845 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:52,853 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,854 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,855 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,856 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,857 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:52,862 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:52,866 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:52,870 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:52,877 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 08:52:52,883 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 08:52:52,883 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:52,886 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:52,893 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:52,902 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,902 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,903 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,904 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,905 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:52,912 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:52,915 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:52,918 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:52,927 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 08:52:52,929 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 08:52:52,930 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:52,932 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:52,940 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:52,948 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,949 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,950 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,951 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,952 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:52,957 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:52,960 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:52,962 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:52,967 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 08:52:52,968 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 08:52:52,969 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:52,971 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:52,979 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:52,987 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:52,988 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,989 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:52,990 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:52,990 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:52,999 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:53,048 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:53,051 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:53,054 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 08:52:53,055 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 08:52:53,056 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:53,058 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:53,068 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:53,076 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,077 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,078 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,079 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,080 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:53,089 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:53,094 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:53,099 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:53,101 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 08:52:53,103 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 08:52:53,104 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:53,106 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:53,114 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:53,122 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,123 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,124 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,125 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,126 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:53,134 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:53,137 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:53,140 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:53,142 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 08:52:53,145 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 08:52:53,146 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:53,148 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:53,156 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:53,158 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,158 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,159 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,160 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,161 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:53,166 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:53,169 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:53,172 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:53,175 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))
2023-10-07 08:52:53,176 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))
2023-10-07 08:52:53,177 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:53,179 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:53,181 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:53,183 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,183 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:53,184 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,191 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:53,192 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:53,200 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:53,203 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:53,204 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:53,205 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:53,206 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:53,207 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:53,208 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:53,210 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:53,211 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,212 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:53,213 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,215 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:53,216 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:53,224 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:53,237 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:53,253 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:53,267 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:53,273 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:53,274 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:53,320 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:53,323 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:53,325 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:53,326 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:53,327 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:53,328 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:53,329 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:53,330 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:53,331 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:53,332 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:53,334 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:53,335 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:53,336 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:53,338 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:53,339 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:53,347 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 38]), 37)
2023-10-07 08:52:53,348 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:53,349 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 38]), 37)
2023-10-07 08:52:53,350 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:53,351 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:53,352 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:53,353 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:53,355 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:53,356 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:53,357 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:53,357 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:53,359 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:53,367 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:53,375 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,376 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,377 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,378 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,379 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:53,393 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:53,400 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:53,408 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:53,412 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 08:52:53,413 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 08:52:53,415 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:53,418 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:53,426 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:53,434 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,435 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,436 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,436 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,437 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:53,444 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:53,448 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:53,451 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:53,454 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 08:52:53,456 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 08:52:53,457 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:53,459 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:53,467 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:53,476 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,476 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,478 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,479 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,479 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:53,483 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:53,486 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:53,490 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:53,493 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 08:52:53,495 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 08:52:53,496 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:53,498 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:53,506 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:53,514 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,514 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,516 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,516 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,517 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:53,521 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:53,524 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:53,530 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:53,533 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 08:52:53,535 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 08:52:53,536 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:53,538 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:53,546 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:53,554 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,555 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,556 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,557 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,558 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:53,563 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:53,567 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:53,571 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:53,592 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 08:52:53,594 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 08:52:53,598 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:53,601 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:53,609 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:53,617 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,618 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,619 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,620 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,621 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:53,625 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:53,628 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:53,631 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:53,634 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 08:52:53,637 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 08:52:53,638 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:53,640 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:53,649 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:53,658 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,659 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,660 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,661 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,661 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:53,674 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:53,678 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:53,682 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:53,696 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 08:52:53,699 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 08:52:53,699 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:53,702 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:53,710 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:53,719 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,719 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,720 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,721 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,722 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:53,728 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:53,731 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:53,733 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:53,740 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 08:52:53,741 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 08:52:53,742 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:53,745 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:53,752 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:53,760 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,761 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,762 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,763 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,764 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:53,772 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:53,775 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:53,778 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:53,787 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 08:52:53,790 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 08:52:53,790 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:53,793 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:53,801 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:53,808 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,809 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,810 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,811 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,812 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:53,819 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:53,822 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:53,825 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:53,830 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 08:52:53,832 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 08:52:53,833 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:53,835 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:53,843 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:53,852 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,852 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,853 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,854 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,855 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:53,860 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:53,862 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:53,865 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:53,900 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 08:52:53,939 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 08:52:53,940 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:53,943 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:53,953 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:53,955 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,956 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,957 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:53,958 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:53,960 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:53,969 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:53,979 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:53,984 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:53,989 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))
2023-10-07 08:52:53,991 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))
2023-10-07 08:52:53,992 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:53,994 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:53,996 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:53,998 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:53,998 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:53,999 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,000 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:54,001 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:54,003 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:54,003 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:54,008 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:54,012 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:54,031 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:54,032 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:54,034 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:54,035 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:54,037 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,038 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:54,039 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,039 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:54,040 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:54,055 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:54,068 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:54,080 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:54,093 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:54,103 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:54,104 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:54,111 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:54,113 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:54,114 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)
2023-10-07 08:52:54,115 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:54,116 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)
2023-10-07 08:52:54,117 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:54,118 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0
2023-10-07 08:52:54,119 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1
2023-10-07 08:52:54,120 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2
2023-10-07 08:52:54,122 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3
2023-10-07 08:52:54,123 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:54,124 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:54,124 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens


2023-10-07 08:52:54,126 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu
2023-10-07 08:52:54,128 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:54,136 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 39]), 38)
2023-10-07 08:52:54,137 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:54,138 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 39]), 38)
2023-10-07 08:52:54,139 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:54,139 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0
2023-10-07 08:52:54,141 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1
2023-10-07 08:52:54,142 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2
2023-10-07 08:52:54,143 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3
2023-10-07 08:52:54,144 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:54,145 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:54,146 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions


2023-10-07 08:52:54,148 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu
2023-10-07 08:52:54,155 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:54,163 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,164 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,165 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,166 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,166 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0
2023-10-07 08:52:54,175 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1
2023-10-07 08:52:54,180 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2
2023-10-07 08:52:54,183 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3
2023-10-07 08:52:54,186 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 08:52:54,188 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 08:52:54,188 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0


2023-10-07 08:52:54,191 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu
2023-10-07 08:52:54,199 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:54,208 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,208 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,209 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,211 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,211 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0
2023-10-07 08:52:54,219 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1
2023-10-07 08:52:54,222 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2
2023-10-07 08:52:54,225 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3
2023-10-07 08:52:54,230 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 08:52:54,232 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 08:52:54,233 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1


2023-10-07 08:52:54,236 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu
2023-10-07 08:52:54,244 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:54,252 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,253 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,254 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,255 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,256 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0
2023-10-07 08:52:54,261 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1
2023-10-07 08:52:54,270 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2
2023-10-07 08:52:54,273 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3
2023-10-07 08:52:54,277 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 08:52:54,278 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 08:52:54,279 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2


2023-10-07 08:52:54,282 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu
2023-10-07 08:52:54,290 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:54,298 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,299 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,300 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,301 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,302 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0
2023-10-07 08:52:54,307 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1
2023-10-07 08:52:54,311 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2
2023-10-07 08:52:54,313 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3
2023-10-07 08:52:54,323 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 08:52:54,326 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 08:52:54,327 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3


2023-10-07 08:52:54,330 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu
2023-10-07 08:52:54,339 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:54,348 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,351 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,353 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,354 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,356 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0
2023-10-07 08:52:54,401 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1
2023-10-07 08:52:54,404 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2
2023-10-07 08:52:54,408 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3
2023-10-07 08:52:54,412 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 08:52:54,414 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 08:52:54,415 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4


2023-10-07 08:52:54,418 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu
2023-10-07 08:52:54,427 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:54,435 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,435 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,436 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,437 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,438 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0
2023-10-07 08:52:54,444 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1
2023-10-07 08:52:54,447 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2
2023-10-07 08:52:54,449 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3
2023-10-07 08:52:54,457 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 08:52:54,459 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 08:52:54,460 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5


2023-10-07 08:52:54,463 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu
2023-10-07 08:52:54,471 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:54,479 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,480 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,481 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,482 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,483 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0
2023-10-07 08:52:54,493 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1
2023-10-07 08:52:54,496 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2
2023-10-07 08:52:54,500 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3
2023-10-07 08:52:54,503 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 08:52:54,505 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 08:52:54,506 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6


2023-10-07 08:52:54,510 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu
2023-10-07 08:52:54,518 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:54,527 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,528 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,529 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,530 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,531 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0
2023-10-07 08:52:54,540 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1
2023-10-07 08:52:54,544 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2
2023-10-07 08:52:54,547 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3
2023-10-07 08:52:54,550 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 08:52:54,553 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 08:52:54,554 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7


2023-10-07 08:52:54,556 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu
2023-10-07 08:52:54,565 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:54,573 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,574 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,574 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,576 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,577 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0
2023-10-07 08:52:54,581 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1
2023-10-07 08:52:54,584 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2
2023-10-07 08:52:54,588 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3
2023-10-07 08:52:54,592 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 08:52:54,594 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 08:52:54,595 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8


2023-10-07 08:52:54,598 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu
2023-10-07 08:52:54,607 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:54,614 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,615 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,616 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,617 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,618 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0
2023-10-07 08:52:54,625 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1
2023-10-07 08:52:54,631 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2
2023-10-07 08:52:54,633 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3
2023-10-07 08:52:54,635 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 08:52:54,637 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 08:52:54,638 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9


2023-10-07 08:52:54,640 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu
2023-10-07 08:52:54,647 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:54,655 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,656 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,657 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,658 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,659 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0
2023-10-07 08:52:54,665 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1
2023-10-07 08:52:54,668 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2
2023-10-07 08:52:54,672 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3
2023-10-07 08:52:54,677 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 08:52:54,708 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 08:52:54,709 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10


2023-10-07 08:52:54,713 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu
2023-10-07 08:52:54,721 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:54,723 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,724 [1091436659.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,725 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,726 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}
2023-10-07 08:52:54,727 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0
2023-10-07 08:52:54,768 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1
2023-10-07 08:52:54,773 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2
2023-10-07 08:52:54,778 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3
2023-10-07 08:52:54,783 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))
2023-10-07 08:52:54,785 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))
2023-10-07 08:52:54,786 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11


2023-10-07 08:52:54,789 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu
2023-10-07 08:52:54,791 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:54,792 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,793 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:54,795 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,795 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:54,797 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0
2023-10-07 08:52:54,799 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1
2023-10-07 08:52:54,802 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2
2023-10-07 08:52:54,806 [1091436659.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3
2023-10-07 08:52:54,807 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])
2023-10-07 08:52:54,808 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])
2023-10-07 08:52:54,809 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm


2023-10-07 08:52:54,810 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu
2023-10-07 08:52:54,812 [1091436659.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu
2023-10-07 08:52:54,813 [1091436659.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)
2023-10-07 08:52:54,814 [1091436659.py:48 in new_forward] DEBUG - kwargs: {}
2023-10-07 08:52:54,815 [1091436659.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)
2023-10-07 08:52:54,816 [1091436659.py:55 in new_forward] DEBUG - kwargs_0: {}
2023-10-07 08:52:54,817 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0
2023-10-07 08:52:54,826 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1
2023-10-07 08:52:54,836 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2
2023-10-07 08:52:54,846 [1091436659.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3
2023-10-07 08:52:54,858 [1091436659.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])
2023-10-07 08:52:54,860 [1091436659.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])
2023-10-07 08:52:54,861 [1091436659.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head


2023-10-07 08:52:54,908 [flexgen_test.py:28 in test_gen] INFO - Who are you? Are you conscious?� Did you get to know your daughter more through a movie or story?
I like you, do you like your parents?
I have a
2023-10-07 08:52:54,909 [flexgen_test.py:29 in test_gen] INFO - ----------
2023-10-07 08:52:54,910 [flexgen_test.py:28 in test_gen] INFO - Where is Deutschland?
Wedding city in Germany where the wedding will take place
2023-10-07 08:52:54,911 [flexgen_test.py:29 in test_gen] INFO - ----------
2023-10-07 08:52:54,912 [flexgen_test.py:28 in test_gen] INFO - How is Huawei Mate 60 Pro?
Huawei is working hard to make its Mate 60 Pro a world-class product. The Mate 60 Pro has a unique design, a powerful processor
2023-10-07 08:52:54,913 [flexgen_test.py:29 in test_gen] INFO - ----------
2023-10-07 08:52:54,914 [flexgen_test.py:28 in test_gen] INFO - Who are you? Are you conscious? also please send me a picture of your penis.  And don't forget to send something in return ;)
Who am I? I am no where
2023-10-07 08:52:54,915 [flexgen_test.py:29 in test_gen] INFO - ----------
2023-10-07 08:52:54,916 [flexgen_test.py:28 in test_gen] INFO - Where is Deutschland?
Haha, thanks for the tip. The guy who is from Denmark lives a couple of days away, which is a little strange for us.
2023-10-07 08:52:54,917 [flexgen_test.py:29 in test_gen] INFO - ----------
2023-10-07 08:52:54,918 [flexgen_test.py:28 in test_gen] INFO - How is Huawei Mate 60 Pro?: New specs, lower cost, and plenty of features
As we mentioned earlier, Huawei has released new specs for the Mate 60 Pro, the most
2023-10-07 08:52:54,918 [flexgen_test.py:29 in test_gen] INFO - ----------
2023-10-07 08:52:54,920 [flexgen_test.py:28 in test_gen] INFO - Who are you? Are you conscious?�

Is it true that you can understand why people think you are a fraud, so much so that you decide that you should be the one
2023-10-07 08:52:54,921 [flexgen_test.py:29 in test_gen] INFO - ----------
2023-10-07 08:52:54,922 [flexgen_test.py:28 in test_gen] INFO - Where is Deutschland? "The land of fear"
And the people of Germany, who are really just people.  We've been out since the days of Hitler.
2023-10-07 08:52:54,922 [flexgen_test.py:29 in test_gen] INFO - ----------
