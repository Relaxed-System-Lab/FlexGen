{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fsuser/miniconda3/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2023-10-04 09:18:49,018 [instantiator.py:21 in <module>] INFO - Created a temporary directory at /tmp/tmpcwi8pqix\n",
      "2023-10-04 09:18:49,020 [instantiator.py:76 in _write] INFO - Writing /tmp/tmpcwi8pqix/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Module \n",
    "import functools \n",
    "\n",
    "from flexgen_utils import logging, Policy, get_module_from_name\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "from flexgen_init import policy_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:18:49,445 [connectionpool.py:1003 in _new_conn] DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2023-10-04 09:18:49,530 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-04 09:18:50.192536: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-04 09:18:51,178 [tpu_cluster_resolver.py:32 in <module>] DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2023-10-04 09:18:51,353 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5\n",
      "2023-10-04 09:18:51,354 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7\n",
      "2023-10-04 09:18:51,355 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5\n",
      "2023-10-04 09:18:51,356 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7\n",
      "2023-10-04 09:18:52,473 [flexgen_init.py:201 in get_policy_weight_map] INFO - device_map is prepared!\n",
      "2023-10-04 09:18:52,477 [flexgen_init.py:207 in get_policy_weight_map] INFO - CausalLM facebook/opt-125m is to be loaded on: \n",
      "GPU Mem 0.00 GiB (0.00%), CPU Mem 0.07 GiB (30.19%), Disk Mem 0.16 Gib (69.81%)\n",
      "2023-10-04 09:18:52,515 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-04 09:18:52,651 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-04 09:18:52,752 [flexgen_init.py:67 in policy_init] INFO - The whole model has been downloaded an processed to offload_folder: 'offload_dir/facebook.opt-125m'\n",
      "model init: loading by policy...:   0%|          | 0/197 [00:00<?, ?it/s]/home/fsuser/FlexGen/general/flexgen_utils/offload.py:41: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995026/work/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  tmp = torch.from_numpy(np_memmap).to(device)\n",
      "model init: loading by policy...: 100%|██████████| 197/197 [00:00<00:00, 2517.51it/s]\n",
      "2023-10-04 09:18:52,837 [flexgen_init.py:79 in policy_init] INFO - model has been loaded by policy.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"facebook/opt-125m\" # 125m 6.7b 13b 30b\n",
    "\n",
    "policy = Policy(\n",
    "    gpu_batch_size=2, \n",
    "    num_gpu_batches=4, \n",
    "    weights_gpu_percent=0.0, \n",
    "    weights_cpu_percent=0.3, \n",
    "    cache_gpu_percent=0.0, \n",
    "    cache_cpu_percent=0.2, \n",
    "    act_gpu_percent=0.0, \n",
    "    act_cpu_percent=0.5, \n",
    "    overlap=True, \n",
    "    pin_weight=True,\n",
    ")\n",
    "\n",
    "# for test\n",
    "gbs = policy.gpu_batch_size\n",
    "ngb = policy.num_gpu_batches\n",
    "num_prompts = ngb * gbs \n",
    "\n",
    "# model init\n",
    "output = policy_init(checkpoint, policy)\n",
    "\n",
    "model = output.model\n",
    "weight_map = output.weight_map\n",
    "layer_names = output.layer_names\n",
    "index = output.index\n",
    "dat_files = output.dat_files\n",
    "tied_params = output.tied_params\n",
    "offload_folder = output.offload_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:18:52,859 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.embed_tokens to flexgen forward\n",
      "2023-10-04 09:18:52,860 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.embed_positions to flexgen forward\n",
      "2023-10-04 09:18:52,861 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.final_layer_norm to flexgen forward\n",
      "2023-10-04 09:18:52,862 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.0 to flexgen forward\n",
      "2023-10-04 09:18:52,863 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.1 to flexgen forward\n",
      "2023-10-04 09:18:52,864 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.2 to flexgen forward\n",
      "2023-10-04 09:18:52,865 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.3 to flexgen forward\n",
      "2023-10-04 09:18:52,866 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.4 to flexgen forward\n",
      "2023-10-04 09:18:52,867 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.5 to flexgen forward\n",
      "2023-10-04 09:18:52,868 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.6 to flexgen forward\n",
      "2023-10-04 09:18:52,869 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.7 to flexgen forward\n",
      "2023-10-04 09:18:52,870 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.8 to flexgen forward\n",
      "2023-10-04 09:18:52,871 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.9 to flexgen forward\n",
      "2023-10-04 09:18:52,872 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.10 to flexgen forward\n",
      "2023-10-04 09:18:52,873 [891690013.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.11 to flexgen forward\n",
      "2023-10-04 09:18:52,873 [891690013.py:36 in to_flexgen_forward] DEBUG - lm_head to flexgen forward\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from accelerate.utils import named_module_tensors \n",
    "from flexgen_utils import get_tied_target\n",
    "from flexgen_utils import flexgen_load_module_tensor, flexgen_offload_module_tensor\n",
    "from flexgen_minibatch import get_size_info, get_kth_batch_inputs, concat_outputs\n",
    "\n",
    "def load_layer_weights(model, layer_name, compute_device, offload_folder, dat_files):\n",
    "    logger.debug(f'load_layer_weights: {layer_name} to {compute_device}')\n",
    "    layer_module = get_module_from_name(model, layer_name)\n",
    "    weight_names = [layer_name + '.' + name for name, _ in named_module_tensors(layer_module, True, True)]\n",
    "    layer_dat_files = [os.path.join(offload_folder, get_tied_target(w, tied_params, dat_files) + '.dat') for w in weight_names]\n",
    "    assert all([os.path.isfile(f) for f in layer_dat_files]), f'dat file error, {dat_files}'\n",
    "    \n",
    "    for w in weight_names:\n",
    "        flexgen_load_module_tensor(model, w, compute_device, index, offload_folder, tied_params)\n",
    "\n",
    "\n",
    "def offload_layer_weights(model, layer_name, weight_map):\n",
    "    logger.debug(f'offload_layer_weights: {layer_name}')\n",
    "    layer_module = get_module_from_name(model, layer_name)\n",
    "    weight_names = [layer_name + '.' + name for name, _ in named_module_tensors(layer_module, True, True)]\n",
    "    for w in weight_names:\n",
    "        flexgen_offload_module_tensor(model, w, weight_map) \n",
    "\n",
    "\n",
    "def to_flexgen_forward(model, layer_names, j, compute_device, weight_map, offload_folder, ngb, gbs):\n",
    "    # rewrite the j-th layer's forward\n",
    "    \n",
    "    layer_name = layer_names[j]\n",
    "    next_layer_name = layer_names[(j + 1) % len(layer_names)]\n",
    "\n",
    "    layer = get_module_from_name(model, layer_name)  \n",
    "    if hasattr(layer, \"_flexgen_old_forward\"): # has been rewriten\n",
    "        return layer \n",
    "    \n",
    "    logger.debug(f'{layer_name} to flexgen forward')\n",
    "    layer._flexgen_old_forward = old_forward = layer.forward \n",
    "\n",
    "    @functools.wraps(old_forward)\n",
    "    def new_forward(*args, **kwargs):\n",
    "        # pre fwd: load curr & next weights\n",
    "        load_layer_weights(model, layer_name, compute_device, offload_folder, dat_files)\n",
    "        load_layer_weights(model, next_layer_name, compute_device, offload_folder, dat_files)\n",
    "        \n",
    "        # loop forward pass of K minibatches\n",
    "        with torch.no_grad():\n",
    "            logger.debug(f'args: {get_size_info(args)}')\n",
    "            logger.debug(f'kwargs: {get_size_info(kwargs)}')\n",
    "            # output = old_forward(*args, **kwargs)\n",
    "            # logger.debug(f'output: {get_size_info(output)}')\n",
    "\n",
    "            args_0 = get_kth_batch_inputs(args, 0, gbs)\n",
    "            kwargs_0 = get_kth_batch_inputs(kwargs, 0, gbs)\n",
    "            logger.debug(f'args_0: {get_size_info(args_0)}')\n",
    "            logger.debug(f'kwargs_0: {get_size_info(kwargs_0)}')\n",
    "            # output_0 = old_forward(*args_0, **kwargs_0)\n",
    "            # logger.debug(f'output0: {get_size_info(output_0)}')\n",
    "\n",
    "            outputs = []\n",
    "            for k in range(ngb):\n",
    "                logger.debug(f'layer: {layer_name}, batch: {k}')\n",
    "\n",
    "                # pre fwd: load curr & next inputs (activations, KV cache), store prev output\n",
    "                args_k = get_kth_batch_inputs(args, k, gbs)\n",
    "                kwargs_k = get_kth_batch_inputs(kwargs, k, gbs)\n",
    "\n",
    "                # the k-th fwd pass\n",
    "                output = old_forward(*args_k, **kwargs_k)\n",
    "                outputs.append(output) \n",
    "                \n",
    "                # post fwd: offload curr inputs\n",
    "\n",
    "            logger.debug(f'outputs before concat: {ngb} x {get_size_info(outputs[0])}')\n",
    "            output = concat_outputs(outputs)\n",
    "            logger.debug(f'outputs after concat: {get_size_info(output)}')                \n",
    "\n",
    "        # post fwd: free curr weights\n",
    "        offload_layer_weights(model, layer_name, weight_map)\n",
    "        return output\n",
    "\n",
    "    layer.forward = new_forward\n",
    "    return layer\n",
    "\n",
    "\n",
    "def to_old_forward(model, layer_name):\n",
    "    layer = get_module_from_name(model, layer_name) \n",
    "\n",
    "    if hasattr(layer, \"_flexgen_old_forward\"):\n",
    "        layer.forward = layer._flexgen_old_forward\n",
    "        delattr(layer, \"_flexgen_old_forward\")\n",
    "        logger.debug(f'{layer_name} to old forward')\n",
    "    return layer\n",
    "\n",
    "\n",
    "layer_nums = len(layer_names)\n",
    "\n",
    "for j in range(layer_nums):\n",
    "    to_old_forward(model, layer_names[j])\n",
    "    \n",
    "# rewrite layers' forward\n",
    "for j in range(layer_nums):\n",
    "    compute_device = 'cpu'\n",
    "    to_flexgen_forward(model, layer_names, j, compute_device, weight_map, offload_folder, ngb, gbs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:18:52,924 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "/home/fsuser/miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1535: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on meta. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('meta') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "2023-10-04 09:18:53,129 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:53,131 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:53,133 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10]),)\n",
      "2023-10-04 09:18:53,133 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:53,134 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10]),)\n",
      "2023-10-04 09:18:53,135 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:53,137 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:18:53,138 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:18:53,139 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:18:53,140 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:18:53,141 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])\n",
      "2023-10-04 09:18:53,142 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])\n",
      "2023-10-04 09:18:53,143 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:18:53,145 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:53,146 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:53,148 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10]), 0)\n",
      "2023-10-04 09:18:53,148 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:53,149 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10]), 0)\n",
      "2023-10-04 09:18:53,150 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:53,151 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:18:53,153 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:18:53,154 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:18:53,155 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:18:53,156 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])\n",
      "2023-10-04 09:18:53,157 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])\n",
      "2023-10-04 09:18:53,158 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:18:53,161 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:53,170 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:53,177 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,178 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,179 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,180 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,181 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:18:53,193 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:18:53,200 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:18:53,205 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:18:53,215 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,217 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,218 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:18:53,221 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:53,229 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:53,236 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,237 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,238 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,239 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,239 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:18:53,246 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:18:53,251 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:18:53,256 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:18:53,260 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,262 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,263 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:18:53,265 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:53,273 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:53,281 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,282 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,282 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,283 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,284 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:18:53,292 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:18:53,297 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:18:53,304 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:18:53,309 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,310 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,311 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:18:53,314 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:53,322 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:53,330 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,331 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,332 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,334 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,335 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:18:53,342 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:18:53,349 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:18:53,354 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:18:53,360 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,361 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,362 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:18:53,364 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:53,372 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:53,380 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,381 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,381 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,383 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,383 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:18:53,390 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:18:53,395 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:18:53,409 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:18:53,416 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,418 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,419 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:18:53,421 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:53,430 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:53,439 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,440 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,441 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,442 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,443 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:18:53,453 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:18:53,462 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:18:53,468 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:18:53,476 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,478 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,479 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:18:53,481 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:53,489 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:53,497 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,498 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,499 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,500 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,501 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:18:53,506 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:18:53,513 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:18:53,520 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:18:53,526 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,527 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,528 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:18:53,530 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:53,539 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:53,547 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,548 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,549 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,550 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,551 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:18:53,560 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:18:53,574 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:18:53,583 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:18:53,589 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,591 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,592 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:18:53,594 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:53,602 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:53,611 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,611 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,612 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,613 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,614 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:18:53,624 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:18:53,628 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:18:53,636 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:18:53,640 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,642 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,643 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:18:53,646 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:53,654 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:53,662 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,663 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,665 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,665 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,666 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:18:53,674 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:18:53,679 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:18:53,683 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:18:53,688 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,690 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,691 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:18:53,694 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:53,702 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:53,709 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,710 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,711 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,712 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,713 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:18:53,723 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:18:53,731 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:18:53,737 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:18:53,742 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,745 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,745 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:18:53,748 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:53,757 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:53,758 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,759 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,760 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,761 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,762 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:18:53,773 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:18:53,779 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:18:53,784 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:18:53,793 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,795 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:18:53,796 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:18:53,799 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:53,801 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:53,809 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,810 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:53,811 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,812 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:53,813 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:18:53,816 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:18:53,817 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:18:53,819 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:18:53,820 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])\n",
      "2023-10-04 09:18:53,821 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])\n",
      "2023-10-04 09:18:53,822 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:18:53,823 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:53,825 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:53,826 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:18:53,828 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:53,829 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:18:53,829 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:53,830 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:18:53,848 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:18:53,860 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:18:53,872 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:18:53,884 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 50272])\n",
      "2023-10-04 09:18:53,890 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 50272])\n",
      "2023-10-04 09:18:53,891 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:18:53,908 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:53,910 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:53,911 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:18:53,912 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:53,913 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:18:53,914 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:53,915 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:18:53,916 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:18:53,917 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:18:53,918 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:18:53,919 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:53,920 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:53,921 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:18:53,923 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:53,924 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:53,927 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 11]), 10)\n",
      "2023-10-04 09:18:53,927 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:53,929 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 11]), 10)\n",
      "2023-10-04 09:18:53,930 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:53,931 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:18:53,932 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:18:53,933 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:18:53,934 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:18:53,936 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:53,936 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:53,937 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:18:53,939 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:53,946 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:53,955 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:53,956 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,957 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:53,958 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:53,959 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:18:53,967 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:18:53,973 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:18:53,979 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:18:53,986 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:18:53,988 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:18:53,989 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:18:53,992 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:54,000 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:54,008 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,009 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,010 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,011 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,012 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:18:54,028 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:18:54,032 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:18:54,036 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:18:54,039 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,040 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,041 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:18:54,043 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:54,052 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:54,062 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,062 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,063 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,065 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,065 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:18:54,074 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:18:54,078 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:18:54,081 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:18:54,084 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,085 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,086 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:18:54,089 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:54,099 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:54,108 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,109 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,110 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,111 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,113 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:18:54,119 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:18:54,123 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:18:54,125 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:18:54,135 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,137 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,138 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:18:54,140 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:54,148 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:54,157 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,158 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,159 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,160 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,161 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:18:54,167 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:18:54,174 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:18:54,181 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:18:54,188 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,190 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,191 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:18:54,194 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:54,204 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:54,212 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,213 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,214 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,215 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,216 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:18:54,221 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:18:54,225 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:18:54,232 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:18:54,235 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,237 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,238 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:18:54,240 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:54,249 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:54,258 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,259 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,259 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,260 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,261 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:18:54,271 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:18:54,274 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:18:54,277 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:18:54,279 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,281 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,282 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:18:54,285 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:54,294 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:54,302 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,303 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,304 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,305 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,307 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:18:54,313 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:18:54,316 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:18:54,320 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:18:54,324 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,325 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,326 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:18:54,328 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:54,336 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:54,345 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,346 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,347 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,348 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,349 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:18:54,357 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:18:54,361 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:18:54,364 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:18:54,368 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,369 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,370 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:18:54,373 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:54,382 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:54,390 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,391 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,392 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,393 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,394 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:18:54,400 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:18:54,405 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:18:54,410 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:18:54,414 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,416 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,417 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:18:54,419 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:54,428 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:54,437 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,437 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,439 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,439 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,440 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:18:54,444 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:18:54,447 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:18:54,458 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:18:54,462 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,464 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,464 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:18:54,467 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:54,475 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:54,476 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,478 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,479 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,480 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,481 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:18:54,492 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:18:54,499 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:18:54,504 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:18:54,509 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,511 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:18:54,512 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:18:54,516 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:54,518 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:54,529 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,530 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:54,531 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,531 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:54,532 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:18:54,535 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:18:54,536 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:18:54,540 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:18:54,543 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:54,545 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:54,546 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:18:54,548 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:54,549 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:54,551 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,552 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:54,552 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,553 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:54,554 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:18:54,570 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:18:54,578 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:18:54,587 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:18:54,595 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:18:54,598 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:18:54,599 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:18:54,608 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:54,610 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:54,612 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:18:54,613 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:54,614 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:18:54,615 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:54,616 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:18:54,617 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:18:54,618 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:18:54,619 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:18:54,620 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:54,621 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:54,622 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:18:54,624 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:54,626 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:54,631 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 12]), 11)\n",
      "2023-10-04 09:18:54,632 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:54,634 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 12]), 11)\n",
      "2023-10-04 09:18:54,635 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:54,639 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:18:54,643 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:18:54,645 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:18:54,648 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:18:54,650 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:54,652 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:54,654 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:18:54,657 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:54,672 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:54,686 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,687 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,688 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,689 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,691 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:18:54,703 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:18:54,709 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:18:54,717 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:18:54,732 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:18:54,734 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:18:54,735 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:18:54,738 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:54,747 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:54,756 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,757 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,758 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,758 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,768 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:18:54,826 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:18:54,858 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:18:54,864 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:18:54,869 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:18:54,871 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:18:54,872 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:18:54,875 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:54,883 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:54,891 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,892 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,893 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,895 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,896 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:18:54,904 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:18:54,916 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:18:54,923 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:18:54,935 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:18:54,938 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:18:54,940 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:18:54,943 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:54,952 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:54,965 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:54,966 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,967 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:54,968 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:54,969 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:18:54,976 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:18:54,980 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:18:54,986 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:18:54,989 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:18:54,991 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:18:54,992 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:18:54,995 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:55,003 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:55,012 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,013 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,014 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,015 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,016 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:18:55,021 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:18:55,025 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:18:55,031 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:18:55,037 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,039 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,040 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:18:55,043 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:55,055 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:55,069 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,071 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,072 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,073 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,075 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:18:55,082 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:18:55,095 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:18:55,101 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:18:55,106 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,108 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,109 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:18:55,112 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:55,120 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:55,135 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,136 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,137 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,138 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,139 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:18:55,148 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:18:55,155 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:18:55,168 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:18:55,180 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,182 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,183 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:18:55,186 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:55,195 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:55,203 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,204 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,205 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,206 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,207 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:18:55,213 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:18:55,230 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:18:55,235 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:18:55,240 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,242 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,243 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:18:55,246 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:55,254 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:55,263 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,263 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,264 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,265 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,266 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:18:55,271 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:18:55,274 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:18:55,277 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:18:55,287 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,289 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,290 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:18:55,294 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:55,307 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:55,321 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,322 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,324 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,325 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,326 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:18:55,332 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:18:55,337 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:18:55,341 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:18:55,345 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,346 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,347 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:18:55,350 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:55,362 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:55,376 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,377 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,378 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,379 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,380 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:18:55,403 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:18:55,408 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:18:55,412 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:18:55,416 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,417 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,419 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:18:55,421 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:55,429 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:55,431 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,432 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,433 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,434 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,435 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:18:55,449 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:18:55,456 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:18:55,460 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:18:55,464 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,466 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:18:55,466 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:18:55,469 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:55,471 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:55,479 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,480 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:55,481 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,482 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:55,483 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:18:55,485 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:18:55,487 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:18:55,490 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:18:55,494 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:55,496 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:55,497 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:18:55,499 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:55,500 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:55,502 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,503 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:55,504 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,504 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:55,506 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:18:55,520 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:18:55,529 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:18:55,554 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:18:55,568 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:18:55,589 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:18:55,591 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:18:55,610 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:55,613 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:55,614 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:18:55,615 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:55,616 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:18:55,617 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:55,618 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:18:55,619 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:18:55,620 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:18:55,622 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:18:55,623 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:55,623 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:55,624 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:18:55,626 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:55,628 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:55,629 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 13]), 12)\n",
      "2023-10-04 09:18:55,630 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:55,631 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 13]), 12)\n",
      "2023-10-04 09:18:55,632 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:55,633 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:18:55,635 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:18:55,636 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:18:55,637 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:18:55,638 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:55,639 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:55,640 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:18:55,642 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:55,650 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:55,659 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,660 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,661 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,662 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,663 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:18:55,670 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:18:55,679 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:18:55,683 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:18:55,688 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:18:55,689 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:18:55,690 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:18:55,693 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:55,701 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:55,710 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,711 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,712 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,713 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,715 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:18:55,722 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:18:55,729 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:18:55,732 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:18:55,739 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:18:55,740 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:18:55,741 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:18:55,744 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:55,753 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:55,762 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,763 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,764 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,765 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,766 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:18:55,775 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:18:55,780 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:18:55,786 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:18:55,791 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:18:55,792 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:18:55,793 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:18:55,796 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:55,808 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:55,822 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,823 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,825 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,826 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,827 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:18:55,837 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:18:55,844 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:18:55,848 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:18:55,852 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:18:55,853 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:18:55,854 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:18:55,857 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:55,866 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:55,875 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,876 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,878 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,879 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,880 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:18:55,887 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:18:55,894 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:18:55,901 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:18:55,907 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:18:55,908 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:18:55,909 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:18:55,912 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:55,921 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:55,930 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,931 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,932 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,933 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,934 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:18:55,939 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:18:55,944 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:18:55,950 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:18:55,955 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:18:55,957 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:18:55,958 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:18:55,961 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:55,970 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:55,979 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:55,980 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,981 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:55,982 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:55,983 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:18:55,994 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:18:55,997 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:18:56,000 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:18:56,015 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:18:56,017 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:18:56,018 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:18:56,020 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:56,029 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:56,040 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,041 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,042 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,043 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,044 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:18:56,054 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:18:56,058 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:18:56,061 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:18:56,067 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:18:56,068 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:18:56,070 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:18:56,072 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:56,080 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:56,089 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,090 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,091 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,093 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,094 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:18:56,108 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:18:56,120 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:18:56,125 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:18:56,130 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:18:56,131 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:18:56,132 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:18:56,135 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:56,144 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:56,152 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,153 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,154 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,155 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,156 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:18:56,161 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:18:56,197 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:18:56,204 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:18:56,219 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:18:56,221 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:18:56,222 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:18:56,225 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:56,234 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:56,243 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,244 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,246 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,246 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,247 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:18:56,257 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:18:56,263 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:18:56,267 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:18:56,272 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:18:56,274 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:18:56,275 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:18:56,279 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:56,288 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:56,290 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,291 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,292 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,293 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,294 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:18:56,301 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:18:56,309 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:18:56,313 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:18:56,317 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:18:56,318 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:18:56,320 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:18:56,322 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:56,325 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:56,333 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,334 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:56,335 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,336 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:56,336 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:18:56,340 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:18:56,344 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:18:56,346 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:18:56,350 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:56,351 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:56,353 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:18:56,354 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:56,357 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:56,358 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,359 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:56,361 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,362 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:56,363 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:18:56,375 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:18:56,388 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:18:56,397 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:18:56,408 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:18:56,411 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:18:56,412 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:18:56,431 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:56,433 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:56,435 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:18:56,436 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:56,437 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:18:56,438 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:56,439 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:18:56,440 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:18:56,441 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:18:56,448 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:18:56,450 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:56,452 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:56,452 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:18:56,454 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:56,456 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:56,458 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 14]), 13)\n",
      "2023-10-04 09:18:56,460 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:56,461 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 14]), 13)\n",
      "2023-10-04 09:18:56,462 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:56,463 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:18:56,464 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:18:56,465 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:18:56,466 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:18:56,468 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:56,469 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:56,470 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:18:56,471 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:56,479 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:56,488 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,489 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,490 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,491 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,492 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:18:56,531 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:18:56,540 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:18:56,548 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:18:56,556 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,558 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,559 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:18:56,562 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:56,570 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:56,579 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,580 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,581 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,582 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,583 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:18:56,591 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:18:56,596 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:18:56,599 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:18:56,605 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,607 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,608 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:18:56,611 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:56,620 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:56,628 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,629 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,630 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,631 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,632 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:18:56,638 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:18:56,644 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:18:56,654 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:18:56,668 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,670 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,671 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:18:56,674 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:56,684 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:56,693 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,695 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,696 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,696 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,697 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:18:56,705 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:18:56,709 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:18:56,712 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:18:56,719 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,721 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,723 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:18:56,725 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:56,734 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:56,743 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,744 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,745 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,746 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,747 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:18:56,755 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:18:56,759 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:18:56,762 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:18:56,766 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,767 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,768 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:18:56,771 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:56,779 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:56,787 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,788 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,789 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,790 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,791 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:18:56,800 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:18:56,804 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:18:56,808 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:18:56,812 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,814 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,815 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:18:56,818 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:56,827 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:56,837 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,839 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,839 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,840 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,842 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:18:56,849 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:18:56,853 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:18:56,856 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:18:56,860 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,861 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,863 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:18:56,865 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:56,875 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:56,883 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,884 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,885 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,887 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,887 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:18:56,896 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:18:56,901 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:18:56,909 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:18:56,914 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,916 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,916 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:18:56,919 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:56,940 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:56,950 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:56,952 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,953 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:56,954 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:56,955 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:18:56,962 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:18:56,974 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:18:56,978 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:18:56,982 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,983 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:18:56,984 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:18:56,987 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:56,995 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:57,005 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,006 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,007 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,008 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,009 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:18:57,038 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:18:57,043 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:18:57,046 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:18:57,049 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:18:57,051 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:18:57,052 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:18:57,054 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:57,063 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:57,071 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,072 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,073 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,073 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,074 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:18:57,080 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:18:57,084 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:18:57,087 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:18:57,090 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:18:57,092 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:18:57,093 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:18:57,095 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:57,103 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:57,104 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,105 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,106 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,107 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,108 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:18:57,112 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:18:57,116 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:18:57,120 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:18:57,131 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:18:57,133 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:18:57,134 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:18:57,136 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:57,138 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:57,146 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,147 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:57,148 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,149 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:57,150 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:18:57,153 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:18:57,154 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:18:57,155 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:18:57,156 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:57,157 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:57,158 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:18:57,159 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:57,161 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:57,163 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,164 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:57,165 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,165 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:57,166 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:18:57,185 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:18:57,197 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:18:57,210 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:18:57,220 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:18:57,223 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:18:57,224 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:18:57,232 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:57,235 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:57,237 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:18:57,238 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:57,239 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:18:57,239 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:57,240 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:18:57,242 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:18:57,243 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:18:57,244 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:18:57,245 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:57,247 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:57,247 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:18:57,249 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:57,251 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:57,253 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 15]), 14)\n",
      "2023-10-04 09:18:57,254 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:57,255 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 15]), 14)\n",
      "2023-10-04 09:18:57,256 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:57,257 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:18:57,259 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:18:57,260 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:18:57,261 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:18:57,263 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:57,264 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:57,265 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:18:57,266 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:57,275 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:57,285 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,290 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,291 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,292 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,293 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:18:57,340 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:18:57,357 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:18:57,361 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:18:57,365 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,366 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,368 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:18:57,370 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:57,379 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:57,387 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,388 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,389 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,390 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,391 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:18:57,395 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:18:57,398 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:18:57,401 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:18:57,409 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,410 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,411 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:18:57,414 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:57,423 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:57,432 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,433 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,434 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,435 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,436 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:18:57,443 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:18:57,448 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:18:57,452 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:18:57,457 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,459 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,460 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:18:57,463 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:57,472 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:57,482 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,483 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,485 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,486 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,487 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:18:57,494 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:18:57,501 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:18:57,512 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:18:57,518 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,520 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,522 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:18:57,525 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:57,534 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:57,543 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,544 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,546 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,547 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,548 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:18:57,556 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:18:57,577 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:18:57,584 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:18:57,592 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,595 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,596 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:18:57,600 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:57,612 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:57,625 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,627 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,629 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,629 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,630 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:18:57,637 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:18:57,644 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:18:57,648 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:18:57,651 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,653 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,654 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:18:57,656 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:57,665 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:57,673 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,674 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,675 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,676 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,677 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:18:57,684 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:18:57,689 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:18:57,693 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:18:57,697 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,698 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,700 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:18:57,702 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:57,711 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:57,720 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,721 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,721 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,722 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,724 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:18:57,728 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:18:57,734 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:18:57,741 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:18:57,746 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,748 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,749 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:18:57,751 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:57,760 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:57,768 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,769 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,771 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,772 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,773 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:18:57,836 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:18:57,874 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:18:57,879 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:18:57,883 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,884 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,886 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:18:57,889 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:57,897 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:57,906 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,907 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,908 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,909 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,910 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:18:57,918 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:18:57,922 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:18:57,926 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:18:57,930 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,932 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,933 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:18:57,936 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:57,944 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:57,954 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,955 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,956 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,957 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,958 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:18:57,964 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:18:57,967 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:18:57,975 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:18:57,979 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,981 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:18:57,982 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:18:57,985 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:57,993 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:57,994 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:57,995 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,996 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:57,997 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:57,998 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:18:58,005 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:18:58,008 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:18:58,014 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:18:58,018 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:18:58,020 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:18:58,021 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:18:58,023 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:58,025 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:58,033 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,034 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:58,035 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,036 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:58,036 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:18:58,039 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:18:58,043 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:18:58,047 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:18:58,052 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:58,052 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:58,055 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:18:58,056 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:58,058 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:58,060 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,061 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:58,062 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,063 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:58,064 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:18:58,073 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:18:58,086 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:18:58,094 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:18:58,105 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:18:58,110 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:18:58,111 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:18:58,119 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:58,122 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:58,124 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:18:58,125 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:58,126 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:18:58,127 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:58,128 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:18:58,130 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:18:58,131 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:18:58,132 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:18:58,133 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:58,134 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:58,134 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:18:58,136 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:58,138 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:58,140 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 16]), 15)\n",
      "2023-10-04 09:18:58,141 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:58,142 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 16]), 15)\n",
      "2023-10-04 09:18:58,143 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:58,143 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:18:58,145 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:18:58,146 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:18:58,147 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:18:58,148 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:58,149 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:58,150 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:18:58,152 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:58,160 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:58,169 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,169 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,170 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,171 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,172 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:18:58,180 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:18:58,186 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:18:58,190 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:18:58,194 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,196 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,196 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:18:58,199 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:58,208 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:58,216 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,217 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,218 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,219 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,220 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:18:58,227 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:18:58,231 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:18:58,235 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:18:58,239 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,241 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,242 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:18:58,245 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:58,257 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:58,266 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,267 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,268 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,269 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,270 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:18:58,282 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:18:58,289 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:18:58,293 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:18:58,296 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,297 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,298 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:18:58,301 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:58,309 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:58,317 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,319 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,320 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,321 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,322 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:18:58,326 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:18:58,329 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:18:58,369 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:18:58,390 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,393 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,394 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:18:58,398 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:58,407 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:58,417 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,418 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,419 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,420 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,421 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:18:58,431 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:18:58,436 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:18:58,440 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:18:58,444 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,445 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,446 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:18:58,449 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:58,458 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:58,467 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,468 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,469 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,471 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,471 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:18:58,482 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:18:58,485 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:18:58,488 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:18:58,499 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,500 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,501 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:18:58,504 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:58,512 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:58,522 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,523 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,524 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,526 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,527 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:18:58,534 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:18:58,540 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:18:58,543 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:18:58,546 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,548 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,548 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:18:58,551 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:58,561 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:58,575 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,577 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,578 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,581 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,582 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:18:58,595 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:18:58,610 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:18:58,615 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:18:58,624 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,626 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,628 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:18:58,630 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:58,639 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:58,650 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,651 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,652 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,653 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,654 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:18:58,667 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:18:58,671 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:18:58,675 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:18:58,680 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,681 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,683 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:18:58,686 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:58,695 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:58,706 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,707 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,708 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,709 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,711 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:18:58,716 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:18:58,728 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:18:58,732 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:18:58,742 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,744 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,745 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:18:58,748 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:58,756 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:58,765 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,766 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,767 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,768 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,769 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:18:58,774 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:18:58,780 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:18:58,790 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:18:58,797 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,800 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,800 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:18:58,803 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:58,812 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:58,813 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,814 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,816 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,817 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:58,817 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:18:58,824 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:18:58,887 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:18:58,905 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:18:58,909 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,911 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:18:58,912 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:18:58,914 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:58,916 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:58,924 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,925 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:58,926 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,927 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:58,928 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:18:58,932 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:18:58,935 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:18:58,938 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:18:58,942 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:58,943 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:58,944 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:18:58,946 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:58,948 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:58,949 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:58,950 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:58,951 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:58,952 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:58,953 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:18:58,968 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:18:58,979 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:18:58,989 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:18:58,999 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:18:59,002 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:18:59,004 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:18:59,015 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:59,017 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:59,019 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:18:59,020 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:59,021 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:18:59,022 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:59,023 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:18:59,024 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:18:59,025 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:18:59,026 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:18:59,027 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:59,028 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:59,029 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:18:59,031 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:59,032 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:59,034 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 17]), 16)\n",
      "2023-10-04 09:18:59,035 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:59,036 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 17]), 16)\n",
      "2023-10-04 09:18:59,037 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:59,038 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:18:59,040 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:18:59,041 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:18:59,042 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:18:59,043 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:59,044 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:59,045 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:18:59,046 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:59,055 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:59,066 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,067 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,068 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,069 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,070 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:18:59,076 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:18:59,079 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:18:59,083 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:18:59,089 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,091 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,092 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:18:59,095 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:59,103 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:59,111 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,112 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,113 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,114 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,114 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:18:59,120 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:18:59,126 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:18:59,136 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:18:59,139 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,141 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,141 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:18:59,144 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:18:59,152 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:59,160 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,161 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,161 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,162 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,163 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:18:59,169 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:18:59,179 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:18:59,184 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:18:59,188 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,189 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,190 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:18:59,193 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:18:59,202 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:59,211 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,212 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,213 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,214 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,215 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:18:59,220 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:18:59,229 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:18:59,234 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:18:59,239 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,242 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,243 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:18:59,245 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:18:59,254 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:59,263 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,264 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,265 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,266 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,267 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:18:59,273 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:18:59,281 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:18:59,285 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:18:59,289 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,290 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,291 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:18:59,294 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:18:59,303 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:59,313 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,314 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,315 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,316 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,317 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:18:59,325 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:18:59,334 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:18:59,338 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:18:59,342 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,343 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,345 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:18:59,347 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:18:59,355 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:59,364 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,365 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,366 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,366 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,367 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:18:59,373 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:18:59,379 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:18:59,383 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:18:59,387 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,389 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,390 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:18:59,393 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:18:59,402 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:59,411 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,412 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,413 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,414 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,414 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:18:59,421 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:18:59,432 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:18:59,452 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:18:59,458 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,460 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,461 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:18:59,464 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:18:59,473 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:59,482 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,483 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,484 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,484 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,485 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:18:59,493 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:18:59,504 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:18:59,512 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:18:59,516 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,517 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,518 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:18:59,521 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:18:59,531 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:59,543 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,544 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,546 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,546 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,547 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:18:59,554 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:18:59,559 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:18:59,571 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:18:59,576 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,578 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,578 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:18:59,581 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:18:59,590 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:59,599 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,600 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,601 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,602 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,603 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:18:59,613 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:18:59,616 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:18:59,623 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:18:59,626 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,628 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,629 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:18:59,631 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:18:59,639 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:59,641 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,642 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,642 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,643 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,645 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:18:59,649 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:18:59,652 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:18:59,655 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:18:59,657 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,659 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:18:59,660 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:18:59,662 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:59,665 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:59,673 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,674 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:59,675 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,677 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:59,677 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:18:59,681 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:18:59,685 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:18:59,687 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:18:59,690 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:59,691 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:59,692 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:18:59,694 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:18:59,696 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:59,697 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,698 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:59,699 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,700 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:59,701 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:18:59,713 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:18:59,725 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:18:59,735 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:18:59,745 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:18:59,781 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:18:59,783 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:18:59,834 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:18:59,839 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:59,842 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:18:59,843 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:59,844 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:18:59,846 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:59,848 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:18:59,850 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:18:59,852 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:18:59,853 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:18:59,855 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:59,857 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:59,860 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:18:59,862 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:18:59,870 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:18:59,873 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 18]), 17)\n",
      "2023-10-04 09:18:59,875 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:18:59,877 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 18]), 17)\n",
      "2023-10-04 09:18:59,878 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:18:59,879 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:18:59,883 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:18:59,886 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:18:59,889 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:18:59,890 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:18:59,892 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:18:59,893 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:18:59,894 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:18:59,902 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:18:59,914 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:18:59,916 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,917 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:18:59,919 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:18:59,920 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:18:59,969 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:00,003 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:00,008 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:00,016 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,017 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,019 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:00,022 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:00,030 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:00,038 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:00,040 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,041 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:00,042 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,044 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:00,049 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:00,054 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:00,058 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:00,077 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,080 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,081 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:00,083 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:00,092 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:00,100 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:00,101 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,102 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:00,103 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,104 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:00,137 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:00,144 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:00,148 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:00,197 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,199 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,202 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:00,206 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:00,219 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:00,228 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:00,229 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,230 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:00,231 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,232 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:00,244 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:00,249 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:00,254 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:00,259 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,260 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,261 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:00,264 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:00,272 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:00,280 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:00,281 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,282 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:00,283 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,284 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:00,288 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:00,292 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:00,295 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:00,298 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,300 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,300 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:00,303 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:00,312 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:00,322 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:00,323 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,324 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:00,326 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,327 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:00,333 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:00,341 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:00,347 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:00,352 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,354 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,355 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:00,358 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:00,366 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:00,375 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:00,376 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,377 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:00,377 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,378 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:00,385 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:00,408 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:00,414 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:00,426 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,428 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,429 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:00,433 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:00,442 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:00,451 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:00,452 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,454 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:00,454 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,455 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:00,460 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:00,467 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:00,471 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:00,476 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,478 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,479 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:00,481 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:00,490 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:00,500 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:00,501 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,502 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:00,503 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,504 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:00,584 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:00,646 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:00,694 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:00,700 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,702 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,703 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:00,706 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:00,716 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:00,724 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:00,725 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,726 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:00,727 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,728 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:00,775 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:00,813 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:00,818 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:00,821 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,823 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,824 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:00,826 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:00,834 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:00,843 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:00,844 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,845 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:00,846 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,847 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:00,868 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:00,874 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:00,881 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:00,886 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,887 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,889 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:00,892 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:00,900 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:00,902 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:00,903 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,904 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:00,905 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:00,906 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:00,912 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:00,916 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:00,919 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:00,929 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,930 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:19:00,932 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:00,934 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:00,936 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:00,944 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:00,945 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:00,946 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:00,947 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:00,948 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:00,949 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:00,953 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:00,957 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:00,962 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:00,963 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:00,964 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:00,965 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:00,967 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:00,968 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:00,969 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:00,970 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:00,971 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:00,972 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:00,987 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:00,997 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:01,006 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:01,015 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:01,018 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:01,019 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:01,027 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:01,030 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:01,032 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:01,032 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:01,034 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:01,034 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:01,036 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:01,037 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:01,038 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:01,039 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:01,040 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:01,041 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:01,042 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:01,044 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:01,046 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:01,048 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 19]), 18)\n",
      "2023-10-04 09:19:01,049 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:01,050 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 19]), 18)\n",
      "2023-10-04 09:19:01,051 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:01,052 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:01,053 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:01,054 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:01,056 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:01,057 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:01,058 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:01,059 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:01,060 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:01,069 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:01,077 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,078 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,079 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,081 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,082 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:01,088 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:01,097 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:01,101 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:01,105 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,107 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,108 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:01,110 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:01,118 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:01,127 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,128 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,129 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,130 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,130 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:01,135 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:01,143 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:01,150 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:01,168 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,170 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,171 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:01,174 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:01,182 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:01,191 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,192 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,193 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,195 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,196 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:01,207 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:01,216 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:01,222 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:01,227 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,228 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,229 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:01,232 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:01,245 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:01,258 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,268 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,269 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,270 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,271 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:01,346 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:01,409 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:01,420 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:01,465 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,468 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,469 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:01,472 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:01,480 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:01,489 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,490 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,491 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,492 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,493 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:01,504 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:01,511 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:01,515 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:01,520 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,521 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,522 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:01,525 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:01,533 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:01,542 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,543 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,545 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,545 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,546 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:01,553 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:01,560 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:01,565 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:01,569 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,570 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,571 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:01,574 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:01,582 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:01,590 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,591 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,592 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,593 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,594 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:01,605 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:01,614 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:01,620 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:01,631 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,633 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,634 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:01,637 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:01,645 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:01,654 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,655 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,656 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,657 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,658 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:01,663 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:01,669 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:01,673 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:01,676 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,678 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,679 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:01,682 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:01,691 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:01,700 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,701 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,702 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,703 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,704 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:01,710 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:01,714 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:01,720 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:01,725 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,727 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,728 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:01,731 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:01,739 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:01,749 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,750 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,751 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,752 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,752 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:01,757 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:01,761 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:01,767 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:01,776 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,779 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,780 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:01,783 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:01,792 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:01,802 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,803 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,804 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,805 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,806 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:01,811 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:01,815 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:01,821 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:01,832 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,835 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,835 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:01,838 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:01,847 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:01,849 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,850 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,851 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,852 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:01,853 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:01,859 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:01,867 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:01,880 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:01,888 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,891 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:19:01,892 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:01,894 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:01,896 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:01,905 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,906 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:01,907 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,908 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:01,909 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:01,912 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:01,915 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:01,918 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:01,922 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:01,924 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:01,925 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:01,926 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:01,928 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:01,930 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:01,931 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:01,931 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:01,932 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:01,933 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:01,945 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:01,954 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:01,964 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:01,977 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:01,982 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:01,983 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:01,991 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:01,994 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:01,995 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:01,996 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:01,997 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:01,998 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:01,999 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:02,000 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:02,001 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:02,002 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:02,003 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:02,004 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:02,005 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:02,007 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:02,008 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:02,010 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 20]), 19)\n",
      "2023-10-04 09:19:02,011 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:02,011 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 20]), 19)\n",
      "2023-10-04 09:19:02,013 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:02,013 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:02,015 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:02,016 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:02,017 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:02,019 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:02,020 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:02,021 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:02,022 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:02,030 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:02,040 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,041 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,042 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,043 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,044 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:02,050 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:02,055 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:02,060 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:02,066 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,068 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,069 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:02,072 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:02,081 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:02,089 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,090 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,091 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,092 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,093 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:02,100 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:02,109 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:02,113 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:02,117 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,118 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,119 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:02,122 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:02,131 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:02,140 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,141 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,142 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,143 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,144 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:02,149 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:02,151 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:02,161 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:02,166 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,167 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,169 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:02,172 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:02,180 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:02,188 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,189 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,191 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,192 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,192 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:02,200 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:02,205 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:02,209 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:02,213 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,214 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,215 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:02,218 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:02,226 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:02,234 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,235 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,236 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,237 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,238 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:02,262 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:02,286 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:02,294 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:02,298 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,300 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,301 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:02,304 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:02,312 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:02,322 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,323 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,324 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,325 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,326 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:02,333 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:02,338 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:02,343 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:02,348 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,350 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,351 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:02,354 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:02,362 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:02,371 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,372 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,373 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,374 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,375 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:02,381 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:02,385 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:02,394 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:02,399 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,400 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,401 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:02,404 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:02,413 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:02,421 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,422 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,423 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,424 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,425 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:02,432 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:02,436 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:02,440 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:02,443 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,445 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,446 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:02,449 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:02,457 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:02,466 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,467 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,468 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,469 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,470 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:02,477 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:02,487 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:02,493 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:02,497 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,498 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,500 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:02,503 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:02,511 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:02,521 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,522 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,523 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,524 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,524 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:02,529 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:02,538 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:02,545 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:02,549 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,550 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,552 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:02,554 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:02,562 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:02,575 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,576 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,577 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,578 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,579 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:02,639 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:02,650 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:02,666 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:02,680 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,682 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,683 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:02,685 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:02,693 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:02,695 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,696 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,697 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,698 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,699 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:02,708 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:02,712 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:02,716 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:02,721 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,722 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:19:02,723 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:02,726 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:02,728 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:02,736 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,737 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:02,738 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,739 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:02,740 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:02,742 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:02,746 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:02,749 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:02,755 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:02,757 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:02,758 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:02,760 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:02,761 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:02,763 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,764 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:02,765 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,766 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:02,767 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:02,783 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:02,793 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:02,806 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:02,815 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:02,818 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:02,820 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:02,833 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:02,836 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:02,838 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:02,838 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:02,839 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:02,840 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:02,841 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:02,843 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:02,844 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:02,845 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:02,846 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:02,847 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:02,848 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:02,850 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:02,852 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:02,853 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 21]), 20)\n",
      "2023-10-04 09:19:02,854 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:02,855 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 21]), 20)\n",
      "2023-10-04 09:19:02,856 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:02,857 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:02,859 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:02,860 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:02,862 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:02,864 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:02,865 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:02,866 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:02,868 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:02,877 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:02,886 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,888 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,888 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,889 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,891 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:02,897 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:02,906 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:02,913 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:02,917 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:19:02,920 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:19:02,921 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:02,923 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:02,932 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:02,947 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:02,949 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,951 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:02,953 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:02,955 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:02,963 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:02,970 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:02,979 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:02,985 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:19:02,986 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:19:02,988 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:02,992 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:03,001 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:03,011 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,013 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,014 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,015 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,017 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:03,023 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:03,030 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:03,035 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:03,054 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,056 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,057 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:03,060 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:03,068 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:03,076 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,077 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,078 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,079 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,081 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:03,088 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:03,095 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:03,108 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:03,112 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,113 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,114 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:03,117 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:03,125 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:03,134 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,139 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,140 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,141 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,142 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:03,191 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:03,198 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:03,202 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:03,206 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,207 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,209 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:03,211 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:03,220 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:03,232 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,234 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,235 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,236 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,236 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:03,242 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:03,248 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:03,252 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:03,256 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,257 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,258 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:03,261 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:03,269 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:03,278 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,279 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,280 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,281 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,282 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:03,290 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:03,297 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:03,305 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:03,310 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,312 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,313 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:03,317 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:03,326 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:03,335 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,336 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,337 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,338 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,339 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:03,351 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:03,355 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:03,360 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:03,364 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,366 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,367 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:03,369 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:03,377 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:03,386 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,387 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,388 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,389 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,390 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:03,395 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:03,400 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:03,405 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:03,409 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,410 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,411 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:03,414 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:03,422 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:03,431 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,432 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,433 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,434 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,435 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:03,441 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:03,446 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:03,450 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:03,453 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,455 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,456 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:03,458 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:03,467 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:03,476 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,477 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,478 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,479 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,480 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:03,485 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:03,488 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:03,492 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:03,496 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,498 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,498 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:03,501 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:03,509 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:03,511 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,512 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,513 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,513 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,514 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:03,520 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:03,527 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:03,530 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:03,537 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,540 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:19:03,541 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:03,543 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:03,545 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:03,554 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,555 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:03,556 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,557 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:03,558 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:03,562 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:03,564 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:03,568 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:03,572 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:03,574 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:03,575 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:03,577 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:03,578 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:03,580 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,581 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:03,582 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,583 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:03,584 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:03,600 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:03,609 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:03,619 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:03,630 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:03,634 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:03,635 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:03,643 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:03,646 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:03,647 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:03,648 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:03,649 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:03,650 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:03,651 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:03,652 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:03,653 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:03,654 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:03,655 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:03,656 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:03,657 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:03,659 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:03,660 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:03,662 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 22]), 21)\n",
      "2023-10-04 09:19:03,663 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:03,664 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 22]), 21)\n",
      "2023-10-04 09:19:03,665 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:03,666 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:03,668 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:03,669 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:03,670 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:03,682 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:03,694 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:03,695 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:03,697 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:03,706 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:03,717 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,719 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,720 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,721 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,722 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:03,736 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:03,742 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:03,745 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:03,749 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:19:03,751 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:19:03,752 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:03,755 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:03,763 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:03,772 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,773 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,775 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,776 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,776 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:03,782 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:03,791 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:03,795 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:03,800 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:19:03,802 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:19:03,803 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:03,806 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:03,814 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:03,822 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,823 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,825 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,826 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,827 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:03,834 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:03,840 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:03,845 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:03,848 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:19:03,850 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:19:03,851 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:03,854 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:03,862 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:03,870 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,871 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,873 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,874 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,875 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:03,884 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:03,891 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:03,900 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:03,905 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:19:03,907 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:19:03,907 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:03,910 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:03,919 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:03,928 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,929 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,930 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,931 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,931 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:03,937 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:03,940 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:03,947 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:03,955 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:19:03,957 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:19:03,958 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:03,961 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:03,969 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:03,978 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:03,980 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,981 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:03,983 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:03,983 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:03,991 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:03,997 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:04,001 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:04,005 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,008 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,009 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:04,012 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:04,021 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:04,032 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,043 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,044 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,045 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,047 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:04,088 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:04,128 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:04,133 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:04,138 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,152 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,154 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:04,157 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:04,166 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:04,175 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,176 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,177 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,178 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,179 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:04,186 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:04,190 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:04,194 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:04,200 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,203 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,203 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:04,206 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:04,215 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:04,224 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,225 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,226 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,227 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,228 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:04,235 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:04,244 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:04,250 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:04,255 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,258 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,259 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:04,262 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:04,269 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:04,277 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,278 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,279 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,280 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,281 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:04,287 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:04,292 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:04,299 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:04,305 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,308 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,308 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:04,311 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:04,319 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:04,328 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,330 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,331 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,331 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,333 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:04,339 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:04,348 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:04,352 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:04,356 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,359 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,359 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:04,362 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:04,370 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:04,372 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,373 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,374 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,376 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,377 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:04,384 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:04,389 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:04,394 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:04,399 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,401 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:19:04,401 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:04,404 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:04,406 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:04,414 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,415 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:04,416 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,417 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:04,418 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:04,420 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:04,423 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:04,426 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:04,430 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:04,431 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:04,433 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:04,435 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:04,437 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:04,438 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,439 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:04,440 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,441 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:04,441 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:04,453 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:04,464 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:04,478 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:04,490 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:04,493 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:04,495 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:04,504 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:04,506 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:04,508 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:04,508 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:04,509 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:04,510 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:04,511 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:04,513 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:04,514 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:04,515 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:04,516 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:04,517 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:04,518 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:04,520 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:04,521 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:04,524 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 23]), 22)\n",
      "2023-10-04 09:19:04,525 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:04,526 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 23]), 22)\n",
      "2023-10-04 09:19:04,527 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:04,528 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:04,530 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:04,531 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:04,532 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:04,547 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:04,548 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:04,550 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:04,552 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:04,566 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:04,577 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,579 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,579 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,581 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,582 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:04,617 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:04,679 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:04,708 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:04,716 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:19:04,720 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:19:04,721 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:04,726 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:04,738 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:04,751 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,752 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,754 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,755 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,756 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:04,765 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:04,771 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:04,776 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:04,781 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:19:04,784 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:19:04,785 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:04,788 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:04,796 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:04,805 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,806 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,807 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,808 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,809 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:04,817 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:04,822 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:04,826 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:04,830 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:19:04,832 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:19:04,833 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:04,836 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:04,845 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:04,853 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,854 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,855 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,856 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,858 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:04,862 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:04,867 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:04,876 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:04,887 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:19:04,890 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:19:04,891 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:04,894 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:04,902 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:04,911 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,912 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,913 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,914 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,915 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:04,921 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:04,927 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:04,931 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:04,936 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:19:04,938 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:19:04,938 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:04,942 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:04,949 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:04,957 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:04,959 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,960 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:04,960 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:04,961 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:04,974 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:04,978 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:05,003 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:05,010 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,012 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,014 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:05,017 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:05,030 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:05,044 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,046 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,047 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,048 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,049 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:05,054 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:05,070 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:05,143 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:05,171 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,196 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,198 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:05,201 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:05,209 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:05,218 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,219 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,220 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,220 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,221 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:05,231 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:05,236 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:05,239 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:05,242 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,244 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,245 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:05,248 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:05,256 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:05,265 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,267 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,268 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,269 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,270 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:05,334 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:05,339 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:05,342 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:05,346 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,347 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,348 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:05,351 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:05,359 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:05,368 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,369 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,370 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,372 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,372 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:05,381 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:05,384 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:05,387 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:05,390 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,439 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,441 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:05,445 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:05,453 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:05,462 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,463 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,464 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,465 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,466 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:05,480 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:05,485 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:05,489 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:05,493 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,495 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,496 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:05,498 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:05,506 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:05,508 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,509 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,510 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,511 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,512 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:05,518 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:05,522 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:05,526 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:05,530 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,533 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:19:05,533 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:05,536 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:05,539 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:05,547 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,548 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:05,550 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,551 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:05,552 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:05,554 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:05,558 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:05,563 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:05,567 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:05,568 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:05,569 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:05,570 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:05,573 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:05,575 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,576 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:05,577 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,578 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:05,579 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:05,589 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:05,601 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:05,611 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:05,620 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:05,627 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:05,630 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:05,639 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:05,642 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:05,643 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:05,644 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:05,645 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:05,646 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:05,647 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:05,648 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:05,649 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:05,650 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:05,652 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:05,653 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:05,653 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:05,655 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:05,657 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:05,659 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 24]), 23)\n",
      "2023-10-04 09:19:05,660 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:05,660 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 24]), 23)\n",
      "2023-10-04 09:19:05,661 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:05,662 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:05,664 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:05,665 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:05,666 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:05,667 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:05,668 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:05,669 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:05,670 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:05,678 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:05,686 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,687 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,688 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,689 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,689 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:05,698 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:05,707 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:05,710 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:05,718 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:19:05,720 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:19:05,721 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:05,724 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:05,732 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:05,741 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,742 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,742 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,744 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,744 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:05,749 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:05,752 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:05,756 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:05,763 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:19:05,765 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:19:05,766 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:05,770 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:05,778 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:05,786 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,787 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,788 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,789 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,790 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:05,796 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:05,808 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:05,824 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:05,833 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:19:05,835 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:19:05,837 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:05,840 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:05,849 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:05,858 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,860 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,860 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,862 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,863 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:05,870 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:05,874 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:05,878 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:05,901 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:19:05,905 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:19:05,906 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:05,908 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:05,917 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:05,926 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,927 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,927 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,928 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,929 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:05,937 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:05,942 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:05,948 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:05,952 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:19:05,954 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:19:05,955 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:05,959 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:05,968 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:05,976 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:05,977 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,978 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:05,979 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:05,980 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:05,992 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:06,000 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:06,009 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:06,028 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,031 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,032 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:06,035 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:06,043 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:06,052 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:06,053 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,054 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:06,054 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,056 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:06,060 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:06,064 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:06,067 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:06,072 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,076 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,077 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:06,079 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:06,087 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:06,095 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:06,096 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,097 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:06,099 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,100 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:06,108 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:06,115 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:06,120 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:06,124 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,126 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,126 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:06,130 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:06,138 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:06,147 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:06,148 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,149 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:06,150 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,150 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:06,158 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:06,162 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:06,165 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:06,169 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,171 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,172 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:06,175 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:06,184 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:06,193 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:06,194 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,195 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:06,196 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,197 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:06,205 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:06,216 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:06,221 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:06,225 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,227 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,228 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:06,230 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:06,238 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:06,247 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:06,251 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,252 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:06,253 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,254 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:06,306 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:06,350 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:06,356 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:06,359 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,365 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,367 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:06,369 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:06,377 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:06,379 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:06,380 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,381 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:06,382 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,384 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:06,388 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:06,391 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:06,394 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:06,397 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,453 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:19:06,455 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:06,457 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:06,460 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:06,468 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:06,469 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:06,470 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:06,471 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:06,471 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:06,474 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:06,479 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:06,482 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:06,488 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:06,489 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:06,490 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:06,492 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:06,493 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:06,495 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:06,495 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:06,496 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:06,497 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:06,497 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:06,507 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:06,516 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:06,527 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:06,536 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:06,538 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:06,539 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:06,547 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:06,552 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:06,556 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:06,558 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:06,561 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:06,563 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:06,565 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:06,567 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:06,569 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:06,571 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:06,572 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:06,574 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:06,575 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:06,577 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:06,580 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:06,583 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 25]), 24)\n",
      "2023-10-04 09:19:06,584 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:06,585 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 25]), 24)\n",
      "2023-10-04 09:19:06,586 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:06,587 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:06,588 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:06,589 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:06,590 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:06,591 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:06,592 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:06,592 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:06,593 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:06,601 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:06,611 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:06,612 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,613 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:06,614 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,615 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:06,620 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:06,623 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:06,632 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:06,661 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:19:06,664 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:19:06,665 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:06,668 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:06,675 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:06,684 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:06,685 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,686 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:06,687 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,688 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:06,698 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:06,710 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:06,715 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:06,720 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:19:06,722 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:19:06,724 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:06,727 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:06,740 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:06,753 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:06,754 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,755 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:06,756 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,757 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:06,766 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:06,770 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:06,774 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:06,778 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:19:06,780 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:19:06,781 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:06,784 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:06,792 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:06,801 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:06,802 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,803 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:06,803 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,804 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:06,811 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:06,816 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:06,820 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:06,824 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:19:06,826 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:19:06,827 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:06,830 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:06,839 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:06,848 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:06,849 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,850 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:06,851 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:06,852 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:06,909 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:06,961 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:06,994 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:07,002 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,005 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,006 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:07,009 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:07,018 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:07,027 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,028 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,029 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,030 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,030 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:07,042 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:07,045 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:07,060 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:07,064 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,065 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,066 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:07,069 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:07,076 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:07,085 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,086 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,087 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,087 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,088 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:07,098 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:07,102 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:07,108 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:07,114 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,116 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,117 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:07,120 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:07,128 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:07,137 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,138 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,139 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,140 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,141 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:07,156 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:07,160 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:07,163 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:07,178 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,182 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,183 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:07,186 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:07,194 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:07,203 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,204 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,205 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,206 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,207 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:07,211 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:07,215 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:07,222 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:07,226 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,228 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,229 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:07,232 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:07,240 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:07,249 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,249 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,250 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,251 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,252 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:07,258 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:07,262 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:07,265 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:07,269 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,271 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,271 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:07,274 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:07,282 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:07,291 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,292 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,293 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,294 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,295 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:07,314 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:07,320 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:07,324 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:07,328 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,330 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,331 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:07,333 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:07,341 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:07,343 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,344 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,345 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,346 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,347 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:07,357 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:07,361 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:07,366 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:07,370 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,372 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:19:07,373 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:07,376 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:07,378 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:07,387 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,388 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:07,389 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,390 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:07,392 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:07,393 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:07,396 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:07,401 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:07,406 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:07,408 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:07,409 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:07,411 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:07,413 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:07,414 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,415 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:07,416 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,417 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:07,418 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:07,432 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:07,443 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:07,454 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:07,465 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:07,478 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:07,479 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:07,489 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:07,491 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:07,492 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:07,493 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:07,494 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:07,495 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:07,496 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:07,497 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:07,498 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:07,499 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:07,500 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:07,501 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:07,502 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:07,503 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:07,505 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:07,507 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 26]), 25)\n",
      "2023-10-04 09:19:07,508 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:07,509 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 26]), 25)\n",
      "2023-10-04 09:19:07,510 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:07,511 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:07,512 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:07,514 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:07,515 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:07,516 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:07,517 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:07,518 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:07,520 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:07,528 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:07,537 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,538 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,539 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,540 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,541 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:07,547 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:07,557 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:07,562 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:07,567 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,569 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,570 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:07,573 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:07,581 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:07,591 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,592 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,593 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,594 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,595 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:07,601 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:07,610 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:07,632 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:07,637 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,639 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,641 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:07,643 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:07,651 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:07,660 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,661 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,662 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,663 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,664 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:07,670 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:07,674 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:07,677 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:07,686 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,688 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,689 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:07,691 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:07,700 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:07,709 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,710 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,711 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,712 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,712 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:07,719 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:07,722 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:07,726 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:07,744 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,746 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,748 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:07,750 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:07,759 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:07,769 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,770 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,771 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,773 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,773 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:07,779 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:07,785 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:07,790 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:07,797 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,799 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,801 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:07,804 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:07,812 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:07,820 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,821 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,822 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,823 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,824 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:07,829 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:07,833 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:07,844 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:07,849 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,852 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,853 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:07,855 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:07,863 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:07,872 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,873 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,874 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,874 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,875 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:07,882 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:07,887 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:07,892 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:07,896 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,898 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,899 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:07,902 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:07,910 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:07,919 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:07,920 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,921 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:07,923 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:07,924 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:07,930 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:07,948 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:07,977 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:07,983 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,985 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:19:07,986 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:07,988 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:07,996 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:08,005 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,006 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,007 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,008 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,009 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:08,036 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:08,041 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:08,048 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:08,051 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:19:08,053 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:19:08,054 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:08,057 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:08,065 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:08,074 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,075 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,076 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,078 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,079 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:08,086 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:08,090 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:08,097 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:08,104 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:19:08,109 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:19:08,110 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:08,112 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:08,121 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:08,130 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,131 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,131 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,133 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,134 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:08,140 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:08,144 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:08,149 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:08,152 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:19:08,155 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:19:08,157 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:08,160 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:08,168 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:08,169 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,170 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,172 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,172 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,173 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:08,180 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:08,185 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:08,193 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:08,198 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:19:08,201 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:19:08,202 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:08,205 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:08,208 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:08,216 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,217 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:08,219 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,220 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:08,221 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:08,224 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:08,228 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:08,231 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:08,235 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:08,236 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:08,237 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:08,239 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:08,241 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:08,243 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,244 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:08,245 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,246 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:08,247 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:08,260 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:08,271 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:08,280 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:08,290 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:08,297 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:08,299 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:08,307 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:08,309 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:08,311 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:08,312 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:08,313 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:08,314 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:08,315 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:08,316 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:08,317 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:08,319 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:08,320 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:08,321 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:08,322 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:08,323 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:08,325 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:08,327 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 27]), 26)\n",
      "2023-10-04 09:19:08,328 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:08,329 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 27]), 26)\n",
      "2023-10-04 09:19:08,330 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:08,330 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:08,332 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:08,333 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:08,334 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:08,336 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:08,336 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:08,337 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:08,338 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:08,347 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:08,355 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,356 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,357 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,358 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,359 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:08,365 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:08,372 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:08,380 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:08,388 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,390 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,391 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:08,394 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:08,402 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:08,411 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,412 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,413 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,414 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,414 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:08,423 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:08,433 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:08,441 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:08,509 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,538 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,539 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:08,544 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:08,552 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:08,561 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,562 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,563 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,564 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,565 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:08,571 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:08,577 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:08,580 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:08,584 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,586 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,587 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:08,590 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:08,598 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:08,621 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,625 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,628 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,629 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,630 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:08,687 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:08,696 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:08,704 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:08,709 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,711 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,712 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:08,715 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:08,724 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:08,733 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,734 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,735 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,736 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,737 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:08,741 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:08,745 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:08,748 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:08,795 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,803 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,805 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:08,815 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:08,824 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:08,832 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,834 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,835 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,836 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,836 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:08,847 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:08,851 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:08,853 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:08,857 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,859 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,859 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:08,862 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:08,870 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:08,878 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,879 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,881 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,882 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,882 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:08,890 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:08,893 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:08,897 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:08,900 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,902 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,903 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:08,906 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:08,917 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:08,927 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:08,928 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,929 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:08,930 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:08,931 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:08,937 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:08,946 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:08,953 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:08,966 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,970 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:19:08,971 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:08,978 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:08,993 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:09,004 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,005 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,006 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,007 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,008 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:09,013 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:09,023 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:09,034 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:09,041 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:19:09,044 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:19:09,045 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:09,048 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:09,056 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:09,071 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,072 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,073 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,074 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,075 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:09,131 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:09,147 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:09,152 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:09,158 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:19:09,160 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:19:09,161 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:09,164 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:09,173 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:09,182 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,183 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,184 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,185 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,186 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:09,194 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:09,206 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:09,212 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:09,217 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:19:09,221 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:19:09,222 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:09,225 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:09,233 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:09,235 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,237 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,238 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,239 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,240 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:09,248 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:09,253 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:09,261 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:09,267 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:19:09,270 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:19:09,272 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:09,274 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:09,277 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:09,285 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,286 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:09,286 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,287 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:09,288 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:09,291 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:09,294 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:09,297 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:09,299 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:09,300 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:09,301 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:09,303 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:09,304 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:09,306 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,307 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:09,309 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,310 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:09,311 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:09,325 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:09,337 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:09,349 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:09,361 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:09,364 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:09,365 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:09,373 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:09,375 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:09,377 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:09,378 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:09,379 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:09,380 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:09,381 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:09,382 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:09,383 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:09,384 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:09,386 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:09,387 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:09,387 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:09,389 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:09,390 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:09,392 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 28]), 27)\n",
      "2023-10-04 09:19:09,393 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:09,394 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 28]), 27)\n",
      "2023-10-04 09:19:09,395 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:09,396 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:09,399 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:09,401 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:09,402 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:09,404 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:09,405 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:09,406 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:09,408 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:09,418 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:09,427 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,428 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,429 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,430 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,430 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:09,441 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:09,447 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:09,452 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:09,456 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,466 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,467 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:09,470 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:09,478 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:09,487 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,488 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,489 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,490 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,491 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:09,503 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:09,508 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:09,513 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:09,519 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,521 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,522 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:09,525 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:09,534 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:09,543 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,544 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,545 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,546 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,547 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:09,555 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:09,569 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:09,589 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:09,595 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,605 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,606 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:09,609 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:09,617 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:09,626 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,628 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,629 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,630 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,631 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:09,640 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:09,660 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:09,676 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:09,682 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,686 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,687 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:09,690 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:09,698 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:09,707 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,708 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,709 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,710 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,711 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:09,717 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:09,724 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:09,732 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:09,739 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,742 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,743 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:09,747 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:09,755 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:09,764 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,765 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,766 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,768 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,769 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:09,782 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:09,787 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:09,799 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:09,804 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,806 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,806 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:09,809 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:09,817 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:09,826 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,827 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,828 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,829 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,830 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:09,837 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:09,844 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:09,851 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:09,857 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,861 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,862 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:09,865 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:09,873 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:09,888 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,890 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,891 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,892 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,893 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:09,902 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:09,910 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:09,919 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:09,927 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,933 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:19:09,936 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:09,939 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:09,952 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:09,962 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:09,963 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,964 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:09,965 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:09,966 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:09,974 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:09,979 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:09,985 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:09,991 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:19:10,070 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:19:10,074 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:10,079 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:10,088 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:10,101 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:10,102 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,104 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:10,105 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,106 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:10,117 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:10,121 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:10,126 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:10,133 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:19:10,136 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:19:10,136 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:10,139 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:10,147 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:10,156 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:10,157 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,158 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:10,159 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,160 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:10,172 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:10,180 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:10,186 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:10,198 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:19:10,201 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:19:10,202 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:10,205 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:10,213 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:10,214 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:10,215 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,222 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:10,223 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,224 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:10,268 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:10,274 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:10,306 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:10,310 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:19:10,312 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:19:10,313 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:10,315 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:10,317 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:10,325 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:10,327 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:10,328 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:10,329 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:10,330 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:10,331 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:10,333 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:10,334 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:10,335 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:10,336 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:10,337 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:10,338 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:10,340 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:10,342 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:10,343 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:10,344 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:10,344 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:10,345 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:10,362 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:10,376 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:10,388 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:10,400 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:10,402 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:10,404 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:10,414 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:10,416 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:10,417 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:10,418 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:10,419 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:10,420 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:10,421 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:10,422 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:10,423 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:10,424 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:10,425 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:10,426 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:10,427 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:10,429 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:10,430 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:10,432 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 29]), 28)\n",
      "2023-10-04 09:19:10,433 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:10,435 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 29]), 28)\n",
      "2023-10-04 09:19:10,436 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:10,437 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:10,439 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:10,440 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:10,441 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:10,443 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:10,443 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:10,445 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:10,446 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:10,454 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:10,462 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:10,463 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,464 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:10,465 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,466 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:10,475 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:10,482 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:10,486 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:10,493 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,495 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,496 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:10,499 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:10,511 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:10,524 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:10,526 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,527 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:10,528 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,529 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:10,537 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:10,550 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:10,557 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:10,564 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,574 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,575 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:10,578 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:10,586 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:10,594 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:10,595 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,596 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:10,598 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,600 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:10,674 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:10,680 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:10,686 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:10,690 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,692 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,693 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:10,695 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:10,704 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:10,712 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:10,713 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,714 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:10,715 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,716 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:10,721 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:10,725 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:10,735 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:10,739 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,741 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,742 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:10,745 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:10,752 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:10,761 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:10,763 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,764 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:10,764 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,765 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:10,775 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:10,779 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:10,784 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:10,788 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,801 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,802 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:10,805 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:10,813 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:10,821 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:10,822 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,823 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:10,824 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,825 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:10,833 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:10,838 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:10,851 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:10,856 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,870 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,871 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:10,874 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:10,882 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:10,891 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:10,892 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,893 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:10,894 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,898 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:10,935 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:10,938 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:10,945 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:10,954 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,973 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:19:10,975 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:10,978 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:10,986 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:10,996 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:10,997 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:10,998 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:10,999 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,000 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:11,006 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:11,011 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:11,016 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:11,021 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:19:11,023 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:19:11,024 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:11,026 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:11,035 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:11,044 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,045 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,046 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,047 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,048 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:11,114 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:11,132 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:11,135 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:11,141 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:19:11,143 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:19:11,144 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:11,147 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:11,155 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:11,163 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,164 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,165 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,166 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,167 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:11,171 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:11,177 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:11,190 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:11,196 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:19:11,201 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:19:11,203 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:11,206 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:11,218 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:11,232 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,233 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,234 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,235 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,237 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:11,247 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:11,253 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:11,259 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:11,263 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:19:11,267 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:19:11,268 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:11,272 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:11,280 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:11,283 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,284 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,285 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,286 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,287 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:11,342 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:11,347 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:11,368 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:11,372 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:19:11,384 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:19:11,386 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:11,388 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:11,390 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:11,398 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,399 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:11,400 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,401 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:11,402 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:11,406 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:11,409 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:11,413 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:11,414 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:11,415 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:11,417 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:11,419 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:11,420 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:11,422 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,423 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:11,424 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,425 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:11,431 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:11,464 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:11,484 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:11,500 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:11,514 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:11,517 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:11,518 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:11,529 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:11,531 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:11,532 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:11,533 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:11,534 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:11,535 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:11,536 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:11,537 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:11,538 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:11,539 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:11,540 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:11,542 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:11,542 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:11,545 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:11,546 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:11,549 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 30]), 29)\n",
      "2023-10-04 09:19:11,550 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:11,550 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 30]), 29)\n",
      "2023-10-04 09:19:11,552 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:11,553 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:11,555 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:11,556 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:11,557 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:11,558 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:11,559 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:11,560 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:11,562 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:11,570 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:11,578 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,579 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,580 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,581 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,582 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:11,589 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:11,600 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:11,606 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:11,611 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,616 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,617 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:11,621 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:11,629 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:11,638 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,639 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,640 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,641 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,642 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:11,650 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:11,654 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:11,658 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:11,662 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,664 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,665 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:11,668 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:11,676 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:11,684 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,685 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,686 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,687 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,688 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:11,695 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:11,703 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:11,707 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:11,711 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,713 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,714 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:11,717 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:11,725 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:11,733 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,734 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,735 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,736 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,736 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:11,762 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:11,767 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:11,771 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:11,776 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,778 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,779 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:11,782 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:11,789 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:11,798 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,799 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,800 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,801 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,802 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:11,808 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:11,812 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:11,815 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:11,819 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,821 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,823 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:11,825 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:11,834 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:11,842 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,843 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,844 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,845 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,846 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:11,852 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:11,856 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:11,860 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:11,864 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,875 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,877 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:11,879 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:11,888 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:11,900 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,902 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,902 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,903 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,904 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:11,911 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:11,923 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:11,927 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:11,950 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,952 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:19:11,953 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:11,956 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:11,965 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:11,973 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:11,974 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,975 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:11,976 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:11,977 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:11,984 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:11,987 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:11,990 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:11,993 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:19:12,024 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:19:12,025 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:12,028 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:12,036 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:12,046 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,047 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,049 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,050 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,051 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:12,079 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:12,083 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:12,086 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:12,089 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:19:12,091 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:19:12,092 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:12,094 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:12,102 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:12,111 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,112 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,113 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,114 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,115 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:12,121 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:12,125 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:12,129 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:12,135 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:19:12,138 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:19:12,140 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:12,143 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:12,150 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:12,159 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,160 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,161 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,163 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,163 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:12,172 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:12,177 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:12,181 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:12,192 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:19:12,195 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:19:12,196 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:12,198 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:12,206 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:12,208 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,209 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,210 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,210 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,211 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:12,220 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:12,224 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:12,262 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:12,319 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:19:12,331 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:19:12,333 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:12,336 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:12,339 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:12,347 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,348 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:12,349 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,350 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:12,352 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:12,358 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:12,365 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:12,371 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:12,378 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:12,382 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:12,384 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:12,386 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:12,388 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:12,391 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,392 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:12,393 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,395 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:12,396 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:12,417 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:12,433 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:12,446 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:12,458 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:12,460 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:12,461 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:12,470 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:12,472 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:12,473 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:12,474 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:12,475 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:12,476 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:12,477 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:12,478 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:12,479 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:12,480 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:12,481 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:12,482 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:12,483 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:12,484 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:12,486 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:12,487 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 31]), 30)\n",
      "2023-10-04 09:19:12,488 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:12,489 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 31]), 30)\n",
      "2023-10-04 09:19:12,490 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:12,491 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:12,492 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:12,493 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:12,495 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:12,496 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:12,497 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:12,498 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:12,500 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:12,508 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:12,516 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,517 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,519 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,520 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,521 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:12,528 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:12,534 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:12,543 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:12,547 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,549 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,551 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:12,554 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:12,563 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:12,572 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,573 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,575 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,576 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,577 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:12,582 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:12,587 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:12,592 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:12,596 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,599 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,600 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:12,603 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:12,611 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:12,620 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,621 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,622 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,623 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,624 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:12,640 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:12,647 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:12,652 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:12,657 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,663 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,664 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:12,667 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:12,676 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:12,685 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,686 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,687 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,688 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,689 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:12,696 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:12,699 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:12,712 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:12,717 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,719 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,720 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:12,723 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:12,731 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:12,740 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,741 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,742 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,743 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,743 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:12,748 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:12,752 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:12,755 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:12,759 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,760 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,761 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:12,764 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:12,772 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:12,781 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,782 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,783 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,784 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,785 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:12,804 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:12,809 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:12,812 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:12,833 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,836 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,837 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:12,839 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:12,847 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:12,855 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,856 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,857 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,858 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,859 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:12,865 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:12,871 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:12,875 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:12,881 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,886 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:19:12,888 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:12,892 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:12,902 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:12,914 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:12,915 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,916 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:12,917 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:12,918 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:12,922 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:12,929 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:12,969 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:13,033 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:19:13,036 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:19:13,038 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:13,040 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:13,048 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:13,056 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:13,057 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,058 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:13,060 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,061 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:13,071 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:13,077 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:13,082 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:13,087 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:19:13,090 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:19:13,091 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:13,094 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:13,103 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:13,112 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:13,113 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,114 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:13,115 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,116 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:13,195 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:13,201 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:13,205 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:13,216 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:19:13,219 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:19:13,220 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:13,222 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:13,230 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:13,239 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:13,240 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,242 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:13,243 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,244 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:13,253 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:13,257 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:13,262 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:13,266 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:19:13,268 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:19:13,269 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:13,272 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:13,280 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:13,282 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:13,283 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,284 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:13,285 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,286 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:13,294 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:13,299 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:13,304 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:13,308 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:19:13,318 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:19:13,320 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:13,323 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:13,326 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:13,334 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:13,335 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:13,336 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:13,337 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:13,338 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:13,343 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:13,346 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:13,350 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:13,354 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:13,356 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:13,357 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:13,359 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:13,361 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:13,363 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:13,363 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:13,365 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:13,365 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:13,366 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:13,382 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:13,395 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:13,407 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:13,419 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:13,421 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:13,422 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:13,431 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:13,434 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:13,436 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:13,436 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:13,437 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:13,438 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:13,439 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:13,440 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:13,441 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:13,442 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:13,443 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:13,445 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:13,446 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:13,448 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:13,450 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:13,452 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 32]), 31)\n",
      "2023-10-04 09:19:13,453 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:13,454 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 32]), 31)\n",
      "2023-10-04 09:19:13,455 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:13,456 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:13,458 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:13,459 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:13,461 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:13,462 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:13,463 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:13,464 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:13,466 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:13,479 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:13,493 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:13,494 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,495 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:13,496 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,497 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:13,526 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:13,529 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:13,533 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:13,544 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:19:13,551 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:19:13,553 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:13,556 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:13,565 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:13,573 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:13,575 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,576 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:13,577 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,578 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:13,586 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:13,589 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:13,600 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:13,610 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:19:13,613 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:19:13,614 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:13,617 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:13,625 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:13,633 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:13,635 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,636 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:13,637 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,637 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:13,645 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:13,648 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:13,651 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:13,684 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:19:13,721 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:19:13,722 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:13,725 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:13,733 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:13,741 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:13,743 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,744 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:13,745 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,746 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:13,752 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:13,755 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:13,758 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:13,763 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:19:13,766 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:19:13,767 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:13,770 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:13,778 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:13,787 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:13,788 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,789 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:13,790 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,791 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:13,802 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:13,806 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:13,810 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:13,814 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:19:13,822 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:19:13,823 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:13,826 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:13,834 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:13,843 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:13,850 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,851 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:13,852 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,853 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:13,919 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:13,939 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:13,945 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:13,949 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:19:13,952 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:19:13,953 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:13,956 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:13,964 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:13,972 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:13,973 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,974 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:13,975 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:13,976 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:13,983 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:13,997 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:14,016 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:14,021 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:19:14,025 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:19:14,026 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:14,028 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:14,037 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:14,045 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,046 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,047 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,048 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,049 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:14,059 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:14,064 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:14,068 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:14,072 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:19:14,074 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:19:14,075 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:14,078 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:14,086 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:14,095 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,096 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,097 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,098 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,099 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:14,105 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:14,111 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:14,114 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:14,117 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:19:14,118 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:19:14,119 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:14,122 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:14,131 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:14,141 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,142 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,143 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,144 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,145 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:14,150 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:14,157 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:14,161 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:14,164 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:19:14,192 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:19:14,194 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:14,197 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:14,205 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:14,215 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,217 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,218 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,220 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,221 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:14,245 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:14,258 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:14,278 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:14,283 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:19:14,285 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:19:14,286 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:14,289 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:14,297 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:14,299 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,300 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,301 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,302 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,303 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:14,309 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:14,320 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:14,324 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:14,328 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:19:14,330 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:19:14,331 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:14,333 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:14,335 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:14,344 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,345 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:14,349 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,350 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:14,352 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:14,354 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:14,358 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:14,359 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:14,360 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:14,362 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:14,363 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:14,364 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:14,366 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:14,368 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,369 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:14,370 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,370 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:14,371 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:14,385 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:14,395 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:14,403 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:14,411 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:14,414 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:14,414 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:14,422 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:14,424 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:14,425 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:14,426 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:14,427 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:14,428 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:14,429 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:14,430 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:14,431 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:14,432 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:14,433 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:14,434 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:14,435 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:14,436 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:14,437 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:14,439 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 33]), 32)\n",
      "2023-10-04 09:19:14,440 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:14,441 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 33]), 32)\n",
      "2023-10-04 09:19:14,442 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:14,443 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:14,444 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:14,445 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:14,446 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:14,448 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:14,448 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:14,449 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:14,451 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:14,461 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:14,475 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,476 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,477 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,478 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,479 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:14,484 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:14,489 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:14,515 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:14,556 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,561 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,562 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:14,565 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:14,574 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:14,582 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,583 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,584 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,585 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,586 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:14,596 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:14,601 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:14,615 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:14,624 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,627 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,628 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:14,630 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:14,639 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:14,647 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,648 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,649 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,650 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,651 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:14,657 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:14,660 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:14,664 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:14,667 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,669 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,670 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:14,673 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:14,682 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:14,691 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,692 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,692 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,694 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,695 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:14,701 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:14,706 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:14,711 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:14,716 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,718 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,719 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:14,722 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:14,730 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:14,740 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,741 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,742 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,742 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,743 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:14,749 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:14,753 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:14,758 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:14,771 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,794 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,796 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:14,798 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:14,813 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:14,821 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,823 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,824 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,825 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,826 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:14,884 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:14,889 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:14,893 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:14,898 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,902 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,904 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:14,907 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:14,915 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:14,924 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,925 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,926 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,927 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,928 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:14,936 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:14,940 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:14,944 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:14,947 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,949 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,950 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:14,953 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:14,960 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:14,968 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:14,969 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,969 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:14,970 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:14,971 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:14,976 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:14,980 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:14,984 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:14,987 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,989 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:19:14,990 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:14,992 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:15,001 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:15,010 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,011 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,012 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,013 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,014 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:15,023 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:15,030 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:15,034 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:15,038 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:19:15,040 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:19:15,041 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:15,044 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:15,051 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:15,059 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,060 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,061 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,062 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,063 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:15,072 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:15,076 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:15,080 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:15,107 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:19:15,109 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:19:15,111 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:15,113 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:15,121 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:15,130 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,131 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,132 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,133 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,134 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:15,141 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:15,156 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:15,161 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:15,165 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:19:15,169 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:19:15,170 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:15,175 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:15,184 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:15,186 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,186 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,187 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,188 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,189 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:15,198 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:15,206 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:15,210 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:15,213 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:19:15,221 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:19:15,222 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:15,225 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:15,227 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:15,235 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,236 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:15,237 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,238 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:15,239 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:15,240 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:15,244 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:15,249 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:15,252 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:15,252 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:15,253 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:15,255 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:15,257 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:15,258 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,259 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:15,260 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,260 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:15,261 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:15,271 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:15,286 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:15,294 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:15,306 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:15,344 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:15,345 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:15,397 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:15,399 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:15,401 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:15,402 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:15,403 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:15,404 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:15,405 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:15,407 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:15,408 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:15,409 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:15,410 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:15,411 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:15,412 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:15,414 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:15,416 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:15,417 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 34]), 33)\n",
      "2023-10-04 09:19:15,418 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:15,419 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 34]), 33)\n",
      "2023-10-04 09:19:15,420 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:15,421 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:15,422 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:15,424 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:15,425 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:15,426 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:15,427 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:15,427 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:15,429 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:15,437 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:15,445 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,446 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,447 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,447 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,448 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:15,454 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:15,464 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:15,468 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:15,471 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,473 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,474 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:15,476 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:15,483 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:15,491 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,493 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,494 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,495 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,496 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:15,505 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:15,512 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:15,518 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:15,522 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,523 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,524 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:15,527 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:15,535 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:15,543 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,544 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,545 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,546 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,547 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:15,552 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:15,554 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:15,557 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:15,609 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,611 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,613 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:15,616 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:15,624 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:15,634 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,635 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,636 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,637 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,638 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:15,643 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:15,647 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:15,650 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:15,653 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,655 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,656 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:15,659 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:15,667 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:15,676 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,677 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,677 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,678 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,679 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:15,686 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:15,690 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:15,695 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:15,720 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,725 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,727 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:15,731 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:15,742 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:15,750 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,752 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,752 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,754 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,755 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:15,759 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:15,766 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:15,770 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:15,773 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,775 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,776 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:15,778 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:15,786 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:15,794 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,795 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,796 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,797 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,797 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:15,802 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:15,806 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:15,810 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:15,815 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,817 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,818 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:15,822 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:15,831 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:15,839 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,840 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,841 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,842 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,842 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:15,848 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:15,852 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:15,855 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:15,860 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,862 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,863 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:15,867 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:15,876 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:15,886 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,887 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,888 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,889 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,890 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:15,897 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:15,901 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:15,905 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:15,908 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,910 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,911 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:15,913 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:15,921 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:15,930 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,931 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,931 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,932 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,933 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:15,940 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:15,945 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:15,948 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:15,952 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,954 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,955 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:15,957 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:15,965 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:15,974 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:15,975 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,976 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:15,977 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:15,978 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:15,984 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:15,988 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:15,992 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:15,995 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,997 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:19:15,998 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:16,001 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:16,009 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:16,011 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:16,011 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,013 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:16,014 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,015 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:16,020 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:16,024 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:16,080 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:16,126 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:19:16,156 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:19:16,158 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:16,160 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:16,163 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:16,171 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:16,172 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:16,173 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:16,174 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:16,174 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:16,178 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:16,189 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:16,194 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:16,203 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:16,205 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:16,205 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:16,207 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:16,208 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:16,210 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:16,211 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:16,212 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:16,213 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:16,213 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:16,229 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:16,241 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:16,251 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:16,260 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:16,272 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:16,273 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:16,295 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:16,298 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:16,299 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:16,300 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:16,302 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:16,303 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:16,304 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:16,305 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:16,306 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:16,308 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:16,309 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:16,310 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:16,311 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:16,313 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:16,314 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:16,316 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 35]), 34)\n",
      "2023-10-04 09:19:16,317 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:16,318 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 35]), 34)\n",
      "2023-10-04 09:19:16,319 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:16,320 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:16,321 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:16,322 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:16,324 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:16,325 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:16,325 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:16,326 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:16,328 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:16,335 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:16,344 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:16,344 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,345 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:16,346 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,347 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:16,356 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:16,366 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:16,370 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:16,374 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,376 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,377 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:16,379 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:16,387 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:16,395 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:16,396 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,397 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:16,398 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,398 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:16,467 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:16,485 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:16,501 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:16,506 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,508 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,510 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:16,512 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:16,521 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:16,530 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:16,531 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,532 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:16,534 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,535 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:16,541 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:16,545 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:16,550 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:16,554 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,556 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,558 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:16,561 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:16,570 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:16,579 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:16,580 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,581 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:16,582 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,582 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:16,589 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:16,596 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:16,602 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:16,607 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,609 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,610 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:16,613 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:16,621 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:16,630 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:16,631 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,632 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:16,633 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,633 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:16,642 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:16,646 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:16,650 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:16,654 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,656 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,658 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:16,660 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:16,668 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:16,676 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:16,677 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,678 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:16,678 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,679 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:16,685 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:16,688 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:16,692 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:16,696 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,698 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,699 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:16,703 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:16,711 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:16,721 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:16,722 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,723 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:16,724 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,725 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:16,732 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:16,736 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:16,741 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:16,746 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,776 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,778 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:16,781 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:16,791 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:16,800 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:16,801 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,802 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:16,803 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,804 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:16,856 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:16,866 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:16,869 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:16,871 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,873 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,874 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:16,876 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:16,884 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:16,893 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:16,894 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,895 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:16,895 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,896 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:16,908 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:16,913 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:16,917 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:16,921 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,923 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,924 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:16,927 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:16,936 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:16,944 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:16,946 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,947 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:16,948 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:16,950 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:16,959 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:16,964 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:16,970 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:16,980 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,983 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:19:16,984 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:16,986 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:16,995 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:17,003 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,004 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,005 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,007 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,008 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:17,016 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:17,023 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:17,074 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:17,126 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:19:17,128 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:19:17,130 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:17,133 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:17,140 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:17,142 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,143 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,144 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,145 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,146 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:17,151 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:17,154 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:17,157 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:17,160 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:19:17,165 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:19:17,166 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:17,168 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:17,171 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:17,179 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,180 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:17,181 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,182 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:17,183 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:17,185 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:17,186 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:17,187 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:17,188 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:17,191 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:17,192 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:17,193 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:17,195 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:17,196 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,197 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:17,198 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,199 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:17,200 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:17,214 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:17,222 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:17,231 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:17,241 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:17,243 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:17,244 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:17,252 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:17,254 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:17,256 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:17,257 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:17,258 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:17,258 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:17,259 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:17,261 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:17,262 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:17,263 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:17,264 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:17,265 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:17,265 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:17,267 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:17,269 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:17,271 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 36]), 35)\n",
      "2023-10-04 09:19:17,271 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:17,272 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 36]), 35)\n",
      "2023-10-04 09:19:17,273 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:17,273 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:17,275 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:17,276 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:17,277 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:17,278 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:17,279 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:17,280 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:17,282 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:17,289 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:17,297 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,298 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,299 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,300 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,301 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:17,307 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:17,314 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:17,317 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:17,320 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,322 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,323 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:17,325 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:17,333 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:17,341 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,342 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,344 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,345 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,346 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:17,355 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:17,360 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:17,364 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:17,369 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,371 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,371 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:17,375 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:17,382 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:17,391 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,392 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,392 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,394 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,394 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:17,399 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:17,403 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:17,407 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:17,411 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,413 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,414 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:17,416 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:17,424 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:17,432 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,433 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,434 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,435 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,436 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:17,456 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:17,485 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:17,493 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:17,498 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,500 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,501 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:17,504 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:17,513 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:17,522 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,524 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,525 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,526 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,527 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:17,533 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:17,539 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:17,552 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:17,558 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,560 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,561 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:17,565 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:17,573 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:17,582 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,587 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,588 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,589 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,590 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:17,635 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:17,655 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:17,660 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:17,665 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,667 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,668 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:17,670 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:17,679 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:17,687 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,688 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,689 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,690 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,691 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:17,697 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:17,704 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:17,708 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:17,724 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,726 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,728 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:17,730 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:17,739 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:17,747 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,748 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,749 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,749 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,750 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:17,755 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:17,758 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:17,761 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:17,767 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,769 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,770 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:17,772 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:17,780 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:17,789 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,790 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,791 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,792 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,792 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:17,798 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:17,801 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:17,804 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:17,815 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,817 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,818 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:17,820 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:17,828 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:17,836 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,837 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,838 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,839 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,840 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:17,847 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:17,850 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:17,853 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:17,859 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,861 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,862 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:17,864 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:17,873 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:17,882 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,883 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,883 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,884 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,885 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:17,893 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:17,896 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:17,900 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:17,903 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,904 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,905 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:17,908 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:17,919 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:17,921 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,922 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,923 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,924 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:17,925 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:17,933 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:17,938 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:17,944 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:17,948 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,950 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:19:17,951 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:17,954 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:17,957 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:17,970 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,971 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:17,973 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,973 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:17,975 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:17,979 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:17,982 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:17,983 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:17,985 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:17,987 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:17,987 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:17,990 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:17,991 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:17,993 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:17,993 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:17,994 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:17,995 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:17,996 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:18,011 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:18,021 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:18,030 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:18,039 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:18,042 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:18,043 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:18,052 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:18,054 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:18,055 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:18,056 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:18,057 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:18,058 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:18,059 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:18,060 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:18,061 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:18,062 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:18,063 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:18,064 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:18,065 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:18,066 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:18,068 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:18,070 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 37]), 36)\n",
      "2023-10-04 09:19:18,071 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:18,072 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 37]), 36)\n",
      "2023-10-04 09:19:18,074 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:18,075 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:18,076 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:18,078 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:18,079 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:18,080 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:18,081 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:18,082 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:18,083 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:18,092 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:18,101 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,102 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,103 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,104 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,105 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:18,112 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:18,124 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:18,128 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:18,132 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,133 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,135 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:18,137 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:18,145 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:18,154 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,155 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,156 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,157 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,158 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:18,167 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:18,176 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:18,180 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:18,184 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,186 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,187 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:18,191 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:18,200 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:18,208 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,209 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,210 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,211 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,212 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:18,238 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:18,243 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:18,247 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:18,251 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,253 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,254 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:18,256 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:18,265 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:18,273 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,273 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,274 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,275 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,276 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:18,280 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:18,284 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:18,287 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:18,294 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,295 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,296 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:18,299 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:18,307 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:18,316 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,317 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,318 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,318 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,319 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:18,327 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:18,332 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:18,338 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:18,341 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,343 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,344 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:18,347 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:18,355 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:18,369 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,370 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,372 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,373 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,374 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:18,379 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:18,439 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:18,467 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:18,471 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,473 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,474 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:18,477 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:18,485 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:18,494 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,495 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,495 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,496 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,497 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:18,505 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:18,509 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:18,513 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:18,516 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,517 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,518 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:18,521 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:18,529 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:18,538 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,539 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,540 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,541 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,542 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:18,547 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:18,551 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:18,556 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:18,560 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,562 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,563 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:18,565 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:18,574 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:18,582 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,583 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,584 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,585 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,586 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:18,592 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:18,598 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:18,609 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:18,623 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,638 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,640 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:18,642 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:18,650 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:18,658 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,659 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,660 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,661 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,662 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:18,676 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:18,681 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:18,684 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:18,688 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,690 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,691 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:18,694 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:18,702 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:18,711 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,713 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,714 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,715 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,716 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:18,734 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:18,739 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:18,746 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:18,750 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,752 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,753 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:18,755 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:18,763 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:18,765 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,766 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,766 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,767 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,768 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:18,774 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:18,779 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:18,784 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:18,788 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,791 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:19:18,792 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:18,794 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:18,796 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:18,804 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,805 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:18,806 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,807 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:18,809 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:18,811 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:18,812 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:18,814 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:18,816 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:18,817 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:18,818 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:18,819 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:18,821 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:18,822 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,823 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:18,824 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,824 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:18,825 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:18,845 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:18,857 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:18,869 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:18,881 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:18,883 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:18,884 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:18,893 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:18,896 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:18,898 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:18,899 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:18,900 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:18,901 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:18,901 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:18,903 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:18,904 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:18,905 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:18,906 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:18,907 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:18,907 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:18,909 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:18,911 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:18,913 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 38]), 37)\n",
      "2023-10-04 09:19:18,913 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:18,914 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 38]), 37)\n",
      "2023-10-04 09:19:18,915 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:18,916 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:18,918 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:18,919 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:18,920 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:18,921 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:18,922 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:18,923 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:18,925 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:18,932 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:18,941 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:18,943 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,943 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:18,944 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:18,945 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:19,009 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:19,077 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:19,100 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:19,112 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,115 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,116 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:19,118 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:19,127 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:19,135 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,136 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,137 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,138 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,139 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:19,143 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:19,147 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:19,152 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:19,156 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,158 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,160 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:19,162 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:19,171 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:19,185 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,186 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,187 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,188 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,189 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:19,197 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:19,201 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:19,205 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:19,209 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,212 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,213 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:19,215 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:19,223 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:19,231 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,232 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,233 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,234 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,236 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:19,244 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:19,248 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:19,256 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:19,259 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,261 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,262 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:19,265 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:19,272 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:19,281 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,281 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,282 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,283 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,284 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:19,297 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:19,302 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:19,307 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:19,311 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,313 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,314 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:19,317 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:19,325 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:19,333 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,334 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,335 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,336 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,337 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:19,409 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:19,417 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:19,421 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:19,425 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,427 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,428 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:19,430 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:19,438 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:19,445 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,447 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,448 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,449 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,449 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:19,455 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:19,459 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:19,464 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:19,468 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,470 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,471 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:19,474 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:19,482 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:19,490 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,492 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,492 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,493 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,495 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:19,499 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:19,503 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:19,507 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:19,511 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,513 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,514 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:19,517 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:19,525 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:19,533 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,535 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,536 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,537 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,537 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:19,545 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:19,550 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:19,555 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:19,559 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,561 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,563 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:19,565 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:19,573 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:19,581 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,582 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,583 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,584 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,584 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:19,655 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:19,660 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:19,664 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:19,669 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,672 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,673 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:19,676 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:19,683 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:19,693 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,694 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,695 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,696 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,697 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:19,702 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:19,706 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:19,710 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:19,714 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,716 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,717 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:19,720 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:19,728 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:19,730 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,731 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,732 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,733 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,733 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:19,742 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:19,746 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:19,750 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:19,754 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,756 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:19:19,757 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:19,759 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:19,761 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:19,769 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,771 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:19,771 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,772 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:19,773 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:19,776 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:19,779 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:19,780 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:19,782 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:19,783 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:19,783 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:19,785 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:19,787 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:19,788 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,789 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:19,791 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,792 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:19,793 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:19,804 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:19,816 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:19,825 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:19,834 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:19,836 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:19,837 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:19,845 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:19,847 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:19,848 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:19:19,849 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:19,850 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:19:19,851 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:19,852 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:19:19,853 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:19:19,855 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:19:19,857 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:19:19,857 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:19,858 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:19,859 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:19:19,861 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:19:19,862 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:19,864 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 39]), 38)\n",
      "2023-10-04 09:19:19,864 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:19,865 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 39]), 38)\n",
      "2023-10-04 09:19:19,866 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:19,867 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:19:19,868 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:19:19,869 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:19:19,870 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:19:19,871 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:19,872 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:19,873 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:19:19,875 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:19,883 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:19,891 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,893 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,893 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,894 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,895 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:19:19,903 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:19:19,912 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:19:19,916 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:19:19,920 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:19:19,922 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:19:19,923 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:19:19,926 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:19:19,934 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:19,942 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,943 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,944 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,946 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,947 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:19:19,951 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:19:19,955 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:19:19,959 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:19:19,962 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:19:19,964 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:19:19,964 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:19:19,968 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:19:19,976 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:19,984 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:19,985 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,986 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:19,987 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:19,988 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:19:19,996 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:19:20,004 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:19:20,011 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:19:20,015 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,017 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,017 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:19:20,020 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:19:20,028 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:20,036 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:20,037 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,038 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:20,039 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,040 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:19:20,047 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:19:20,118 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:19:20,135 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:19:20,142 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,146 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,147 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:19:20,149 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:19:20,157 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:20,166 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:20,167 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,168 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:20,169 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,169 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:19:20,174 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:19:20,177 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:19:20,180 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:19:20,185 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,186 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,187 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:19:20,189 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:19:20,197 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:20,206 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:20,207 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,208 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:20,208 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,209 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:19:20,216 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:19:20,231 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:19:20,235 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:19:20,238 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,240 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,241 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:19:20,243 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:19:20,251 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:20,260 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:20,263 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,264 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:20,265 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,266 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:19:20,333 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:19:20,340 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:19:20,349 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:19:20,354 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,356 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,358 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:19:20,361 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:19:20,369 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:20,379 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:20,381 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,382 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:20,384 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,385 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:19:20,389 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:19:20,394 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:19:20,447 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:19:20,452 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,455 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,457 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:19:20,459 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:19:20,467 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:20,475 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:20,477 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,477 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:20,479 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,479 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:19:20,485 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:19:20,488 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:19:20,492 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:19:20,496 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,498 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,499 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:19:20,503 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:19:20,514 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:20,523 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:20,524 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,525 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:20,526 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,527 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:19:20,533 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:19:20,536 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:19:20,539 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:19:20,542 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,544 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,545 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:19:20,547 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:19:20,556 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:20,564 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:20,565 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,566 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:20,567 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,567 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:19:20,574 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:19:20,578 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:19:20,581 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:19:20,585 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,586 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,587 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:19:20,590 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:19:20,598 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:20,600 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:20,601 [891690013.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,602 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:20,602 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:19:20,604 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:19:20,610 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:19:20,614 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:19:20,618 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:19:20,622 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,624 [891690013.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:19:20,624 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:19:20,627 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:19:20,629 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:19:20,637 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:20,638 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:20,639 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:20,640 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:20,641 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:19:20,644 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:19:20,647 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:19:20,649 [891690013.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:19:20,651 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:19:20,652 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:19:20,653 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:19:20,654 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:19:20,656 [891690013.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:19:20,658 [891690013.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:19:20,659 [891690013.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:19:20,659 [891690013.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:19:20,660 [891690013.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:19:20,661 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:19:20,678 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:19:20,690 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:19:20,699 [891690013.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:19:20,709 [891690013.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:19:20,712 [891690013.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:19:20,712 [891690013.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:19:20,722 [3316428403.py:28 in <module>] INFO - Who are you? Are you conscious?...\n",
      "I think thats him. I used to be in like 10th grade.\n",
      "Do you live with any family members like them?\n",
      "I\n",
      "2023-10-04 09:19:20,723 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:19:20,724 [3316428403.py:28 in <module>] INFO - Where is Deutschland? - Gjallerhorn, Netherlands (from German for 'The Gannerhorn').\n",
      "It's the first place where you can tell\n",
      "2023-10-04 09:19:20,725 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:19:20,726 [3316428403.py:28 in <module>] INFO - How is Huawei Mate 60 Pro? (H1) and how much should I pay for it?\n",
      "The Huawei Mate 60 Pro was released in China at last week's opening of its\n",
      "2023-10-04 09:19:20,727 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:19:20,728 [3316428403.py:28 in <module>] INFO - Who are you? Are you conscious?/ are you looking for a girlfriend? Are you doing well? Do you have friends? Are you single? The answer to all can be found in\n",
      "2023-10-04 09:19:20,729 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:19:20,730 [3316428403.py:28 in <module>] INFO - Where is Deutschland? \"Dab\" is just fucking dutch, its a fucking \"Dab\".\n",
      "dab is always dutch.  >Dab.\n",
      "2023-10-04 09:19:20,731 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:19:20,732 [3316428403.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?�\n",
      "Huawei Mate 60 Pro is the brand to buy. You should like the Mate 60 Pro compared to any of the other Mate 50 and Mate\n",
      "2023-10-04 09:19:20,733 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:19:20,733 [3316428403.py:28 in <module>] INFO - Who are you? Are you conscious?\n",
      "My name is John \"the_shifty_Posey\"\n",
      "I see a lot of these replies to your posts to get people to\n",
      "2023-10-04 09:19:20,734 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:19:20,736 [3316428403.py:28 in <module>] INFO - Where is Deutschland?/s\n",
      "In Germany. Deltabonschnitzel.\n",
      "2023-10-04 09:19:20,736 [3316428403.py:29 in <module>] INFO - ----------\n"
     ]
    }
   ],
   "source": [
    "# generate test\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "prompts = [\n",
    "    'Who are you? Are you conscious?',\n",
    "    'Where is Deutschland?',\n",
    "    'How is Huawei Mate 60 Pro?'\n",
    "] \n",
    "prompts = prompts * (gbs * ngb // len(prompts)) + prompts[:(gbs * ngb % len(prompts))]\n",
    "\n",
    "prompt_len = 10\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "inputs = tokenizer(prompts, padding=\"max_length\", max_length=prompt_len, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(\n",
    "    inputs.input_ids, \n",
    "    max_length=30 + prompt_len,\n",
    "    # num_beams=2, #\n",
    "    # num_beam_groups=2, #\n",
    "    # diversity_penalty=0.1, #\n",
    "    do_sample=True, #\n",
    ")\n",
    "\n",
    "output_texts = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "for output_text in output_texts:\n",
    "    logging.info(output_text)\n",
    "    logging.info('-' * 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
