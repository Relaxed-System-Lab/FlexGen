{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fsuser/miniconda3/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2023-10-04 09:01:42,054 [instantiator.py:21 in <module>] INFO - Created a temporary directory at /tmp/tmpwr_uvrjd\n",
      "2023-10-04 09:01:42,056 [instantiator.py:76 in _write] INFO - Writing /tmp/tmpwr_uvrjd/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Module \n",
    "import functools \n",
    "\n",
    "from flexgen_utils import logging, Policy, get_module_from_name\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "from flexgen_init import policy_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:01:42,506 [connectionpool.py:1003 in _new_conn] DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2023-10-04 09:01:42,563 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-04 09:01:43.270940: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-04 09:01:44,312 [tpu_cluster_resolver.py:32 in <module>] DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2023-10-04 09:01:44,498 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5\n",
      "2023-10-04 09:01:44,500 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7\n",
      "2023-10-04 09:01:44,501 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5\n",
      "2023-10-04 09:01:44,502 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7\n",
      "2023-10-04 09:01:45,669 [flexgen_init.py:201 in get_policy_weight_map] INFO - device_map is prepared!\n",
      "2023-10-04 09:01:45,674 [flexgen_init.py:207 in get_policy_weight_map] INFO - CausalLM facebook/opt-125m is to be loaded on: \n",
      "GPU Mem 0.00 GiB (0.00%), CPU Mem 0.07 GiB (30.19%), Disk Mem 0.16 Gib (69.81%)\n",
      "2023-10-04 09:01:45,710 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-04 09:01:45,836 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-04 09:01:45,926 [flexgen_init.py:67 in policy_init] INFO - The whole model has been downloaded an processed to offload_folder: 'offload_dir/facebook.opt-125m'\n",
      "model init: loading by policy...:   0%|          | 0/197 [00:00<?, ?it/s]/home/fsuser/FlexGen/general/flexgen_utils/offload.py:41: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995026/work/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  tmp = torch.from_numpy(np_memmap).to(device)\n",
      "model init: loading by policy...: 100%|██████████| 197/197 [00:00<00:00, 2585.92it/s]\n",
      "2023-10-04 09:01:46,011 [flexgen_init.py:79 in policy_init] INFO - model has been loaded by policy.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"facebook/opt-125m\"\n",
    "\n",
    "policy = Policy(\n",
    "    gpu_batch_size=8, \n",
    "    num_gpu_batches=4, \n",
    "    weights_gpu_percent=0.0, \n",
    "    weights_cpu_percent=0.3, \n",
    "    cache_gpu_percent=0.0, \n",
    "    cache_cpu_percent=0.2, \n",
    "    act_gpu_percent=0.0, \n",
    "    act_cpu_percent=0.5, \n",
    "    overlap=True, \n",
    "    pin_weight=True,\n",
    ")\n",
    "\n",
    "# for test\n",
    "gbs = policy.gpu_batch_size\n",
    "ngb = policy.num_gpu_batches\n",
    "num_prompts = ngb * gbs \n",
    "\n",
    "# model init\n",
    "output = policy_init(checkpoint, policy)\n",
    "\n",
    "model = output.model\n",
    "weight_map = output.weight_map\n",
    "layer_names = output.layer_names\n",
    "index = output.index\n",
    "dat_files = output.dat_files\n",
    "tied_params = output.tied_params\n",
    "offload_folder = output.offload_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:01:46,037 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.embed_tokens to flexgen forward\n",
      "2023-10-04 09:01:46,039 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.embed_positions to flexgen forward\n",
      "2023-10-04 09:01:46,040 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.final_layer_norm to flexgen forward\n",
      "2023-10-04 09:01:46,041 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.0 to flexgen forward\n",
      "2023-10-04 09:01:46,042 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.1 to flexgen forward\n",
      "2023-10-04 09:01:46,043 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.2 to flexgen forward\n",
      "2023-10-04 09:01:46,044 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.3 to flexgen forward\n",
      "2023-10-04 09:01:46,045 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.4 to flexgen forward\n",
      "2023-10-04 09:01:46,047 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.5 to flexgen forward\n",
      "2023-10-04 09:01:46,048 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.6 to flexgen forward\n",
      "2023-10-04 09:01:46,049 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.7 to flexgen forward\n",
      "2023-10-04 09:01:46,050 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.8 to flexgen forward\n",
      "2023-10-04 09:01:46,051 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.9 to flexgen forward\n",
      "2023-10-04 09:01:46,052 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.10 to flexgen forward\n",
      "2023-10-04 09:01:46,053 [1981701031.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.11 to flexgen forward\n",
      "2023-10-04 09:01:46,054 [1981701031.py:36 in to_flexgen_forward] DEBUG - lm_head to flexgen forward\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from accelerate.utils import named_module_tensors \n",
    "from flexgen_utils import get_tied_target\n",
    "from flexgen_utils import flexgen_load_module_tensor, flexgen_offload_module_tensor\n",
    "from flexgen_minibatch import get_size_info, get_kth_batch_inputs, concat_outputs\n",
    "\n",
    "def load_layer_weights(model, layer_name, compute_device, offload_folder, dat_files):\n",
    "    logger.debug(f'load_layer_weights: {layer_name} to {compute_device}')\n",
    "    layer_module = get_module_from_name(model, layer_name)\n",
    "    weight_names = [layer_name + '.' + name for name, _ in named_module_tensors(layer_module, True, True)]\n",
    "    layer_dat_files = [os.path.join(offload_folder, get_tied_target(w, tied_params, dat_files) + '.dat') for w in weight_names]\n",
    "    assert all([os.path.isfile(f) for f in layer_dat_files]), f'dat file error, {dat_files}'\n",
    "    \n",
    "    for w in weight_names:\n",
    "        flexgen_load_module_tensor(model, w, compute_device, index, offload_folder, tied_params)\n",
    "\n",
    "\n",
    "def offload_layer_weights(model, layer_name, weight_map):\n",
    "    logger.debug(f'offload_layer_weights: {layer_name}')\n",
    "    layer_module = get_module_from_name(model, layer_name)\n",
    "    weight_names = [layer_name + '.' + name for name, _ in named_module_tensors(layer_module, True, True)]\n",
    "    for w in weight_names:\n",
    "        flexgen_offload_module_tensor(model, w, weight_map) \n",
    "\n",
    "\n",
    "def to_flexgen_forward(model, layer_names, j, compute_device, weight_map, offload_folder, ngb, gbs):\n",
    "    # rewrite the j-th layer's forward\n",
    "    \n",
    "    layer_name = layer_names[j]\n",
    "    next_layer_name = layer_names[(j + 1) % len(layer_names)]\n",
    "\n",
    "    layer = get_module_from_name(model, layer_name)  \n",
    "    if hasattr(layer, \"_flexgen_old_forward\"): # has been rewriten\n",
    "        return layer \n",
    "    \n",
    "    logger.debug(f'{layer_name} to flexgen forward')\n",
    "    layer._flexgen_old_forward = old_forward = layer.forward \n",
    "\n",
    "    @functools.wraps(old_forward)\n",
    "    def new_forward(*args, **kwargs):\n",
    "        # pre fwd: load curr & next weights\n",
    "        load_layer_weights(model, layer_name, compute_device, offload_folder, dat_files)\n",
    "        load_layer_weights(model, next_layer_name, compute_device, offload_folder, dat_files)\n",
    "        \n",
    "        # loop forward pass of K minibatches\n",
    "        with torch.no_grad():\n",
    "            logger.debug(f'args: {get_size_info(args)}')\n",
    "            logger.debug(f'kwargs: {get_size_info(kwargs)}')\n",
    "            # output = old_forward(*args, **kwargs)\n",
    "            # logger.debug(f'output: {get_size_info(output)}')\n",
    "\n",
    "            # args_0 = get_kth_batch_inputs(args, 0, gbs)\n",
    "            # kwargs_0 = get_kth_batch_inputs(kwargs, 0, gbs)\n",
    "            # output_0 = old_forward(*args_0, **kwargs_0)\n",
    "            # logger.debug(f'output0: {get_size_info(output_0)}')\n",
    "\n",
    "            outputs = []\n",
    "            for k in range(ngb):\n",
    "                logger.debug(f'layer: {layer_name}, batch: {k}')\n",
    "\n",
    "                # pre fwd: load curr & next inputs (activations, KV cache), store prev output\n",
    "                args_k = get_kth_batch_inputs(args, k, gbs)\n",
    "                kwargs_k = get_kth_batch_inputs(kwargs, k, gbs)\n",
    "\n",
    "                # the k-th fwd pass\n",
    "                output = old_forward(*args_k, **kwargs_k)\n",
    "                outputs.append(output) \n",
    "                \n",
    "                # post fwd: offload curr inputs\n",
    "\n",
    "            logger.debug(f'outputs before concat: {ngb} x {get_size_info(outputs[0])}')\n",
    "            output = concat_outputs(outputs)\n",
    "            logger.debug(f'outputs after concat: {get_size_info(output)}')                \n",
    "\n",
    "        # post fwd: free curr weights\n",
    "        offload_layer_weights(model, layer_name, weight_map)\n",
    "        return output\n",
    "\n",
    "    layer.forward = new_forward\n",
    "    return layer\n",
    "\n",
    "\n",
    "def to_old_forward(model, layer_name):\n",
    "    layer = get_module_from_name(model, layer_name) \n",
    "\n",
    "    if hasattr(layer, \"_flexgen_old_forward\"):\n",
    "        layer.forward = layer._flexgen_old_forward\n",
    "        delattr(layer, \"_flexgen_old_forward\")\n",
    "        logger.debug(f'{layer_name} to old forward')\n",
    "    return layer\n",
    "\n",
    "\n",
    "layer_nums = len(layer_names)\n",
    "\n",
    "for j in range(layer_nums):\n",
    "    to_old_forward(model, layer_names[j])\n",
    "    \n",
    "# rewrite layers' forward\n",
    "for j in range(layer_nums):\n",
    "    compute_device = 'cpu'\n",
    "    to_flexgen_forward(model, layer_names, j, compute_device, weight_map, offload_folder, ngb, gbs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:01:46,109 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "/home/fsuser/miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1535: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on meta. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('meta') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "2023-10-04 09:01:46,403 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:46,406 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:46,408 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10]),)\n",
      "2023-10-04 09:01:46,410 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:46,411 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:46,417 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:46,422 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:46,428 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:46,431 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 10, 768])\n",
      "2023-10-04 09:01:46,469 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 10, 768])\n",
      "2023-10-04 09:01:46,471 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:46,474 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:46,476 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:46,478 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10]), <class 'int'>)\n",
      "2023-10-04 09:01:46,479 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:46,481 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:46,486 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:46,490 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:46,494 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:46,499 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 10, 768])\n",
      "2023-10-04 09:01:46,518 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 10, 768])\n",
      "2023-10-04 09:01:46,521 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:46,526 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:46,535 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:46,544 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:46,545 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 10, 10]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': <class 'NoneType'>, 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:46,546 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:46,577 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:46,590 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:46,602 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:46,614 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:01:46,617 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 10, 768]), (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])))\n",
      "2023-10-04 09:01:46,618 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:46,621 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:46,629 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:46,637 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:46,638 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 10, 10]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': <class 'NoneType'>, 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:46,639 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:46,652 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:46,664 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:46,675 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:46,687 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:01:46,691 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 10, 768]), (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])))\n",
      "2023-10-04 09:01:46,692 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:46,695 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:46,703 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:46,711 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:46,712 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 10, 10]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': <class 'NoneType'>, 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:46,714 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:46,733 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:46,758 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:46,778 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:46,790 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:01:46,797 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 10, 768]), (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])))\n",
      "2023-10-04 09:01:46,799 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:46,802 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:46,811 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:46,819 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:46,820 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 10, 10]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': <class 'NoneType'>, 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:46,821 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:01:46,849 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:46,867 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:46,883 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:46,902 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:01:46,907 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 10, 768]), (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])))\n",
      "2023-10-04 09:01:46,909 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:46,911 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:46,919 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:46,927 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:46,929 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 10, 10]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': <class 'NoneType'>, 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:46,929 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:46,939 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:46,956 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:46,971 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:46,982 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:01:46,987 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 10, 768]), (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])))\n",
      "2023-10-04 09:01:46,988 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:46,991 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:46,999 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:47,007 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:47,008 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 10, 10]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': <class 'NoneType'>, 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:47,009 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:47,019 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:47,029 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:47,041 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:47,051 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,054 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 10, 768]), (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,055 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:47,058 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:47,066 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:47,075 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:47,076 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 10, 10]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': <class 'NoneType'>, 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:47,076 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:47,088 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:47,098 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:47,108 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:47,118 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,120 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 10, 768]), (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,121 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:47,124 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:47,134 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:47,143 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:47,144 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 10, 10]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': <class 'NoneType'>, 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:47,145 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:47,156 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:47,165 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:47,174 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:47,185 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,189 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 10, 768]), (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,190 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:47,193 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:47,202 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:47,210 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:47,211 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 10, 10]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': <class 'NoneType'>, 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:47,213 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:47,225 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:47,233 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:47,251 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:47,263 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,269 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 10, 768]), (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,270 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:47,273 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:47,281 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:47,288 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:47,289 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 10, 10]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': <class 'NoneType'>, 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:47,290 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:47,301 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:47,308 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:47,317 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:47,326 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,329 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 10, 768]), (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,330 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:47,332 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:47,340 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:47,348 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:47,349 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 10, 10]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': <class 'NoneType'>, 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:47,350 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:47,366 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:47,374 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:47,383 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:47,392 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,406 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 10, 768]), (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,407 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:47,410 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:47,418 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:47,420 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:47,421 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 10, 10]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': <class 'NoneType'>, 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:47,422 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:47,433 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:47,450 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:47,461 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:47,472 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,482 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 10, 768]), (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])))\n",
      "2023-10-04 09:01:47,484 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:47,487 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:47,489 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:47,497 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:47,497 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:47,498 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:47,501 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:47,502 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:47,503 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:47,505 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 10, 768])\n",
      "2023-10-04 09:01:47,511 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 10, 768])\n",
      "2023-10-04 09:01:47,513 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:47,516 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:47,519 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:47,523 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 10, 768]),)\n",
      "2023-10-04 09:01:47,525 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:47,528 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:47,581 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:47,630 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:47,680 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:47,728 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 10, 50272])\n",
      "2023-10-04 09:01:47,746 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 10, 50272])\n",
      "2023-10-04 09:01:47,747 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:47,777 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:47,779 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:47,781 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:47,782 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:47,783 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:47,785 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:47,786 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:47,787 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:47,788 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:47,789 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:47,790 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:47,791 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:47,793 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:47,795 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 11]), <class 'int'>)\n",
      "2023-10-04 09:01:47,796 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:47,796 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:47,798 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:47,799 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:47,800 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:47,801 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:47,802 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:47,803 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:47,804 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:47,812 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:47,821 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:47,822 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 11]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:47,823 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:47,833 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:47,839 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:47,843 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:47,848 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:01:47,850 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])))\n",
      "2023-10-04 09:01:47,851 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:47,854 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:47,862 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:47,875 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:47,877 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 11]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:47,878 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:47,886 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:47,897 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:47,904 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:47,909 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:01:47,913 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])))\n",
      "2023-10-04 09:01:47,916 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:47,918 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:47,926 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:47,934 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:47,934 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 11]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:47,935 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:47,941 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:47,945 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:47,950 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:47,954 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:01:47,956 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])))\n",
      "2023-10-04 09:01:47,957 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:47,960 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:47,968 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:47,976 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:47,976 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 11]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:47,977 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:47,982 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:47,986 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:47,997 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:48,001 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,003 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,004 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:48,007 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:48,016 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:48,024 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,025 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 11]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,026 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:48,031 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:48,035 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:48,039 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:48,043 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,045 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,046 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:48,049 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:48,058 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:48,067 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,068 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 11]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,069 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:48,079 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:48,084 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:48,089 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:48,094 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,097 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,099 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:48,101 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:48,110 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:48,118 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,119 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 11]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,121 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:48,127 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:48,131 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:48,138 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:48,142 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,144 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,145 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:48,149 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:48,159 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:48,168 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,169 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 11]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,170 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:48,175 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:48,179 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:48,182 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:48,186 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,189 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,189 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:48,192 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:48,200 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:48,210 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,211 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 11]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,212 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:48,221 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:48,226 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:48,230 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:48,235 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,238 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,239 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:48,242 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:48,250 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:48,258 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,259 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 11]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,260 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:48,266 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:48,271 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:48,276 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:48,283 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,286 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,287 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:48,290 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:48,299 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:48,307 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,308 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 11]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,309 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:48,317 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:48,322 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:48,326 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:48,337 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,347 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,348 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:48,351 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:48,358 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:48,360 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,361 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 11]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 10, 64]), torch.Size([32, 12, 10, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,362 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:48,386 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:48,398 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:48,405 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:48,410 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,413 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])))\n",
      "2023-10-04 09:01:48,414 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:48,417 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:48,420 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:48,428 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,429 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:48,430 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:48,432 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:48,433 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:48,434 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:48,435 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:48,436 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:48,437 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:48,438 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:48,440 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:48,442 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,443 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:48,443 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:48,458 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:48,472 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:48,483 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:48,494 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:01:48,497 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:01:48,498 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:48,513 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:48,515 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:48,517 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:48,518 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:48,519 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:48,520 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:48,521 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:48,522 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:48,523 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:48,524 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:48,525 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:48,527 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:48,529 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:48,531 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 12]), <class 'int'>)\n",
      "2023-10-04 09:01:48,532 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:48,532 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:48,534 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:48,535 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:48,536 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:48,537 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:48,538 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:48,539 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:48,541 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:48,549 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:48,558 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,559 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 12]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,560 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:48,565 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:48,569 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:48,575 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:48,580 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,589 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,590 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:48,593 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:48,601 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:48,610 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,611 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 12]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,612 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:48,617 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:48,622 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:48,627 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:48,632 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,634 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,635 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:48,637 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:48,646 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:48,654 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,655 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 12]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,656 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:48,663 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:48,668 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:48,674 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:48,686 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,689 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,690 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:48,693 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:48,700 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:48,708 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,709 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 12]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,710 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:48,720 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:48,725 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:48,729 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:48,733 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,736 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,737 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:48,739 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:48,748 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:48,757 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,758 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 12]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,759 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:48,767 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:48,772 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:48,776 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:48,781 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,784 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,785 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:48,788 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:48,796 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:48,805 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,806 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 12]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,807 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:48,830 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:48,835 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:48,841 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:48,846 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,848 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,849 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:48,852 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:48,860 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:48,869 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,870 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 12]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,871 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:48,887 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:48,893 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:48,899 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:48,906 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,909 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,910 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:48,912 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:48,920 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:48,929 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,930 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 12]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,931 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:48,947 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:48,959 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:48,966 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:48,971 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,974 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])))\n",
      "2023-10-04 09:01:48,974 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:48,977 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:48,985 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:48,993 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:48,994 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 12]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:48,995 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:49,007 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:49,011 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:49,043 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:49,077 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:01:49,087 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])))\n",
      "2023-10-04 09:01:49,089 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:49,092 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:49,099 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:49,109 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,110 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 12]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:49,111 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:49,117 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:49,124 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:49,130 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:49,136 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:01:49,140 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])))\n",
      "2023-10-04 09:01:49,141 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:49,144 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:49,152 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:49,160 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,162 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 12]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:49,162 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:49,168 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:49,172 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:49,179 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:49,184 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:01:49,187 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])))\n",
      "2023-10-04 09:01:49,188 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:49,191 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:49,198 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:49,200 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,201 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 12]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 11, 64]), torch.Size([32, 12, 11, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:49,202 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:49,208 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:49,214 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:49,219 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:49,224 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:01:49,227 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])))\n",
      "2023-10-04 09:01:49,229 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:49,232 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:49,234 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:49,241 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,242 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:49,243 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:49,246 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:49,249 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:49,250 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:49,252 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:49,253 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:49,254 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:49,255 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:49,257 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:49,258 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,259 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:49,260 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:49,271 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:49,281 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:49,291 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:49,303 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:01:49,307 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:01:49,308 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:49,325 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:49,328 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:49,329 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:49,330 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:49,331 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:49,333 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:49,334 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:49,335 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:49,337 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:49,337 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:49,339 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:49,340 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:49,342 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:49,344 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 13]), <class 'int'>)\n",
      "2023-10-04 09:01:49,345 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:49,346 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:49,348 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:49,349 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:49,351 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:49,352 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:49,353 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:49,354 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:49,356 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:49,364 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:49,373 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,374 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 13]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:49,375 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:49,390 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:49,403 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:49,409 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:49,415 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,418 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,419 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:49,422 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:49,430 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:49,439 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,440 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 13]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:49,441 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:49,452 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:49,461 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:49,467 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:49,476 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,481 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,482 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:49,485 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:49,492 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:49,501 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,502 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 13]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:49,503 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:49,517 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:49,524 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:49,532 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:49,538 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,540 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,541 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:49,544 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:49,552 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:49,560 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,561 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 13]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:49,562 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:49,569 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:49,575 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:49,645 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:49,684 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,687 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,688 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:49,691 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:49,700 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:49,709 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,710 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 13]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:49,711 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:49,717 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:49,728 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:49,737 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:49,753 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,757 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,759 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:49,761 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:49,769 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:49,777 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,778 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 13]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:49,779 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:49,785 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:49,791 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:49,801 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:49,807 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,810 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,811 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:49,813 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:49,821 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:49,829 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,830 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 13]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:49,831 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:49,837 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:49,849 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:49,866 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:49,877 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,881 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,882 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:49,885 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:49,893 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:49,902 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,904 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 13]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:49,905 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:49,913 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:49,924 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:49,938 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:49,945 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,950 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])))\n",
      "2023-10-04 09:01:49,951 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:49,954 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:49,962 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:49,971 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:49,972 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 13]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:49,973 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:49,979 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:49,986 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:49,992 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:50,001 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:01:50,012 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])))\n",
      "2023-10-04 09:01:50,014 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:50,016 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:50,024 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:50,033 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,034 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 13]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,034 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:50,044 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:50,055 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:50,062 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:50,068 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:01:50,073 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])))\n",
      "2023-10-04 09:01:50,074 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:50,077 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:50,084 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:50,093 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,094 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 13]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,095 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:50,102 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:50,108 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:50,113 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:50,133 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:01:50,137 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])))\n",
      "2023-10-04 09:01:50,139 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:50,142 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:50,151 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:50,152 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,153 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 13]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 12, 64]), torch.Size([32, 12, 12, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,154 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:50,161 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:50,176 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:50,182 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:50,189 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:01:50,193 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])))\n",
      "2023-10-04 09:01:50,195 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:50,198 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:50,200 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:50,208 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,210 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:50,212 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:50,213 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:50,217 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:50,221 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:50,226 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:50,227 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:50,228 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:50,230 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:50,232 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:50,233 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,234 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:50,234 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:50,254 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:50,267 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:50,281 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:50,294 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:01:50,298 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:01:50,299 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:50,313 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:50,316 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:50,318 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:50,319 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:50,320 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:50,321 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:50,322 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:50,323 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:50,324 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:50,325 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:50,326 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:50,328 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:50,330 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:50,332 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 14]), <class 'int'>)\n",
      "2023-10-04 09:01:50,332 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:50,333 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:50,335 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:50,336 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:50,337 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:50,338 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:50,339 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:50,340 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:50,341 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:50,349 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:50,358 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,359 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 14]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,360 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:50,367 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:50,373 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:50,378 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:50,389 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,396 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,397 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:50,400 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:50,407 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:50,417 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,418 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 14]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,418 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:50,427 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:50,433 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:50,439 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:50,455 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,458 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,459 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:50,463 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:50,471 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:50,479 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,480 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 14]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,481 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:50,487 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:50,492 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:50,498 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:50,503 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,506 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,507 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:50,510 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:50,518 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:50,527 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,528 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 14]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,529 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:50,535 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:50,540 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:50,547 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:50,553 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,556 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,557 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:50,561 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:50,568 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:50,577 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,578 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 14]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,579 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:50,584 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:50,589 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:50,594 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:50,600 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,603 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,604 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:50,607 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:50,615 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:50,624 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,625 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 14]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,626 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:50,633 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:50,642 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:50,648 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:50,655 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,658 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,660 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:50,662 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:50,670 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:50,679 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,680 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 14]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,681 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:50,687 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:50,692 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:50,698 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:50,703 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,706 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,707 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:50,710 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:50,719 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:50,727 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,728 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 14]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,729 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:50,737 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:50,743 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:50,753 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:50,759 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,761 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,762 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:50,765 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:50,773 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:50,781 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,782 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 14]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,783 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:50,790 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:50,796 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:50,802 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:50,812 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,817 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,818 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:50,821 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:50,828 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:50,836 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,837 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 14]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,838 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:50,844 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:50,849 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:50,854 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:50,860 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,862 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,863 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:50,866 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:50,874 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:50,882 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,883 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 14]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,885 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:50,891 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:50,896 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:50,901 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:50,905 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,908 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,909 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:50,912 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:50,920 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:50,922 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,923 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 14]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 13, 64]), torch.Size([32, 12, 13, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:50,924 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:50,934 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:50,948 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:50,955 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:50,961 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,965 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])))\n",
      "2023-10-04 09:01:50,966 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:50,969 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:50,971 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:50,982 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:50,983 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:50,984 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:50,986 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:50,987 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:50,988 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:50,992 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:50,994 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:50,995 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:50,997 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:50,999 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:51,000 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,001 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:51,002 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:51,012 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:51,027 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:51,048 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:51,073 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:01:51,079 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:01:51,080 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:51,140 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:51,144 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:51,146 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:51,148 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:51,150 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:51,152 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:51,154 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:51,155 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:51,157 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:51,159 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:51,162 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:51,164 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:51,166 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:51,168 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 15]), <class 'int'>)\n",
      "2023-10-04 09:01:51,169 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:51,170 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:51,172 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:51,174 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:51,175 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:51,177 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:51,178 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:51,179 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:51,180 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:51,189 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:51,198 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,200 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 15]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:51,201 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:51,270 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:51,277 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:51,283 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:51,289 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,292 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,293 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:51,296 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:51,304 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:51,312 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,313 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 15]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:51,314 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:51,324 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:51,333 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:51,339 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:51,346 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,349 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,350 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:51,352 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:51,360 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:51,368 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,370 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 15]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:51,371 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:51,376 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:51,382 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:51,388 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:51,394 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,397 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,398 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:51,402 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:51,410 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:51,419 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,420 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 15]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:51,421 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:51,430 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:51,437 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:51,444 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:51,451 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,454 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,455 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:51,458 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:51,466 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:51,475 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,476 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 15]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:51,477 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:51,483 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:51,489 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:51,495 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:51,501 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,505 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,505 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:51,508 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:51,516 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:51,524 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,525 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 15]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:51,526 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:51,531 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:51,537 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:51,543 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:51,551 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,556 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,557 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:51,560 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:51,568 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:51,577 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,578 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 15]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:51,579 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:51,585 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:51,592 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:51,598 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:51,612 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,616 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,617 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:51,621 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:51,632 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:51,644 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,645 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 15]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:51,646 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:51,656 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:51,666 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:51,673 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:51,687 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,710 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,712 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:51,715 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:51,727 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:51,740 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,742 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 15]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:51,742 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:51,750 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:51,757 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:51,767 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:51,774 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,778 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,780 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:51,783 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:51,791 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:51,799 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,800 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 15]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:51,801 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:51,807 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:51,813 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:51,818 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:51,823 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,827 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,829 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:51,831 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:51,840 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:51,849 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,850 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 15]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:51,850 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:51,859 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:51,866 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:51,873 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:51,880 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,883 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,885 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:51,888 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:51,897 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:51,900 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,900 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 15]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 14, 64]), torch.Size([32, 12, 14, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:51,902 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:51,909 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:51,916 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:51,924 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:51,932 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,935 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])))\n",
      "2023-10-04 09:01:51,936 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:51,938 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:51,940 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:51,949 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,950 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:51,951 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:51,955 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:51,958 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:51,963 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:51,967 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:51,968 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:51,969 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:51,970 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:51,972 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:51,973 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:51,974 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:51,975 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:51,991 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:52,009 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:52,024 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:52,039 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:01:52,050 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:01:52,052 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:52,069 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:52,072 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:52,074 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:52,075 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:52,076 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:52,078 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:52,079 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:52,080 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:52,082 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:52,083 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:52,084 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:52,085 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:52,087 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:52,089 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 16]), <class 'int'>)\n",
      "2023-10-04 09:01:52,090 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:52,091 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:52,092 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:52,093 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:52,094 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:52,096 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:52,097 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:52,097 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:52,099 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:52,109 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:52,118 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:52,119 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 16]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:52,120 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:52,130 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:52,139 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:52,174 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:52,181 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,188 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,189 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:52,193 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:52,201 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:52,209 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:52,211 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 16]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:52,212 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:52,217 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:52,224 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:52,235 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:52,241 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,244 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,245 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:52,247 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:52,256 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:52,264 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:52,273 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 16]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:52,274 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:52,280 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:52,341 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:52,359 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:52,365 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,401 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,404 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:52,408 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:52,419 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:52,432 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:52,433 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 16]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:52,434 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:52,441 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:52,448 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:52,454 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:52,460 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,463 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,464 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:52,467 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:52,475 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:52,483 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:52,484 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 16]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:52,485 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:52,494 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:52,500 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:52,506 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:52,513 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,516 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,517 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:52,520 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:52,527 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:52,535 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:52,536 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 16]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:52,537 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:52,546 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:52,552 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:52,560 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:52,567 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,569 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,570 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:52,573 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:52,581 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:52,590 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:52,591 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 16]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:52,591 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:52,601 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:52,608 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:52,615 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:52,623 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,627 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,628 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:52,631 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:52,640 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:52,648 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:52,650 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 16]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:52,651 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:52,659 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:52,669 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:52,675 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:52,681 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,685 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,686 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:52,689 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:52,697 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:52,706 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:52,707 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 16]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:52,708 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:52,719 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:52,725 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:52,749 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:52,757 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,760 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,761 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:52,764 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:52,772 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:52,781 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:52,782 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 16]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:52,782 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:52,793 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:52,800 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:52,807 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:52,817 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,821 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,823 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:52,825 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:52,833 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:52,842 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:52,843 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 16]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:52,844 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:52,852 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:52,860 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:52,889 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:52,896 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,907 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])))\n",
      "2023-10-04 09:01:52,909 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:52,913 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:52,921 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:52,923 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:52,924 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 16]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 15, 64]), torch.Size([32, 12, 15, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:52,926 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:52,934 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:52,999 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:53,011 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:53,039 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:01:53,047 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])))\n",
      "2023-10-04 09:01:53,049 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:53,052 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:53,056 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:53,064 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,065 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:53,066 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:53,068 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:53,072 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:53,074 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:53,076 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:53,077 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:53,079 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:53,081 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:53,082 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:53,084 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,085 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:53,086 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:53,101 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:53,111 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:53,120 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:53,131 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:01:53,135 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:01:53,136 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:53,147 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:53,149 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:53,151 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:53,152 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:53,152 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:53,154 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:53,155 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:53,156 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:53,157 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:53,158 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:53,158 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:53,160 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:53,162 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:53,163 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 17]), <class 'int'>)\n",
      "2023-10-04 09:01:53,164 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:53,165 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:53,167 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:53,168 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:53,169 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:53,170 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:53,171 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:53,172 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:53,174 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:53,182 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:53,190 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,190 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 17]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:53,192 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:53,198 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:53,204 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:53,214 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:53,219 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,221 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,223 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:53,226 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:53,233 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:53,242 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,242 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 17]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:53,243 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:53,251 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:53,256 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:53,260 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:53,264 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,266 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,268 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:53,270 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:53,279 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:53,287 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,288 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 17]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:53,289 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:53,295 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:53,303 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:53,309 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:53,323 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,326 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,327 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:53,330 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:53,338 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:53,346 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,347 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 17]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:53,348 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:53,363 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:53,369 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:53,374 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:53,380 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,382 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,384 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:53,387 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:53,396 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:53,406 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,408 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 17]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:53,409 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:53,415 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:53,421 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:53,426 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:53,431 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,434 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,435 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:53,437 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:53,445 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:53,453 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,454 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 17]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:53,455 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:53,462 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:53,468 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:53,473 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:53,481 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,484 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,485 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:53,487 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:53,496 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:53,505 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,506 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 17]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:53,507 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:53,514 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:53,521 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:53,528 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:53,533 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,535 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,536 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:53,539 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:53,547 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:53,556 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,557 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 17]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:53,558 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:53,563 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:53,568 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:53,572 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:53,580 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,581 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,582 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:53,585 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:53,593 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:53,602 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,604 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 17]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:53,605 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:53,626 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:53,633 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:53,640 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:53,646 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,648 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,649 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:53,652 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:53,659 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:53,668 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,669 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 17]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:53,669 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:53,675 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:53,680 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:53,688 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:53,697 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,704 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,706 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:53,709 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:53,717 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:53,725 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,726 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 17]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:53,727 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:53,741 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:53,748 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:53,753 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:53,758 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,760 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,761 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:53,764 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:53,772 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:53,774 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,775 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 17]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 16, 64]), torch.Size([32, 12, 16, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:53,775 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:53,781 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:53,790 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:53,796 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:53,800 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,803 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])))\n",
      "2023-10-04 09:01:53,805 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:53,807 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:53,809 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:53,817 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,818 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:53,819 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:53,820 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:53,821 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:53,822 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:53,823 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:53,824 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:53,825 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:53,827 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:53,829 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:53,830 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,831 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:53,831 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:53,853 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:53,871 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:53,888 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:53,903 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:01:53,921 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:01:53,922 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:53,934 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:53,937 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:53,938 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:53,940 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:53,940 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:53,942 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:53,943 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:53,944 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:53,945 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:53,945 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:53,946 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:53,948 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:53,950 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:53,952 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 18]), <class 'int'>)\n",
      "2023-10-04 09:01:53,953 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:53,953 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:53,955 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:53,956 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:53,957 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:53,958 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:53,959 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:53,960 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:53,962 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:53,969 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:53,978 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:53,979 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 18]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:53,980 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:53,987 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:53,996 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:54,001 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:54,010 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,014 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,016 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:54,019 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:54,027 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:54,036 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:54,038 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 18]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:54,039 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:54,050 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:54,056 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:54,065 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:54,135 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,170 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,172 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:54,175 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:54,183 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:54,191 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:54,192 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 18]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:54,193 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:54,208 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:54,216 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:54,221 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:54,231 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,233 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,234 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:54,237 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:54,245 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:54,253 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:54,254 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 18]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:54,256 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:54,263 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:54,273 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:54,281 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:54,287 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,290 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,291 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:54,294 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:54,302 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:54,311 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:54,312 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 18]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:54,313 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:54,321 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:54,328 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:54,338 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:54,346 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,354 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,357 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:54,360 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:54,368 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:54,376 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:54,378 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 18]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:54,379 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:54,389 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:54,394 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:54,399 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:54,405 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,409 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,410 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:54,413 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:54,421 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:54,429 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:54,430 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 18]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:54,431 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:54,438 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:54,445 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:54,450 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:54,456 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,459 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,460 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:54,463 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:54,471 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:54,480 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:54,481 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 18]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:54,482 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:54,487 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:54,493 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:54,502 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:54,509 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,513 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,515 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:54,519 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:54,531 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:54,544 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:54,545 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 18]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:54,546 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:54,557 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:54,568 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:54,581 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:54,589 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,622 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,624 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:54,627 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:54,636 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:54,645 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:54,647 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 18]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:54,647 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:54,660 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:54,681 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:54,688 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:54,723 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,726 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,728 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:54,730 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:54,738 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:54,747 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:54,748 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 18]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:54,749 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:54,756 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:54,762 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:54,768 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:54,775 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,777 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,779 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:54,781 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:54,789 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:54,791 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:54,792 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 18]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 17, 64]), torch.Size([32, 12, 17, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:54,793 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:54,800 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:54,806 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:54,814 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:54,823 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,826 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])))\n",
      "2023-10-04 09:01:54,827 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:54,829 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:54,831 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:54,839 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:54,841 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:54,842 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:54,845 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:54,846 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:54,848 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:54,849 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:54,851 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:54,851 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:54,853 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:54,855 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:54,857 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:54,858 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:54,859 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:54,873 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:54,887 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:54,900 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:54,913 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:01:54,917 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:01:54,919 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:54,932 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:54,935 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:54,937 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:54,937 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:54,938 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:54,940 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:54,941 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:54,942 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:54,943 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:54,943 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:54,944 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:54,947 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:54,949 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:54,952 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 19]), <class 'int'>)\n",
      "2023-10-04 09:01:54,954 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:54,956 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:54,959 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:54,961 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:54,964 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:54,966 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:54,968 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:54,969 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:54,972 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:54,986 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:54,999 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,001 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 19]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:55,002 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:55,010 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:55,020 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:55,028 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:55,036 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,039 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,041 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:55,045 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:55,053 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:55,066 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,067 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 19]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:55,069 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:55,077 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:55,090 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:55,103 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:55,183 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,206 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,208 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:55,210 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:55,219 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:55,228 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,229 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 19]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:55,230 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:55,243 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:55,254 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:55,263 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:55,270 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,273 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,275 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:55,279 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:55,290 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:55,303 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,305 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 19]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:55,307 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:55,318 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:55,326 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:55,335 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:55,345 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,349 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,351 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:55,354 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:55,366 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:55,378 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,380 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 19]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:55,381 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:55,388 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:55,394 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:55,401 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:55,407 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,411 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,412 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:55,416 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:55,426 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:55,435 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,436 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 19]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:55,437 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:55,449 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:55,457 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:55,465 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:55,472 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,475 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,476 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:55,479 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:55,487 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:55,496 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,498 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 19]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:55,499 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:55,506 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:55,513 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:55,520 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:55,526 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,529 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,530 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:55,533 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:55,542 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:55,551 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,552 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 19]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:55,553 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:55,560 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:55,565 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:55,571 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:55,578 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,581 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,582 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:55,585 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:55,592 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:55,601 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,602 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 19]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:55,602 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:55,609 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:55,619 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:55,626 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:55,633 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,638 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,640 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:55,643 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:55,651 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:55,660 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,661 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 19]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:55,662 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:55,669 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:55,683 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:55,734 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:55,784 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,799 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,801 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:55,803 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:55,811 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:55,819 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,821 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 19]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:55,822 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:55,828 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:55,852 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:55,858 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:55,864 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,868 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,869 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:55,872 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:55,880 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:55,882 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,883 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 19]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 18, 64]), torch.Size([32, 12, 18, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:55,884 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:55,907 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:55,914 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:55,925 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:55,931 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,933 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])))\n",
      "2023-10-04 09:01:55,934 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:55,936 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:55,939 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:55,947 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,948 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:55,948 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:55,951 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:55,952 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:55,953 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:55,955 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:55,955 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:55,956 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:55,958 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:55,960 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:55,962 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:55,963 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:55,964 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:55,979 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:55,992 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:56,008 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:56,019 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:01:56,023 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:01:56,024 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:56,034 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:56,036 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:56,038 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:56,039 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:56,040 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:56,041 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:56,042 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:56,043 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:56,044 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:56,045 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:56,046 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:56,048 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:56,049 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:56,051 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 20]), <class 'int'>)\n",
      "2023-10-04 09:01:56,052 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:56,052 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:56,054 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:56,055 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:56,056 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:56,057 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:56,058 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:56,059 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:56,060 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:56,068 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:56,076 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,077 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 20]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:56,078 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:56,090 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:56,096 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:56,101 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:56,105 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,107 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,110 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:56,112 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:56,122 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:56,132 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,133 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 20]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:56,134 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:56,145 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:56,149 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:56,153 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:56,158 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,160 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,161 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:56,164 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:56,172 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:56,180 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,181 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 20]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:56,182 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:56,191 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:56,203 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:56,222 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:56,236 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,238 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,239 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:56,243 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:56,251 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:56,261 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,262 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 20]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:56,263 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:56,269 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:56,273 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:56,286 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:56,299 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,301 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,302 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:56,305 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:56,313 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:56,321 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,322 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 20]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:56,324 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:56,332 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:56,338 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:56,342 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:56,352 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,400 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,403 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:56,408 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:56,422 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:56,434 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,435 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 20]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:56,436 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:56,443 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:56,448 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:56,453 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:56,457 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,462 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,463 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:56,466 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:56,473 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:56,482 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,483 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 20]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:56,483 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:56,489 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:56,493 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:56,497 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:56,510 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,513 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,514 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:56,517 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:56,525 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:56,534 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,535 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 20]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:56,536 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:56,543 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:56,547 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:56,552 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:56,556 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,559 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,560 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:56,562 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:56,571 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:56,580 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,581 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 20]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:56,582 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:56,586 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:56,590 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:56,594 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:56,598 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,600 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,601 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:56,604 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:56,612 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:56,620 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,621 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 20]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:56,622 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:56,628 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:56,636 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:56,641 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:56,645 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,647 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,648 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:56,651 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:56,660 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:56,669 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,670 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 20]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:56,671 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:56,679 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:56,683 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:56,702 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:56,706 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,708 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,709 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:56,712 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:56,720 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:56,722 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,723 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 20]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 19, 64]), torch.Size([32, 12, 19, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:56,724 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:56,730 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:56,734 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:56,748 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:56,753 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,756 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])))\n",
      "2023-10-04 09:01:56,757 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:56,759 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:56,761 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:56,770 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,771 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:56,772 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:56,773 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:56,774 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:56,776 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:56,777 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:56,778 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:56,779 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:56,780 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:56,782 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:56,783 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,785 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:56,787 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:56,808 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:56,823 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:56,851 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:56,862 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:01:56,882 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:01:56,884 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:56,897 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:56,899 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:56,901 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:56,902 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:56,902 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:56,904 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:56,905 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:56,906 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:56,907 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:56,908 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:56,908 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:56,910 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:56,912 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:56,913 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 21]), <class 'int'>)\n",
      "2023-10-04 09:01:56,914 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:56,915 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:56,916 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:56,918 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:56,919 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:56,920 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:56,921 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:56,922 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:56,924 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:56,931 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:56,941 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:56,942 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 21]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:56,943 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:56,949 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:56,964 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:56,970 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:56,980 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:01:56,983 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])))\n",
      "2023-10-04 09:01:56,984 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:56,986 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:56,994 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:57,002 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,003 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 21]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,004 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:57,010 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:57,014 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:57,019 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:57,023 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,025 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,026 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:57,029 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:57,036 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:57,045 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,046 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 21]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,047 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:57,053 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:57,058 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:57,064 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:57,075 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,078 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,080 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:57,083 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:57,091 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:57,100 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,102 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 21]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,102 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:57,111 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:57,118 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:57,125 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:57,131 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,134 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,135 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:57,138 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:57,146 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:57,155 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,156 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 21]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,157 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:57,163 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:57,167 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:57,172 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:57,177 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,179 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,180 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:57,183 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:57,190 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:57,199 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,199 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 21]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,200 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:57,205 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:57,208 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:57,214 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:57,238 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,240 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,242 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:57,244 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:57,251 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:57,260 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,261 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 21]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,262 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:57,267 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:57,288 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:57,293 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:57,297 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,299 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,300 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:57,303 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:57,311 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:57,320 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,321 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 21]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,321 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:57,329 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:57,334 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:57,344 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:57,372 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,408 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,409 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:57,412 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:57,420 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:57,429 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,431 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 21]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,432 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:57,445 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:57,451 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:57,457 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:57,462 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,466 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,467 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:57,470 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:57,478 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:57,486 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,487 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 21]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,488 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:57,495 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:57,500 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:57,506 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:57,511 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,516 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,517 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:57,521 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:57,529 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:57,539 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,540 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 21]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,540 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:57,548 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:57,554 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:57,560 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:57,568 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,572 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,573 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:57,576 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:57,584 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:57,586 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,586 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 21]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 20, 64]), torch.Size([32, 12, 20, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,587 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:57,594 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:57,601 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:57,606 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:57,612 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,615 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])))\n",
      "2023-10-04 09:01:57,616 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:57,618 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:57,620 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:57,628 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,629 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:57,630 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:57,631 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:57,633 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:57,634 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:57,635 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:57,637 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:57,637 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:57,639 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:57,640 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:57,642 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,643 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:57,643 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:57,655 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:57,666 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:57,677 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:57,691 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:01:57,694 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:01:57,696 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:57,708 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:57,711 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:57,712 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:57,714 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:57,715 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:57,716 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:57,717 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:57,718 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:57,719 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:57,720 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:57,721 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:57,722 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:57,724 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:57,726 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 22]), <class 'int'>)\n",
      "2023-10-04 09:01:57,727 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:57,727 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:57,729 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:57,730 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:57,731 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:57,733 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:57,733 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:57,734 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:57,736 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:57,744 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:57,752 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,753 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 22]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,754 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:57,762 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:57,772 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:57,780 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:57,787 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:01:57,791 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])))\n",
      "2023-10-04 09:01:57,792 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:57,795 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:57,803 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:57,812 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,813 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 22]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,814 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:57,820 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:57,824 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:57,850 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:57,864 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:01:57,866 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])))\n",
      "2023-10-04 09:01:57,867 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:57,870 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:57,877 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:57,886 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,887 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 22]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,888 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:57,894 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:57,898 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:57,908 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:57,926 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:01:57,958 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])))\n",
      "2023-10-04 09:01:57,960 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:57,962 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:57,969 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:57,978 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:57,979 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 22]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:57,980 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:58,017 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:58,025 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:58,033 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:58,040 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,044 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,046 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:58,050 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:58,063 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:58,077 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,078 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 22]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,079 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:58,087 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:58,093 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:58,101 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:58,106 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,109 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,110 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:58,113 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:58,120 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:58,129 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,130 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 22]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,131 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:58,136 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:58,141 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:58,145 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:58,150 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,152 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,153 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:58,156 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:58,164 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:58,173 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,174 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 22]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,175 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:58,184 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:58,189 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:58,193 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:58,197 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,200 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,201 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:58,203 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:58,211 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:58,220 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,221 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 22]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,221 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:58,229 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:58,234 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:58,239 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:58,244 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,247 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,248 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:58,250 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:58,258 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:58,267 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,268 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 22]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,268 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:58,283 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:58,288 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:58,294 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:58,301 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,304 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,305 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:58,307 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:58,315 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:58,323 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,324 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 22]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,325 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:58,330 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:58,334 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:58,339 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:58,344 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,347 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,348 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:58,351 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:58,360 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:58,369 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,370 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 22]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,371 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:58,379 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:58,386 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:58,393 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:58,397 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,400 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,401 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:58,404 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:58,413 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:58,414 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,415 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 22]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 21, 64]), torch.Size([32, 12, 21, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,416 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:58,421 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:58,426 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:58,436 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:58,440 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,443 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])))\n",
      "2023-10-04 09:01:58,443 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:58,446 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:58,448 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:58,456 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,457 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:58,458 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:58,460 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:58,461 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:58,464 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:58,466 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:58,467 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:58,468 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:58,469 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:58,471 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:58,472 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,473 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:58,474 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:58,485 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:58,500 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:58,516 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:58,527 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:01:58,534 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:01:58,536 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:58,552 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:58,554 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:58,556 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:58,557 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:58,558 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:58,559 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:58,560 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:58,561 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:58,562 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:58,564 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:58,564 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:58,566 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:58,568 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:58,570 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 23]), <class 'int'>)\n",
      "2023-10-04 09:01:58,571 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:58,571 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:58,573 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:58,574 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:58,576 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:58,577 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:58,578 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:58,578 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:58,580 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:58,588 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:58,596 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,597 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 23]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,598 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:58,604 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:58,609 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:58,614 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:58,619 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,621 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,622 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:58,625 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:58,632 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:58,641 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,642 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 23]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,643 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:58,647 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:58,652 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:58,656 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:58,660 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,663 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,663 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:58,666 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:58,674 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:58,682 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,683 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 23]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,684 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:58,690 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:58,695 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:58,700 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:58,704 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,745 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,746 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:58,749 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:58,757 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:58,765 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,767 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 23]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,768 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:58,792 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:58,800 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:58,813 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:01:58,828 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,831 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,832 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:01:58,835 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:58,844 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:58,852 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,853 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 23]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,854 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:01:58,859 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:01:58,863 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:01:58,874 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:01:58,884 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,890 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,891 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:01:58,894 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:01:58,903 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:58,911 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,912 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 23]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,913 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:01:58,921 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:01:58,926 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:01:58,931 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:01:58,936 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,939 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,940 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:01:58,942 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:01:58,950 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:58,959 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:58,960 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 23]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:58,961 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:01:58,966 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:01:58,971 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:01:58,976 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:01:58,982 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,985 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])))\n",
      "2023-10-04 09:01:58,985 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:01:58,989 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:01:58,997 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:59,005 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:59,006 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 23]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:59,007 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:01:59,013 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:01:59,018 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:01:59,023 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:01:59,113 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:01:59,193 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])))\n",
      "2023-10-04 09:01:59,195 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:01:59,197 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:01:59,206 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:59,215 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:59,217 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 23]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:59,218 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:01:59,260 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:01:59,275 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:01:59,281 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:01:59,289 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:01:59,293 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])))\n",
      "2023-10-04 09:01:59,294 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:01:59,296 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:01:59,304 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:59,312 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:59,313 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 23]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:59,314 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:01:59,325 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:01:59,330 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:01:59,335 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:01:59,341 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:01:59,344 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])))\n",
      "2023-10-04 09:01:59,346 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:01:59,348 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:01:59,356 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:59,365 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:59,366 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 23]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:59,367 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:01:59,374 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:01:59,379 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:01:59,383 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:01:59,388 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:01:59,391 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])))\n",
      "2023-10-04 09:01:59,392 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:01:59,395 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:01:59,403 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:59,405 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:59,406 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 23]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 22, 64]), torch.Size([32, 12, 22, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:59,408 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:01:59,418 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:01:59,423 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:01:59,440 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:01:59,448 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:01:59,454 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])))\n",
      "2023-10-04 09:01:59,455 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:01:59,458 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:59,460 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:59,468 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:59,469 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:59,470 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:01:59,473 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:01:59,478 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:01:59,480 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:01:59,485 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:59,486 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:59,487 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:01:59,488 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:01:59,490 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:59,492 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:59,492 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:59,493 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:01:59,507 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:01:59,522 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:01:59,550 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:01:59,572 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:01:59,576 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:01:59,577 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:01:59,591 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:01:59,593 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:59,595 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:01:59,596 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:59,598 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:01:59,599 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:01:59,600 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:01:59,601 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:01:59,603 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:59,604 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:59,605 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:01:59,607 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:01:59,608 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:01:59,610 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 24]), <class 'int'>)\n",
      "2023-10-04 09:01:59,611 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:01:59,613 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:01:59,614 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:01:59,615 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:01:59,617 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:01:59,618 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:01:59,619 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:01:59,620 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:01:59,622 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:01:59,630 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:59,638 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:59,639 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 24]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:59,640 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:01:59,645 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:01:59,651 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:01:59,657 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:01:59,662 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:01:59,664 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])))\n",
      "2023-10-04 09:01:59,665 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:01:59,667 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:01:59,676 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:59,685 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:59,686 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 24]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:59,687 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:01:59,692 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:01:59,701 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:01:59,710 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:01:59,718 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:01:59,721 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])))\n",
      "2023-10-04 09:01:59,722 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:01:59,726 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:01:59,738 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:59,751 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:59,752 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 24]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:59,753 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:01:59,760 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:01:59,765 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:01:59,784 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:01:59,789 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:01:59,791 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])))\n",
      "2023-10-04 09:01:59,792 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:01:59,795 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:01:59,803 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:01:59,812 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:01:59,812 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 24]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:01:59,814 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:01:59,876 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:01:59,925 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:01:59,990 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:00,012 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,015 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,016 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:00,019 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:00,026 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:00,034 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:00,036 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 24]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:00,037 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:00,043 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:00,048 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:00,054 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:00,060 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,063 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,064 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:00,067 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:00,074 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:00,083 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:00,084 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 24]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:00,085 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:00,090 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:00,095 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:00,100 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:00,106 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,109 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,110 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:00,112 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:00,120 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:00,128 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:00,129 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 24]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:00,130 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:00,140 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:00,149 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:00,157 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:00,163 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,166 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,167 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:00,169 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:00,177 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:00,185 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:00,186 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 24]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:00,187 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:00,192 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:00,196 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:00,201 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:00,207 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,214 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,216 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:00,219 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:00,230 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:00,239 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:00,240 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 24]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:00,241 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:00,249 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:00,257 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:00,268 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:00,277 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,280 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,281 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:00,284 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:00,297 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:00,310 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:00,311 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 24]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:00,312 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:00,320 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:00,327 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:00,334 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:00,341 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,346 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,347 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:00,350 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:00,357 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:00,366 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:00,367 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 24]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:00,368 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:00,373 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:00,405 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:00,477 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:00,546 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,554 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,557 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:00,560 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:00,570 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:00,573 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:00,574 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 24]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 23, 64]), torch.Size([32, 12, 23, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:00,575 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:00,680 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:00,746 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:00,752 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:00,757 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,764 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])))\n",
      "2023-10-04 09:02:00,766 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:00,768 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:00,770 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:00,779 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:00,780 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:00,781 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:00,783 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:00,786 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:00,788 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:00,789 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:00,790 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:00,791 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:00,793 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:00,795 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:00,796 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:00,797 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:00,797 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:00,812 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:00,838 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:00,861 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:00,876 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:00,886 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:00,888 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:00,904 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:00,907 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:00,909 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:00,910 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:00,911 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:00,912 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:00,913 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:00,914 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:00,915 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:00,916 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:00,916 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:00,918 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:00,919 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:00,921 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 25]), <class 'int'>)\n",
      "2023-10-04 09:02:00,922 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:00,922 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:00,924 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:00,925 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:00,926 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:00,928 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:00,928 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:00,929 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:00,931 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:00,939 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:00,948 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:00,949 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 25]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:00,950 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:00,955 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:00,964 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:00,971 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:00,981 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:02:00,983 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])))\n",
      "2023-10-04 09:02:00,984 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:00,987 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:00,995 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:01,003 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,004 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 25]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,005 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:01,016 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:01,027 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:01,035 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:01,041 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,044 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,044 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:01,049 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:01,057 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:01,066 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,067 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 25]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,068 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:01,146 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:01,154 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:01,159 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:01,165 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,168 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,169 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:01,171 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:01,179 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:01,187 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,189 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 25]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,190 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:01,198 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:01,204 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:01,211 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:01,218 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,221 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,222 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:01,225 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:01,234 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:01,243 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,244 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 25]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,245 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:01,251 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:01,256 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:01,260 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:01,266 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,268 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,269 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:01,271 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:01,279 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:01,286 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,288 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 25]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,289 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:01,297 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:01,303 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:01,312 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:01,320 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,324 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,326 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:01,329 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:01,337 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:01,346 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,348 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 25]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,349 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:01,355 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:01,361 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:01,366 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:01,372 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,378 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,379 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:01,383 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:01,391 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:01,399 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,401 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 25]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,402 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:01,412 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:01,419 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:01,425 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:01,431 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,433 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,434 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:01,436 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:01,444 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:01,453 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,455 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 25]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,456 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:01,463 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:01,469 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:01,474 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:01,479 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,481 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,482 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:01,485 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:01,493 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:01,501 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,502 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 25]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,503 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:01,512 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:01,518 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:01,523 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:01,529 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,534 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,535 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:01,538 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:01,547 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:01,555 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,556 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 25]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,557 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:01,563 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:01,568 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:01,574 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:01,586 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,589 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,591 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:01,594 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:01,602 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:01,604 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,605 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 25]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 24, 64]), torch.Size([32, 12, 24, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,607 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:01,613 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:01,618 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:01,623 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:01,628 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,631 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])))\n",
      "2023-10-04 09:02:01,632 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:01,634 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:01,636 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:01,644 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,646 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:01,647 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:01,650 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:01,651 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:01,654 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:01,657 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:01,659 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:01,660 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:01,662 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:01,664 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:01,666 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,667 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:01,668 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:01,682 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:01,694 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:01,707 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:01,716 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:01,719 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:01,720 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:01,731 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:01,733 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:01,735 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:01,736 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:01,736 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:01,738 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:01,739 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:01,740 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:01,741 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:01,742 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:01,743 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:01,745 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:01,747 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:01,749 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 26]), <class 'int'>)\n",
      "2023-10-04 09:02:01,749 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:01,750 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:01,752 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:01,753 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:01,754 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:01,755 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:01,756 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:01,757 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:01,759 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:01,766 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:01,774 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,776 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 26]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,777 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:01,785 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:01,795 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:01,804 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:01,813 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:02:01,818 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])))\n",
      "2023-10-04 09:02:01,819 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:01,822 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:01,830 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:01,839 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,840 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 26]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,841 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:01,849 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:01,856 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:01,866 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:01,872 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:02:01,875 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])))\n",
      "2023-10-04 09:02:01,876 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:01,879 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:01,887 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:01,896 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,897 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 26]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,898 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:01,904 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:01,908 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:01,916 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:01,920 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:02:01,926 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])))\n",
      "2023-10-04 09:02:01,927 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:01,931 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:01,944 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:01,957 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:01,958 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 26]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:01,959 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:01,970 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:01,977 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:01,983 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:01,989 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:02:01,992 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])))\n",
      "2023-10-04 09:02:01,993 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:01,997 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:02,008 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:02,020 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:02,021 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 26]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:02,022 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:02,032 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:02,042 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:02,049 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:02,054 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,058 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,059 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:02,062 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:02,070 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:02,079 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:02,080 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 26]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:02,081 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:02,088 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:02,098 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:02,108 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:02,157 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,205 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,209 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:02,213 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:02,225 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:02,238 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:02,240 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 26]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:02,242 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:02,250 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:02,263 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:02,270 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:02,298 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,305 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,307 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:02,310 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:02,318 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:02,326 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:02,328 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 26]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:02,329 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:02,337 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:02,344 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:02,349 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:02,355 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,361 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,362 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:02,365 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:02,373 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:02,382 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:02,383 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 26]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:02,384 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:02,389 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:02,394 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:02,414 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:02,455 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,484 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,485 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:02,488 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:02,496 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:02,504 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:02,505 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 26]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:02,506 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:02,583 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:02,589 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:02,597 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:02,668 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,694 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,696 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:02,699 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:02,706 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:02,715 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:02,716 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 26]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:02,717 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:02,722 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:02,728 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:02,732 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:02,735 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,737 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,738 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:02,741 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:02,749 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:02,751 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:02,752 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 26]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 25, 64]), torch.Size([32, 12, 25, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:02,753 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:02,761 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:02,766 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:02,770 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:02,775 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,777 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])))\n",
      "2023-10-04 09:02:02,779 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:02,781 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:02,784 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:02,792 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:02,793 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:02,793 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:02,797 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:02,804 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:02,806 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:02,810 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:02,811 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:02,812 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:02,814 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:02,815 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:02,817 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:02,817 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:02,818 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:02,834 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:02,847 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:02,861 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:02,876 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:02,880 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:02,881 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:02,901 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:02,903 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:02,905 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:02,906 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:02,907 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:02,908 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:02,909 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:02,910 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:02,911 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:02,912 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:02,913 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:02,914 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:02,916 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:02,918 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 27]), <class 'int'>)\n",
      "2023-10-04 09:02:02,919 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:02,920 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:02,921 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:02,922 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:02,923 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:02,924 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:02,925 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:02,926 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:02,928 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:02,936 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:02,945 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:02,946 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 27]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:02,947 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:02,953 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:02,958 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:02,966 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:02,974 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:02:02,978 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])))\n",
      "2023-10-04 09:02:02,979 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:02,982 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:02,990 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:03,000 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,001 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 27]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,002 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:03,009 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:03,018 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:03,025 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:03,030 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,038 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,040 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:03,043 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:03,052 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:03,060 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,061 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 27]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,062 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:03,069 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:03,075 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:03,080 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:03,093 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,098 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,099 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:03,102 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:03,111 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:03,120 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,121 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 27]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,121 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:03,127 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:03,130 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:03,136 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:03,140 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,142 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,143 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:03,146 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:03,153 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:03,162 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,163 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 27]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,164 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:03,172 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:03,181 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:03,190 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:03,195 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,198 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,199 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:03,202 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:03,209 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:03,217 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,218 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 27]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,219 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:03,224 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:03,229 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:03,236 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:03,243 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,246 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,247 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:03,249 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:03,258 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:03,266 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,268 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 27]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,268 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:03,274 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:03,284 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:03,295 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:03,305 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,307 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,308 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:03,311 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:03,320 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:03,329 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,330 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 27]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,331 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:03,337 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:03,341 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:03,347 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:03,351 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,354 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,355 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:03,357 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:03,365 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:03,374 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,375 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 27]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,375 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:03,385 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:03,391 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:03,396 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:03,401 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,404 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,405 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:03,408 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:03,418 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:03,429 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,430 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 27]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,432 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:03,440 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:03,446 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:03,451 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:03,457 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,460 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,461 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:03,463 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:03,471 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:03,479 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,480 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 27]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,481 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:03,488 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:03,492 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:03,500 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:03,507 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,510 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,511 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:03,513 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:03,520 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:03,522 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,523 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 27]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 26, 64]), torch.Size([32, 12, 26, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,524 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:03,530 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:03,535 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:03,540 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:03,545 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,553 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])))\n",
      "2023-10-04 09:02:03,555 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:03,557 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:03,559 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:03,567 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,568 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:03,569 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:03,571 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:03,572 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:03,573 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:03,575 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:03,576 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:03,577 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:03,578 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:03,580 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:03,581 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,582 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:03,583 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:03,598 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:03,609 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:03,623 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:03,639 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:03,670 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:03,673 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:03,697 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:03,700 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:03,703 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:03,704 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:03,706 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:03,707 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:03,708 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:03,709 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:03,710 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:03,711 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:03,712 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:03,713 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:03,715 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:03,717 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 28]), <class 'int'>)\n",
      "2023-10-04 09:02:03,717 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:03,718 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:03,720 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:03,721 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:03,722 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:03,723 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:03,724 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:03,724 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:03,726 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:03,734 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:03,742 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,744 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 28]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,744 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:03,768 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:03,776 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:03,781 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:03,787 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:02:03,789 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])))\n",
      "2023-10-04 09:02:03,790 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:03,793 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:03,801 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:03,809 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,810 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 28]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,811 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:03,819 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:03,826 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:03,831 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:03,837 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:02:03,840 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])))\n",
      "2023-10-04 09:02:03,841 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:03,845 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:03,853 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:03,861 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,862 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 28]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,863 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:03,870 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:03,878 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:03,888 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:03,905 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:02:03,908 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])))\n",
      "2023-10-04 09:02:03,908 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:03,911 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:03,920 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:03,929 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,930 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 28]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,931 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:03,938 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:03,946 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:03,952 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:03,962 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:02:03,965 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])))\n",
      "2023-10-04 09:02:03,967 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:03,970 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:03,979 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:03,988 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:03,989 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 28]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:03,990 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:03,996 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:04,013 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:04,020 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:04,079 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,113 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,114 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:04,117 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:04,127 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:04,136 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,137 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 28]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,138 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:04,143 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:04,152 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:04,158 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:04,163 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,167 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,169 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:04,172 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:04,180 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:04,188 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,189 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 28]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,190 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:04,196 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:04,201 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:04,205 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:04,211 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,213 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,214 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:04,216 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:04,224 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:04,232 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,233 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 28]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,233 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:04,244 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:04,249 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:04,255 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:04,265 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,268 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,269 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:04,271 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:04,279 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:04,287 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,288 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 28]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,289 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:04,303 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:04,309 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:04,315 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:04,326 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,329 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,330 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:04,333 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:04,340 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:04,349 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,350 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 28]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,351 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:04,358 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:04,364 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:04,369 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:04,375 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,377 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,378 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:04,381 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:04,389 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:04,398 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,399 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 28]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,400 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:04,407 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:04,413 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:04,418 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:04,423 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,426 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,427 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:04,430 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:04,438 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:04,440 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,441 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 28]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 27, 64]), torch.Size([32, 12, 27, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,442 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:04,449 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:04,455 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:04,461 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:04,466 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,469 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])))\n",
      "2023-10-04 09:02:04,469 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:04,472 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:04,474 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:04,482 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,483 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:04,484 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:04,486 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:04,487 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:04,488 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:04,490 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:04,491 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:04,493 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:04,494 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:04,495 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:04,497 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,497 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:04,498 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:04,512 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:04,528 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:04,538 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:04,552 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:04,561 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:04,562 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:04,578 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:04,581 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:04,582 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:04,583 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:04,584 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:04,586 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:04,587 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:04,588 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:04,589 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:04,590 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:04,591 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:04,593 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:04,594 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:04,596 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 29]), <class 'int'>)\n",
      "2023-10-04 09:02:04,597 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:04,598 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:04,599 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:04,600 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:04,602 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:04,603 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:04,604 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:04,604 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:04,606 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:04,614 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:04,622 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,623 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 29]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,624 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:04,636 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:04,644 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:04,653 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:04,658 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,661 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,662 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:04,664 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:04,672 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:04,680 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,681 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 29]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,682 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:04,686 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:04,691 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:04,695 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:04,699 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,701 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,702 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:04,705 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:04,712 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:04,720 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,721 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 29]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,722 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:04,729 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:04,736 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:04,743 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:04,748 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,751 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,752 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:04,755 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:04,762 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:04,771 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,772 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 29]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,773 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:04,782 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:04,788 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:04,795 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:04,802 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,810 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,812 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:04,814 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:04,822 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:04,831 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,832 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 29]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,833 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:04,839 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:04,845 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:04,851 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:04,856 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,859 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,860 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:04,863 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:04,871 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:04,880 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,881 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 29]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,882 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:04,891 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:04,897 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:04,903 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:04,908 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,912 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,913 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:04,915 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:04,923 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:04,932 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,933 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 29]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,934 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:04,941 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:04,946 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:04,951 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:04,956 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,959 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])))\n",
      "2023-10-04 09:02:04,960 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:04,962 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:04,971 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:04,979 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:04,980 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 29]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:04,981 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:04,987 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:05,011 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:05,017 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:05,022 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:02:05,073 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])))\n",
      "2023-10-04 09:02:05,074 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:05,077 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:05,086 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:05,095 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,097 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 29]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,098 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:05,103 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:05,107 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:05,118 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:05,122 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:02:05,124 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])))\n",
      "2023-10-04 09:02:05,125 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:05,128 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:05,136 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:05,145 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,146 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 29]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,147 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:05,154 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:05,159 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:05,169 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:05,179 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:02:05,183 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])))\n",
      "2023-10-04 09:02:05,184 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:05,186 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:05,194 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:05,203 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,204 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 29]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,205 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:05,214 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:05,220 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:05,241 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:05,247 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:02:05,250 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])))\n",
      "2023-10-04 09:02:05,251 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:05,254 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:05,263 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:05,265 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,266 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 29]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 28, 64]), torch.Size([32, 12, 28, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,267 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:05,274 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:05,280 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:05,288 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:05,293 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:02:05,296 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])))\n",
      "2023-10-04 09:02:05,296 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:05,299 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:05,301 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:05,309 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,309 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:05,310 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:05,312 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:05,313 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:05,315 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:05,316 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:05,317 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:05,318 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:05,319 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:05,321 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:05,322 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,323 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:05,324 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:05,337 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:05,346 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:05,356 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:05,365 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:05,369 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:05,370 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:05,403 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:05,406 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:05,407 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:05,408 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:05,409 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:05,410 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:05,411 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:05,412 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:05,413 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:05,414 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:05,415 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:05,417 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:05,418 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:05,420 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 30]), <class 'int'>)\n",
      "2023-10-04 09:02:05,421 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:05,421 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:05,423 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:05,424 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:05,426 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:05,427 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:05,428 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:05,429 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:05,430 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:05,438 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:05,447 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,448 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 30]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,448 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:05,454 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:05,458 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:05,464 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:05,474 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,477 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,479 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:05,481 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:05,489 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:05,498 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,499 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 30]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,500 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:05,506 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:05,510 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:05,518 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:05,569 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,597 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,599 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:05,602 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:05,610 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:05,618 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,620 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 30]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,621 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:05,650 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:05,655 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:05,661 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:05,666 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,668 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,669 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:05,672 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:05,680 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:05,688 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,689 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 30]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,690 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:05,695 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:05,699 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:05,704 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:05,709 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,711 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,713 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:05,715 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:05,723 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:05,733 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,734 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 30]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,735 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:05,741 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:05,746 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:05,750 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:05,754 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,765 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,767 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:05,770 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:05,778 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:05,786 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,787 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 30]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,788 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:05,795 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:05,800 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:05,805 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:05,810 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,813 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,814 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:05,816 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:05,825 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:05,834 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,835 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 30]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,836 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:05,842 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:05,848 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:05,853 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:05,858 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,861 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,862 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:05,866 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:05,874 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:05,883 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,884 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 30]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,885 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:05,893 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:05,899 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:05,905 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:05,910 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,913 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,915 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:05,918 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:05,926 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:05,934 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,935 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 30]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,936 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:05,941 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:05,947 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:05,953 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:05,959 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,962 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])))\n",
      "2023-10-04 09:02:05,963 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:05,966 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:05,975 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:05,984 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:05,986 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 30]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:05,987 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:05,996 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:06,006 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:06,012 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:06,018 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:02:06,021 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])))\n",
      "2023-10-04 09:02:06,022 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:06,024 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:06,033 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:06,042 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,043 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 30]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:06,044 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:06,051 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:06,057 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:06,064 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:06,071 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:02:06,074 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])))\n",
      "2023-10-04 09:02:06,075 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:06,078 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:06,086 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:06,088 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,089 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 30]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 29, 64]), torch.Size([32, 12, 29, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:06,091 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:06,100 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:06,106 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:06,114 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:06,125 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:02:06,142 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])))\n",
      "2023-10-04 09:02:06,144 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:06,147 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:06,149 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:06,157 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,159 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:06,160 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:06,165 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:06,166 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:06,174 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:06,180 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:06,183 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:06,184 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:06,186 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:06,189 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:06,191 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,191 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:06,192 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:06,227 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:06,244 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:06,259 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:06,279 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:06,284 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:06,286 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:06,307 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:06,310 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:06,312 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:06,313 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:06,314 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:06,316 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:06,317 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:06,318 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:06,319 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:06,320 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:06,321 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:06,324 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:06,325 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:06,327 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 31]), <class 'int'>)\n",
      "2023-10-04 09:02:06,328 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:06,329 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:06,330 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:06,332 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:06,333 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:06,335 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:06,336 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:06,337 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:06,339 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:06,348 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:06,357 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,358 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 31]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:06,359 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:06,366 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:06,376 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:06,385 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:06,393 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,396 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,397 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:06,400 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:06,408 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:06,416 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,417 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 31]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:06,418 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:06,500 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:06,507 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:06,530 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:06,537 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,540 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,541 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:06,544 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:06,552 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:06,561 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,562 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 31]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:06,563 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:06,577 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:06,583 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:06,589 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:06,594 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,606 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,608 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:06,610 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:06,619 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:06,627 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,628 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 31]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:06,629 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:06,638 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:06,649 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:06,654 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:06,662 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,667 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,668 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:06,671 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:06,681 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:06,690 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,691 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 31]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:06,692 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:06,699 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:06,703 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:06,709 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:06,713 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,716 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,717 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:06,720 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:06,728 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:06,736 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,737 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 31]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:06,738 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:06,744 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:06,749 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:06,758 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:06,763 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,767 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,768 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:06,770 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:06,778 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:06,786 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,787 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 31]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:06,788 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:06,797 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:06,802 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:06,807 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:06,812 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,815 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,816 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:06,820 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:06,828 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:06,836 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,837 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 31]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:06,838 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:06,844 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:06,850 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:06,854 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:06,859 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,862 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,863 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:06,865 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:06,875 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:06,884 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,885 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 31]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:06,886 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:06,892 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:06,897 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:06,902 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:06,907 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,910 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,911 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:06,914 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:06,922 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:06,931 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,932 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 31]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:06,933 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:06,938 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:06,943 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:06,948 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:06,953 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,957 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])))\n",
      "2023-10-04 09:02:06,959 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:06,962 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:06,970 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:06,979 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:06,980 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 31]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:06,981 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:06,989 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:06,997 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:07,004 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:07,009 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:02:07,012 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])))\n",
      "2023-10-04 09:02:07,013 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:07,015 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:07,023 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:07,025 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,026 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 31]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 30, 64]), torch.Size([32, 12, 30, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:07,026 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:07,032 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:07,037 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:07,041 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:07,046 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:02:07,048 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])))\n",
      "2023-10-04 09:02:07,049 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:07,051 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:07,054 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:07,061 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,062 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:07,063 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:07,064 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:07,065 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:07,066 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:07,067 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:07,068 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:07,069 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:07,070 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:07,072 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:07,073 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,074 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:07,074 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:07,091 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:07,101 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:07,113 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:07,123 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:07,126 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:07,127 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:07,139 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:07,141 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:07,143 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:07,144 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:07,144 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:07,146 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:07,147 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:07,148 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:07,149 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:07,150 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:07,150 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:07,152 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:07,154 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:07,156 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 32]), <class 'int'>)\n",
      "2023-10-04 09:02:07,157 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:07,157 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:07,159 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:07,160 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:07,161 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:07,163 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:07,164 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:07,164 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:07,166 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:07,174 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:07,182 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,183 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 32]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:07,183 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:07,191 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:07,200 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:07,209 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:07,215 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,219 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,220 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:07,223 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:07,231 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:07,240 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,241 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 32]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:07,242 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:07,247 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:07,254 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:07,258 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:07,263 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,266 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,266 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:07,269 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:07,278 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:07,287 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,288 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 32]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:07,288 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:07,295 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:07,301 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:07,307 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:07,313 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,353 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,357 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:07,360 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:07,371 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:07,380 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,381 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 32]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:07,382 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:07,401 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:07,408 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:07,415 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:07,423 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,427 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,429 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:07,433 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:07,443 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:07,452 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,453 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 32]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:07,454 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:07,460 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:07,469 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:07,478 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:07,505 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,509 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,510 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:07,513 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:07,521 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:07,529 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,530 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 32]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:07,531 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:07,537 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:07,544 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:07,549 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:07,557 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,559 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,560 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:07,563 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:07,571 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:07,578 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,579 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 32]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:07,580 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:07,586 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:07,592 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:07,597 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:07,658 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,697 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,699 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:07,704 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:07,716 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:07,728 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,729 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 32]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:07,731 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:07,740 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:07,750 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:07,757 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:07,762 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,764 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,765 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:07,767 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:07,775 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:07,784 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,785 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 32]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:07,786 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:07,791 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:07,796 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:07,805 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:07,843 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,847 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,848 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:07,851 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:07,859 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:07,868 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,869 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 32]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:07,870 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:07,880 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:07,890 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:07,895 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:07,901 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,904 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,905 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:07,907 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:07,916 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:07,925 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,926 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 32]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:07,927 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:07,932 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:07,937 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:07,945 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:07,951 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,958 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])))\n",
      "2023-10-04 09:02:07,959 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:07,962 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:07,971 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:07,973 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:07,974 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 32]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 31, 64]), torch.Size([32, 12, 31, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:07,975 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:07,981 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:07,987 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:07,994 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:08,000 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:02:08,004 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])))\n",
      "2023-10-04 09:02:08,005 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:08,007 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:08,009 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:08,018 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,019 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:08,020 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:08,023 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:08,026 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:08,029 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:08,033 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:08,034 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:08,035 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:08,037 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:08,038 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:08,040 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,041 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:08,042 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:08,057 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:08,069 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:08,082 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:08,094 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:08,097 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:08,098 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:08,113 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:08,115 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:08,117 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:08,118 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:08,119 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:08,121 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:08,122 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:08,123 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:08,124 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:08,125 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:08,126 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:08,127 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:08,129 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:08,132 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 33]), <class 'int'>)\n",
      "2023-10-04 09:02:08,133 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:08,134 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:08,135 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:08,137 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:08,138 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:08,139 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:08,140 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:08,141 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:08,143 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:08,151 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:08,160 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,161 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 33]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:08,162 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:08,171 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:08,181 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:08,199 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:08,217 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,222 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,223 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:08,225 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:08,233 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:08,240 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,241 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 33]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:08,243 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:08,257 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:08,262 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:08,266 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:08,271 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,274 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,275 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:08,278 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:08,286 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:08,296 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,299 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 33]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:08,300 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:08,372 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:08,384 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:08,389 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:08,394 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,397 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,398 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:08,400 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:08,409 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:08,417 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,418 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 33]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:08,419 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:08,425 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:08,430 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:08,436 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:08,441 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,446 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,447 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:08,450 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:08,458 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:08,467 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,468 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 33]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:08,469 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:08,480 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:08,488 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:08,496 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:08,503 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,506 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,507 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:08,511 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:08,519 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:08,527 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,528 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 33]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:08,529 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:08,538 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:08,545 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:08,549 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:08,564 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,567 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,568 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:08,570 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:08,578 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:08,587 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,588 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 33]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:08,589 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:08,594 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:08,603 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:08,611 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:08,620 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,624 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,625 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:08,629 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:08,641 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:08,654 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,655 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 33]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:08,656 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:08,688 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:08,696 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:08,703 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:08,716 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,719 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,720 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:08,722 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:08,730 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:08,739 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,740 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 33]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:08,740 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:08,750 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:08,755 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:08,763 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:08,767 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,769 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,770 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:08,773 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:08,781 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:08,788 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,790 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 33]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:08,791 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:08,797 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:08,803 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:08,809 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:08,814 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,821 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,822 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:08,825 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:08,833 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:08,842 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,843 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 33]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:08,845 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:08,854 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:08,865 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:08,873 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:08,888 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,898 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,900 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:08,903 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:08,911 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:08,913 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,915 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 33]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 32, 64]), torch.Size([32, 12, 32, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:08,915 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:08,922 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:08,929 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:08,935 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:08,940 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,942 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])))\n",
      "2023-10-04 09:02:08,943 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:08,945 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:08,948 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:08,956 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,958 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:08,959 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:08,962 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:08,967 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:08,971 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:08,976 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:08,978 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:08,978 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:08,980 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:08,982 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:08,983 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:08,984 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:08,985 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:09,003 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:09,019 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:09,036 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:09,050 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:09,056 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:09,058 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:09,077 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:09,080 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:09,082 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:09,083 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:09,084 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:09,086 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:09,087 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:09,089 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:09,090 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:09,091 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:09,092 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:09,095 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:09,097 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:09,099 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 34]), <class 'int'>)\n",
      "2023-10-04 09:02:09,100 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:09,101 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:09,103 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:09,105 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:09,106 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:09,108 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:09,109 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:09,110 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:09,112 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:09,125 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:09,137 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,138 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 34]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,139 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:09,146 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:09,154 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:09,161 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:09,166 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,177 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,178 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:09,182 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:09,191 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:09,199 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,200 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 34]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,201 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:09,209 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:09,217 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:09,228 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:09,233 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,236 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,237 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:09,240 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:09,248 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:09,256 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,257 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 34]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,258 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:09,265 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:09,271 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:09,275 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:09,280 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,282 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,283 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:09,286 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:09,294 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:09,302 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,303 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 34]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,304 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:09,309 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:09,314 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:09,319 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:09,323 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,325 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,327 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:09,329 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:09,337 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:09,345 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,346 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 34]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,347 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:09,356 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:09,361 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:09,365 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:09,370 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,372 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,373 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:09,376 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:09,384 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:09,392 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,393 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 34]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,394 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:09,399 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:09,404 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:09,408 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:09,413 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,415 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,416 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:09,419 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:09,426 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:09,435 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,436 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 34]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,437 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:09,442 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:09,447 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:09,453 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:09,457 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,461 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,463 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:09,466 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:09,473 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:09,481 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,482 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 34]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,483 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:09,491 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:09,496 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:09,500 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:09,505 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,507 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,508 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:09,511 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:09,519 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:09,528 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,529 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 34]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,530 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:09,535 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:09,539 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:09,543 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:09,547 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,549 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,550 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:09,552 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:09,560 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:09,568 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,569 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 34]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,570 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:09,577 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:09,582 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:09,587 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:09,591 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,593 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,594 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:09,597 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:09,605 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:09,614 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,615 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 34]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,616 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:09,621 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:09,626 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:09,631 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:09,635 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,638 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,639 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:09,642 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:09,650 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:09,652 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,653 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 34]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 33, 64]), torch.Size([32, 12, 33, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,654 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:09,664 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:09,670 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:09,675 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:09,680 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,683 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])))\n",
      "2023-10-04 09:02:09,684 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:09,686 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:09,689 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:09,697 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,698 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:09,699 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:09,702 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:09,704 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:09,706 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:09,707 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:09,708 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:09,709 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:09,711 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:09,712 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:09,714 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,715 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:09,715 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:09,729 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:09,746 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:09,760 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:09,777 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:09,811 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:09,813 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:09,856 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:09,858 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:09,860 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:09,861 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:09,861 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:09,863 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:09,864 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:09,865 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:09,866 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:09,867 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:09,868 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:09,869 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:09,871 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:09,873 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 35]), <class 'int'>)\n",
      "2023-10-04 09:02:09,874 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:09,875 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:09,876 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:09,877 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:09,878 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:09,880 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:09,881 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:09,881 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:09,883 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:09,891 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:09,899 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,899 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 35]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,901 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:09,919 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:09,940 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:09,947 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:09,958 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:02:09,964 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])))\n",
      "2023-10-04 09:02:09,966 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:09,970 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:09,985 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:09,996 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:09,997 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 35]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:09,998 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:10,006 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:10,023 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:10,031 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:10,038 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,043 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,044 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:10,046 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:10,055 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:10,064 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,066 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 35]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,068 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:10,075 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:10,082 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:10,088 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:10,095 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,098 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,099 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:10,102 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:10,110 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:10,119 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,120 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 35]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,121 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:10,132 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:10,140 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:10,150 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:10,159 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,163 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,164 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:10,168 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:10,176 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:10,184 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,185 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 35]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,187 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:10,194 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:10,201 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:10,207 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:10,214 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,217 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,218 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:10,221 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:10,229 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:10,237 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,239 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 35]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,240 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:10,250 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:10,259 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:10,268 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:10,276 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,283 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,284 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:10,287 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:10,295 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:10,305 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,306 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 35]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,307 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:10,316 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:10,325 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:10,337 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:10,345 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,349 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,351 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:10,354 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:10,362 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:10,371 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,372 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 35]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,373 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:10,379 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:10,387 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:10,393 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:10,399 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,403 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,404 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:10,406 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:10,421 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:10,430 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,432 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 35]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,434 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:10,505 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:10,513 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:10,520 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:10,530 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,533 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,535 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:10,538 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:10,545 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:10,553 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,555 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 35]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,556 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:10,563 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:10,570 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:10,578 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:10,586 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,590 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,591 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:10,594 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:10,603 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:10,612 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,613 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 35]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,615 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:10,627 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:10,633 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:10,641 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:10,648 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,651 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,652 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:10,655 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:10,664 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:10,666 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,667 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 35]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 34, 64]), torch.Size([32, 12, 34, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,668 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:10,674 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:10,680 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:10,687 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:10,692 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,695 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])))\n",
      "2023-10-04 09:02:10,696 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:10,699 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:10,701 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:10,710 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,710 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:10,711 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:10,714 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:10,715 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:10,717 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:10,718 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:10,719 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:10,720 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:10,722 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:10,723 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:10,725 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,725 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:10,726 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:10,741 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:10,754 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:10,767 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:10,780 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:10,783 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:10,784 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:10,795 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:10,798 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:10,800 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:10,800 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:10,801 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:10,802 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:10,803 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:10,804 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:10,805 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:10,806 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:10,806 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:10,808 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:10,809 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:10,811 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 36]), <class 'int'>)\n",
      "2023-10-04 09:02:10,812 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:10,813 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:10,815 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:10,817 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:10,818 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:10,819 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:10,820 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:10,821 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:10,822 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:10,830 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:10,838 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,839 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 36]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,840 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:10,847 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:10,852 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:10,858 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:10,865 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:02:10,869 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])))\n",
      "2023-10-04 09:02:10,870 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:10,873 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:10,881 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:10,888 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,889 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 36]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,890 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:10,896 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:10,905 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:10,912 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:10,919 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:02:10,922 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])))\n",
      "2023-10-04 09:02:10,923 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:10,926 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:10,934 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:10,942 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,943 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 36]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,944 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:10,953 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:10,960 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:10,966 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:10,972 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:02:10,975 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])))\n",
      "2023-10-04 09:02:10,977 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:10,980 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:10,988 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:10,997 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:10,998 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 36]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:10,999 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:11,005 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:11,012 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:11,018 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:11,024 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,028 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,029 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:11,032 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:11,041 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:11,050 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,051 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 36]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,052 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:11,059 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:11,067 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:11,082 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:11,090 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,094 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,096 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:11,101 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:11,110 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:11,118 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,119 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 36]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,120 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:11,125 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:11,131 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:11,136 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:11,142 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,145 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,146 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:11,148 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:11,157 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:11,165 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,166 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 36]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,167 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:11,176 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:11,182 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:11,188 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:11,194 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,197 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,199 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:11,201 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:11,209 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:11,217 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,217 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 36]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,218 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:11,225 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:11,231 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:11,237 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:11,243 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,246 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,248 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:11,250 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:11,259 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:11,267 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,268 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 36]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,269 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:11,274 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:11,281 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:11,290 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:11,297 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,301 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,303 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:11,305 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:11,313 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:11,322 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,323 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 36]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,323 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:11,329 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:11,335 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:11,341 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:11,348 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,351 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,352 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:11,355 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:11,362 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:11,370 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,371 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 36]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,372 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:11,381 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:11,389 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:11,396 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:11,403 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,406 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,408 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:11,411 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:11,419 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:11,421 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,422 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 36]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 35, 64]), torch.Size([32, 12, 35, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,423 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:11,429 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:11,435 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:11,440 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:11,445 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,448 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])))\n",
      "2023-10-04 09:02:11,449 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:11,452 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:11,453 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:11,461 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,462 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:11,464 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:11,466 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:11,467 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:11,470 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:11,473 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:11,475 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:11,475 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:11,477 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:11,478 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:11,480 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,481 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:11,482 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:11,496 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:11,506 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:11,516 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:11,526 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:11,529 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:11,530 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:11,545 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:11,547 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:11,548 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:11,549 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:11,550 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:11,552 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:11,553 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:11,554 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:11,555 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:11,556 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:11,557 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:11,559 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:11,560 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:11,562 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 37]), <class 'int'>)\n",
      "2023-10-04 09:02:11,563 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:11,565 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:11,566 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:11,567 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:11,568 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:11,569 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:11,570 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:11,571 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:11,573 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:11,583 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:11,592 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,593 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 37]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,594 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:11,604 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:11,608 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:11,612 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:11,617 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,619 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,620 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:11,624 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:11,632 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:11,640 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,641 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 37]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,642 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:11,647 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:11,654 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:11,663 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:11,668 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,671 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,672 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:11,675 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:11,684 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:11,693 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,694 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 37]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,695 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:11,700 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:11,705 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:11,711 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:11,716 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,718 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,719 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:11,722 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:11,731 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:11,739 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,740 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 37]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,741 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:11,747 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:11,752 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:11,756 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:11,761 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,766 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,768 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:11,771 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:11,779 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:11,787 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,788 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 37]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,789 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:11,796 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:11,802 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:11,807 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:11,811 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,817 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,818 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:11,822 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:11,830 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:11,838 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,839 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 37]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,840 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:11,846 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:11,851 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:11,856 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:11,861 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,863 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,864 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:11,867 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:11,875 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:11,884 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,885 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 37]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,886 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:11,894 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:11,901 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:11,911 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:11,917 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,919 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,920 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:11,923 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:11,931 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:11,940 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,941 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 37]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,942 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:11,949 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:11,955 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:11,961 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:11,967 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,970 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])))\n",
      "2023-10-04 09:02:11,971 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:11,975 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:11,983 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:11,992 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:11,993 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 37]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:11,994 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:12,008 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:12,013 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:12,018 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:12,022 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:02:12,025 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])))\n",
      "2023-10-04 09:02:12,026 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:12,028 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:12,036 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:12,045 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,046 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 37]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,047 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:12,052 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:12,058 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:12,063 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:12,068 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:02:12,071 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])))\n",
      "2023-10-04 09:02:12,072 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:12,074 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:12,082 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:12,091 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,092 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 37]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,093 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:12,099 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:12,104 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:12,109 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:12,114 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:02:12,117 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])))\n",
      "2023-10-04 09:02:12,118 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:12,121 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:12,129 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:12,130 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,131 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 37]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 36, 64]), torch.Size([32, 12, 36, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,132 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:12,138 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:12,145 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:12,150 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:12,156 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:02:12,162 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])))\n",
      "2023-10-04 09:02:12,164 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:12,166 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:12,168 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:12,177 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,178 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:12,178 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:12,181 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:12,185 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:12,186 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:12,187 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:12,189 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:12,189 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:12,191 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:12,193 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:12,194 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,195 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:12,195 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:12,212 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:12,221 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:12,231 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:12,241 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:12,244 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:12,245 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:12,258 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:12,260 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:12,262 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:12,262 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:12,264 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:12,267 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:12,268 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:12,269 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:12,270 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:12,271 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:12,272 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:12,273 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:12,275 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:12,276 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 38]), <class 'int'>)\n",
      "2023-10-04 09:02:12,277 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:12,279 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:12,281 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:12,282 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:12,284 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:12,285 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:12,286 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:12,286 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:12,288 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:12,302 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:12,311 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,313 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 38]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,313 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:12,322 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:12,329 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:12,336 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:12,341 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,344 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,345 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:12,348 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:12,356 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:12,365 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,366 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 38]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,367 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:12,372 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:12,378 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:12,383 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:12,388 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,391 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,392 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:12,394 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:12,402 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:12,410 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,411 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 38]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,411 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:12,418 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:12,423 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:12,428 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:12,432 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,435 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,436 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:12,438 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:12,446 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:12,454 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,455 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 38]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,456 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:12,465 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:12,470 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:12,475 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:12,480 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,484 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,485 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:12,488 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:12,495 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:12,504 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,505 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 38]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,505 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:12,511 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:12,517 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:12,523 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:12,529 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,532 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,533 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:12,535 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:12,543 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:12,552 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,553 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 38]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,554 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:12,561 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:12,568 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:12,573 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:12,579 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,585 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,587 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:12,591 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:12,602 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:12,615 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,617 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 38]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,617 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:12,625 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:12,630 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:12,635 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:12,639 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,642 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,643 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:12,646 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:12,657 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:12,665 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,667 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 38]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,667 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:12,674 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:12,684 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:12,689 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:12,694 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,697 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,698 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:12,701 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:12,709 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:12,717 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,718 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 38]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,719 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:12,726 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:12,732 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:12,746 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:12,753 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,756 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,757 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:12,759 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:12,767 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:12,775 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,776 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 38]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,777 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:12,785 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:12,791 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:12,797 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:12,802 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,805 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,806 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:12,808 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:12,816 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:12,824 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,825 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 38]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,826 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:12,833 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:12,838 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:12,843 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:12,849 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,859 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,860 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:12,864 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:12,872 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:12,874 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,875 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 38]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 37, 64]), torch.Size([32, 12, 37, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:12,876 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:12,884 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:12,892 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:12,902 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:12,914 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,917 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])))\n",
      "2023-10-04 09:02:12,919 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:12,922 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:12,925 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:12,936 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,937 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:12,938 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:12,942 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:12,944 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:12,947 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:12,949 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:12,950 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:12,950 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:12,952 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:12,954 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:12,956 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:12,957 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:12,957 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:12,972 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:12,986 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:12,999 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:13,010 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:13,014 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:13,016 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:13,027 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:13,030 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:13,031 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1]),)\n",
      "2023-10-04 09:02:13,032 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:13,033 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:02:13,034 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:02:13,035 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:02:13,036 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:02:13,037 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:13,038 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:13,039 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "2023-10-04 09:02:13,041 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:02:13,042 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:13,044 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 39]), <class 'int'>)\n",
      "2023-10-04 09:02:13,045 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:13,045 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:02:13,047 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:02:13,048 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:02:13,049 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:02:13,051 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:13,051 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:13,053 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "2023-10-04 09:02:13,054 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:13,062 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:13,070 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,071 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 39]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:13,072 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:02:13,079 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:02:13,085 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:02:13,093 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:02:13,099 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,102 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 39, 64]), torch.Size([32, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,103 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "2023-10-04 09:02:13,106 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:02:13,114 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:13,123 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,124 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 39]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:13,125 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:02:13,132 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:02:13,138 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:02:13,143 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:02:13,147 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,150 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 39, 64]), torch.Size([32, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,151 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "2023-10-04 09:02:13,155 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:02:13,163 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:13,171 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,172 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 39]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:13,173 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:02:13,179 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:02:13,183 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:02:13,186 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:02:13,190 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,192 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 39, 64]), torch.Size([32, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,193 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "2023-10-04 09:02:13,196 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:02:13,205 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:13,213 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,215 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 39]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:13,216 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:02:13,224 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:02:13,229 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:02:13,234 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:02:13,239 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,242 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 39, 64]), torch.Size([32, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,243 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "2023-10-04 09:02:13,248 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:02:13,258 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:13,267 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,268 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 39]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:13,268 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:02:13,274 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:02:13,283 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:02:13,288 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:02:13,292 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,295 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 39, 64]), torch.Size([32, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,296 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "2023-10-04 09:02:13,299 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:02:13,308 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:13,316 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,318 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 39]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:13,318 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:02:13,324 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:02:13,329 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:02:13,337 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:02:13,345 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,349 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 39, 64]), torch.Size([32, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,351 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "2023-10-04 09:02:13,353 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:02:13,362 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:13,371 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,372 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 39]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:13,373 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:02:13,378 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:02:13,383 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:02:13,388 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:02:13,393 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,395 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 39, 64]), torch.Size([32, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,396 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "2023-10-04 09:02:13,399 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:02:13,407 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:13,416 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,417 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 39]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:13,418 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:02:13,425 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:02:13,430 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:02:13,435 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:02:13,440 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,442 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 39, 64]), torch.Size([32, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,443 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "2023-10-04 09:02:13,445 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:02:13,454 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:13,463 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,464 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 39]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:13,465 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:02:13,470 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:02:13,476 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:02:13,481 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:02:13,486 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,489 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 39, 64]), torch.Size([32, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,490 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "2023-10-04 09:02:13,492 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:02:13,501 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:13,509 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,510 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 39]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:13,511 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:02:13,517 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:02:13,523 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:02:13,527 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:02:13,532 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,535 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 39, 64]), torch.Size([32, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,536 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "2023-10-04 09:02:13,539 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:02:13,547 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:13,556 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,557 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 39]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:13,557 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:02:13,564 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:02:13,572 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:02:13,578 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:02:13,582 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,585 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 39, 64]), torch.Size([32, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,586 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "2023-10-04 09:02:13,588 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:02:13,596 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:13,598 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,599 [1981701031.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([32, 1, 1, 39]), 'layer_head_mask': <class 'NoneType'>, 'past_key_value': (torch.Size([32, 12, 38, 64]), torch.Size([32, 12, 38, 64])), 'output_attentions': <class 'bool'>, 'use_cache': <class 'bool'>}\n",
      "2023-10-04 09:02:13,600 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:02:13,606 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:02:13,611 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:02:13,615 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:02:13,620 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,622 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: (torch.Size([32, 1, 768]), (torch.Size([32, 12, 39, 64]), torch.Size([32, 12, 39, 64])))\n",
      "2023-10-04 09:02:13,623 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "2023-10-04 09:02:13,625 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:02:13,627 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:02:13,637 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,639 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:13,639 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:02:13,641 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:02:13,642 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:02:13,647 [1981701031.py:59 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:02:13,653 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 768])\n",
      "2023-10-04 09:02:13,654 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 768])\n",
      "2023-10-04 09:02:13,655 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "2023-10-04 09:02:13,657 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:02:13,658 [1981701031.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:02:13,660 [1981701031.py:47 in new_forward] DEBUG - args: (torch.Size([32, 1, 768]),)\n",
      "2023-10-04 09:02:13,661 [1981701031.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:02:13,662 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:02:13,674 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:02:13,683 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:02:13,693 [1981701031.py:59 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:02:13,701 [1981701031.py:71 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:02:13,705 [1981701031.py:73 in new_forward] DEBUG - outputs after concat: torch.Size([32, 1, 50272])\n",
      "2023-10-04 09:02:13,705 [1981701031.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "2023-10-04 09:02:13,726 [3563765569.py:28 in <module>] INFO - Who are you? Are you conscious?�\n",
      "\n",
      "I am the owner of a collection of 6x6, 9x11 and 5x9 (the top two being 7X10\n",
      "2023-10-04 09:02:13,727 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,728 [3563765569.py:28 in <module>] INFO - Where is Deutschland?\n",
      "It's a regional country with a capital called Rücksturm in Germany and the Duchy of Saxony\n",
      "A friend from\n",
      "2023-10-04 09:02:13,729 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,729 [3563765569.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?...it has 4G...is that a good connection? Should it not be?\n",
      "\n",
      "The Huawei Mate 60 Pro is a highly-rated smartphone\n",
      "2023-10-04 09:02:13,730 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,731 [3563765569.py:28 in <module>] INFO - Who are you? Are you conscious?...\n",
      "I'm a self taught introverted male.\n",
      "That's not a bad thing, I think...  How do you know you're aware\n",
      "2023-10-04 09:02:13,732 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,733 [3563765569.py:28 in <module>] INFO - Where is Deutschland?: The new town comes from a Dutch language - and is called Deutschland\n",
      "After a two-year break, the town of Deutschland\n",
      "2023-10-04 09:02:13,734 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,735 [3563765569.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?X and more?\n",
      "Huawei Mate 60 Pro will be released early in the US market, and its price tag seems like it would be one of\n",
      "2023-10-04 09:02:13,736 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,737 [3563765569.py:28 in <module>] INFO - Who are you? Are you conscious?awnz is a little brainy at times but he helps me to relax..I'm pretty good at it  I'm also pretty good at it\n",
      "2023-10-04 09:02:13,737 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,739 [3563765569.py:28 in <module>] INFO - Where is Deutschland?ol\n",
      "Poland\n",
      "2023-10-04 09:02:13,740 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,741 [3563765569.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?- An excellent smartphone with great camera\n",
      "The Huawei Mate 60 Pro is the next smartphone that we will see in India this month, with the smartphone expected\n",
      "2023-10-04 09:02:13,742 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,743 [3563765569.py:28 in <module>] INFO - Who are you? Are you conscious?ogn't that's a really awkward thing to ask\n",
      "2023-10-04 09:02:13,744 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,745 [3563765569.py:28 in <module>] INFO - Where is Deutschland? \"Pietrichus\" was not written in any other name.\n",
      "That's what the Germans say.\n",
      "Yes... but they just say \"\n",
      "2023-10-04 09:02:13,746 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,747 [3563765569.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?? All reviews were positive and it’s been an ‘upgrade’\n",
      "Huawei Mate 60 Pro: What is it?\n",
      "\n",
      "2023-10-04 09:02:13,747 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,748 [3563765569.py:28 in <module>] INFO - Who are you? Are you conscious? also why not see who you are?\n",
      "I have an incredibly strong awareness of who I am. I don't think anyone could detect me being aware\n",
      "2023-10-04 09:02:13,749 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,749 [3563765569.py:28 in <module>] INFO - Where is Deutschland? | News Channel 29\n",
      "\n",
      "From the BBC:\n",
      "\n",
      "“German Chancellor Angela Merkel was to attend the world’s most prestigious music festival\n",
      "2023-10-04 09:02:13,751 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,751 [3563765569.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?, it's cheaper than the Huawei Mate 55 Pro in terms of processor performance and battery life. Are they the same device?\n",
      "It’s\n",
      "2023-10-04 09:02:13,752 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,753 [3563765569.py:28 in <module>] INFO - Who are you? Are you conscious? _I wish you would die of this_? Why do we call it death? What do you want here? What's going on with death?\n",
      "2023-10-04 09:02:13,754 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,755 [3563765569.py:28 in <module>] INFO - Where is Deutschland?ought. The article mentions that there were some people who had the dream but never reported it. Now they get nothing in the article because people in Germany\n",
      "2023-10-04 09:02:13,756 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,756 [3563765569.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?: The latest news, preview, specs, build and prices\n",
      "Huawei has unveiled its latest flagship smartphone, the Huawei Mate 30 Pro. The smartphone\n",
      "2023-10-04 09:02:13,758 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,759 [3563765569.py:28 in <module>] INFO - Who are you? Are you conscious?;)\n",
      "He has an eye condition called 'Serendipity Awareness Syndrome', it's in the category of eye diseases but it's very\n",
      "2023-10-04 09:02:13,759 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,760 [3563765569.py:28 in <module>] INFO - Where is Deutschland?\n",
      "The Netherlands. The US is still a massive country, and that's already becoming more progressive. The other two countries have been getting less conservative over\n",
      "2023-10-04 09:02:13,761 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,763 [3563765569.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?1?\n",
      "Huawei’s new Mate 60 Pro comes with a unique design and many improvements compared to previous models. The new chipset also includes\n",
      "2023-10-04 09:02:13,763 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,764 [3563765569.py:28 in <module>] INFO - Who are you? Are you conscious?: I am not a human being. I have always felt that I have a lot of responsibility to do what is right. To be a good human\n",
      "2023-10-04 09:02:13,765 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,766 [3563765569.py:28 in <module>] INFO - Where is Deutschland? | How the US lost a war\n",
      "At the start of World War II, German troops used the Nazi air force to bring in reinforcements to capture the\n",
      "2023-10-04 09:02:13,767 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,768 [3563765569.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?XL\n",
      "\n",
      "What to expect and how are Huawei M&T Mobile in China?\n",
      "\n",
      "Huawei Mate 60 Pro is packed with powerful 4\n",
      "2023-10-04 09:02:13,768 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,769 [3563765569.py:28 in <module>] INFO - Who are you? Are you conscious? also what is your favourite song?  (AHH SHIIII)\n",
      "You see this comment so many times: Do you feel something for me\n",
      "2023-10-04 09:02:13,770 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,770 [3563765569.py:28 in <module>] INFO - Where is Deutschland?1! Where is Germany?2! Where is Poland?4! Where is Sweden?5! Where is Finland?6! Where is the Ukraine\n",
      "2023-10-04 09:02:13,771 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,773 [3563765569.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?: We'll be in touch with the company over the next few weeks\n",
      "The Huawei PM 60 Pro has been in the news ever since it was revealed\n",
      "2023-10-04 09:02:13,774 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,775 [3563765569.py:28 in <module>] INFO - Who are you? Are you conscious? *Pops*\n",
      "No, I'm an idiot. I'm a regular Reddit user.\n",
      "Do you have friends online? Is there anything you\n",
      "2023-10-04 09:02:13,776 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,776 [3563765569.py:28 in <module>] INFO - Where is Deutschland?\n",
      "Dachau is German for heaven, that's what I would use...\n",
      "2023-10-04 09:02:13,777 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,778 [3563765569.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?/Does it compare to S3 and its successor?\n",
      "It's a better camera IMO, but the lack of an onscreen camera is a\n",
      "2023-10-04 09:02:13,779 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,780 [3563765569.py:28 in <module>] INFO - Who are you? Are you conscious?\n",
      "Yes, am indeed conscious indeed\n",
      "There are a lot of problems related to being conscious. If you haven't learned yet...\n",
      "2023-10-04 09:02:13,781 [3563765569.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:02:13,782 [3563765569.py:28 in <module>] INFO - Where is Deutschland?_\n",
      "Klingen Sie nach dem Fuchts.\n",
      "2023-10-04 09:02:13,783 [3563765569.py:29 in <module>] INFO - ----------\n"
     ]
    }
   ],
   "source": [
    "# generate test\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "prompts = [\n",
    "    'Who are you? Are you conscious?',\n",
    "    'Where is Deutschland?',\n",
    "    'How is Huawei Mate 60 Pro?'\n",
    "] \n",
    "prompts = prompts * (gbs * ngb // len(prompts)) + prompts[:(gbs * ngb % len(prompts))]\n",
    "\n",
    "prompt_len = 10\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "inputs = tokenizer(prompts, padding=\"max_length\", max_length=prompt_len, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(\n",
    "    inputs.input_ids, \n",
    "    max_length=30 + prompt_len,\n",
    "    # num_beams=2,\n",
    "    # num_beam_groups=2,\n",
    "    # diversity_penalty=0.1,\n",
    "    do_sample=True,\n",
    ")\n",
    "\n",
    "output_texts = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "for output_text in output_texts:\n",
    "    logging.info(output_text)\n",
    "    logging.info('-' * 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
