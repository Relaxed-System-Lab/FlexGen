{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fsuser/miniconda3/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2023-10-04 09:24:56,046 [instantiator.py:21 in <module>] INFO - Created a temporary directory at /tmp/tmp4n6pxhcv\n",
      "2023-10-04 09:24:56,048 [instantiator.py:76 in _write] INFO - Writing /tmp/tmp4n6pxhcv/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Module \n",
    "import functools \n",
    "\n",
    "from flexgen_utils import logging, Policy, get_module_from_name\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "from flexgen_init import policy_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:24:56,476 [connectionpool.py:1003 in _new_conn] DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2023-10-04 09:24:56,528 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-04 09:24:57.184272: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-04 09:24:58,188 [tpu_cluster_resolver.py:32 in <module>] DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2023-10-04 09:24:58,380 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5\n",
      "2023-10-04 09:24:58,382 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7\n",
      "2023-10-04 09:24:58,383 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5\n",
      "2023-10-04 09:24:58,383 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7\n",
      "2023-10-04 09:24:59,465 [flexgen_init.py:201 in get_policy_weight_map] INFO - device_map is prepared!\n",
      "2023-10-04 09:24:59,469 [flexgen_init.py:207 in get_policy_weight_map] INFO - CausalLM facebook/opt-125m is to be loaded on: \n",
      "GPU Mem 0.00 GiB (0.00%), CPU Mem 0.07 GiB (30.19%), Disk Mem 0.16 Gib (69.81%)\n",
      "2023-10-04 09:24:59,511 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-04 09:24:59,640 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-04 09:24:59,760 [flexgen_init.py:67 in policy_init] INFO - The whole model has been downloaded an processed to offload_folder: 'offload_dir/facebook.opt-125m'\n",
      "model init: loading by policy...:   0%|          | 0/197 [00:00<?, ?it/s]/home/fsuser/FlexGen/general/flexgen_utils/offload.py:41: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995026/work/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  tmp = torch.from_numpy(np_memmap).to(device)\n",
      "model init: loading by policy...: 100%|██████████| 197/197 [00:00<00:00, 2345.97it/s]\n",
      "2023-10-04 09:24:59,851 [flexgen_init.py:79 in policy_init] INFO - model has been loaded by policy.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"facebook/opt-125m\" # 125m 6.7b 13b 30b\n",
    "\n",
    "policy = Policy(\n",
    "    gpu_batch_size=2, \n",
    "    num_gpu_batches=4, \n",
    "    weights_gpu_percent=0.0, \n",
    "    weights_cpu_percent=0.3, \n",
    "    cache_gpu_percent=0.0, \n",
    "    cache_cpu_percent=0.2, \n",
    "    act_gpu_percent=0.0, \n",
    "    act_cpu_percent=0.5, \n",
    "    overlap=True, \n",
    "    pin_weight=True,\n",
    ")\n",
    "\n",
    "# for test\n",
    "gbs = policy.gpu_batch_size\n",
    "ngb = policy.num_gpu_batches\n",
    "num_prompts = ngb * gbs \n",
    "\n",
    "# model init\n",
    "output = policy_init(checkpoint, policy)\n",
    "\n",
    "model = output.model\n",
    "weight_map = output.weight_map\n",
    "layer_names = output.layer_names\n",
    "index = output.index\n",
    "dat_files = output.dat_files\n",
    "tied_params = output.tied_params\n",
    "offload_folder = output.offload_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:24:59,872 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.embed_tokens to flexgen forward\n",
      "2023-10-04 09:24:59,873 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.embed_positions to flexgen forward\n",
      "2023-10-04 09:24:59,874 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.final_layer_norm to flexgen forward\n",
      "2023-10-04 09:24:59,875 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.0 to flexgen forward\n",
      "2023-10-04 09:24:59,876 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.1 to flexgen forward\n",
      "2023-10-04 09:24:59,877 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.2 to flexgen forward\n",
      "2023-10-04 09:24:59,878 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.3 to flexgen forward\n",
      "2023-10-04 09:24:59,879 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.4 to flexgen forward\n",
      "2023-10-04 09:24:59,880 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.5 to flexgen forward\n",
      "2023-10-04 09:24:59,881 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.6 to flexgen forward\n",
      "2023-10-04 09:24:59,882 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.7 to flexgen forward\n",
      "2023-10-04 09:24:59,883 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.8 to flexgen forward\n",
      "2023-10-04 09:24:59,885 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.9 to flexgen forward\n",
      "2023-10-04 09:24:59,886 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.10 to flexgen forward\n",
      "2023-10-04 09:24:59,887 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.11 to flexgen forward\n",
      "2023-10-04 09:24:59,888 [2440752808.py:36 in to_flexgen_forward] DEBUG - lm_head to flexgen forward\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from accelerate.utils import named_module_tensors \n",
    "from flexgen_utils import get_tied_target\n",
    "from flexgen_utils import flexgen_load_module_tensor, flexgen_offload_module_tensor\n",
    "from flexgen_minibatch import get_size_info, get_kth_batch_inputs, concat_outputs\n",
    "\n",
    "def load_layer_weights(model, layer_name, compute_device, offload_folder, dat_files):\n",
    "    logger.debug(f'load_layer_weights: {layer_name} to {compute_device}')\n",
    "    layer_module = get_module_from_name(model, layer_name)\n",
    "    weight_names = [layer_name + '.' + name for name, _ in named_module_tensors(layer_module, True, True)]\n",
    "    layer_dat_files = [os.path.join(offload_folder, get_tied_target(w, tied_params, dat_files) + '.dat') for w in weight_names]\n",
    "    assert all([os.path.isfile(f) for f in layer_dat_files]), f'dat file error, {dat_files}'\n",
    "    \n",
    "    for w in weight_names:\n",
    "        flexgen_load_module_tensor(model, w, compute_device, index, offload_folder, tied_params)\n",
    "\n",
    "\n",
    "def offload_layer_weights(model, layer_name, weight_map):\n",
    "    logger.debug(f'offload_layer_weights: {layer_name}\\n\\n')\n",
    "    layer_module = get_module_from_name(model, layer_name)\n",
    "    weight_names = [layer_name + '.' + name for name, _ in named_module_tensors(layer_module, True, True)]\n",
    "    for w in weight_names:\n",
    "        flexgen_offload_module_tensor(model, w, weight_map) \n",
    "\n",
    "\n",
    "def to_flexgen_forward(model, layer_names, j, compute_device, weight_map, offload_folder, ngb, gbs):\n",
    "    # rewrite the j-th layer's forward\n",
    "    \n",
    "    layer_name = layer_names[j]\n",
    "    next_layer_name = layer_names[(j + 1) % len(layer_names)]\n",
    "\n",
    "    layer = get_module_from_name(model, layer_name)  \n",
    "    if hasattr(layer, \"_flexgen_old_forward\"): # has been rewriten\n",
    "        return layer \n",
    "    \n",
    "    logger.debug(f'{layer_name} to flexgen forward')\n",
    "    layer._flexgen_old_forward = old_forward = layer.forward \n",
    "\n",
    "    @functools.wraps(old_forward)\n",
    "    def new_forward(*args, **kwargs):\n",
    "        # pre fwd: load curr & next weights, TODO: cuda stream\n",
    "        load_layer_weights(model, layer_name, compute_device, offload_folder, dat_files)\n",
    "        load_layer_weights(model, next_layer_name, compute_device, offload_folder, dat_files)\n",
    "        \n",
    "        # loop forward pass of K minibatches, TODO: cuda stream\n",
    "        with torch.no_grad():\n",
    "            logger.debug(f'args: {get_size_info(args)}')\n",
    "            logger.debug(f'kwargs: {get_size_info(kwargs)}')\n",
    "            # output = old_forward(*args, **kwargs)\n",
    "            # logger.debug(f'output: {get_size_info(output)}')\n",
    "\n",
    "            args_0 = get_kth_batch_inputs(args, 0, gbs)\n",
    "            kwargs_0 = get_kth_batch_inputs(kwargs, 0, gbs)\n",
    "            logger.debug(f'args_0: {get_size_info(args_0)}')\n",
    "            logger.debug(f'kwargs_0: {get_size_info(kwargs_0)}')\n",
    "            # output_0 = old_forward(*args_0, **kwargs_0)\n",
    "            # logger.debug(f'output0: {get_size_info(output_0)}')\n",
    "\n",
    "            outputs = []\n",
    "            for k in range(ngb):\n",
    "                logger.debug(f'layer: {layer_name}, batch: {k}')\n",
    "\n",
    "                # 'pre' fwd: load curr & next inputs (activations, KV cache), store prev output\n",
    "                args_k = get_kth_batch_inputs(args, k, gbs)\n",
    "                kwargs_k = get_kth_batch_inputs(kwargs, k, gbs)\n",
    "\n",
    "                # the k-th fwd pass\n",
    "                output = old_forward(*args_k, **kwargs_k)\n",
    "                outputs.append(output) \n",
    "                \n",
    "                # 'post' fwd: offload curr inputs\n",
    "\n",
    "            logger.debug(f'outputs before concat: {ngb} x {get_size_info(outputs[0])}')\n",
    "            output = concat_outputs(outputs)\n",
    "            logger.debug(f'outputs after concat: {get_size_info(output)}')                \n",
    "\n",
    "        # post fwd: free curr weights\n",
    "        offload_layer_weights(model, layer_name, weight_map)\n",
    "        return output\n",
    "\n",
    "    layer.forward = new_forward\n",
    "    return layer\n",
    "\n",
    "\n",
    "def to_old_forward(model, layer_name):\n",
    "    layer = get_module_from_name(model, layer_name) \n",
    "\n",
    "    if hasattr(layer, \"_flexgen_old_forward\"):\n",
    "        layer.forward = layer._flexgen_old_forward\n",
    "        delattr(layer, \"_flexgen_old_forward\")\n",
    "        logger.debug(f'{layer_name} to old forward')\n",
    "    return layer\n",
    "\n",
    "\n",
    "layer_nums = len(layer_names)\n",
    "\n",
    "for j in range(layer_nums):\n",
    "    to_old_forward(model, layer_names[j])\n",
    "    \n",
    "# rewrite layers' forward\n",
    "for j in range(layer_nums):\n",
    "    compute_device = 'cpu'\n",
    "    to_flexgen_forward(model, layer_names, j, compute_device, weight_map, offload_folder, ngb, gbs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:24:59,935 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "/home/fsuser/miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1535: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on meta. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('meta') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "2023-10-04 09:25:00,129 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:00,130 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:00,132 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10]),)\n",
      "2023-10-04 09:25:00,132 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:00,133 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10]),)\n",
      "2023-10-04 09:25:00,134 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:00,135 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:00,137 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:00,138 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:00,139 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:00,140 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])\n",
      "2023-10-04 09:25:00,141 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])\n",
      "2023-10-04 09:25:00,141 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,144 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:00,145 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:00,147 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10]), 0)\n",
      "2023-10-04 09:25:00,148 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:00,149 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10]), 0)\n",
      "2023-10-04 09:25:00,149 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:00,150 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:00,152 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:00,153 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:00,155 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:00,156 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])\n",
      "2023-10-04 09:25:00,156 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])\n",
      "2023-10-04 09:25:00,157 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,159 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:00,168 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:00,175 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,176 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,177 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,178 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,179 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:00,230 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:00,255 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:00,261 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:00,266 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,268 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,269 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,271 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:00,279 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:00,287 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,288 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,289 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,290 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,291 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:00,297 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:00,302 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:00,308 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:00,319 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,322 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,323 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,328 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:00,341 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:00,354 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,356 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,357 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,358 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,359 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:00,367 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:00,374 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:00,381 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:00,388 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,389 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,390 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,394 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:00,402 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:00,410 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,411 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,412 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,412 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,413 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:00,421 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:00,426 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:00,430 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:00,434 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,435 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,436 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,439 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:00,446 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:00,454 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,455 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,456 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,457 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,457 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:00,469 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:00,476 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:00,481 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:00,485 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,487 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,488 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,490 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:00,498 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:00,506 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,506 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,508 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,509 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,509 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:00,516 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:00,521 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:00,525 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:00,530 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,532 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,533 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,535 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:00,543 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:00,551 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,552 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,553 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,554 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,555 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:00,563 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:00,570 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:00,575 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:00,580 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,582 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,583 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,585 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:00,593 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:00,601 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,602 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,603 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,604 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,605 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:00,615 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:00,622 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:00,628 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:00,633 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,635 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,636 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,640 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:00,649 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:00,656 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,657 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,658 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,659 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,659 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:00,668 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:00,678 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:00,682 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:00,687 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,688 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,689 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,692 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:00,699 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:00,706 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,707 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,708 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,709 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,710 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:00,741 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:00,746 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:00,750 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:00,754 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,755 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,756 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,759 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:00,767 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:00,774 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,775 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,776 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,777 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,778 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:00,783 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:00,787 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:00,791 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:00,797 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,799 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,799 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,802 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:00,810 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:00,812 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,812 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,813 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,814 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:00,815 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:00,821 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:00,828 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:00,834 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:00,838 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,839 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:25:00,840 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,843 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:00,844 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:00,852 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,853 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:00,854 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,855 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:00,856 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:00,860 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:00,862 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:00,866 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:00,870 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])\n",
      "2023-10-04 09:25:00,871 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])\n",
      "2023-10-04 09:25:00,871 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,873 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:00,874 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:00,876 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:25:00,877 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:00,878 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:25:00,878 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:00,879 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:00,898 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:00,908 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:00,919 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:00,930 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 50272])\n",
      "2023-10-04 09:25:00,936 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 50272])\n",
      "2023-10-04 09:25:00,938 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,951 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:00,953 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:00,955 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:00,956 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:00,957 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:00,966 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:00,967 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:00,968 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:00,969 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:00,970 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:00,971 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:00,972 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:00,973 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,975 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:00,977 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:00,979 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 11]), 10)\n",
      "2023-10-04 09:25:00,980 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:00,981 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 11]), 10)\n",
      "2023-10-04 09:25:00,981 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:00,982 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:00,984 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:00,985 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:00,986 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:00,987 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:00,988 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:00,989 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:00,990 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:00,999 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:01,008 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,009 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,010 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,011 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,012 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:01,019 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:01,056 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:01,073 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:01,077 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,078 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,079 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,082 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:01,090 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:01,099 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,100 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,101 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,102 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,103 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:01,108 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:01,112 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:01,116 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:01,119 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,121 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,121 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,124 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:01,132 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:01,140 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,141 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,142 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,143 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,144 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:01,153 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:01,158 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:01,161 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:01,166 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,167 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,168 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,171 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:01,179 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:01,188 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,189 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,189 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,191 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,192 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:01,196 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:01,202 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:01,206 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:01,210 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,211 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,212 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,215 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:01,223 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:01,233 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,234 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,234 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,235 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,236 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:01,243 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:01,247 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:01,252 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:01,255 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,257 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,258 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,260 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:01,269 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:01,278 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,279 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,280 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,281 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,282 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:01,287 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:01,291 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:01,296 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:01,302 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,303 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,304 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,306 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:01,314 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:01,322 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,323 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,324 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,325 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,326 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:01,332 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:01,336 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:01,340 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:01,344 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,346 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,347 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,349 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:01,358 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:01,369 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,369 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,371 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,372 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,373 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:01,380 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:01,384 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:01,389 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:01,393 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,395 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,396 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,398 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:01,406 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:01,415 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,415 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,416 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,417 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,418 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:01,424 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:01,429 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:01,433 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:01,437 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,439 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,440 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,442 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:01,450 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:01,459 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,459 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,460 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,461 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,462 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:01,468 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:01,477 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:01,481 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:01,485 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,487 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,487 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,490 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:01,498 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:01,507 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,507 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,508 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,509 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,510 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:01,515 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:01,519 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:01,523 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:01,531 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,533 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,534 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,537 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:01,545 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:01,547 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,548 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,548 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,550 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,550 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:01,558 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:01,562 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:01,566 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:01,571 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,573 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:25:01,574 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,576 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:01,578 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:01,587 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,588 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:01,589 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,590 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:01,590 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:01,594 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:01,598 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:01,602 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:01,606 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:01,606 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:01,608 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,609 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:01,611 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:01,613 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,614 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:01,615 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,616 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:01,617 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:01,629 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:01,639 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:01,653 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:01,661 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:01,664 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:01,665 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,675 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:01,677 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:01,679 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:01,680 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:01,681 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:01,682 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:01,683 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:01,684 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:01,685 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:01,686 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:01,687 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:01,688 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:01,689 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,690 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:01,692 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:01,694 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 12]), 11)\n",
      "2023-10-04 09:25:01,695 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:01,696 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 12]), 11)\n",
      "2023-10-04 09:25:01,697 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:01,698 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:01,699 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:01,701 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:01,703 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:01,705 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:01,706 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:01,707 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,709 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:01,717 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:01,725 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,726 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,727 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,728 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,729 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:01,736 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:01,739 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:01,743 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:01,746 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:25:01,748 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:25:01,749 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,752 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:01,760 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:01,767 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,768 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,769 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,770 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,771 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:01,781 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:01,785 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:01,789 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:01,800 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:25:01,802 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:25:01,803 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,805 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:25:01,814 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:01,822 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,823 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,824 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,825 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,826 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:01,832 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:01,840 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:01,844 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:01,848 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:25:01,849 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:25:01,850 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,852 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:01,860 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:01,868 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,869 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,870 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,870 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,871 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:01,879 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:01,884 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:01,888 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:01,891 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:25:01,894 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:25:01,895 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,898 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:01,906 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:01,915 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,916 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,917 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,918 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,918 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:01,923 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:01,928 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:01,937 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:01,941 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:25:01,942 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:25:01,943 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:01,946 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:01,954 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:01,962 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:01,963 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,964 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:01,965 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:01,966 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:01,975 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:01,980 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:02,018 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:02,025 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,027 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,029 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,032 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:02,044 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:02,056 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,057 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,058 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,059 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,060 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:02,065 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:02,068 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:02,071 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:02,076 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,078 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,079 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,082 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:02,091 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:02,099 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,100 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,101 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,102 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,103 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:02,111 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:02,122 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:02,136 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:02,141 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,143 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,144 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,148 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:02,156 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:02,165 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,166 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,167 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,167 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,169 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:02,174 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:02,182 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:02,187 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:02,194 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,197 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,198 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,201 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:02,214 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:02,222 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,223 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,224 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,226 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,227 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:02,233 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:02,241 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:02,246 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:02,250 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,251 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,252 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,256 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:02,265 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:02,274 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,275 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,277 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,278 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,279 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:02,289 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:02,305 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:02,313 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:02,319 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,321 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,322 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,325 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:02,333 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:02,334 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,335 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,336 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,337 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,338 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:02,348 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:02,352 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:02,355 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:02,361 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,362 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:25:02,363 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,366 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:02,368 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:02,377 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,378 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:02,379 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,380 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:02,381 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:02,384 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:02,386 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:02,389 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:02,390 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:02,392 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:02,393 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,394 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:02,396 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:02,397 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,398 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:02,399 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,400 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:02,401 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:02,412 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:02,421 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:02,430 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:02,439 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:02,444 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:02,445 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,453 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:02,455 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:02,456 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:02,457 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:02,458 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:02,459 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:02,460 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:02,461 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:02,462 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:02,463 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:02,464 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:02,465 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:02,465 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,467 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:02,469 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:02,470 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 13]), 12)\n",
      "2023-10-04 09:25:02,471 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:02,472 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 13]), 12)\n",
      "2023-10-04 09:25:02,473 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:02,474 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:02,475 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:02,477 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:02,478 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:02,479 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:02,480 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:02,481 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,483 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:02,490 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:02,498 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,500 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,501 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,502 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,502 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:02,510 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:02,517 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:02,523 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:02,527 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,528 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,529 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,532 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:02,540 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:02,549 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,550 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,551 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,552 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,553 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:02,561 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:02,566 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:02,570 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:02,574 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,575 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,576 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,579 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:02,588 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:02,596 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,598 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,599 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,599 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,600 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:02,605 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:02,613 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:02,617 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:02,624 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,628 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,629 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,632 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:02,640 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:02,648 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,649 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,650 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,651 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,652 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:02,660 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:02,667 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:02,675 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:02,683 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,686 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,687 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,689 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:02,698 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:02,707 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,708 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,709 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,709 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,710 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:02,717 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:02,722 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:02,725 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:02,730 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,731 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,732 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,735 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:02,743 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:02,751 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,752 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,753 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,753 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,754 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:02,764 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:02,768 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:02,772 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:02,775 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,776 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,777 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,780 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:02,788 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:02,798 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,799 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,800 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,801 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,803 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:02,810 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:02,815 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:02,819 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:02,823 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,825 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,825 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,829 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:02,837 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:02,845 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,846 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,847 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,848 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,849 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:02,854 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:02,860 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:02,866 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:02,871 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,874 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,874 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,877 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:02,884 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:02,893 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,894 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,895 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,896 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,897 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:02,904 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:02,908 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:02,915 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:02,919 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,920 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,921 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,924 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:02,934 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:02,943 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,944 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,945 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,946 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,947 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:02,953 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:02,959 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:02,965 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:02,969 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,970 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:25:02,972 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:02,974 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:02,983 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:02,991 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:02,992 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,994 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:02,995 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:02,996 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:03,002 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:03,008 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:03,014 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:03,018 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:25:03,020 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:25:03,021 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,024 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:03,033 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:03,035 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,036 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,037 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,038 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,039 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:03,047 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:03,054 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:03,058 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:03,061 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:25:03,063 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:25:03,064 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,067 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:03,069 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:03,078 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,079 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:03,080 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,081 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:03,082 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:03,085 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:03,088 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:03,092 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:03,096 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:03,099 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:03,100 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,102 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:03,104 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:03,106 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,106 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:03,107 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,108 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:03,110 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:03,125 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:03,137 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:03,150 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:03,163 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:03,166 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:03,168 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,176 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:03,178 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:03,180 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:03,181 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:03,182 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:03,183 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:03,184 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:03,185 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:03,186 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:03,187 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:03,189 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:03,190 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:03,191 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,193 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:03,195 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:03,197 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 14]), 13)\n",
      "2023-10-04 09:25:03,198 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:03,199 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 14]), 13)\n",
      "2023-10-04 09:25:03,200 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:03,200 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:03,202 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:03,204 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:03,205 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:03,206 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:03,207 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:03,208 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,210 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:03,218 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:03,227 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,228 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,229 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,230 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,231 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:03,239 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:03,248 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:03,254 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:03,259 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,261 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,262 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,265 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:03,273 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:03,282 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,283 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,285 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,286 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,287 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:03,293 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:03,301 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:03,307 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:03,314 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,316 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,317 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,321 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:03,329 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:03,337 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,338 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,339 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,340 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,341 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:03,347 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:03,351 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:03,366 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:03,370 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,372 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,373 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,375 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:03,383 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:03,396 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,398 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,399 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,400 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,403 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:03,414 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:03,425 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:03,431 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:03,440 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,443 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,444 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,447 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:03,456 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:03,466 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,468 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,469 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,470 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,471 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:03,477 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:03,482 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:03,488 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:03,497 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,500 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,501 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,505 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:03,517 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:03,526 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,527 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,528 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,529 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,530 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:03,536 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:03,543 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:03,551 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:03,558 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,561 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,561 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,565 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:03,573 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:03,582 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,583 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,584 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,585 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,585 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:03,592 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:03,597 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:03,603 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:03,608 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,610 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,611 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,613 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:03,622 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:03,631 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,632 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,633 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,634 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,635 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:03,642 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:03,651 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:03,666 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:03,673 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,675 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,676 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,680 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:03,689 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:03,700 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,701 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,703 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,704 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,705 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:03,713 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:03,750 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:03,758 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:03,768 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,771 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,772 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,775 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:03,783 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:03,793 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,794 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,795 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,796 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,797 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:03,805 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:03,811 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:03,817 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:03,823 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,824 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,825 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,828 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:03,837 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:03,846 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,847 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,848 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,848 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,850 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:03,856 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:03,864 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:03,881 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:03,886 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,888 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,889 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,892 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:03,900 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:03,902 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,903 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,904 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,905 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:03,906 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:03,912 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:03,918 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:03,922 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:03,934 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,936 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:25:03,937 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,940 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:03,942 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:03,951 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,952 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:03,953 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,954 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:03,956 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:03,958 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:03,962 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:03,966 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:03,969 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:03,971 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:03,972 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:03,974 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:03,976 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:03,977 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:03,978 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:03,979 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:03,980 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:03,981 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:03,994 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:04,010 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:04,022 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:04,032 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:04,039 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:04,040 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,049 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:04,051 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:04,053 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:04,054 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:04,054 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:04,055 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:04,056 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:04,058 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:04,060 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:04,061 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:04,062 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:04,064 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:04,065 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,067 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:04,069 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:04,071 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 15]), 14)\n",
      "2023-10-04 09:25:04,072 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:04,073 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 15]), 14)\n",
      "2023-10-04 09:25:04,074 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:04,074 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:04,076 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:04,078 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:04,080 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:04,081 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:04,082 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:04,083 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,085 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:04,093 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:04,101 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,102 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,103 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,104 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,105 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:04,111 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:04,119 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:04,126 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:04,131 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,133 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,134 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,137 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:04,146 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:04,155 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,156 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,157 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,158 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,159 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:04,164 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:04,167 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:04,181 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:04,188 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,190 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,191 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,193 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:04,202 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:04,211 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,212 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,213 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,214 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,215 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:04,221 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:04,224 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:04,228 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:04,231 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,232 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,233 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,236 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:04,245 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:04,256 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,257 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,258 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,259 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,260 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:04,265 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:04,273 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:04,278 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:04,284 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,286 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,287 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,290 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:04,298 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:04,308 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,309 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,310 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,311 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,312 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:04,324 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:04,329 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:04,332 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:04,338 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,340 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,341 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,343 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:04,352 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:04,361 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,362 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,362 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,363 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,364 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:04,368 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:04,374 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:04,379 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:04,383 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,384 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,385 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,388 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:04,397 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:04,406 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,407 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,408 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,409 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,409 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:04,416 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:04,425 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:04,437 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:04,444 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,446 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,447 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,449 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:04,457 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:04,466 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,467 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,468 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,469 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,470 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:04,481 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:04,486 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:04,490 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:04,495 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,497 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,498 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,501 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:04,509 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:04,522 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,524 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,525 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,527 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,528 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:04,536 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:04,572 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:04,594 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:04,598 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,600 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,601 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,604 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:04,612 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:04,620 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,621 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,622 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,623 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,625 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:04,632 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:04,637 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:04,646 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:04,652 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,654 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,655 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,657 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:04,665 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:04,674 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,675 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,676 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,677 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,678 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:04,695 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:04,704 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:04,710 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:04,714 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,716 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,717 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,720 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:04,728 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:04,730 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,732 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,733 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,734 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,735 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:04,742 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:04,746 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:04,756 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:04,764 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,767 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:25:04,768 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,772 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:04,775 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:04,785 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,786 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:04,786 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,787 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:04,789 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:04,792 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:04,794 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:04,796 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:04,797 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:04,798 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:04,800 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,802 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:04,804 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:04,805 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,806 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:04,807 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,808 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:04,809 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:04,821 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:04,832 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:04,845 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:04,854 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:04,857 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:04,858 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,866 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:04,869 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:04,871 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:04,871 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:04,872 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:04,873 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:04,874 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:04,875 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:04,877 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:04,878 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:04,879 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:04,880 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:04,881 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,883 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:04,885 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:04,887 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 16]), 15)\n",
      "2023-10-04 09:25:04,888 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:04,889 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 16]), 15)\n",
      "2023-10-04 09:25:04,890 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:04,892 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:04,894 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:04,895 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:04,896 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:04,898 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:04,899 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:04,899 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,901 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:04,911 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:04,920 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,921 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,922 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,923 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,924 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:04,930 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:04,937 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:04,946 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:04,954 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:25:04,956 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:25:04,957 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:04,961 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:04,970 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:04,978 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:04,979 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,980 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:04,981 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:04,982 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:04,990 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:04,996 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:05,002 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:05,016 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,018 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,018 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,022 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:05,030 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:05,039 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,040 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,041 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,042 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,044 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:05,049 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:05,061 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:05,068 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:05,073 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,076 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,077 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,081 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:05,090 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:05,099 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,100 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,101 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,102 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,103 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:05,108 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:05,117 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:05,121 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:05,133 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,137 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,137 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,140 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:05,149 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:05,158 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,159 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,160 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,161 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,162 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:05,169 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:05,174 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:05,179 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:05,186 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,188 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,189 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,192 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:05,200 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:05,209 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,211 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,212 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,213 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,213 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:05,219 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:05,226 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:05,238 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:05,243 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,245 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,246 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,249 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:05,257 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:05,266 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,267 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,268 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,269 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,271 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:05,275 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:05,282 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:05,287 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:05,290 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,291 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,292 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,295 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:05,304 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:05,313 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,314 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,315 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,317 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,318 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:05,325 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:05,331 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:05,337 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:05,343 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,345 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,346 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,348 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:05,356 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:05,365 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,366 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,367 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,368 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,369 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:05,378 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:05,384 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:05,389 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:05,398 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,399 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,400 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,403 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:05,411 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:05,422 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,423 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,424 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,425 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,426 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:05,438 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:05,443 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:05,448 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:05,452 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,453 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,454 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,457 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:05,465 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:05,474 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,475 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,476 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,477 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,478 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:05,484 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:05,488 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:05,493 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:05,501 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,503 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,505 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,510 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:05,522 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:05,525 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,527 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,529 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,530 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,532 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:05,544 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:05,559 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:05,565 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:05,572 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,574 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:25:05,575 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,577 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:05,579 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:05,587 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,588 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:05,589 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,590 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:05,591 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:05,594 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:05,598 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:05,602 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:05,606 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:05,609 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:05,610 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,612 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:05,614 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:05,616 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,617 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:05,618 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,619 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:05,620 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:05,633 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:05,644 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:05,655 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:05,665 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:05,668 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:05,670 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,677 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:05,680 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:05,681 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:05,682 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:05,683 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:05,684 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:05,685 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:05,686 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:05,687 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:05,688 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:05,689 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:05,690 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:05,691 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,693 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:05,694 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:05,696 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 17]), 16)\n",
      "2023-10-04 09:25:05,697 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:05,698 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 17]), 16)\n",
      "2023-10-04 09:25:05,699 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:05,700 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:05,701 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:05,703 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:05,704 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:05,705 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:05,706 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:05,707 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,708 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:05,716 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:05,725 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,726 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,727 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,728 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,729 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:05,737 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:05,743 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:05,747 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:05,753 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:25:05,755 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:25:05,756 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,759 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:05,767 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:05,776 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,777 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,778 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,779 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,780 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:05,789 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:05,797 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:05,809 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:05,814 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:25:05,816 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:25:05,817 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,820 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:05,828 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:05,837 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,838 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,839 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,840 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,841 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:05,850 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:05,855 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:05,860 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:05,866 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:25:05,868 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:25:05,869 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,871 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:05,880 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:05,889 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,890 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,891 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,892 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,893 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:05,899 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:05,908 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:05,913 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:05,917 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:25:05,919 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:25:05,919 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,922 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:05,930 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:05,939 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:05,940 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,941 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:05,942 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:05,943 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:05,951 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:05,961 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:05,967 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:05,992 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:25:05,995 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:25:05,996 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:05,998 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:06,007 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:06,015 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,016 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,017 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,018 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,019 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:06,027 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:06,035 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:06,042 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:06,046 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,048 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,049 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,051 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:06,059 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:06,067 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,068 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,069 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,070 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,071 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:06,077 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:06,084 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:06,095 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:06,100 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,102 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,103 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,106 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:06,115 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:06,124 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,125 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,126 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,127 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,128 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:06,133 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:06,139 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:06,164 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:06,205 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,207 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,208 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,210 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:06,219 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:06,229 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,230 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,231 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,232 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,233 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:06,239 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:06,244 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:06,250 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:06,255 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,257 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,258 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,261 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:06,269 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:06,277 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,278 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,279 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,280 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,281 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:06,288 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:06,294 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:06,300 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:06,306 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,308 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,309 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,312 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:06,320 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:06,329 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,331 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,332 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,333 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,334 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:06,340 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:06,352 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:06,372 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:06,380 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,382 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,383 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,385 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:06,394 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:06,396 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,396 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,397 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,398 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,399 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:06,415 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:06,420 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:06,434 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:06,445 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,447 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:25:06,448 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,451 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:06,454 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:06,462 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,463 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:06,464 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,465 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:06,466 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:06,469 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:06,472 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:06,474 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:06,477 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:06,478 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:06,479 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,480 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:06,482 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:06,483 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,484 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:06,485 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,486 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:06,486 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:06,502 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:06,515 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:06,525 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:06,534 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:06,539 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:06,540 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,548 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:06,551 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:06,552 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:06,553 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:06,554 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:06,555 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:06,556 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:06,557 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:06,558 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:06,559 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:06,560 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:06,561 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:06,562 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,563 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:06,565 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:06,567 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 18]), 17)\n",
      "2023-10-04 09:25:06,568 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:06,569 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 18]), 17)\n",
      "2023-10-04 09:25:06,570 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:06,571 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:06,573 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:06,574 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:06,575 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:06,577 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:06,578 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:06,578 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,580 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:06,589 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:06,598 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,599 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,600 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,602 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,603 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:06,610 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:06,615 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:06,623 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:06,627 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:25:06,629 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:25:06,630 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,632 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:06,640 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:06,652 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,655 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,656 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,658 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,659 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:06,702 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:06,706 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:06,738 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:06,743 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:25:06,746 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:25:06,747 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,750 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:06,759 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:06,768 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,769 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,770 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,771 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,772 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:06,779 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:06,790 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:06,796 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:06,807 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:25:06,810 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:25:06,811 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,814 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:06,823 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:06,833 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,834 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,835 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,836 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,836 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:06,841 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:06,848 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:06,857 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:06,862 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:25:06,864 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:25:06,865 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,868 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:06,877 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:06,887 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,888 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,889 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,890 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,890 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:06,897 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:06,904 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:06,916 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:06,926 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:25:06,929 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:25:06,930 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,934 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:06,945 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:06,956 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:06,957 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,958 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:06,959 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:06,960 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:06,971 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:06,979 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:06,984 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:06,992 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:25:06,994 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:25:06,995 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:06,998 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:07,005 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:07,015 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,016 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,017 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,019 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,019 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:07,024 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:07,033 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:07,036 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:07,040 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:25:07,041 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:25:07,042 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,045 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:07,053 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:07,061 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,062 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,063 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,064 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,064 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:07,073 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:07,077 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:07,081 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:07,095 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:25:07,097 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:25:07,098 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,101 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:07,109 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:07,118 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,119 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,120 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,121 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,122 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:07,128 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:07,133 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:07,137 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:07,150 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:25:07,153 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:25:07,153 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,156 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:07,165 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:07,173 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,174 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,175 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,176 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,178 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:07,183 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:07,187 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:07,196 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:07,210 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:25:07,212 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:25:07,213 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,215 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:07,224 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:07,233 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,234 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,234 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,235 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,236 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:07,252 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:07,264 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:07,269 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:07,276 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:25:07,278 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:25:07,280 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,282 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:07,290 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:07,292 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,293 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,294 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,294 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,296 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:07,316 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:07,320 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:07,324 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:07,329 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:25:07,331 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:25:07,332 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,335 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:07,337 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:07,345 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,347 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:07,349 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,350 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:07,351 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:07,355 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:07,361 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:07,366 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:07,371 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:07,372 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:07,373 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,375 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:07,376 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:07,378 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,379 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:07,380 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,381 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:07,382 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:07,399 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:07,411 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:07,425 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:07,438 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:07,441 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:07,442 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,475 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:07,478 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:07,479 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:07,480 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:07,481 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:07,482 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:07,483 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:07,484 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:07,485 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:07,486 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:07,487 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:07,488 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:07,489 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,496 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:07,498 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:07,500 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 19]), 18)\n",
      "2023-10-04 09:25:07,501 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:07,502 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 19]), 18)\n",
      "2023-10-04 09:25:07,502 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:07,503 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:07,505 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:07,506 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:07,507 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:07,508 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:07,509 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:07,510 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,511 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:07,519 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:07,527 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,529 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,530 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,531 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,532 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:07,537 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:07,542 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:07,545 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:07,566 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:25:07,568 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:25:07,569 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,571 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:07,579 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:07,587 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,588 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,589 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,590 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,591 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:07,596 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:07,602 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:07,606 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:07,610 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:25:07,612 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:25:07,613 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,615 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:07,623 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:07,632 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,633 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,634 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,634 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,635 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:07,659 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:07,664 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:07,699 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:07,711 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:25:07,713 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:25:07,714 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,717 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:07,725 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:07,733 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,734 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,735 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,735 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,736 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:07,745 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:07,766 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:07,840 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:07,871 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:25:07,874 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:25:07,875 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,877 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:07,885 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:07,895 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,896 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,897 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,897 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,898 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:07,908 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:07,930 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:07,938 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:07,947 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:25:07,949 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:25:07,950 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:07,953 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:07,975 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:07,985 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:07,986 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,987 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:07,988 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:07,989 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:08,008 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:08,015 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:08,038 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:08,047 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,050 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,051 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,053 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:08,061 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:08,070 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,071 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,072 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,073 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,074 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:08,079 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:08,085 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:08,107 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:08,117 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,120 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,120 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,123 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:08,131 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:08,155 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,157 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,158 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,159 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,160 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:08,199 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:08,206 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:08,211 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:08,222 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,224 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,225 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,228 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:08,236 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:08,245 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,246 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,247 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,248 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,249 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:08,266 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:08,276 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:08,284 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:08,288 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,290 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,291 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,294 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:08,301 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:08,309 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,310 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,311 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,312 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,313 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:08,321 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:08,326 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:08,330 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:08,335 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,337 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,338 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,340 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:08,348 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:08,357 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,357 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,359 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,360 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,360 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:08,367 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:08,371 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:08,376 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:08,380 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,382 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,383 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,386 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:08,394 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:08,396 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,397 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,398 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,399 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,400 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:08,411 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:08,419 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:08,423 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:08,429 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,431 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:25:08,432 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,434 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:08,437 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:08,445 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,446 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:08,447 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,448 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:08,448 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:08,452 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:08,457 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:08,461 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:08,465 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:08,466 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:08,468 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,469 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:08,471 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:08,472 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,473 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:08,474 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,475 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:08,476 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:08,486 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:08,503 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:08,512 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:08,525 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:08,530 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:08,531 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,539 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:08,542 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:08,543 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:08,544 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:08,545 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:08,546 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:08,546 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:08,548 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:08,549 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:08,550 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:08,551 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:08,552 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:08,553 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,554 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:08,556 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:08,557 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 20]), 19)\n",
      "2023-10-04 09:25:08,558 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:08,559 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 20]), 19)\n",
      "2023-10-04 09:25:08,560 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:08,561 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:08,562 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:08,564 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:08,565 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:08,567 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:08,567 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:08,569 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,570 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:08,579 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:08,592 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,593 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,594 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,595 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,596 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:08,603 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:08,611 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:08,618 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:08,626 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,628 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,629 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,632 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:08,640 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:08,649 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,650 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,651 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,653 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,654 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:08,660 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:08,668 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:08,674 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:08,680 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,682 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,683 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,687 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:08,697 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:08,706 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,707 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,708 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,709 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,710 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:08,717 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:08,736 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:08,741 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:08,747 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,749 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,750 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,753 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:08,762 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:08,771 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,772 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,773 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,774 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,774 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:08,784 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:08,790 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:08,795 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:08,800 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,802 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,802 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,805 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:08,814 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:08,823 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,825 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,826 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,827 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,828 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:08,833 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:08,840 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:08,846 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:08,852 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,854 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,854 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,857 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:08,865 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:08,874 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,875 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,876 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,876 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,877 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:08,882 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:08,888 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:08,893 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:08,898 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,900 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,901 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,903 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:08,912 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:08,921 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,922 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,923 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,924 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,925 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:08,930 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:08,934 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:08,941 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:08,946 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,948 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:25:08,950 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:08,953 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:08,963 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:08,972 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:08,974 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,975 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:08,976 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:08,977 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:09,026 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:09,038 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:09,044 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:09,052 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:25:09,054 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:25:09,055 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,058 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:09,066 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:09,075 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,076 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,078 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,078 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,079 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:09,086 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:09,092 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:09,097 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:09,102 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:25:09,104 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:25:09,105 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,108 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:09,116 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:09,124 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,126 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,127 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,128 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,129 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:09,139 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:09,143 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:09,149 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:09,154 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:25:09,156 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:25:09,157 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,159 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:09,168 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:09,177 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,178 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,179 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,181 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,182 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:09,188 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:09,194 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:09,199 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:09,204 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:25:09,206 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:25:09,206 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,210 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:09,218 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:09,219 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,220 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,222 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,222 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,223 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:09,230 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:09,241 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:09,253 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:09,258 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:25:09,260 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:25:09,261 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,264 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:09,266 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:09,275 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,276 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:09,277 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,278 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:09,278 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:09,281 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:09,285 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:09,287 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:09,288 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:09,289 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:09,290 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,292 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:09,294 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:09,296 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,297 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:09,298 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,299 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:09,300 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:09,313 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:09,331 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:09,347 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:09,361 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:09,364 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:09,365 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,375 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:09,378 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:09,379 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:09,380 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:09,381 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:09,382 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:09,383 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:09,384 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:09,385 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:09,386 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:09,387 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:09,388 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:09,389 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,391 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:09,392 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:09,394 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 21]), 20)\n",
      "2023-10-04 09:25:09,395 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:09,396 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 21]), 20)\n",
      "2023-10-04 09:25:09,397 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:09,398 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:09,401 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:09,403 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:09,405 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:09,406 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:09,408 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:09,409 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,411 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:09,419 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:09,428 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,429 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,430 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,432 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,433 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:09,442 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:09,448 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:09,454 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:09,459 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,461 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,463 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,466 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:09,474 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:09,484 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,485 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,487 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,488 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,488 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:09,497 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:09,504 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:09,508 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:09,513 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,515 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,516 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,519 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:09,528 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:09,536 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,537 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,538 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,540 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,541 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:09,547 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:09,613 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:09,635 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:09,641 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,643 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,643 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,646 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:09,655 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:09,664 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,665 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,665 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,667 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,668 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:09,674 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:09,678 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:09,682 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:09,685 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,687 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,688 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,691 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:09,698 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:09,707 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,707 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,708 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,709 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,710 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:09,716 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:09,722 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:09,729 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:09,732 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,734 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,735 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,738 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:09,746 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:09,754 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,755 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,756 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,757 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,757 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:09,762 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:09,770 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:09,775 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:09,779 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,780 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,781 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,783 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:09,792 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:09,800 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,801 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,802 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,803 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,804 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:09,812 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:09,819 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:09,824 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:09,828 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,830 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,831 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,833 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:09,842 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:09,851 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,852 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,853 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,854 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,855 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:09,860 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:09,864 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:09,882 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:09,888 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,890 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,891 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,894 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:09,902 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:09,911 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,912 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,913 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,914 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,914 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:09,919 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:09,926 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:09,938 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:09,943 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,944 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:25:09,946 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:09,948 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:09,957 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:09,965 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:09,966 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,968 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:09,969 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:09,969 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:09,977 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:10,001 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:10,010 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:10,016 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:25:10,019 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:25:10,019 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,022 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:10,030 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:10,039 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:10,040 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,041 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:10,042 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,043 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:10,049 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:10,153 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:10,183 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:10,202 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:25:10,204 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:25:10,205 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,208 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:10,217 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:10,219 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:10,220 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,220 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:10,221 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,222 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:10,248 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:10,253 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:10,258 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:10,262 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:25:10,264 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:25:10,265 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,268 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:10,270 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:10,278 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:10,279 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:10,280 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:10,281 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:10,282 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:10,285 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:10,287 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:10,291 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:10,294 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:10,295 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:10,295 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,297 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:10,299 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:10,300 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:10,301 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:10,302 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:10,303 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:10,303 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:10,319 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:10,329 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:10,340 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:10,351 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:10,354 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:10,355 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,363 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:10,365 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:10,366 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:10,367 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:10,368 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:10,369 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:10,369 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:10,371 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:10,372 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:10,373 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:10,374 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:10,375 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:10,375 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,377 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:10,378 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:10,381 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 22]), 21)\n",
      "2023-10-04 09:25:10,381 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:10,382 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 22]), 21)\n",
      "2023-10-04 09:25:10,383 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:10,384 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:10,386 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:10,387 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:10,388 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:10,390 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:10,391 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:10,392 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,393 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:10,401 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:10,410 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:10,411 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,412 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:10,413 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,414 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:10,420 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:10,427 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:10,432 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:10,437 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,439 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,440 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,443 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:10,450 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:10,459 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:10,460 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,461 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:10,462 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,463 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:10,471 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:10,481 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:10,491 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:10,496 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,498 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,499 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,501 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:10,509 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:10,517 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:10,518 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,519 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:10,520 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,521 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:10,525 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:10,529 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:10,534 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:10,542 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,550 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,551 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,554 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:10,563 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:10,573 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:10,574 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,575 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:10,576 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,577 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:10,585 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:10,596 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:10,604 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:10,608 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,609 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,610 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,613 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:10,621 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:10,629 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:10,630 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,631 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:10,632 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,634 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:10,640 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:10,648 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:10,651 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:10,655 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,656 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,657 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,660 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:10,668 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:10,676 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:10,677 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,678 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:10,679 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,680 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:10,688 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:10,692 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:10,695 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:10,701 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,703 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,704 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,707 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:10,714 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:10,724 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:10,725 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,726 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:10,726 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,727 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:10,754 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:10,759 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:10,765 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:10,769 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,771 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:25:10,772 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:10,775 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:10,784 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:10,792 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:10,793 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,794 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:10,795 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:10,797 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:10,804 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:10,810 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:10,907 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:10,972 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:25:11,011 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:25:11,014 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,018 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:11,029 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:11,038 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:11,040 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,041 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:11,042 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,042 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:11,049 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:11,067 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:11,072 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:11,077 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:25:11,079 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:25:11,080 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,083 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:11,092 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:11,100 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:11,101 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,102 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:11,104 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,105 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:11,115 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:11,120 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:11,125 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:11,131 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:25:11,133 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:25:11,134 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,137 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:11,145 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:11,153 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:11,154 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,155 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:11,156 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,157 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:11,167 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:11,171 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:11,177 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:11,181 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:25:11,186 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:25:11,187 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,191 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:11,198 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:11,200 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:11,201 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,202 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:11,204 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,205 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:11,263 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:11,288 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:11,297 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:11,305 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:25:11,308 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:25:11,309 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,311 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:11,314 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:11,322 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:11,323 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:11,324 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:11,325 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:11,326 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:11,329 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:11,333 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:11,336 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:11,339 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:11,341 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:11,342 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,343 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:11,345 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:11,347 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:11,348 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:11,349 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:11,351 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:11,352 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:11,362 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:11,375 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:11,386 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:11,400 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:11,407 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:11,408 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,416 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:11,419 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:11,420 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:11,421 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:11,422 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:11,423 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:11,424 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:11,425 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:11,427 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:11,428 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:11,429 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:11,430 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:11,431 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,432 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:11,434 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:11,436 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 23]), 22)\n",
      "2023-10-04 09:25:11,436 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:11,437 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 23]), 22)\n",
      "2023-10-04 09:25:11,438 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:11,439 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:11,441 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:11,442 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:11,444 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:11,445 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:11,446 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:11,447 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,448 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:11,456 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:11,465 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:11,466 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,467 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:11,468 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,469 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:11,475 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:11,480 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:11,485 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:11,489 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,490 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,491 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,494 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:11,503 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:11,512 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:11,513 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,514 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:11,515 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,516 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:11,522 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:11,531 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:11,537 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:11,543 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,555 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,557 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,560 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:11,568 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:11,585 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:11,587 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,588 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:11,590 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,591 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:11,663 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:11,727 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:11,737 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:11,746 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,748 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,750 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,753 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:11,761 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:11,769 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:11,771 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,771 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:11,773 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,773 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:11,784 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:11,796 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:11,802 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:11,807 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,810 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,811 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,814 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:11,823 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:11,833 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:11,835 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,836 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:11,836 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,837 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:11,842 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:11,848 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:11,857 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:11,863 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,870 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,871 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,874 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:11,882 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:11,889 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:11,890 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,891 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:11,892 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,893 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:11,898 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:11,903 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:11,908 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:11,913 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,920 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,922 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,925 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:11,932 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:11,941 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:11,942 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,943 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:11,943 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:11,945 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:11,950 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:11,957 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:11,963 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:11,969 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,972 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:25:11,973 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:11,977 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:11,988 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:12,000 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,001 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,002 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,003 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,004 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:12,010 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:12,015 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:12,020 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:12,025 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:25:12,028 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:25:12,029 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,032 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:12,040 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:12,049 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,050 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,051 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,052 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,053 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:12,059 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:12,065 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:12,071 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:12,076 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:25:12,081 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:25:12,082 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,085 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:12,094 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:12,103 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,103 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,104 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,105 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,106 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:12,114 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:12,118 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:12,122 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:12,125 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:25:12,151 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:25:12,154 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,157 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:12,169 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:12,180 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,181 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,182 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,183 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,184 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:12,194 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:12,198 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:12,201 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:12,215 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:25:12,221 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:25:12,222 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,224 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:12,234 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:12,235 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,236 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,237 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,238 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,239 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:12,248 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:12,252 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:12,255 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:12,260 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:25:12,263 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:25:12,264 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,266 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:12,269 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:12,278 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,279 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:12,280 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,281 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:12,282 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:12,286 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:12,290 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:12,291 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:12,295 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:12,296 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:12,297 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,300 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:12,301 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:12,303 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,303 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:12,304 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,305 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:12,306 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:12,317 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:12,326 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:12,337 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:12,346 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:12,350 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:12,350 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,368 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:12,370 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:12,372 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:12,372 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:12,373 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:12,374 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:12,375 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:12,377 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:12,379 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:12,380 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:12,381 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:12,382 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:12,383 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,384 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:12,386 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:12,388 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 24]), 23)\n",
      "2023-10-04 09:25:12,389 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:12,390 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 24]), 23)\n",
      "2023-10-04 09:25:12,391 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:12,392 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:12,394 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:12,395 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:12,396 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:12,398 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:12,399 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:12,400 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,402 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:12,414 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:12,427 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,428 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,430 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,431 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,432 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:12,441 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:12,447 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:12,450 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:12,453 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,460 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,461 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,465 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:12,472 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:12,481 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,482 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,483 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,483 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,484 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:12,489 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:12,493 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:12,498 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:12,503 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,505 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,507 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,510 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:12,518 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:12,527 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,528 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,529 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,530 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,530 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:12,538 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:12,542 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:12,546 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:12,550 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,551 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,552 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,555 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:12,563 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:12,571 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,572 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,573 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,574 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,575 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:12,579 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:12,584 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:12,588 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:12,592 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,594 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,594 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,597 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:12,605 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:12,614 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,615 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,616 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,617 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,618 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:12,626 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:12,630 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:12,634 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:12,637 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,639 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,640 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,643 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:12,651 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:12,660 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,661 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,662 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,664 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,665 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:12,670 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:12,675 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:12,682 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:12,687 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,690 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,691 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,694 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:12,702 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:12,711 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,712 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,713 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,714 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,715 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:12,721 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:12,726 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:12,735 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:12,739 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,741 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,742 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,745 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:12,753 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:12,762 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,763 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,764 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,766 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,766 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:12,771 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:12,775 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:12,779 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:12,783 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,785 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,785 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,788 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:12,796 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:12,805 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,806 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,806 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,808 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,808 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:12,813 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:12,817 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:12,821 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:12,824 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,826 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,827 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,830 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:12,838 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:12,846 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,847 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,849 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,850 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,851 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:12,855 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:12,859 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:12,863 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:12,866 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,868 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,869 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,872 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:12,880 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:12,889 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,890 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,892 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,892 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,894 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:12,900 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:12,905 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:12,908 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:12,911 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,921 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:25:12,923 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:12,926 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:12,934 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:12,936 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:12,936 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,937 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:12,938 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:12,939 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:12,952 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:13,013 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:13,050 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:13,054 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:25:13,055 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:25:13,056 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,059 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:13,061 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:13,070 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,071 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:13,071 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,073 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:13,074 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:13,077 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:13,082 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:13,086 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:13,088 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:13,090 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:13,091 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,093 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:13,094 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:13,096 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,096 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:13,097 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,098 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:13,100 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:13,109 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:13,123 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:13,133 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:13,143 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:13,145 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:13,146 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,155 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:13,157 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:13,159 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:13,160 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:13,161 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:13,162 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:13,163 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:13,164 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:13,165 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:13,166 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:13,168 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:13,168 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:13,169 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,171 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:13,173 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:13,175 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 25]), 24)\n",
      "2023-10-04 09:25:13,176 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:13,177 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 25]), 24)\n",
      "2023-10-04 09:25:13,178 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:13,179 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:13,180 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:13,182 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:13,183 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:13,184 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:13,185 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:13,186 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,188 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:13,201 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:13,214 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,216 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,217 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,219 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,220 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:13,225 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:13,236 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:13,242 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:13,247 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,264 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,265 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,269 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:13,278 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:13,287 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,288 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,289 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,290 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,292 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:13,314 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:13,321 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:13,325 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:13,330 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,332 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,333 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,338 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:13,347 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:13,355 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,356 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,357 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,358 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,359 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:13,365 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:13,376 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:13,381 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:13,385 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,386 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,387 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,390 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:13,398 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:13,406 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,407 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,408 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,409 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,410 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:13,416 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:13,420 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:13,427 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:13,494 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,526 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,527 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,530 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:13,538 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:13,549 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,550 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,551 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,552 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,553 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:13,558 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:13,561 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:13,565 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:13,572 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,574 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,575 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,578 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:13,586 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:13,595 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,596 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,597 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,597 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,598 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:13,661 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:13,679 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:13,683 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:13,687 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,689 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,691 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,693 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:13,701 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:13,709 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,711 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,712 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,713 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,714 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:13,721 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:13,729 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:13,735 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:13,750 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,755 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,757 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,760 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:13,769 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:13,778 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,779 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,781 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,782 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,783 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:13,787 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:13,791 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:13,796 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:13,801 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,803 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,804 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,807 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:13,814 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:13,823 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,824 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,825 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,826 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,827 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:13,834 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:13,839 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:13,847 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:13,856 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,864 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,866 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,871 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:13,880 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:13,889 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,890 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,892 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,893 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,893 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:13,899 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:13,903 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:13,907 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:13,911 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,912 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,913 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,916 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:13,924 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:13,933 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,934 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,935 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,936 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,937 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:13,944 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:13,948 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:13,952 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:13,955 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,957 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,958 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,961 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:13,968 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:13,970 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:13,971 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,972 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:13,973 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:13,974 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:13,978 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:13,982 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:13,985 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:13,990 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,993 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:25:13,994 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:13,997 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:13,999 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:14,009 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:14,010 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:14,011 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:14,012 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:14,013 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:14,019 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:14,023 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:14,028 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:14,029 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:14,030 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:14,032 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,034 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:14,035 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:14,037 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:14,038 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:14,039 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:14,040 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:14,041 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:14,056 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:14,068 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:14,081 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:14,093 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:14,098 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:14,100 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,111 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:14,114 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:14,116 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:14,116 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:14,117 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:14,119 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:14,120 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:14,122 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:14,123 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:14,124 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:14,126 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:14,127 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:14,128 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,129 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:14,131 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:14,133 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 26]), 25)\n",
      "2023-10-04 09:25:14,133 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:14,135 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 26]), 25)\n",
      "2023-10-04 09:25:14,135 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:14,137 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:14,138 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:14,139 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:14,141 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:14,142 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:14,143 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:14,144 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,146 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:14,154 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:14,164 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:14,165 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,166 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:14,167 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,170 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:14,193 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:14,262 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:14,320 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:14,364 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,394 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,396 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,398 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:14,407 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:14,415 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:14,417 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,417 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:14,418 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,419 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:14,424 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:14,427 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:14,431 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:14,435 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,436 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,437 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,440 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:14,447 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:14,456 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:14,457 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,458 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:14,459 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,460 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:14,464 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:14,467 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:14,470 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:14,473 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,476 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,477 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,479 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:14,487 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:14,495 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:14,496 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,497 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:14,498 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,499 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:14,514 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:14,518 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:14,521 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:14,525 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,531 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,532 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,535 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:14,543 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:14,552 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:14,553 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,553 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:14,554 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,555 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:14,560 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:14,563 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:14,567 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:14,572 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,575 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,576 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,579 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:14,588 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:14,597 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:14,598 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,599 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:14,600 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,601 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:14,609 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:14,616 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:14,621 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:14,625 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,628 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,629 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,632 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:14,640 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:14,649 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:14,650 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,651 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:14,652 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,654 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:14,660 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:14,666 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:14,671 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:14,676 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,678 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,679 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,682 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:14,691 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:14,699 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:14,701 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,702 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:14,703 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,703 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:14,708 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:14,712 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:14,716 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:14,720 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,722 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,723 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,726 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:14,734 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:14,743 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:14,744 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,745 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:14,746 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,747 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:14,753 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:14,757 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:14,762 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:14,768 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,770 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,771 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,774 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:14,782 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:14,791 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:14,792 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,793 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:14,794 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,794 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:14,807 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:14,814 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:14,872 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:14,921 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,924 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:25:14,925 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:14,928 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:14,940 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:14,952 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:14,953 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,954 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:14,955 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:14,956 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:14,960 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:14,977 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:14,981 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:15,050 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:25:15,052 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:25:15,053 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,056 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:15,064 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:15,065 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,066 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,067 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,068 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,069 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:15,075 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:15,078 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:15,081 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:15,096 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:25:15,098 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:25:15,099 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,101 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:15,103 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:15,111 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,112 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:15,113 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,114 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:15,115 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:15,116 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:15,118 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:15,119 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:15,121 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:15,122 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:15,124 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,127 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:15,128 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:15,130 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,131 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:15,132 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,133 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:15,134 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:15,145 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:15,157 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:15,168 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:15,183 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:15,188 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:15,190 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,212 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:15,216 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:15,218 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:15,219 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:15,220 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:15,221 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:15,221 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:15,223 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:15,224 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:15,225 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:15,226 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:15,227 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:15,228 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,230 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:15,232 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:15,234 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 27]), 26)\n",
      "2023-10-04 09:25:15,235 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:15,236 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 27]), 26)\n",
      "2023-10-04 09:25:15,237 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:15,238 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:15,239 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:15,240 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:15,242 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:15,243 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:15,244 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:15,245 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,247 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:15,255 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:15,264 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,267 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,268 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,269 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,270 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:15,279 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:15,335 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:15,340 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:15,345 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,347 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,349 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,351 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:15,360 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:15,368 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,369 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,370 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,371 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,373 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:15,379 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:15,383 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:15,387 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:15,391 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,394 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,395 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,398 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:15,405 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:15,414 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,414 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,415 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,416 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,417 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:15,422 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:15,425 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:15,428 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:15,433 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,435 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,436 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,438 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:15,447 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:15,456 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,456 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,458 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,459 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,459 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:15,467 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:15,471 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:15,475 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:15,479 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,481 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,482 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,485 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:15,493 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:15,501 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,502 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,502 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,503 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,504 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:15,509 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:15,514 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:15,518 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:15,523 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,525 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,526 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,529 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:15,536 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:15,544 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,545 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,546 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,547 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,548 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:15,553 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:15,556 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:15,562 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:15,566 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,568 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,569 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,572 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:15,580 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:15,588 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,590 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,590 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,591 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,592 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:15,600 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:15,608 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:15,614 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:15,619 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,623 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,624 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,627 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:15,636 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:15,644 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,645 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,646 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,647 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,648 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:15,655 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:15,660 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:15,667 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:15,672 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,674 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,676 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,678 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:15,686 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:15,695 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,696 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,697 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,698 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,699 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:15,707 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:15,714 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:15,718 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:15,722 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,724 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,725 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,728 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:15,735 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:15,744 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,745 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,746 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,747 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,747 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:15,767 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:15,772 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:15,776 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:15,789 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,791 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,792 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,794 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:15,803 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:15,812 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,813 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,814 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,815 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,815 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:15,820 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:15,827 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:15,834 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:15,906 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,934 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,936 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,939 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:15,947 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:15,948 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:15,949 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,950 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:15,951 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:15,952 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:15,957 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:15,963 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:15,968 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:15,983 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,986 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:25:15,987 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:15,990 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:15,992 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:16,001 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,001 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:16,002 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,004 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:16,005 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:16,006 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:16,010 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:16,014 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:16,017 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:16,018 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:16,019 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,021 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:16,022 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:16,024 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,025 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:16,026 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,026 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:16,027 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:16,048 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:16,070 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:16,085 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:16,103 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:16,109 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:16,111 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,131 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:16,134 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:16,137 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:16,138 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:16,140 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:16,141 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:16,142 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:16,143 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:16,145 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:16,146 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:16,147 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:16,148 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:16,150 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,160 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:16,163 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:16,176 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 28]), 27)\n",
      "2023-10-04 09:25:16,177 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:16,178 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 28]), 27)\n",
      "2023-10-04 09:25:16,179 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:16,180 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:16,181 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:16,182 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:16,183 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:16,184 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:16,185 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:16,186 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,187 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:16,198 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:16,208 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,209 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,211 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,212 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,213 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:16,224 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:16,232 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:16,237 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:16,242 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,244 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,245 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,248 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:16,256 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:16,265 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,266 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,267 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,268 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,269 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:16,280 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:16,285 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:16,290 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:16,295 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,298 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,299 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,302 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:16,310 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:16,319 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,320 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,322 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,323 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,324 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:16,333 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:16,339 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:16,344 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:16,350 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,352 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,354 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,356 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:16,364 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:16,373 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,374 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,375 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,376 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,377 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:16,383 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:16,390 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:16,396 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:16,402 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,404 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,405 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,408 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:16,416 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:16,429 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,430 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,431 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,432 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,434 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:16,441 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:16,445 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:16,450 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:16,455 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,458 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,460 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,464 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:16,476 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:16,485 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,486 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,487 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,488 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,489 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:16,502 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:16,510 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:16,515 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:16,519 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,522 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,524 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,527 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:16,536 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:16,544 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,545 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,546 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,547 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,549 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:16,604 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:16,657 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:16,689 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:16,695 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,698 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,699 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,702 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:16,711 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:16,719 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,720 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,722 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,723 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,724 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:16,738 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:16,746 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:16,751 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:16,757 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,798 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,800 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,804 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:16,817 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:16,832 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,833 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,835 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,836 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,837 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:16,850 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:16,855 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:16,859 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:16,864 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,866 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,868 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,871 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:16,879 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:16,887 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,889 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,890 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,891 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,892 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:16,904 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:16,912 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:16,917 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:16,924 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,926 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,927 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,930 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:16,937 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:16,946 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,947 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,948 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,949 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,950 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:16,956 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:16,960 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:16,965 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:16,969 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,971 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:25:16,972 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:16,974 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:16,982 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:16,984 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:16,985 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,986 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:16,987 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:16,988 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:16,994 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:17,000 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:17,006 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:17,013 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:25:17,015 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:25:17,017 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,019 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:17,022 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:17,031 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:17,033 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:17,034 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:17,035 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:17,036 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:17,039 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:17,043 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:17,046 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:17,047 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:17,050 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:17,051 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,053 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:17,056 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:17,058 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:17,059 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:17,060 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:17,061 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:17,063 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:17,076 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:17,089 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:17,101 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:17,114 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:17,116 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:17,118 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,127 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:17,129 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:17,131 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:17,132 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:17,133 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:17,134 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:17,135 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:17,137 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:17,138 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:17,140 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:17,142 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:17,143 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:17,144 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,148 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:17,151 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:17,153 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 29]), 28)\n",
      "2023-10-04 09:25:17,154 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:17,156 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 29]), 28)\n",
      "2023-10-04 09:25:17,157 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:17,158 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:17,161 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:17,163 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:17,164 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:17,166 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:17,167 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:17,168 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,171 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:17,182 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:17,194 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:17,196 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,197 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:17,198 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,199 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:17,207 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:17,217 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:17,223 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:17,228 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,231 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,233 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,237 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:17,248 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:17,256 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:17,257 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,259 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:17,259 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,260 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:17,266 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:17,270 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:17,275 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:17,279 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,281 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,282 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,284 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:17,292 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:17,300 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:17,300 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,301 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:17,302 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,303 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:17,366 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:17,388 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:17,394 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:17,402 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,403 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,404 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,407 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:17,414 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:17,423 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:17,423 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,424 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:17,425 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,426 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:17,433 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:17,438 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:17,447 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:17,451 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,454 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,455 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,458 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:17,466 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:17,475 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:17,475 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,477 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:17,477 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,478 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:17,488 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:17,493 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:17,497 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:17,500 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,502 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,503 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,506 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:17,513 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:17,521 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:17,522 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,523 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:17,524 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,525 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:17,530 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:17,540 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:17,610 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:17,642 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,647 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,649 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,651 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:17,659 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:17,669 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:17,670 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,671 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:17,673 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,674 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:17,684 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:17,689 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:17,696 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:17,702 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,705 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,707 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,710 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:17,723 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:17,734 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:17,735 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,737 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:17,738 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,740 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:17,785 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:17,790 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:17,835 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:17,840 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,843 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,844 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,846 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:17,855 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:17,865 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:17,867 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,868 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:17,869 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,870 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:17,877 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:17,884 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:17,889 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:17,893 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,896 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,898 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,900 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:17,910 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:17,919 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:17,920 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,921 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:17,922 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,923 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:17,951 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:17,956 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:17,960 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:17,965 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,967 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:25:17,968 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:17,970 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:17,978 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:17,987 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:17,988 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,989 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:17,990 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:17,990 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:17,995 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:18,000 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:18,006 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:18,011 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:25:18,014 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:25:18,015 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,018 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:18,026 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:18,028 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,029 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,030 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,031 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,032 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:18,037 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:18,041 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:18,044 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:18,048 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:25:18,050 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:25:18,051 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,053 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:18,055 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:18,064 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,065 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:18,065 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,066 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:18,067 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:18,069 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:18,073 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:18,077 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:18,080 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:18,082 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:18,083 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,084 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:18,086 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:18,087 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,088 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:18,089 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,090 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:18,090 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:18,105 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:18,115 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:18,127 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:18,138 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:18,142 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:18,144 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,152 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:18,154 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:18,156 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:18,157 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:18,158 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:18,159 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:18,160 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:18,161 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:18,162 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:18,163 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:18,164 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:18,165 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:18,166 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,168 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:18,169 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:18,172 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 30]), 29)\n",
      "2023-10-04 09:25:18,172 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:18,173 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 30]), 29)\n",
      "2023-10-04 09:25:18,174 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:18,175 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:18,177 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:18,178 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:18,179 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:18,180 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:18,181 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:18,182 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,183 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:18,192 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:18,200 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,201 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,202 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,203 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,204 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:18,212 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:18,215 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:18,220 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:18,223 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,225 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,227 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,229 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:18,237 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:18,246 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,247 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,248 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,249 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,249 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:18,259 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:18,265 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:18,271 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:18,275 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,277 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,278 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,281 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:18,289 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:18,297 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,298 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,299 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,301 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,301 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:18,311 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:18,320 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:18,325 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:18,329 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,331 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,333 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,335 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:18,343 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:18,352 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,353 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,354 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,355 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,356 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:18,367 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:18,376 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:18,383 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:18,389 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,394 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,395 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,398 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:18,408 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:18,417 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,418 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,419 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,419 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,420 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:18,425 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:18,432 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:18,441 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:18,447 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,449 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,451 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,453 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:18,462 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:18,471 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,473 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,474 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,475 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,476 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:18,481 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:18,486 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:18,493 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:18,500 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,503 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,504 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,507 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:18,516 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:18,525 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,526 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,527 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,528 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,529 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:18,535 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:18,544 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:18,551 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:18,556 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,560 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,561 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,564 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:18,572 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:18,581 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,583 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,584 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,585 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,586 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:18,590 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:18,595 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:18,599 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:18,607 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,609 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,611 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,613 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:18,621 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:18,630 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,631 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,632 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,633 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,634 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:18,638 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:18,643 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:18,647 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:18,651 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,653 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,654 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,657 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:18,666 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:18,675 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,676 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,700 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,704 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,705 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:18,715 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:18,760 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:18,833 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:18,875 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,882 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:25:18,883 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:18,886 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:18,894 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:18,903 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:18,904 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,905 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:18,905 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:18,906 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:18,913 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:18,917 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:18,950 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:19,012 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:25:19,047 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:25:19,048 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,051 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:19,060 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:19,062 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,063 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,064 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,064 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,066 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:19,074 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:19,079 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:19,083 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:19,094 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:25:19,097 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:25:19,098 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,100 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:19,102 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:19,110 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,111 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:19,112 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,113 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:19,113 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:19,116 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:19,118 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:19,119 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:19,120 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:19,121 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:19,123 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,124 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:19,125 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:19,127 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,128 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:19,128 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,129 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:19,130 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:19,148 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:19,158 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:19,169 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:19,180 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:19,183 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:19,184 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,193 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:19,195 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:19,197 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:19,197 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:19,198 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:19,199 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:19,200 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:19,201 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:19,202 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:19,203 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:19,204 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:19,205 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:19,206 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,207 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:19,209 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:19,211 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 31]), 30)\n",
      "2023-10-04 09:25:19,211 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:19,212 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 31]), 30)\n",
      "2023-10-04 09:25:19,213 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:19,214 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:19,216 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:19,217 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:19,219 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:19,220 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:19,220 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:19,223 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,225 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:19,233 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:19,241 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,243 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,243 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,244 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,245 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:19,256 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:19,261 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:19,271 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:19,276 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,278 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,279 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,282 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:19,290 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:19,299 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,300 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,301 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,303 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,304 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:19,313 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:19,320 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:19,327 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:19,335 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,337 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,338 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,341 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:19,349 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:19,358 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,359 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,360 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,361 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,361 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:19,372 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:19,392 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:19,396 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:19,400 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,406 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,407 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,410 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:19,420 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:19,429 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,431 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,432 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,433 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,434 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:19,441 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:19,445 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:19,449 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:19,453 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,455 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,456 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,459 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:19,467 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:19,475 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,476 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,477 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,478 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,479 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:19,485 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:19,493 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:19,497 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:19,501 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,503 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,505 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,507 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:19,514 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:19,523 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,524 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,525 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,526 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,526 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:19,532 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:19,537 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:19,543 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:19,549 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,579 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,580 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,583 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:19,592 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:19,602 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,604 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,605 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,606 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,608 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:19,658 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:19,664 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:19,668 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:19,673 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,676 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,677 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,680 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:19,689 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:19,698 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,699 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,700 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,701 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,703 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:19,709 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:19,715 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:19,727 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:19,735 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,743 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,746 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,749 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:19,758 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:19,766 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,767 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,769 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,770 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,770 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:19,775 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:19,779 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:19,783 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:19,787 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,789 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,790 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,794 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:19,802 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:19,810 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,811 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,813 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,813 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,814 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:19,824 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:19,828 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:19,832 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:19,836 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,838 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,839 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,841 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:19,850 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:19,859 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,860 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,861 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,862 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,862 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:19,867 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:19,870 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:19,873 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:19,880 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,882 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,882 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,885 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:19,893 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:19,895 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,896 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,896 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,897 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:19,898 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:19,904 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:19,911 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:19,916 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:19,928 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,931 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:25:19,932 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,934 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:19,936 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:19,944 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,945 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:19,946 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,947 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:19,948 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:19,950 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:19,951 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:19,952 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:19,956 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:19,957 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:19,958 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:19,960 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:19,962 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:19,964 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:19,965 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:19,966 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:19,967 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:19,968 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:19,984 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:19,994 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:20,005 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:20,016 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:20,019 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:20,020 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,029 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:20,032 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:20,034 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:20,035 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:20,036 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:20,037 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:20,037 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:20,039 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:20,040 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:20,041 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:20,042 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:20,043 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:20,044 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,046 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:20,048 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:20,049 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 32]), 31)\n",
      "2023-10-04 09:25:20,050 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:20,051 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 32]), 31)\n",
      "2023-10-04 09:25:20,053 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:20,054 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:20,055 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:20,056 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:20,058 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:20,059 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:20,060 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:20,061 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,063 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:20,072 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:20,081 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,082 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,083 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,084 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,085 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:20,100 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:20,131 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:20,136 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:20,141 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,158 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,160 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,163 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:20,174 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:20,185 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,187 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,189 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,190 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,192 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:20,243 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:20,247 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:20,250 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:20,253 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,256 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,257 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,260 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:20,268 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:20,276 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,277 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,278 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,278 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,279 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:20,288 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:20,292 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:20,296 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:20,299 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,301 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,302 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,304 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:20,312 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:20,319 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,320 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,321 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,322 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,323 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:20,332 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:20,336 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:20,339 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:20,342 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,349 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,351 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,353 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:20,361 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:20,370 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,371 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,372 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,372 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,373 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:20,380 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:20,383 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:20,388 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:20,465 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,468 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,469 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,471 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:20,479 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:20,487 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,488 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,489 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,490 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,491 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:20,495 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:20,499 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:20,504 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:20,531 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,533 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,535 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,537 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:20,545 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:20,553 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,554 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,555 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,556 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,556 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:20,561 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:20,565 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:20,568 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:20,571 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,573 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,574 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,576 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:20,585 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:20,593 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,594 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,595 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,596 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,597 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:20,603 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:20,607 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:20,611 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:20,615 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,618 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,618 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,622 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:20,630 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:20,638 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,639 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,640 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,641 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,642 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:20,648 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:20,653 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:20,658 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:20,661 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,666 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,667 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,670 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:20,679 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:20,687 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,689 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,689 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,690 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,691 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:20,699 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:20,703 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:20,707 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:20,711 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,713 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,714 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,717 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:20,725 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:20,733 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,734 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,735 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,736 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,738 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:20,745 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:20,749 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:20,753 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:20,757 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,759 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,760 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,763 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:20,772 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:20,773 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,774 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,776 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,776 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:20,777 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:20,783 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:20,788 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:20,791 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:20,795 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,796 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:25:20,797 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,800 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:20,802 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:20,810 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,811 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:20,812 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,813 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:20,814 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:20,817 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:20,820 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:20,828 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:20,832 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:20,833 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:20,836 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,837 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:20,839 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:20,840 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:20,841 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:20,842 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:20,842 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:20,844 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:20,865 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:20,882 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:20,899 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:20,914 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:20,930 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:20,932 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,967 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:20,969 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:20,971 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:20,972 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:20,973 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:20,974 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:20,975 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:20,976 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:20,977 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:20,978 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:20,979 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:20,980 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:20,981 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,983 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:20,984 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:20,986 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 33]), 32)\n",
      "2023-10-04 09:25:20,987 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:20,988 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 33]), 32)\n",
      "2023-10-04 09:25:20,989 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:20,990 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:20,992 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:20,993 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:20,994 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:20,995 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:20,996 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:20,997 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:20,998 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:21,007 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:21,015 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,016 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,017 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,017 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,019 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:21,025 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:21,028 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:21,032 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:21,049 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,085 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,086 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,089 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:21,098 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:21,106 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,107 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,109 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,110 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,110 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:21,122 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:21,126 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:21,133 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:21,136 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,138 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,139 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,142 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:21,150 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:21,158 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,159 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,160 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,161 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,162 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:21,170 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:21,175 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:21,178 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:21,181 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,194 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,195 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,198 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:21,206 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:21,215 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,217 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,218 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,218 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,220 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:21,228 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:21,246 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:21,252 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:21,256 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,259 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,260 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,263 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:21,272 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:21,281 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,281 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,282 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,283 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,284 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:21,291 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:21,294 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:21,297 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:21,301 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,303 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,306 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,308 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:21,317 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:21,326 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,327 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,328 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,329 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,330 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:21,337 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:21,340 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:21,372 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:21,396 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,399 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,400 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,407 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:21,424 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:21,434 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,435 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,437 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,437 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,438 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:21,444 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:21,454 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:21,458 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:21,464 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,476 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,478 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,481 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:21,489 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:21,497 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,498 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,499 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,500 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,501 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:21,511 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:21,576 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:21,612 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:21,617 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,619 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,620 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,623 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:21,631 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:21,640 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,642 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,643 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,644 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,645 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:21,653 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:21,656 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:21,660 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:21,665 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,673 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,674 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,677 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:21,686 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:21,694 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,695 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,696 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,697 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,698 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:21,705 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:21,709 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:21,713 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:21,717 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,719 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,720 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,725 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:21,734 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:21,742 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,744 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,745 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,746 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,747 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:21,798 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:21,810 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:21,813 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:21,816 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,817 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,819 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,821 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:21,829 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:21,831 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,832 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,832 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,833 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:21,834 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:21,841 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:21,845 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:21,856 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:21,861 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,864 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:25:21,865 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,868 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:21,870 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:21,878 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,879 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:21,880 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,881 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:21,882 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:21,885 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:21,886 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:21,887 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:21,888 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:21,889 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:21,890 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,892 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:21,894 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:21,895 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:21,896 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:21,897 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:21,897 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:21,899 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:21,913 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:21,924 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:21,934 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:21,947 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:21,950 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:21,951 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,960 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:21,963 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:21,964 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:21,965 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:21,965 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:21,966 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:21,967 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:21,969 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:21,969 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:21,971 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:21,972 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:21,972 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:21,973 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,975 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:21,976 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:21,978 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 34]), 33)\n",
      "2023-10-04 09:25:21,979 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:21,980 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 34]), 33)\n",
      "2023-10-04 09:25:21,981 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:21,981 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:21,983 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:21,984 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:21,985 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:21,986 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:21,987 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:21,988 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:21,990 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:21,998 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:22,006 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,007 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,008 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,009 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,009 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:22,015 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:22,022 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:22,029 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:22,039 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,042 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,043 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,046 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:22,054 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:22,062 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,063 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,064 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,065 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,066 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:22,072 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:22,080 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:22,088 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:22,096 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,099 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,100 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,103 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:22,111 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:22,119 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,120 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,121 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,121 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,122 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:22,129 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:22,134 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:22,137 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:22,150 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,164 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,166 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,168 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:22,177 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:22,185 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,186 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,187 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,188 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,189 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:22,200 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:22,203 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:22,213 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:22,217 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,219 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,220 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,223 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:22,231 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:22,241 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,242 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,243 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,244 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,245 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:22,251 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:22,257 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:22,261 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:22,264 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,266 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,267 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,270 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:22,278 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:22,286 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,286 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,288 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,289 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,290 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:22,297 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:22,301 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:22,305 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:22,308 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,310 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,311 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,314 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:22,323 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:22,333 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,334 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,335 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,336 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,337 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:22,345 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:22,350 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:22,353 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:22,359 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,361 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,362 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,365 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:22,373 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:22,382 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,383 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,384 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,386 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,386 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:22,397 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:22,403 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:22,407 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:22,411 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,413 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,414 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,417 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:22,428 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:22,439 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,441 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,442 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,443 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,444 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:22,449 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:22,453 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:22,455 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:22,458 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,459 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,460 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,463 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:22,472 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:22,480 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,481 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,482 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,483 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,483 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:22,497 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:22,504 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:22,507 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:22,516 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,521 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,523 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,526 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:22,534 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:22,542 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,543 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,544 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,545 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,546 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:22,556 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:22,564 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:22,568 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:22,573 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,575 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,576 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,579 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:22,586 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:22,588 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,589 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,590 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,591 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,591 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:22,598 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:22,601 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:22,604 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:22,607 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,609 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:25:22,610 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,613 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:22,615 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:22,623 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,624 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:22,625 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,626 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:22,627 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:22,631 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:22,634 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:22,638 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:22,642 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:22,644 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:22,645 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,646 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:22,648 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:22,650 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,651 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:22,651 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,652 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:22,653 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:22,668 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:22,677 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:22,687 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:22,695 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:22,697 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:22,699 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,708 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:22,710 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:22,712 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:22,713 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:22,714 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:22,715 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:22,716 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:22,717 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:22,718 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:22,719 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:22,720 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:22,722 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:22,723 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,724 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:22,726 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:22,728 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 35]), 34)\n",
      "2023-10-04 09:25:22,729 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:22,730 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 35]), 34)\n",
      "2023-10-04 09:25:22,732 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:22,733 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:22,734 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:22,736 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:22,737 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:22,739 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:22,740 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:22,741 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,743 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:22,751 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:22,760 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,761 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,762 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,763 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,763 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:22,769 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:22,797 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:22,801 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:22,805 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:25:22,807 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:25:22,808 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,811 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:22,819 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:22,828 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,829 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,830 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,831 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,831 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:22,837 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:22,840 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:22,855 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:22,876 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:25:22,879 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:25:22,880 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,882 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:22,890 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:22,899 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,900 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,901 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,902 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,903 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:22,907 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:22,911 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:22,915 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:22,919 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:25:22,921 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:25:22,922 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:22,925 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:22,933 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:22,942 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:22,943 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,944 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:22,945 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:22,945 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:22,957 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:22,967 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:23,020 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:23,064 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,068 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,069 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,072 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:23,081 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:23,090 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,091 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,092 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,093 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,094 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:23,099 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:23,102 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:23,105 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:23,118 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,120 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,121 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,124 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:23,131 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:23,140 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,141 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,142 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,143 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,144 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:23,151 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:23,156 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:23,159 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:23,162 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,165 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,165 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,169 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:23,176 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:23,185 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,186 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,187 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,188 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,189 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:23,200 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:23,210 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:23,214 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:23,218 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,220 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,222 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,224 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:23,232 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:23,241 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,242 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,243 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,244 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,244 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:23,254 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:23,259 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:23,264 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:23,269 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,272 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,273 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,276 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:23,285 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:23,294 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,295 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,296 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,297 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,298 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:23,304 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:23,308 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:23,312 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:23,316 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,318 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,318 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,321 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:23,330 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:23,338 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,339 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,340 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,341 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,342 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:23,348 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:23,353 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:23,357 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:23,361 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,365 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,366 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,369 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:23,378 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:23,386 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,388 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,389 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,390 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,391 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:23,397 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:23,401 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:23,408 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:23,412 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,414 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,415 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,418 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:23,427 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:23,429 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,430 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,432 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,433 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,434 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:23,441 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:23,445 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:23,449 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:23,453 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,455 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:25:23,455 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,458 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:23,460 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:23,468 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,469 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:23,470 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,471 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:23,472 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:23,473 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:23,477 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:23,479 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:23,481 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:23,482 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:23,482 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,484 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:23,486 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:23,487 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,488 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:23,489 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,490 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:23,491 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:23,504 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:23,516 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:23,529 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:23,545 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:23,555 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:23,557 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,632 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:23,634 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:23,636 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:23,636 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:23,637 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:23,639 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:23,640 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:23,641 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:23,642 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:23,643 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:23,644 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:23,645 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:23,646 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,648 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:23,650 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:23,652 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 36]), 35)\n",
      "2023-10-04 09:25:23,653 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:23,653 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 36]), 35)\n",
      "2023-10-04 09:25:23,655 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:23,656 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:23,658 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:23,659 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:23,661 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:23,662 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:23,663 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:23,663 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,665 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:23,673 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:23,681 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,682 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,683 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,684 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,685 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:23,696 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:23,704 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:23,718 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:23,731 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:25:23,791 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:25:23,792 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,795 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:23,803 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:23,811 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,812 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,813 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,814 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,815 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:23,820 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:23,823 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:23,828 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:23,840 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:25:23,842 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:25:23,843 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,845 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:23,853 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:23,864 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,865 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,866 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,867 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,868 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:23,872 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:23,875 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:23,897 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:23,943 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:25:23,946 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:25:23,947 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,950 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:23,958 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:23,966 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:23,968 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,969 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:23,970 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:23,971 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:23,979 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:23,984 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:23,987 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:23,991 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:25:23,993 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:25:23,994 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:23,997 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:24,005 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:24,014 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:24,016 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,017 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:24,018 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,019 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:24,025 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:24,043 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:24,048 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:24,053 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,055 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,056 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,059 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:24,067 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:24,075 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:24,076 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,077 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:24,078 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,079 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:24,083 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:24,087 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:24,091 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:24,095 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,097 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,098 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,100 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:24,108 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:24,116 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:24,119 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,119 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:24,120 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,126 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:24,152 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:24,165 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:24,192 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:24,197 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,203 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,205 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,208 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:24,215 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:24,223 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:24,224 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,225 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:24,226 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,227 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:24,234 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:24,239 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:24,274 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:24,321 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,324 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,325 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,327 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:24,335 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:24,343 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:24,345 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,346 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:24,347 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,347 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:24,353 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:24,359 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:24,364 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:24,368 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,370 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,372 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,375 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:24,384 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:24,393 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:24,394 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,395 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:24,397 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,398 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:24,406 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:24,411 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:24,415 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:24,419 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,421 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,422 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,425 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:24,434 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:24,442 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:24,443 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,444 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:24,445 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,446 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:24,452 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:24,457 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:24,462 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:24,470 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,472 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,473 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,476 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:24,484 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:24,486 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:24,486 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,487 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:24,488 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,489 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:24,494 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:24,497 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:24,501 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:24,504 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,505 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:25:24,506 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,508 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:24,511 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:24,519 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:24,520 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:24,521 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:24,522 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:24,523 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:24,524 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:24,526 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:24,526 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:24,530 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:24,533 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:24,534 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,535 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:24,537 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:24,538 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:24,539 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:24,540 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:24,540 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:24,541 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:24,554 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:24,563 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:24,573 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:24,583 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:24,596 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:24,597 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,665 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:24,667 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:24,669 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:24,669 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:24,670 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:24,671 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:24,672 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:24,674 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:24,675 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:24,676 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:24,677 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:24,678 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:24,679 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,681 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:24,682 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:24,684 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 37]), 36)\n",
      "2023-10-04 09:25:24,685 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:24,685 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 37]), 36)\n",
      "2023-10-04 09:25:24,687 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:24,687 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:24,689 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:24,690 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:24,691 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:24,692 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:24,693 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:24,694 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,695 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:24,703 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:24,712 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:24,713 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,714 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:24,715 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,716 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:24,723 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:24,732 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:24,736 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:24,746 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:25:24,768 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:25:24,770 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,773 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:24,784 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:24,798 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:24,799 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,801 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:24,802 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,804 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:24,810 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:24,820 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:24,825 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:24,897 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:25:24,911 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:25:24,913 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:24,916 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:24,924 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:24,933 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:24,934 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,935 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:24,935 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:24,936 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:24,973 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:24,979 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:25,007 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:25,013 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,014 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,015 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,018 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:25,026 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:25,033 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,035 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,036 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,037 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,038 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:25,084 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:25,106 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:25,111 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:25,116 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,118 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,120 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,123 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:25,131 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:25,140 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,141 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,143 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,143 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,144 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:25,153 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:25,157 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:25,160 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:25,163 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,165 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,166 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,169 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:25,176 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:25,185 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,186 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,186 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,187 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,188 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:25,194 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:25,198 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:25,203 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:25,207 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,209 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,210 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,213 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:25,222 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:25,230 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,231 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,232 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,233 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,234 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:25,242 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:25,246 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:25,251 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:25,255 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,257 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,258 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,261 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:25,270 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:25,278 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,279 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,280 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,281 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,281 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:25,287 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:25,296 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:25,300 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:25,304 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,305 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,306 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,309 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:25,317 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:25,325 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,326 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,327 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,328 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,328 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:25,344 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:25,351 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:25,356 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:25,361 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,364 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,365 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,368 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:25,376 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:25,385 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,386 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,386 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,388 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,389 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:25,398 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:25,402 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:25,407 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:25,416 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,419 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,420 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,423 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:25,431 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:25,439 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,440 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,441 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,442 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,443 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:25,449 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:25,453 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:25,458 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:25,461 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,463 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,464 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,467 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:25,475 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:25,476 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,477 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,478 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,479 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,479 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:25,485 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:25,492 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:25,496 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:25,512 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,514 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:25:25,516 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,518 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:25,520 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:25,528 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,530 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:25,530 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,531 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:25,532 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:25,535 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:25,540 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:25,542 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:25,547 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:25,548 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:25,549 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,551 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:25,552 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:25,554 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,555 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:25,556 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,556 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:25,557 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:25,572 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:25,584 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:25,599 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:25,610 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:25,613 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:25,614 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,622 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:25,624 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:25,626 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:25,627 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:25,627 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:25,629 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:25,629 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:25,631 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:25,632 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:25,633 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:25,634 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:25,635 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:25,636 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,638 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:25,640 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:25,641 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 38]), 37)\n",
      "2023-10-04 09:25:25,642 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:25,643 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 38]), 37)\n",
      "2023-10-04 09:25:25,644 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:25,646 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:25,647 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:25,648 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:25,649 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:25,651 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:25,652 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:25,652 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,654 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:25,661 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:25,671 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,672 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,673 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,673 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,674 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:25,680 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:25,686 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:25,691 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:25,695 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:25:25,697 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:25:25,698 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,701 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:25,710 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:25,721 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,722 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,723 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,724 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,730 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:25,780 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:25,785 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:25,789 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:25,803 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:25:25,806 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:25:25,807 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,809 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:25,817 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:25,825 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,827 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,828 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,829 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,830 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:25,834 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:25,837 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:25,843 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:25,855 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:25:25,860 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:25:25,863 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,865 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:25,874 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:25,882 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,883 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,884 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:25,885 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:25,886 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:25,898 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:25,902 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:25,905 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:25,959 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:25:25,974 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:25:25,975 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:25,979 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:25,988 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:25,997 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:25,999 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,000 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,001 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,002 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:26,021 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:26,029 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:26,042 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:26,048 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,050 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,051 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,054 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:26,062 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:26,072 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,073 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,074 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,075 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,076 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:26,145 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:26,157 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:26,162 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:26,166 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,168 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,169 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,171 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:26,179 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:26,187 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,188 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,189 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,190 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,190 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:26,195 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:26,199 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:26,206 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:26,210 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,212 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,213 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,215 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:26,224 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:26,232 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,233 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,234 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,235 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,236 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:26,241 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:26,244 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:26,247 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:26,252 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,254 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,255 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,258 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:26,265 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:26,273 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,275 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,275 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,276 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,277 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:26,282 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:26,285 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:26,288 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:26,294 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,297 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,297 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,300 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:26,309 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:26,317 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,318 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,319 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,320 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,320 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:26,328 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:26,332 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:26,335 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:26,338 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,341 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,342 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,344 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:26,352 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:26,360 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,361 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,362 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,362 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,364 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:26,369 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:26,373 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:26,377 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:26,382 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,384 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,385 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,388 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:26,400 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:26,402 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,403 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,405 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,406 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,406 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:26,413 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:26,417 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:26,422 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:26,426 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,429 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:25:26,430 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,433 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:26,436 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:26,444 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,445 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:26,446 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,447 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:26,448 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:26,450 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:26,452 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:26,456 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:26,460 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:26,462 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:26,463 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,465 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:26,467 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:26,469 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,469 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:26,470 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,472 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:26,473 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:26,485 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:26,496 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:26,507 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:26,518 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:26,523 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:26,524 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,534 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:26,536 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:26,538 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:25:26,540 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:26,540 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:25:26,541 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:26,542 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:25:26,544 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:25:26,546 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:25:26,547 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:25:26,548 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:26,549 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:26,550 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,552 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:25:26,554 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:26,556 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 39]), 38)\n",
      "2023-10-04 09:25:26,556 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:26,557 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 39]), 38)\n",
      "2023-10-04 09:25:26,558 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:26,559 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:25:26,561 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:25:26,562 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:25:26,564 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:25:26,565 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:26,567 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:26,568 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,569 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:26,578 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:26,591 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,593 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,594 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,595 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,596 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:25:26,645 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:25:26,720 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:25:26,764 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:25:26,770 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:25:26,773 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:25:26,774 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,776 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:25:26,784 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:26,792 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,793 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,794 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,795 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,796 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:25:26,803 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:25:26,809 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:25:26,816 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:25:26,836 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:25:26,839 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:25:26,840 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,843 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:25:26,852 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:26,860 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,861 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,862 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,862 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,863 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:25:26,870 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:25:26,873 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:25:26,877 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:25:26,886 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:25:26,889 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:25:26,889 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,893 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:25:26,902 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:26,910 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,911 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,913 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,913 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,914 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:25:26,927 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:25:26,932 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:25:26,936 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:25:26,940 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:25:26,942 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:25:26,943 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,947 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:25:26,955 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:26,964 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:26,965 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,966 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:26,967 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:26,968 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:25:26,973 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:25:26,977 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:25:26,986 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:25:26,992 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:25:26,994 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:25:26,995 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:25:26,998 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:25:27,006 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:27,014 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:27,015 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,016 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:27,017 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,018 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:25:27,023 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:25:27,036 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:25:27,040 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:25:27,046 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,048 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,050 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:25:27,052 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:25:27,059 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:27,068 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:27,069 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,070 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:27,070 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,071 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:25:27,076 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:25:27,088 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:25:27,093 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:25:27,098 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,101 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,102 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:25:27,106 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:25:27,117 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:27,125 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:27,126 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,127 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:27,128 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,129 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:25:27,135 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:25:27,142 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:25:27,147 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:25:27,155 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,158 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,159 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:25:27,161 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:25:27,169 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:27,177 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:27,178 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,179 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:27,180 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,181 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:25:27,208 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:25:27,267 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:25:27,299 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:25:27,306 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,309 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,310 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:25:27,313 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:25:27,322 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:27,331 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:27,332 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,334 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:27,336 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,336 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:25:27,350 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:25:27,363 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:25:27,368 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:25:27,372 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,374 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,375 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:25:27,378 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:25:27,386 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:27,398 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:27,400 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,401 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:27,403 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,405 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:25:27,414 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:25:27,430 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:25:27,446 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:25:27,455 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,457 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,458 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:25:27,460 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:25:27,469 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:27,471 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:27,472 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,473 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:27,474 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:25:27,475 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:25:27,489 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:25:27,492 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:25:27,498 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:25:27,511 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,513 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:25:27,514 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:25:27,517 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:25:27,519 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:25:27,526 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:27,527 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:27,528 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:27,528 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:27,529 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:25:27,532 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:25:27,533 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:25:27,534 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:25:27,536 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:25:27,537 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:25:27,538 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:25:27,539 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:25:27,540 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:25:27,541 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:25:27,542 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:25:27,543 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:25:27,545 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:25:27,545 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:25:27,561 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:25:27,570 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:25:27,578 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:25:27,588 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:25:27,590 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:25:27,591 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:25:27,600 [3316428403.py:28 in <module>] INFO - Who are you? Are you conscious?�\n",
      "2023-10-04 09:25:27,602 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:25:27,603 [3316428403.py:28 in <module>] INFO - Where is Deutschland?” asks the man\n",
      "\n",
      "That is no normal question. What questions is it I face every day? The answer to the question is always the\n",
      "2023-10-04 09:25:27,604 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:25:27,605 [3316428403.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?2 working so far? (Hint: it hasn't even tested properly yet)\n",
      "Its running Mate Mate 40 Pro. It runs on Android Loll\n",
      "2023-10-04 09:25:27,606 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:25:27,607 [3316428403.py:28 in <module>] INFO - Who are you? Are you conscious?�\n",
      "I am, yes it's hard not to be.\n",
      "2023-10-04 09:25:27,608 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:25:27,609 [3316428403.py:28 in <module>] INFO - Where is Deutschland?1?\n",
      "That should be good.\n",
      "I am in Berlin, the city with the biggest concentration of German states, there are no more states anymore\n",
      "2023-10-04 09:25:27,609 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:25:27,610 [3316428403.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?\n",
      "Huawei’s Mate 60 Pro is the first Huawei Mate 60 Pro to ship with the dual SIM card you see in other models.\n",
      "\n",
      "2023-10-04 09:25:27,611 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:25:27,612 [3316428403.py:28 in <module>] INFO - Who are you? Are you conscious?� I am thinking I am, and I can't stop watching you now.\n",
      "I know you're dreaming, but I just wanted to tell you\n",
      "2023-10-04 09:25:27,613 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:25:27,614 [3316428403.py:28 in <module>] INFO - Where is Deutschland?\n",
      "\n",
      "I live in Germany. Deutscher Dachau is in the Bavaria countryside. There are many things to do in Parentland\n",
      "2023-10-04 09:25:27,615 [3316428403.py:29 in <module>] INFO - ----------\n"
     ]
    }
   ],
   "source": [
    "# generate test\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "prompts = [\n",
    "    'Who are you? Are you conscious?',\n",
    "    'Where is Deutschland?',\n",
    "    'How is Huawei Mate 60 Pro?'\n",
    "] \n",
    "prompts = prompts * (gbs * ngb // len(prompts)) + prompts[:(gbs * ngb % len(prompts))]\n",
    "\n",
    "prompt_len = 10\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "inputs = tokenizer(prompts, padding=\"max_length\", max_length=prompt_len, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(\n",
    "    inputs.input_ids, \n",
    "    max_length=30 + prompt_len,\n",
    "    # num_beams=2, #\n",
    "    # num_beam_groups=2, #\n",
    "    # diversity_penalty=0.1, #\n",
    "    do_sample=True, #\n",
    ")\n",
    "\n",
    "output_texts = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "for output_text in output_texts:\n",
    "    logging.info(output_text)\n",
    "    logging.info('-' * 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
