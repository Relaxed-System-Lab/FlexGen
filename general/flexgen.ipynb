{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Policy, logging\n",
    "# from forward import flexgen\n",
    "from test import test_hf_gen\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "checkpoint = \"facebook/opt-125m\" # 125m 6.7b 13b 30b\n",
    "# checkpoint = \"Salesforce/codegen-350M-mono\"\n",
    "# checkpoint = 'bigscience/bloom-560m'\n",
    "\n",
    "policy = Policy(\n",
    "    gpu_batch_size=2, \n",
    "    num_gpu_batches=4, \n",
    "    weights_gpu_percent=0.0, \n",
    "    weights_cpu_percent=0.3, \n",
    "    cache_gpu_percent=0.0, \n",
    "    cache_cpu_percent=0.2, \n",
    "    act_gpu_percent=0.0, \n",
    "    act_cpu_percent=0.6, \n",
    "    overlap=True, \n",
    "    pin_weight=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward.py: rewrite layer forward function\n",
    "\n",
    "import torch\n",
    "import functools \n",
    "import contextlib\n",
    "\n",
    "# from minibatch import get_size_info, load_kth_batch_inputs, concat_outputs\n",
    "from utils import get_module_from_name\n",
    "\n",
    "\n",
    "def reset_forward(model, layer_name):        \n",
    "    layer = get_module_from_name(model, layer_name) \n",
    "\n",
    "    if hasattr(layer, \"_flexgen_old_forward\"):\n",
    "        layer.forward = layer._flexgen_old_forward\n",
    "        delattr(layer, \"_flexgen_old_forward\")\n",
    "        logger.debug(f'{layer_name} from flexgen to old.')\n",
    "\n",
    "    if hasattr(layer, \"_test_old_forward\"):\n",
    "        layer.forward = layer._test_old_forward\n",
    "        delattr(layer, \"_test_old_forward\")\n",
    "        logger.debug(f'{layer_name} from test to old.')\n",
    "\n",
    "def to_test_forward(mpl, layer_name, call_layer_log):\n",
    "    layer = get_module_from_name(mpl.model, layer_name) \n",
    "    compute_device = 'cpu' \n",
    "    layer._test_old_forward = old_forward = layer.forward \n",
    "\n",
    "    @functools.wraps(old_forward)\n",
    "    def new_forward(*args, **kwargs):\n",
    "        mpl.load_layer_weights(layer_name, compute_device) \n",
    "\n",
    "        call_layer_log.append(layer_name)  # \n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = old_forward(*args, **kwargs)\n",
    "\n",
    "        mpl.offload_layer_weights(layer_name)\n",
    "        return output\n",
    "\n",
    "    layer.forward = new_forward\n",
    "    logger.debug(f'{layer_name} to test forward') \n",
    "\n",
    "@contextlib.contextmanager\n",
    "def test(mpl, call_layer_log):\n",
    "    model = mpl.model\n",
    "    layer_names = mpl.layer_names\n",
    "\n",
    "    # test run to get layer calling order\n",
    "    for layer_name in layer_names:\n",
    "        to_test_forward(mpl, layer_name, call_layer_log)\n",
    "    yield \n",
    "    for layer_name in layer_names:\n",
    "        reset_forward(model, layer_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "from typing import Mapping, Tuple\n",
    "import numpy as np \n",
    "import os \n",
    "import torch\n",
    "from math import floor\n",
    "\n",
    "class MixTensor:\n",
    "    def __init__(\n",
    "        self, \n",
    "        mix_data: Tuple, \n",
    "        split_dim: int, \n",
    "        device: torch.device, \n",
    "        shape: torch.Size,\n",
    "        percents: Mapping[str, float],\n",
    "        file_path: str,\n",
    "        dtype\n",
    "    ):\n",
    "        self.mix_data = mix_data\n",
    "        self.split_dim = split_dim \n",
    "        self.device = device \n",
    "        self.shape = shape \n",
    "        self.percents = percents\n",
    "        self.file_path = file_path\n",
    "        self.dtype = dtype\n",
    "    \n",
    "    def size(self):\n",
    "        return self.shape \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_split_dim(tensor):\n",
    "        dim_sizes = tensor.size()\n",
    "        max_dim, max_size = -1, -1\n",
    "        for dim, size in enumerate(dim_sizes):\n",
    "            if size > max_size:\n",
    "                max_size = size\n",
    "                max_dim = dim \n",
    "        return max_dim \n",
    "    \n",
    "    @staticmethod\n",
    "    def tensor_dim_slice(tensor, dim, dim_slice):\n",
    "        return tensor[(dim if dim >= 0 else dim + tensor.dim()) * (slice(None), ) + (dim_slice, )]\n",
    "    \n",
    "    @staticmethod\n",
    "    def split_tensor(tensor, dim, percents):\n",
    "        dim_size = tensor.size(dim)\n",
    "        g_per, c_per, _ = [percents[dev] for dev in ['cuda', 'cpu', 'disk']]\n",
    "        \n",
    "        g_cut = floor(dim_size * g_per)\n",
    "        c_cut = floor(dim_size * (g_per + c_per))\n",
    "\n",
    "        g_data = MixTensor.tensor_dim_slice(tensor, dim, slice(0, g_cut))\n",
    "        c_data = MixTensor.tensor_dim_slice(tensor, dim, slice(g_cut, c_cut))\n",
    "        d_data = MixTensor.tensor_dim_slice(tensor, dim, slice(c_cut, dim_size))\n",
    "        return g_data, c_data, d_data \n",
    "\n",
    "    @classmethod\n",
    "    def from_tensor(\n",
    "        cls, \n",
    "        tensor: torch.Tensor, \n",
    "        percents: Mapping[str, float],\n",
    "        file_path: str \n",
    "    ):\n",
    "        split_dim = cls.get_split_dim(tensor) \n",
    "        device = tensor.device \n",
    "        shape = tensor.shape\n",
    "        dtype = tensor.dtype\n",
    "        \n",
    "        g_data, c_data, d_data = cls.split_tensor(tensor, split_dim, percents) \n",
    "        \n",
    "        g_data = g_data.to('cuda' if torch.cuda.is_available() else 'cpu') if g_data.numel() else None\n",
    "        c_data = c_data.to('cpu') if c_data.numel() else None\n",
    "        if d_data.numel():\n",
    "            d_data = d_data.cpu().numpy()\n",
    "            np_shape = d_data.shape\n",
    "            np_dtype = d_data.dtype \n",
    "\n",
    "            fp = np.memmap(file_path, mode=\"w+\", shape=np_shape, dtype=np_dtype)\n",
    "            fp[:] = d_data[:]\n",
    "            d_data = (np_shape, np_dtype)\n",
    "        else:\n",
    "            d_data = None \n",
    "        mix_data = (g_data, c_data, d_data)\n",
    "\n",
    "        return cls(\n",
    "            mix_data=mix_data,\n",
    "            split_dim=split_dim,\n",
    "            device=device,\n",
    "            shape=shape,\n",
    "            percents=percents,\n",
    "            file_path=file_path,\n",
    "            dtype=dtype\n",
    "        )\n",
    "\n",
    "    @classmethod \n",
    "    def from_mixtensor(cls, mix_tensor):\n",
    "        self = mix_tensor \n",
    "        return self \n",
    "\n",
    "    def to_tensor(self):\n",
    "        g_data, c_data, d_data = self.mix_data \n",
    "        compute_device = self.device \n",
    "\n",
    "        tensor = []\n",
    "        if g_data is not None:\n",
    "            if g_data.device != torch.device(compute_device):\n",
    "                g_data = g_data.to(compute_device) \n",
    "            tensor.append(g_data)\n",
    "        if c_data is not None:\n",
    "            if c_data.device != torch.device(compute_device):\n",
    "                c_data = c_data.to(compute_device) \n",
    "            tensor.append(c_data)\n",
    "        if d_data is not None:\n",
    "            (shape, np_dtype) = d_data \n",
    "            d_data = np.memmap(self.file_path, shape=shape, dtype=np_dtype, mode='r')\n",
    "            d_data = torch.from_numpy(d_data).to(compute_device)\n",
    "            tensor.append(d_data)\n",
    "            \n",
    "        tensor = torch.cat(tensor, dim=self.split_dim) \n",
    "\n",
    "        return tensor        \n",
    "\n",
    "    def __add__(self, mix_tensor):\n",
    "        assert self.shape == mix_tensor.shape and type(self) == type(mix_tensor) # is same shape mix tensor\n",
    "        res = self.to_tensor() + mix_tensor.to_tensor() \n",
    "        return self.from_tensor(res, self.percents, self.file_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    x = torch.rand(8, 500, 64, dtype=torch.float32)\n",
    "    m = MixTensor.from_tensor(x, percents={'cuda':0, 'cpu':0.5, 'disk':0.5}, file_path='test/m.dat')\n",
    "    m2 = MixTensor.from_tensor(x, percents={'cuda':0, 'cpu':0.5, 'disk':0.5}, file_path='test/m2.dat')\n",
    "    m = m + m2\n",
    "    print((m.to_tensor() - 2 * x).abs().sum() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "from accelerate.utils import honor_type\n",
    "from typing import Mapping\n",
    "from utils import logging \n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "def get_type_size_info(obj): # recursive\n",
    "    if isinstance(obj, (tuple, list)):\n",
    "        return honor_type(obj, (get_type_size_info(o) for o in obj))\n",
    "    elif isinstance(obj, Mapping):\n",
    "        return type(obj)({k:get_type_size_info(v) for k, v in obj.items()})\n",
    "    \n",
    "    elif isinstance(obj, (torch.Tensor, MixTensor, BatchMixTensor)):\n",
    "        return f'{type(obj)}: {obj.size()}'\n",
    "\n",
    "    elif isinstance(obj, (int, bool, type(None))): \n",
    "        return f'{type(obj)}: {obj}'\n",
    "    else:\n",
    "        logger.warning(f'inputs: {obj} of type \\'{type(obj)}\\' is not implemented.')\n",
    "        return f'{type(obj)}: {obj}'\n",
    "\n",
    "def to_tensor(obj): # recursive\n",
    "    if isinstance(obj, (tuple, list)):\n",
    "        return honor_type(obj, (to_tensor(o) for o in obj))\n",
    "    elif isinstance(obj, Mapping):\n",
    "        return type(obj)({k:to_tensor(v) for k, v in obj.items()})\n",
    "    elif isinstance(obj, torch.Tensor):\n",
    "        return obj\n",
    "    elif isinstance(obj, (MixTensor, BatchMixTensor)):\n",
    "        return obj.to_tensor()\n",
    "\n",
    "    elif isinstance(obj, (int, bool, type(None))): \n",
    "        return obj\n",
    "    else:\n",
    "        logger.warning(f'inputs: {obj} of type \\'{type(obj)}\\' is not implemented.')\n",
    "        return obj\n",
    "\n",
    "def to_mixed_device(obj, policy, prefix): \n",
    "    if isinstance(obj, tuple) and len(obj) == 2 and isinstance(obj[0], torch.Tensor) and isinstance(obj[1], torch.Tensor): # KV cache\n",
    "        m0 = MixTensor.from_tensor(\n",
    "            obj[0], \n",
    "            percents={\n",
    "                'cuda':policy.cache_gpu_percent, \n",
    "                'cpu':policy.cache_cpu_percent, \n",
    "                'disk':policy.cache_disk_percent, \n",
    "            }, \n",
    "            file_path=f'{prefix}.key.dat'\n",
    "        )\n",
    "        m1 = MixTensor.from_tensor(\n",
    "            obj[1], \n",
    "            percents={\n",
    "                'cuda':policy.cache_gpu_percent, \n",
    "                'cpu':policy.cache_cpu_percent, \n",
    "                'disk':policy.cache_disk_percent, \n",
    "            }, \n",
    "            file_path=f'{prefix}.value.dat'\n",
    "        )\n",
    "        return (m0, m1)\n",
    "    elif isinstance(obj, torch.Tensor):\n",
    "        return MixTensor.from_tensor(\n",
    "            obj, \n",
    "            percents={\n",
    "                'cuda':policy.act_gpu_percent, \n",
    "                'cpu':policy.act_cpu_percent, \n",
    "                'disk':policy.act_disk_percent, \n",
    "            }, \n",
    "            file_path=f'{prefix}.dat'\n",
    "        )\n",
    "    elif isinstance(obj, tuple):\n",
    "        return honor_type(obj, (to_mixed_device(o, policy, f'{prefix}.{i}') for i, o in enumerate(obj)))\n",
    "    else:\n",
    "        logger.warning(f'inputs: {obj} of type \\'{type(obj)}\\' is not implemented.')\n",
    "        return obj\n",
    "\n",
    "from typing import Iterable\n",
    "class BatchMixTensor:\n",
    "    def __init__(self, batches: Iterable[MixTensor]):\n",
    "        self.dtype = batches[0].dtype\n",
    "        self.device = batches[0].device\n",
    "        self.batches = batches \n",
    "\n",
    "        self.shape = self.size()\n",
    "\n",
    "    # def __getitem__(self, i):\n",
    "    #     return self.batches[i]\n",
    "    \n",
    "    # def __setitem__(self, i, mt: MixTensor):\n",
    "    #     self.batches[i] = mt\n",
    "\n",
    "    # def __len__(self):\n",
    "    #     return len(self.batches)\n",
    "    \n",
    "    def size(self):\n",
    "        shape = list(self.batches[0].size()) \n",
    "        shape[0] *= len(self.batches)\n",
    "        return torch.Size(shape)\n",
    "\n",
    "    def __add__(self, bmt):\n",
    "        for k in range(len(self.batches)): \n",
    "            # TODO flexgen: parallelly load k+1\n",
    "            self_k = self.batches[k].to_tensor()\n",
    "            bmt_k = bmt.batches[k].to_tensor()\n",
    "            res = self_k + bmt_k \n",
    "            self.batches[k] = MixTensor.from_tensor(res, self.batches[k].percents, self.batches[k].file_path)\n",
    "        return self \n",
    "\n",
    "    def contiguous(self):\n",
    "        return self.to_tensor()\n",
    "\n",
    "    def to_tensor(self):\n",
    "        tensor = []\n",
    "        for mt in self.batches:\n",
    "            tensor.append(mt.to_tensor())\n",
    "        return torch.cat(tensor)\n",
    "\n",
    "def concat_outputs(outputs): # concatenate K outputs to one output\n",
    "    assert len(outputs), 'empty outputs.'\n",
    "    assert isinstance(outputs[0], (MixTensor, torch.Tensor, tuple)), f'not supported type: {type(outputs[0])}.'\n",
    "    \n",
    "    if isinstance(outputs[0], torch.Tensor):\n",
    "        return torch.cat(outputs, dim=0)\n",
    "    elif isinstance(outputs[0], MixTensor):\n",
    "        return BatchMixTensor(outputs)\n",
    "    elif isinstance(outputs[0], tuple):\n",
    "        def f(outputs):\n",
    "            ans = []\n",
    "            for elem in zip(*outputs):\n",
    "                if isinstance(elem[0], torch.Tensor):\n",
    "                    ans.append(torch.cat(elem, dim=0))\n",
    "                elif isinstance(elem[0], MixTensor):\n",
    "                    ans.append(BatchMixTensor(elem))\n",
    "                elif isinstance(elem[0], tuple):\n",
    "                    ans.append(f(elem))\n",
    "                else:\n",
    "                    logger.warning(f'outputs: {elem[0]} of type \\'{type(elem[0])}\\' is not implemented.')\n",
    "                    ans.append(elem[0])\n",
    "            return tuple(ans)\n",
    "\n",
    "        return f(outputs)\n",
    "\n",
    "\n",
    "def load_kth_batch_inputs(inputs, k, ngb): # for both args, kwargs, with a nested structure of tuple/list/dict/Tensor\n",
    "    if isinstance(inputs, (tuple, list)): # e.g. args\n",
    "        return honor_type(inputs, (load_kth_batch_inputs(inp, k, ngb) for inp in inputs))\n",
    "    elif isinstance(inputs, Mapping): # e.g. kwargs\n",
    "        return type(inputs)({key:load_kth_batch_inputs(value, k, ngb) for key, value in inputs.items()})\n",
    "    elif isinstance(inputs, torch.Tensor):\n",
    "        mini_size = inputs.size(0) // ngb\n",
    "        return inputs[k * mini_size:(k + 1) * mini_size]\n",
    "    # elif isinstance(inputs, MixTensor):\n",
    "    #     inputs = inputs.to_tensor()\n",
    "    #     mini_size = inputs.size(0) // ngb\n",
    "    #     return inputs[k * mini_size:(k + 1) * mini_size]\n",
    "    elif isinstance(inputs, BatchMixTensor):\n",
    "        mini_batch = inputs.batches[k]\n",
    "        return mini_batch.to_tensor()\n",
    "    elif isinstance(inputs, (int, bool, type(None))): \n",
    "        return inputs\n",
    "    else:\n",
    "        logger.warning(f'inputs: {inputs} of type \\'{type(inputs)}\\' is not implemented.')\n",
    "        return inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_flexgen_forward(mpl, j, compute_device):\n",
    "    # rewrite the j-th layer's forward\n",
    "    layer_name = mpl.layer_names[j]\n",
    "    next_layer_name = mpl.layer_names[(j + 1) % len(mpl.layer_names)]\n",
    "\n",
    "    policy = mpl.policy\n",
    "    ngb = policy.num_gpu_batches\n",
    "\n",
    "    layer = get_module_from_name(mpl.model, layer_name)  \n",
    "    if hasattr(layer, \"_flexgen_old_forward\"): return  \n",
    "    \n",
    "    layer._flexgen_old_forward = old_forward = layer.forward \n",
    "\n",
    "    @functools.wraps(old_forward)\n",
    "    def new_forward(*args, **kwargs):\n",
    "        # pre fwd: load curr & next weights, TODO: cuda stream\n",
    "        mpl.load_layer_weights(layer_name, compute_device) \n",
    "        mpl.load_layer_weights(next_layer_name, compute_device) \n",
    "        \n",
    "        # loop forward pass of K minibatches, TODO: cuda stream\n",
    "        with torch.no_grad():\n",
    "\n",
    "            logger.debug(f'args: {get_type_size_info(args)}')\n",
    "            logger.debug(f'kwargs: {get_type_size_info(kwargs)}')\n",
    "            \n",
    "            outputs = []\n",
    "            for k in range(ngb):\n",
    "\n",
    "                # 'pre' fwd: load curr & next inputs (activations, KV cache) to compute device\n",
    "                args_k = load_kth_batch_inputs(args, k, ngb)\n",
    "                kwargs_k = load_kth_batch_inputs(kwargs, k, ngb)\n",
    "\n",
    "                # the k-th fwd pass\n",
    "                output = old_forward(*args_k, **kwargs_k)\n",
    "\n",
    "                # post fwd: 1) output: to mix, 2) args_k, kwargs_k: free (TODO?)\n",
    "                output = to_mixed_device(output, policy, prefix=f'tmp/{layer_name}.output')\n",
    "                # output = to_tensor(output)\n",
    "\n",
    "                logger.debug(f'layer: {layer_name}, '\n",
    "                             f'batch: {k}, '\n",
    "                             f'args: {get_type_size_info(args_k)}, '\n",
    "                             f'kwargs: {get_type_size_info(kwargs_k)}, '\n",
    "                             f'output: {get_type_size_info(output)}')\n",
    "                outputs.append(output) \n",
    "\n",
    "            output = concat_outputs(outputs)\n",
    "            output = to_tensor(output)\n",
    "            logger.debug(f'outputs after concat: {get_type_size_info(output)}')  \n",
    "\n",
    "        # post fwd: free curr weights\n",
    "        mpl.offload_layer_weights(layer_name)\n",
    "        return output\n",
    "\n",
    "    layer.forward = new_forward\n",
    "    logger.debug(f'{layer_name} to flexgen forward')\n",
    "\n",
    "@contextlib.contextmanager \n",
    "def flexgen(checkpoint, policy):\n",
    "    # init model \n",
    "    from model import ModelPolicyLoader\n",
    "    mpl = ModelPolicyLoader(checkpoint, policy)\n",
    "    mpl.init_all_weights() # init \n",
    "\n",
    "    # test run, get layer order\n",
    "    call_layer_log = []\n",
    "    with test(mpl, call_layer_log):\n",
    "        from test import test_hf_gen\n",
    "        test_hf_gen(mpl.checkpoint, mpl.model, 1,1, prompts=['0'])\n",
    "\n",
    "    assert len(call_layer_log) == len(mpl.layer_names) and set(call_layer_log) == set(mpl.layer_names)\n",
    "    mpl.layer_names = call_layer_log\n",
    "\n",
    "    # rewrite layer forward\n",
    "    for j, _ in enumerate(mpl.layer_names):\n",
    "        compute_device = 'cpu'\n",
    "        to_flexgen_forward(mpl, j, compute_device)\n",
    "    yield mpl.model \n",
    "    for layer_name in mpl.layer_names:\n",
    "        reset_forward(mpl.model, layer_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 14:22:51,985 [connectionpool.py:273 in _get_conn] DEBUG - Resetting dropped connection: huggingface.co\n",
      "2023-10-11 14:22:52,157 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-11 14:22:52,304 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-11 14:22:52,458 [model.py:159 in is_on_disk] INFO - [], ['lm_head.weight']\n",
      "2023-10-11 14:22:52,506 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-11 14:22:52,596 [model.py:159 in is_on_disk] INFO - [], ['lm_head.weight']\n",
      "2023-10-11 14:22:52,598 [model.py:182 in download] INFO - The whole model has been downloaded an processed to offload_folder: 'offload_dir/facebook.opt-125m'\n",
      "2023-10-11 14:22:52,605 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.embed_tokens, [0. 0. 1.], size_todo: 86630400\n",
      "2023-10-11 14:22:52,606 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.embed_positions, [0. 0. 1.], size_todo: 85056000\n",
      "2023-10-11 14:22:52,608 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.final_layer_norm, [0.00000000e+00 1.91116887e-05 9.99980888e-01], size_todo: 85054464\n",
      "2023-10-11 14:22:52,610 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.0, [0.         0.05002193 0.94997807], size_todo: 77966592\n",
      "2023-10-11 14:22:52,612 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.1, [0.         0.08698539 0.91301461], size_todo: 70878720\n",
      "2023-10-11 14:22:52,613 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.2, [0.         0.11542163 0.88457837], size_todo: 63790848\n",
      "2023-10-11 14:22:52,615 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.3, [0.         0.13797624 0.86202376], size_todo: 56702976\n",
      "2023-10-11 14:22:52,617 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.4, [0.       0.156303 0.843697], size_todo: 49615104\n",
      "2023-10-11 14:22:52,618 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.5, [0.       0.200013 0.799987], size_todo: 42527232\n",
      "2023-10-11 14:22:52,620 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.6, [0.         0.21055017 0.78944983], size_todo: 35439360\n",
      "2023-10-11 14:22:52,622 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.7, [0.         0.24389645 0.75610355], size_todo: 28351488\n",
      "2023-10-11 14:22:52,624 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.8, [0.         0.25000554 0.74999446], size_todo: 21263616\n",
      "2023-10-11 14:22:52,625 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.9, [0.         0.27657765 0.72342235], size_todo: 14175744\n",
      "2023-10-11 14:22:52,627 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.10, [0.         0.27999324 0.72000676], size_todo: 7087872\n",
      "2023-10-11 14:22:52,628 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.11, [0.         0.30186053 0.69813947], size_todo: 0\n",
      "2023-10-11 14:22:52,630 [model.py:138 in get_policy_weight_map] DEBUG - lm_head, [0.         0.30186053 0.69813947], size_todo: 0\n",
      "2023-10-11 14:22:52,631 [model.py:142 in get_policy_weight_map] INFO - device_map is prepared!\n",
      "2023-10-11 14:22:52,634 [model.py:148 in get_policy_weight_map] INFO - CausalLM facebook/opt-125m is to be loaded on: \n",
      "GPU Mem 0.00 GiB (0.00%), CPU Mem 0.07 GiB (30.19%), Disk Mem 0.16 Gib (69.81%)\n",
      "2023-10-11 14:22:52,636 [model.py:241 in init_all_weights] DEBUG - init all weights...\n",
      "model init: loading by policy...: 100%|██████████| 197/197 [00:00<00:00, 7650.15it/s]\n",
      "2023-10-11 14:22:52,665 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.embed_tokens to test forward\n",
      "2023-10-11 14:22:52,666 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.embed_positions to test forward\n",
      "2023-10-11 14:22:52,667 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.final_layer_norm to test forward\n",
      "2023-10-11 14:22:52,668 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.0 to test forward\n",
      "2023-10-11 14:22:52,669 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.1 to test forward\n",
      "2023-10-11 14:22:52,670 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.2 to test forward\n",
      "2023-10-11 14:22:52,671 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.3 to test forward\n",
      "2023-10-11 14:22:52,672 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.4 to test forward\n",
      "2023-10-11 14:22:52,673 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.5 to test forward\n",
      "2023-10-11 14:22:52,675 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.6 to test forward\n",
      "2023-10-11 14:22:52,676 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.7 to test forward\n",
      "2023-10-11 14:22:52,677 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.8 to test forward\n",
      "2023-10-11 14:22:52,678 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.9 to test forward\n",
      "2023-10-11 14:22:52,679 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.10 to test forward\n",
      "2023-10-11 14:22:52,680 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.11 to test forward\n",
      "2023-10-11 14:22:52,681 [520681597.py:42 in to_test_forward] DEBUG - lm_head to test forward\n",
      "2023-10-11 14:22:52,726 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2023-10-11 14:22:52,923 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:52,926 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:22:52,928 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:52,930 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:22:52,932 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:52,943 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:22:52,948 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:52,958 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:22:52,961 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:52,970 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:22:52,973 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:52,982 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:22:52,984 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:52,993 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:22:52,996 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:53,004 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,006 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:53,013 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,016 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:53,024 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,026 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:53,035 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,037 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:53,045 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,048 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:53,055 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,058 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:53,067 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,070 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:53,072 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,074 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:53,085 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,093 [test.py:40 in test_hf_gen] INFO - 0.\n",
      "2023-10-11 14:22:53,094 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 14:22:53,106 [520681597.py:22 in reset_forward] DEBUG - model.decoder.embed_tokens from test to old.\n",
      "2023-10-11 14:22:53,107 [520681597.py:22 in reset_forward] DEBUG - model.decoder.embed_positions from test to old.\n",
      "2023-10-11 14:22:53,108 [520681597.py:22 in reset_forward] DEBUG - model.decoder.final_layer_norm from test to old.\n",
      "2023-10-11 14:22:53,109 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.0 from test to old.\n",
      "2023-10-11 14:22:53,110 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.1 from test to old.\n",
      "2023-10-11 14:22:53,111 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.2 from test to old.\n",
      "2023-10-11 14:22:53,112 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.3 from test to old.\n",
      "2023-10-11 14:22:53,114 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.4 from test to old.\n",
      "2023-10-11 14:22:53,115 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.5 from test to old.\n",
      "2023-10-11 14:22:53,116 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.6 from test to old.\n",
      "2023-10-11 14:22:53,117 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.7 from test to old.\n",
      "2023-10-11 14:22:53,119 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.8 from test to old.\n",
      "2023-10-11 14:22:53,119 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.9 from test to old.\n",
      "2023-10-11 14:22:53,121 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.10 from test to old.\n",
      "2023-10-11 14:22:53,122 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.11 from test to old.\n",
      "2023-10-11 14:22:53,123 [520681597.py:22 in reset_forward] DEBUG - lm_head from test to old.\n",
      "2023-10-11 14:22:53,124 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.embed_tokens to flexgen forward\n",
      "2023-10-11 14:22:53,125 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.embed_positions to flexgen forward\n",
      "2023-10-11 14:22:53,126 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.layers.0 to flexgen forward\n",
      "2023-10-11 14:22:53,127 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.layers.1 to flexgen forward\n",
      "2023-10-11 14:22:53,128 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.layers.2 to flexgen forward\n",
      "2023-10-11 14:22:53,130 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.layers.3 to flexgen forward\n",
      "2023-10-11 14:22:53,131 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.layers.4 to flexgen forward\n",
      "2023-10-11 14:22:53,132 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.layers.5 to flexgen forward\n",
      "2023-10-11 14:22:53,133 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.layers.6 to flexgen forward\n",
      "2023-10-11 14:22:53,134 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.layers.7 to flexgen forward\n",
      "2023-10-11 14:22:53,135 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.layers.8 to flexgen forward\n",
      "2023-10-11 14:22:53,136 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.layers.9 to flexgen forward\n",
      "2023-10-11 14:22:53,136 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.layers.10 to flexgen forward\n",
      "2023-10-11 14:22:53,138 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.layers.11 to flexgen forward\n",
      "2023-10-11 14:22:53,138 [1175756643.py:56 in to_flexgen_forward] DEBUG - model.decoder.final_layer_norm to flexgen forward\n",
      "2023-10-11 14:22:53,140 [1175756643.py:56 in to_flexgen_forward] DEBUG - lm_head to flexgen forward\n",
      "2023-10-11 14:22:53,183 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "2023-10-11 14:22:53,325 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:53,328 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:53,330 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9])\",)\n",
      "2023-10-11 14:22:53,332 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:53,334 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 768])\n",
      "2023-10-11 14:22:53,336 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 768])\n",
      "2023-10-11 14:22:53,337 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 768])\n",
      "2023-10-11 14:22:53,339 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 768])\n",
      "2023-10-11 14:22:53,341 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 9, 768])\n",
      "2023-10-11 14:22:53,342 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,344 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:53,346 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:53,351 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9])\", \"<class 'int'>: 0\")\n",
      "2023-10-11 14:22:53,352 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:53,354 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9])\", \"<class 'int'>: 0\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 768])\n",
      "2023-10-11 14:22:53,356 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9])\", \"<class 'int'>: 0\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 768])\n",
      "2023-10-11 14:22:53,358 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9])\", \"<class 'int'>: 0\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 768])\n",
      "2023-10-11 14:22:53,360 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9])\", \"<class 'int'>: 0\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 768])\n",
      "2023-10-11 14:22:53,362 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 9, 768])\n",
      "2023-10-11 14:22:53,362 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,365 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:53,372 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:53,378 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:53,379 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:53,403 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,412 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,422 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,431 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,435 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,436 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,439 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:53,444 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:53,449 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:53,450 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:53,460 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,468 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,476 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,486 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,490 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,491 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,494 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:53,498 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:53,503 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:53,504 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:53,513 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,520 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,534 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,544 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,548 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,549 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,552 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:53,557 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:53,562 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:53,563 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:53,573 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,590 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,599 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,604 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,608 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,609 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,612 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:53,616 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:53,622 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:53,623 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:53,632 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,657 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,663 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,674 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,678 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,678 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,681 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:53,685 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:53,690 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:53,691 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:53,698 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,737 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,745 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,751 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,754 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,755 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,757 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:53,762 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:53,767 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:53,768 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:53,774 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,787 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,799 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,806 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,810 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,811 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,814 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:53,818 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:53,823 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:53,824 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:53,836 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,847 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,854 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,859 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,863 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,864 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,866 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:53,871 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:53,875 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:53,876 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:53,888 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,900 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,910 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,918 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,922 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,922 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,925 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:53,930 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:53,934 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:53,935 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:53,941 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,948 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,959 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,965 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,969 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:53,970 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:22:53,972 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:53,976 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:53,981 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:53,982 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:53,995 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:54,010 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:54,019 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:54,030 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:54,035 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:54,037 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,040 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:54,046 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:54,048 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:54,049 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:54,059 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:54,068 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:54,079 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:54,089 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 9, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:54,093 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"))\n",
      "2023-10-11 14:22:54,093 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,096 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:54,097 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:54,098 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:54,099 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:54,103 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 768])\n",
      "2023-10-11 14:22:54,105 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 768])\n",
      "2023-10-11 14:22:54,106 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 768])\n",
      "2023-10-11 14:22:54,108 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 768])\n",
      "2023-10-11 14:22:54,110 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 9, 768])\n",
      "2023-10-11 14:22:54,111 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,112 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:54,113 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:54,115 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9, 768])\",)\n",
      "2023-10-11 14:22:54,116 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:54,133 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 50272])\n",
      "2023-10-11 14:22:54,150 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 50272])\n",
      "2023-10-11 14:22:54,170 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 50272])\n",
      "2023-10-11 14:22:54,186 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 9, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 9, 50272])\n",
      "2023-10-11 14:22:54,193 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 9, 50272])\n",
      "2023-10-11 14:22:54,194 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,200 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:54,202 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:54,204 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:22:54,204 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:54,206 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:54,208 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:54,209 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:54,210 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:54,212 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:54,213 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,216 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:54,218 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:54,222 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 10])\", \"<class 'int'>: 9\")\n",
      "2023-10-11 14:22:54,223 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:54,225 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 10])\", \"<class 'int'>: 9\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:54,227 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 10])\", \"<class 'int'>: 9\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:54,228 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 10])\", \"<class 'int'>: 9\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:54,231 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 10])\", \"<class 'int'>: 9\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:54,233 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:54,234 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,235 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:54,240 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:54,245 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,247 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:54,300 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,351 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,381 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,388 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,392 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,393 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,396 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:54,401 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:54,407 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,408 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:54,418 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,423 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,439 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,451 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,455 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,455 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,458 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:54,462 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:54,467 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,468 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:54,478 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,485 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,495 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,500 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,504 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,505 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,507 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:54,512 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:54,517 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,518 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:54,525 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,534 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,540 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,546 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,550 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,551 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,554 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:54,558 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:54,563 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,564 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:54,571 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,580 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,588 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,594 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,598 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,599 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,601 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:54,606 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:54,611 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,611 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:54,617 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,625 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,634 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,650 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,654 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,654 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,657 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:54,661 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:54,666 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,667 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:54,674 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,682 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,687 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,692 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,696 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,696 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,699 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:54,704 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:54,709 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,710 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:54,720 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,730 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,736 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,742 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,746 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,747 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,749 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:54,753 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:54,758 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,759 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:54,767 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,775 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,789 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,795 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,799 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,799 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,802 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:54,806 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:54,811 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,812 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:54,820 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,829 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,836 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,845 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,849 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,850 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,852 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:54,857 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:54,862 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,863 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:54,871 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,881 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,887 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,892 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,896 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,897 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,899 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:54,904 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:54,906 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,907 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:54,914 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,922 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,928 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,934 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 9, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,938 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"))\n",
      "2023-10-11 14:22:54,939 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,941 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:54,943 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:54,944 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,945 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:54,948 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:54,950 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:54,954 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:54,958 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:54,960 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:54,961 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:22:54,963 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:54,964 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:54,965 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:54,966 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:54,979 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:54,989 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:55,000 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:55,009 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:55,014 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:22:55,015 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,021 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:55,023 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:55,024 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:22:55,025 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:55,027 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,029 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,030 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,032 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,034 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:55,034 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,036 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:55,037 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:55,042 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 11])\", \"<class 'int'>: 10\")\n",
      "2023-10-11 14:22:55,043 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:55,045 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 11])\", \"<class 'int'>: 10\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,046 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 11])\", \"<class 'int'>: 10\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,048 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 11])\", \"<class 'int'>: 10\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,050 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 11])\", \"<class 'int'>: 10\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,051 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:55,052 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,054 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:55,058 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:55,063 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,064 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,071 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,077 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,086 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,094 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,098 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,099 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,101 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:55,105 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:55,110 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,111 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,121 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,126 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,148 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,157 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,161 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,162 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,165 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:55,169 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:55,174 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,175 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,180 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,187 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,201 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,206 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,210 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,211 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,214 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:55,219 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:55,224 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,224 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,234 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,239 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,254 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,260 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,265 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,265 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,268 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:55,273 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:55,279 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,280 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,286 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,292 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,298 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,307 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,311 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,312 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,314 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:55,319 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:55,324 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,325 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,346 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,365 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,374 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,382 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,386 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,386 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,389 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:55,394 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:55,399 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,400 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,406 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,412 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,479 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,513 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,517 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,518 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,521 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:55,526 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:55,531 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,532 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,552 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,557 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,562 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,567 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,571 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,572 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,574 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:55,579 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:55,584 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,585 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,595 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,603 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,618 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,629 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,634 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,634 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,637 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:55,642 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:55,647 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,648 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,655 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,662 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,670 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,676 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,680 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,681 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,683 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:55,688 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:55,693 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,694 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,701 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,707 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,714 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,722 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,727 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,728 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,730 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:55,735 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:55,737 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,738 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,743 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,752 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,757 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,766 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 10, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,771 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"))\n",
      "2023-10-11 14:22:55,772 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,774 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:55,776 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:55,777 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,778 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:55,780 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,782 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,786 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,787 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,789 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:55,790 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,792 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:55,793 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:55,795 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,795 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:55,805 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:55,816 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:55,824 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:55,833 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:55,838 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:22:55,839 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,846 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:55,848 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:55,849 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:22:55,850 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:55,852 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,854 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,855 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,857 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,858 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:55,859 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,861 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:55,862 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:55,868 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 12])\", \"<class 'int'>: 11\")\n",
      "2023-10-11 14:22:55,868 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:55,870 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 12])\", \"<class 'int'>: 11\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,872 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 12])\", \"<class 'int'>: 11\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,874 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 12])\", \"<class 'int'>: 11\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,875 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 12])\", \"<class 'int'>: 11\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:55,877 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:55,878 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,879 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:55,884 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:55,890 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,891 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,903 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:55,910 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:55,918 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:55,926 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:55,930 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:55,931 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,934 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:55,938 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:55,943 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,944 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:55,951 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:55,967 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:55,974 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:55,979 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:55,984 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:55,985 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:22:55,987 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:55,992 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:55,997 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:55,998 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,006 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,010 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,029 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,048 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,052 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,053 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,055 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:56,060 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:56,066 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,067 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,073 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,081 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,099 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,110 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,115 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,116 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,119 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:56,124 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:56,130 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,131 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,189 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,218 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,223 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,230 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,234 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,235 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,237 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:56,242 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:56,247 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,248 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,266 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,272 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,282 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,288 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,292 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,293 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,295 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:56,299 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:56,304 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,305 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,312 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,317 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,323 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,327 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,331 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,332 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,334 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:56,339 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:56,344 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,345 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,356 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,362 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,368 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,374 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,377 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,378 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,380 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:56,385 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:56,390 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,391 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,397 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,404 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,410 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,415 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,419 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,420 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,422 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:56,426 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:56,431 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,432 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,439 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,448 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,454 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,465 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,469 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,470 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,472 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:56,476 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:56,481 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,482 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,490 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,498 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,506 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,515 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,519 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,520 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,523 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:56,528 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:56,529 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,530 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,537 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,543 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,556 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,566 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 11, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,572 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"))\n",
      "2023-10-11 14:22:56,574 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,578 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:56,580 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:56,582 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,582 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:56,587 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:56,590 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:56,593 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:56,595 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:56,597 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:56,598 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,600 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:56,601 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:56,603 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,603 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:56,618 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:56,631 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:56,649 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:56,663 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:56,703 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:22:56,704 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,720 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:56,722 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:56,724 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:22:56,725 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:56,727 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:56,728 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:56,730 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:56,731 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:56,733 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:56,734 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,735 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:56,737 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:56,742 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 13])\", \"<class 'int'>: 12\")\n",
      "2023-10-11 14:22:56,743 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:56,745 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 13])\", \"<class 'int'>: 12\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:56,746 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 13])\", \"<class 'int'>: 12\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:56,748 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 13])\", \"<class 'int'>: 12\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:56,750 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 13])\", \"<class 'int'>: 12\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:56,752 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:56,752 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,754 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:56,758 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:56,763 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,764 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,775 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,789 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,806 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,813 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,816 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,817 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,820 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:56,824 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:56,829 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,830 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,837 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,843 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,849 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,854 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,858 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,858 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,861 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:56,865 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:56,870 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,871 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,879 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,885 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,892 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,898 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,902 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,903 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,905 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:56,909 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:56,914 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,915 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,921 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,929 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,935 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,942 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,946 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,947 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:22:56,950 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:56,954 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:56,959 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:56,960 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:56,967 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,974 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,984 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,994 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,998 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:56,999 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,002 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:57,006 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:57,011 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,012 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,076 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,110 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,118 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,123 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,127 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,129 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,132 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:57,137 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:57,142 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,143 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,154 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,160 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,165 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,172 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,176 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,176 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,179 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:57,183 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:57,188 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,189 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,195 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,200 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,206 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,211 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,215 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,216 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,218 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:57,222 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:57,228 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,229 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,235 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,242 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,254 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,268 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,272 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,273 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,275 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:57,280 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:57,285 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,285 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,291 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,296 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,300 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,305 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,309 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,310 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,312 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:57,316 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:57,322 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,323 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,328 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,333 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,339 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,346 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,350 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,351 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,353 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:57,358 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:57,360 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,361 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,367 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,373 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,379 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,383 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 12, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,387 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"))\n",
      "2023-10-11 14:22:57,388 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,391 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:57,392 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:57,394 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,394 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:57,396 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:57,400 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:57,403 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:57,406 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:57,408 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:57,409 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,411 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:57,412 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:57,413 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,414 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:57,429 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:57,440 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:57,451 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:57,460 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:57,464 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:22:57,465 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,472 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:57,473 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:57,475 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:22:57,476 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:57,478 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:57,479 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:57,481 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:57,482 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:57,484 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:57,485 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,486 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:57,487 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:57,492 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 14])\", \"<class 'int'>: 13\")\n",
      "2023-10-11 14:22:57,493 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:57,495 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 14])\", \"<class 'int'>: 13\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:57,496 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 14])\", \"<class 'int'>: 13\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:57,498 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 14])\", \"<class 'int'>: 13\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:57,499 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 14])\", \"<class 'int'>: 13\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:57,501 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:57,502 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,503 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:57,508 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:57,513 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,513 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,528 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,543 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,550 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,570 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,574 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,575 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,577 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:57,582 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:57,587 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,587 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,595 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,603 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,610 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,615 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,619 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,619 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,622 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:57,627 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:57,631 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,632 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,637 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,649 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,658 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,665 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,669 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,670 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,673 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:57,678 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:57,683 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,684 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,692 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,702 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,711 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,717 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,721 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,722 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,725 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:57,730 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:57,734 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,735 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,746 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,755 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,829 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,851 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,855 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,856 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,858 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:57,864 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:57,870 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,871 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,878 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,890 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,895 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,903 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,907 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,908 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,911 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:57,915 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:57,921 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,921 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,928 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,934 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,952 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,964 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,968 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:57,969 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:22:57,972 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:57,978 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:57,985 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:57,986 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:57,995 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,005 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,013 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,019 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,024 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,025 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,028 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:58,032 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:58,038 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,039 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:58,050 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,056 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,063 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,070 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,074 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,075 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,077 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:58,082 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:58,087 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,088 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:58,099 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,114 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,124 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,135 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,140 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,141 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,144 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:58,149 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:58,155 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,155 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:58,164 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,170 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,185 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,190 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,194 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,195 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,198 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:58,202 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:58,204 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,205 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:58,213 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,219 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,227 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,236 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 13, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,240 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"))\n",
      "2023-10-11 14:22:58,241 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,243 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:58,245 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:58,246 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,247 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:58,250 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:58,253 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:58,255 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:58,259 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:58,261 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:58,262 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,264 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:58,265 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:58,267 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,268 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:58,282 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:58,294 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:58,303 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:58,313 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:58,319 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:22:58,320 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,326 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:58,327 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:58,329 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:22:58,330 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:58,332 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:58,333 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:58,335 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:58,336 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:58,338 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:58,339 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,340 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:58,342 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:58,350 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 15])\", \"<class 'int'>: 14\")\n",
      "2023-10-11 14:22:58,362 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:58,364 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 15])\", \"<class 'int'>: 14\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:58,366 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 15])\", \"<class 'int'>: 14\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:58,367 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 15])\", \"<class 'int'>: 14\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:58,370 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 15])\", \"<class 'int'>: 14\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:58,372 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:58,372 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,374 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:58,379 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:58,385 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,386 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:58,406 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,439 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,447 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,453 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,457 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,458 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,461 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:58,466 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:58,471 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,472 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:58,506 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,523 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,530 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,537 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,542 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,543 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,546 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:58,550 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:58,556 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,557 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:58,570 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,581 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,595 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,619 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,623 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,624 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,628 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:58,633 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:58,638 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,639 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:58,644 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,649 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,654 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,658 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,663 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,663 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,666 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:58,670 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:58,675 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,677 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:58,684 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,690 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,700 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,706 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,710 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,712 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,714 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:58,719 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:58,724 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,725 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:58,737 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,805 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,820 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,833 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,837 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,838 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,841 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:58,847 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:58,852 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,853 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:58,862 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,870 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,881 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,887 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,891 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,892 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,895 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:58,899 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:58,904 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,905 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:58,912 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,921 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,929 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,936 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,940 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,941 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,943 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:58,948 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:58,953 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:58,954 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:58,961 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,968 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,977 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,983 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,987 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:58,988 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:22:58,991 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:58,995 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:59,000 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,001 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,007 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,013 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,019 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,026 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,030 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,031 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,034 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:59,038 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:59,044 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,045 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,050 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,058 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,065 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,073 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,077 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,078 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,080 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:59,086 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:59,088 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,088 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,099 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,111 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,118 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,149 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 14, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,154 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"))\n",
      "2023-10-11 14:22:59,155 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,158 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:22:59,160 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:59,162 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,163 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:59,166 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:59,171 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:59,173 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:59,175 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:59,177 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:59,178 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,180 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:22:59,181 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:59,183 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,184 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:59,201 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:59,211 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:59,223 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:59,234 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:22:59,244 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:22:59,245 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,254 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:22:59,256 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:59,258 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:22:59,259 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:59,261 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:59,263 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:59,264 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:59,266 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:59,268 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:59,269 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,271 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:22:59,272 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:59,278 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 16])\", \"<class 'int'>: 15\")\n",
      "2023-10-11 14:22:59,279 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:22:59,281 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 16])\", \"<class 'int'>: 15\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:59,283 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 16])\", \"<class 'int'>: 15\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:59,285 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 16])\", \"<class 'int'>: 15\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:59,287 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 16])\", \"<class 'int'>: 15\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:22:59,289 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:22:59,290 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,292 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:22:59,298 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:59,304 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,304 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,312 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,323 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,341 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,348 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,354 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,355 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,359 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:22:59,364 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:59,370 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,370 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,380 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,395 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,416 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,423 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,428 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,428 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,431 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:22:59,436 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:59,441 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,442 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,449 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,458 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,464 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,474 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,478 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,479 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,481 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:22:59,487 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:59,492 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,493 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,502 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,512 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,520 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,527 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,531 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,532 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,534 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:22:59,539 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:59,544 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,545 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,555 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,560 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,567 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,582 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,586 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,595 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,598 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:22:59,603 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:59,608 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,608 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,653 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,669 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,675 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,684 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,687 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,688 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,690 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:22:59,695 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:59,700 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,701 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,714 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,720 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,725 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,733 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,737 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,738 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,741 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:22:59,745 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:59,750 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,751 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,759 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,768 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,779 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,792 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,796 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,796 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,799 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:22:59,803 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:59,809 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,810 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,819 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,834 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,840 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,850 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,854 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,855 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,858 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:22:59,863 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:59,868 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,868 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,886 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,894 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,907 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,913 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,917 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"))\n",
      "2023-10-11 14:22:59,918 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:22:59,921 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:22:59,925 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:22:59,931 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:22:59,932 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:22:59,987 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:23:00,005 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:23:00,011 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:23:00,018 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:23:00,022 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"))\n",
      "2023-10-11 14:23:00,023 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,026 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:00,030 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:00,033 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,034 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:00,039 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:23:00,046 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:23:00,052 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:23:00,056 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 15, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 16, 64])\"))\n",
      "2023-10-11 14:23:00,060 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"))\n",
      "2023-10-11 14:23:00,061 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,064 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:00,065 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:00,067 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,068 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:00,070 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,074 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,077 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,079 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,080 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:00,081 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,083 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:00,084 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:00,085 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,086 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:00,100 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:00,115 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:00,124 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:00,134 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:00,142 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:00,143 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,150 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:00,152 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:00,154 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:00,155 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:00,157 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,158 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,160 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,161 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,163 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:00,164 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,165 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:00,167 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:00,172 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 17])\", \"<class 'int'>: 16\")\n",
      "2023-10-11 14:23:00,173 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:00,175 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 17])\", \"<class 'int'>: 16\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,177 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 17])\", \"<class 'int'>: 16\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,178 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 17])\", \"<class 'int'>: 16\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,180 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 17])\", \"<class 'int'>: 16\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,182 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:00,183 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,184 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:00,189 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:00,194 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,195 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:00,203 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,214 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,221 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,227 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,231 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,232 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,234 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:00,238 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:00,243 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,244 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:00,252 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,258 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,263 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,271 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,275 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,276 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,278 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:00,283 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:00,288 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,289 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:00,295 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,301 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,309 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,314 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,318 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,319 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,322 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:00,326 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:00,331 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,332 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:00,340 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,346 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,354 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,424 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,428 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,429 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,432 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:00,437 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:00,443 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,444 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:00,453 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,460 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,473 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,484 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,488 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,489 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,491 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:00,496 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:00,501 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,501 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:00,509 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,517 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,526 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,532 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,536 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,537 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,539 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:00,543 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:00,548 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,549 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:00,561 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,567 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,574 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,578 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,582 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,582 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,585 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:00,589 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:00,594 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,595 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:00,601 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,608 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,680 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,687 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,691 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,692 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,694 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:00,699 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:00,705 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,706 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:00,716 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,723 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,731 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,742 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,746 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,747 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,750 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:00,754 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:00,759 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,760 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:00,773 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,780 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,786 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,794 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,798 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,798 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,801 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:00,806 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:00,811 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,812 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:00,818 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,824 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,830 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,841 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,845 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,846 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,848 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:00,853 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:00,855 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,856 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:00,865 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,871 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,880 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,902 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 16, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,906 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"))\n",
      "2023-10-11 14:23:00,907 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,909 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:00,911 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:00,912 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,913 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:00,915 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,917 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,920 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,923 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:00,925 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:00,926 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,927 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:00,929 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:00,930 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:00,931 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:00,945 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:00,957 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:00,970 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:00,979 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:00,987 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:00,988 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:00,994 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:00,995 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:00,996 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:00,997 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:00,999 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,000 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,002 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,004 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,005 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:01,006 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,008 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:01,009 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:01,014 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 18])\", \"<class 'int'>: 17\")\n",
      "2023-10-11 14:23:01,015 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:01,017 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 18])\", \"<class 'int'>: 17\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,018 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 18])\", \"<class 'int'>: 17\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,020 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 18])\", \"<class 'int'>: 17\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,021 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 18])\", \"<class 'int'>: 17\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,023 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:01,024 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,025 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:01,029 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:01,034 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,035 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:01,043 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,049 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,054 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,060 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,064 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,065 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,068 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:01,073 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:01,078 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,079 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:01,086 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,094 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,104 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,110 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,114 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,115 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,118 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:01,123 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:01,128 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,128 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:01,135 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,143 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,151 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,157 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,161 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,162 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,164 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:01,169 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:01,174 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,175 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:01,184 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,192 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,198 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,206 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,211 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,211 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,214 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:01,219 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:01,224 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,225 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:01,233 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,240 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,246 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,251 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,255 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,256 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,258 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:01,263 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:01,268 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,269 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:01,280 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,348 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,376 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,382 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,387 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,388 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,390 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:01,395 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:01,400 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,401 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:01,423 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,430 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,436 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,443 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,447 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,448 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,451 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:01,456 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:01,460 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,461 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:01,467 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,474 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,483 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,491 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,495 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,496 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,499 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:01,503 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:01,509 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,509 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:01,515 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,522 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,527 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,534 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,538 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,539 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,541 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:01,546 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:01,551 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,552 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:01,560 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,566 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,573 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,579 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,583 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,584 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,586 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:01,591 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:01,597 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,598 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:01,606 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,619 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,628 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,634 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,638 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,639 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,642 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:01,647 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:01,648 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,649 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:01,655 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,677 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,756 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,776 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 17, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,781 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"))\n",
      "2023-10-11 14:23:01,782 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,785 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:01,786 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:01,788 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,789 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:01,791 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,794 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,799 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,802 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,803 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:01,805 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,807 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:01,808 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:01,810 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,811 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:01,828 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:01,838 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:01,851 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:01,864 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:01,876 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:01,877 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,882 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:01,884 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:01,885 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:01,886 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:01,888 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,889 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,891 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,892 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,894 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:01,895 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,900 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:01,902 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:01,907 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 19])\", \"<class 'int'>: 18\")\n",
      "2023-10-11 14:23:01,908 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:01,910 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 19])\", \"<class 'int'>: 18\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,911 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 19])\", \"<class 'int'>: 18\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,913 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 19])\", \"<class 'int'>: 18\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,915 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 19])\", \"<class 'int'>: 18\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:01,917 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:01,918 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,919 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:01,924 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:01,929 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:01,930 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:01,943 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:01,969 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:01,978 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:01,988 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:01,992 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:01,993 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:01,996 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:02,001 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:02,006 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,007 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,014 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,021 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,027 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,033 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,037 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,038 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,041 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:02,046 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:02,051 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,052 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,057 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,062 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,068 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,074 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,078 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,078 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,081 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:02,086 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:02,091 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,092 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,100 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,106 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,118 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,125 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,129 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,130 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,132 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:02,137 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:02,142 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,143 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,151 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,156 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,160 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,168 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,172 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,173 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,175 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:02,180 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:02,185 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,185 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,194 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,201 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,206 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,212 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,216 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,217 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,220 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:02,224 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:02,236 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,237 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,296 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,323 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,330 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,336 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,341 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,342 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,345 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:02,349 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:02,353 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,354 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,360 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,373 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,378 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,384 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,389 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,389 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,392 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:02,396 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:02,401 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,402 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,416 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,422 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,427 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,433 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,437 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,438 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,440 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:02,444 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:02,449 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,450 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,455 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,462 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,468 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,478 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,482 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,483 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,485 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:02,489 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:02,494 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,495 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,500 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,506 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,512 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,518 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,523 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,524 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,527 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:02,531 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:02,533 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,534 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,543 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,553 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,616 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,646 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 18, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,651 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"))\n",
      "2023-10-11 14:23:02,652 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,654 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:02,656 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:02,657 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,658 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:02,661 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:02,664 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:02,667 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:02,670 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:02,671 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:02,672 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,673 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:02,674 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:02,676 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,676 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:02,687 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:02,697 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:02,709 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:02,717 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:02,724 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:02,725 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,730 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:02,731 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:02,733 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:02,734 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:02,735 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:02,737 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:02,738 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:02,740 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:02,741 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:02,742 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,743 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:02,745 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:02,749 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 20])\", \"<class 'int'>: 19\")\n",
      "2023-10-11 14:23:02,750 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:02,752 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 20])\", \"<class 'int'>: 19\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:02,753 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 20])\", \"<class 'int'>: 19\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:02,755 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 20])\", \"<class 'int'>: 19\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:02,756 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 20])\", \"<class 'int'>: 19\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:02,758 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:02,758 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,760 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:02,764 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:02,769 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,769 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,775 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,782 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,794 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,813 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,818 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,818 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,821 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:02,826 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:02,830 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,831 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,839 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,844 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,850 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,860 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,864 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,865 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,867 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:02,872 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:02,877 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,878 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,893 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,898 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,906 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,912 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,916 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,917 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,920 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:02,924 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:02,929 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,930 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,936 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,942 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,948 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,962 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,966 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,967 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:02,970 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:02,974 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:02,980 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:02,981 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:02,988 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,994 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:02,998 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,003 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,008 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,008 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,011 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:03,016 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:03,021 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,022 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,029 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,034 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,039 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,104 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,109 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,111 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,113 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:03,118 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:03,123 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,124 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,131 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,139 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,145 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,150 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,154 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,155 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,157 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:03,162 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:03,167 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,168 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,179 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,185 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,195 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,202 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,207 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,208 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,210 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:03,215 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:03,220 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,221 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,231 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,237 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,244 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,253 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,257 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,258 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,261 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:03,265 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:03,270 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,271 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,279 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,284 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,290 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,296 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,301 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,301 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,304 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:03,308 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:03,314 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,314 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,321 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,328 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,355 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,361 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,365 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,366 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,368 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:03,373 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:03,374 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,375 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,383 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,395 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,401 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,406 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 19, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,411 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"))\n",
      "2023-10-11 14:23:03,412 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,414 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:03,416 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:03,417 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,418 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:03,422 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:03,424 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:03,426 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:03,428 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:03,429 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:03,430 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,431 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:03,433 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:03,434 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,434 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:03,446 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:03,458 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:03,469 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:03,478 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:03,492 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:03,493 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,498 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:03,499 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:03,501 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:03,502 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:03,504 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:03,505 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:03,507 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:03,508 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:03,510 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:03,511 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,512 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:03,514 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:03,519 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 21])\", \"<class 'int'>: 20\")\n",
      "2023-10-11 14:23:03,519 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:03,521 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 21])\", \"<class 'int'>: 20\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:03,523 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 21])\", \"<class 'int'>: 20\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:03,524 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 21])\", \"<class 'int'>: 20\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:03,526 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 21])\", \"<class 'int'>: 20\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:03,528 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:03,528 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,530 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:03,534 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:03,539 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,540 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,548 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,560 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,568 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,591 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,595 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,596 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,599 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:03,603 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:03,608 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,609 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,615 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,622 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,627 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,634 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,638 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,641 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,643 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:03,648 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:03,653 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,654 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,659 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,666 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,673 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,686 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,690 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,691 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,694 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:03,698 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:03,703 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,704 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,715 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,723 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,734 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,746 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,750 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,751 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,754 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:03,759 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:03,764 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,764 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,770 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,779 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,784 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,791 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,795 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,796 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,798 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:03,803 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:03,807 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,808 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,816 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,824 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,830 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,847 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,852 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,853 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,855 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:03,859 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:03,864 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,865 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,873 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,880 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,890 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,897 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,902 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,902 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,905 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:03,909 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:03,914 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,915 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,921 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,926 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,932 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,938 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,942 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,943 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,945 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:03,950 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:03,955 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:03,956 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:03,966 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,975 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,985 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,991 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,996 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:03,996 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:03,999 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:04,004 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:04,010 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,011 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,022 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,033 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,042 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,048 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,053 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,054 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,057 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:04,062 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:04,067 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,068 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,075 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,092 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,100 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,166 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,171 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,172 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,175 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:04,180 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:04,181 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,182 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,190 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,196 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,204 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,210 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 20, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,216 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"))\n",
      "2023-10-11 14:23:04,217 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,220 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:04,222 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:04,224 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,224 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:04,227 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:04,231 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:04,234 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:04,237 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:04,240 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:04,242 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,244 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:04,246 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:04,248 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,250 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:04,273 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:04,288 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:04,297 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:04,309 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:04,313 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:04,314 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,319 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:04,321 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:04,322 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:04,323 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:04,324 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:04,326 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:04,327 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:04,329 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:04,330 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:04,331 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,333 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:04,334 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:04,339 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 22])\", \"<class 'int'>: 21\")\n",
      "2023-10-11 14:23:04,339 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:04,342 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 22])\", \"<class 'int'>: 21\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:04,344 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 22])\", \"<class 'int'>: 21\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:04,345 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 22])\", \"<class 'int'>: 21\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:04,347 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 22])\", \"<class 'int'>: 21\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:04,349 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:04,350 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,351 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:04,356 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:04,360 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,361 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,374 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,381 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,390 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,406 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,412 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,413 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,417 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:04,422 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:04,427 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,428 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,436 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,444 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,451 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,459 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,464 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,465 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,467 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:04,472 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:04,477 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,478 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,485 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,492 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,503 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,510 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,515 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,516 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,519 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:04,524 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:04,529 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,530 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,537 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,544 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,553 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,563 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,570 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,571 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,575 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:04,580 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:04,586 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,587 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,596 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,601 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,611 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,617 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,622 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,623 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,626 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:04,631 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:04,636 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,636 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,655 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,664 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,700 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,706 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,714 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,715 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,718 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:04,722 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:04,728 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,728 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,735 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,741 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,747 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,754 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,760 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,761 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,763 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:04,768 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:04,773 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,774 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,780 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,790 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,798 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,807 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,812 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,813 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,816 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:04,821 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:04,826 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,827 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,833 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,839 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,846 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,852 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,857 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,858 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,861 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:04,865 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:04,870 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,871 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,877 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,885 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,894 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,901 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,905 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,906 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,908 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:04,913 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:04,919 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,920 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,943 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,950 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,956 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,962 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,967 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,968 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:04,971 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:04,975 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:04,977 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:04,978 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:04,984 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,990 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:04,995 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:05,006 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 21, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:05,011 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"))\n",
      "2023-10-11 14:23:05,012 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,014 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:05,016 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:05,018 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,018 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:05,024 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,030 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,033 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,035 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,037 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:05,038 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,039 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:05,041 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:05,042 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,043 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:05,055 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:05,065 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:05,074 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:05,087 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:05,092 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:05,093 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,098 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:05,100 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:05,101 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:05,102 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:05,104 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,105 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,107 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,109 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,111 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:05,111 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,113 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:05,114 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:05,119 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 23])\", \"<class 'int'>: 22\")\n",
      "2023-10-11 14:23:05,120 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:05,122 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 23])\", \"<class 'int'>: 22\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,124 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 23])\", \"<class 'int'>: 22\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,125 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 23])\", \"<class 'int'>: 22\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,127 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 23])\", \"<class 'int'>: 22\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,129 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:05,129 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,131 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:05,135 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:05,140 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,140 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:05,152 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,156 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,161 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,166 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,180 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,182 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,185 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:05,190 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:05,195 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,195 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:05,202 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,220 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,227 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,236 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,241 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,241 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,245 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:05,249 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:05,254 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,255 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:05,263 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,270 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,279 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,285 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,291 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,292 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,294 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:05,298 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:05,303 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,304 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:05,317 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,323 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,334 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,342 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,371 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,372 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,374 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:05,379 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:05,384 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,385 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:05,434 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,442 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,464 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,471 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,492 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,493 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,496 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:05,501 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:05,506 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,508 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:05,517 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,526 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,540 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,546 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,551 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,552 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,555 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:05,559 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:05,564 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,564 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:05,571 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,577 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,582 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,588 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,593 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,595 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,597 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:05,602 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:05,607 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,607 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:05,614 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,680 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,701 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,709 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,713 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,714 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,716 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:05,721 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:05,726 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,727 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:05,737 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,745 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,754 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,764 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,787 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,788 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,790 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:05,795 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:05,800 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,801 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:05,806 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,815 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,822 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,832 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,843 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,844 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,846 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:05,850 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:05,856 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,857 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:05,863 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,871 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,881 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,887 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,892 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,892 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,895 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:05,900 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:05,902 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,902 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:05,911 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,922 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,928 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,934 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 22, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,940 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"))\n",
      "2023-10-11 14:23:05,941 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,943 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:05,944 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:05,946 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,947 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:05,948 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,958 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,970 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,975 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:05,977 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:05,977 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:05,979 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:05,980 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:05,982 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:05,983 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:05,997 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:06,017 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:06,036 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:06,045 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:06,051 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:06,052 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,062 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:06,063 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:06,065 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:06,066 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:06,067 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:06,069 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:06,071 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:06,073 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:06,074 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:06,075 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,077 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:06,078 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:06,083 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 24])\", \"<class 'int'>: 23\")\n",
      "2023-10-11 14:23:06,084 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:06,086 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 24])\", \"<class 'int'>: 23\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:06,088 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 24])\", \"<class 'int'>: 23\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:06,090 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 24])\", \"<class 'int'>: 23\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:06,092 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 24])\", \"<class 'int'>: 23\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:06,094 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:06,095 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,097 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:06,105 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:06,112 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:06,113 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:06,121 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,127 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,136 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,148 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,158 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,159 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,163 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:06,168 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:06,174 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:06,175 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:06,182 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,190 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,265 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,278 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,284 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,285 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,290 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:06,296 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:06,301 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:06,302 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:06,311 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,319 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,326 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,332 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,337 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,338 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,340 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:06,345 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:06,350 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:06,351 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:06,360 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,368 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,376 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,380 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,385 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,386 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,388 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:06,393 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:06,398 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:06,399 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:06,411 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,419 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,427 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,504 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,509 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,510 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,513 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:06,517 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:06,523 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:06,524 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:06,552 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,595 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,629 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,635 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,639 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,640 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,643 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:06,647 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:06,653 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:06,654 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:06,667 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,690 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,697 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,704 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,708 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,709 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,711 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:06,716 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:06,720 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:06,721 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:06,728 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,739 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,758 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,774 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,778 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,779 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,781 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:06,785 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:06,790 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:06,791 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:06,799 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,804 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,810 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,818 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,835 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,836 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,839 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:06,844 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:06,849 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:06,850 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:06,860 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,868 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,877 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,882 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,886 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,887 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,889 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:06,894 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:06,898 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:06,900 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:06,907 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,915 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,921 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,936 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,941 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,942 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:06,945 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:06,950 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:06,951 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:06,952 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:06,971 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,978 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,985 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,993 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 23, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,998 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"))\n",
      "2023-10-11 14:23:06,999 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,001 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:07,002 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:07,004 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,004 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:07,008 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:07,010 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:07,014 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:07,017 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:07,018 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:07,019 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,020 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:07,022 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:07,023 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,024 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:07,048 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:07,062 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:07,080 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:07,096 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:07,124 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:07,125 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,130 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:07,132 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:07,133 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:07,134 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:07,136 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:07,138 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:07,139 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:07,141 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:07,143 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:07,144 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,146 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:07,147 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:07,152 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 25])\", \"<class 'int'>: 24\")\n",
      "2023-10-11 14:23:07,153 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:07,155 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 25])\", \"<class 'int'>: 24\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:07,156 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 25])\", \"<class 'int'>: 24\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:07,158 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 25])\", \"<class 'int'>: 24\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:07,159 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 25])\", \"<class 'int'>: 24\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:07,162 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:07,162 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,164 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:07,169 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:07,174 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,175 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:07,184 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,190 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,197 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,203 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,208 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,209 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,212 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:07,217 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:07,222 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,223 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:07,231 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,254 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,280 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,286 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,291 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,292 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,294 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:07,299 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:07,303 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,305 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:07,311 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,329 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,335 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,342 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,347 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,348 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,351 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:07,356 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:07,361 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,362 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:07,372 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,377 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,386 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,402 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,461 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,463 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,466 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:07,471 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:07,476 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,477 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:07,495 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,540 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,553 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,563 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,567 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,568 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,571 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:07,576 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:07,581 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,582 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:07,588 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,595 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,601 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,606 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,610 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,611 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,613 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:07,618 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:07,623 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,624 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:07,630 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,636 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,643 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,648 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,656 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,657 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,660 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:07,664 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:07,669 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,670 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:07,679 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,686 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,694 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,706 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,710 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,711 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,713 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:07,719 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:07,724 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,725 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:07,738 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,745 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,755 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,760 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,772 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,773 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,776 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:07,780 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:07,785 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,786 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:07,806 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,814 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,822 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,831 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,836 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,837 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,839 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:07,843 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:07,848 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,849 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:07,856 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,865 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,871 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,876 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,882 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,883 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:07,885 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:07,889 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:07,891 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:07,892 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:07,903 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,911 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,922 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:07,992 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 24, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:08,012 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"))\n",
      "2023-10-11 14:23:08,013 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,016 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:08,018 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:08,019 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:08,020 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:08,024 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:08,028 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:08,031 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:08,033 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:08,035 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:08,036 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,037 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:08,039 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:08,040 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:08,041 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:08,052 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:08,064 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:08,074 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:08,085 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:08,090 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:08,091 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,098 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:08,099 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:08,101 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:08,102 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:08,104 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:08,105 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:08,107 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:08,108 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:08,110 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:08,111 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,112 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:08,114 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:08,119 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 26])\", \"<class 'int'>: 25\")\n",
      "2023-10-11 14:23:08,120 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:08,122 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 26])\", \"<class 'int'>: 25\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:08,124 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 26])\", \"<class 'int'>: 25\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:08,125 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 26])\", \"<class 'int'>: 25\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:08,127 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 26])\", \"<class 'int'>: 25\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:08,129 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:08,129 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,131 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:08,135 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:08,140 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:08,141 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:08,152 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,230 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,238 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,244 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,249 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,250 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,253 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:08,258 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:08,264 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:08,265 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:08,271 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,280 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,316 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,322 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,327 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,328 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,331 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:08,335 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:08,341 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:08,341 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:08,349 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,355 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,361 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,366 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,370 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,371 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,374 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:08,379 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:08,384 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:08,384 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:08,430 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,491 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,535 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,585 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,626 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,628 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,630 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:08,635 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:08,639 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:08,640 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:08,663 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,668 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,679 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,690 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,694 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,695 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,698 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:08,702 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:08,706 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:08,707 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:08,716 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,722 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,727 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,732 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,737 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,738 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,741 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:08,746 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:08,751 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:08,752 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:08,763 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,773 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,779 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,806 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,819 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,820 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,823 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:08,827 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:08,832 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:08,832 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:08,841 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,847 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,859 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,865 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,869 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,870 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,873 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:08,878 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:08,883 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:08,884 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:08,895 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,906 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,912 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,924 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,929 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:08,930 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:08,932 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:08,937 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:08,942 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:08,942 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:09,007 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,038 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,045 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,052 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,056 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,057 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:09,059 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:09,064 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:09,069 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:09,071 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:09,079 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,086 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,092 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,099 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,103 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,104 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:09,107 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:09,111 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:09,113 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:09,114 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:09,161 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,221 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,235 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,240 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 25, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,245 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"))\n",
      "2023-10-11 14:23:09,246 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:09,249 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:09,251 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:09,252 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:09,253 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:09,256 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:09,259 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:09,262 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:09,265 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:09,267 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:09,268 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:09,271 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:09,272 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:09,273 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:09,274 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:09,288 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:09,300 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:09,312 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:09,324 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:09,332 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:09,333 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:09,340 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:09,341 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:09,342 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:09,343 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:09,345 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:09,346 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:09,348 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:09,349 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:09,351 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:09,352 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:09,354 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:09,355 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:09,360 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 27])\", \"<class 'int'>: 26\")\n",
      "2023-10-11 14:23:09,361 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:09,363 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 27])\", \"<class 'int'>: 26\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:09,365 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 27])\", \"<class 'int'>: 26\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:09,366 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 27])\", \"<class 'int'>: 26\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:09,368 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 27])\", \"<class 'int'>: 26\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:09,370 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:09,370 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:09,372 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:09,376 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:09,383 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:09,384 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:09,458 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,473 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,478 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,488 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,493 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,493 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:09,496 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:09,501 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:09,506 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:09,507 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:09,515 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,522 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,528 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,534 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,538 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,539 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:09,542 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:09,546 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:09,551 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:09,552 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:09,628 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,650 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,656 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,666 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,670 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,671 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:09,674 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:09,679 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:09,683 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:09,684 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:09,690 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,762 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,782 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,801 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,806 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,807 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:09,810 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:09,815 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:09,819 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:09,820 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:09,835 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,840 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,858 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,864 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,868 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,869 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:09,872 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:09,876 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:09,880 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:09,881 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:09,961 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,968 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,974 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,979 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,983 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:09,985 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:09,986 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:09,990 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:09,995 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:09,996 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:10,002 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,006 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,013 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,018 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,023 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,023 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,026 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:10,030 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:10,034 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,035 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:10,041 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,050 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,055 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,060 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,065 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,065 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,068 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:10,072 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:10,077 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,078 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:10,088 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,099 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,107 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,118 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,123 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,123 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,126 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:10,131 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:10,136 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,136 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:10,159 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,174 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,183 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,188 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,192 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,193 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,195 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:10,200 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:10,204 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,205 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:10,212 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,219 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,225 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,229 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,234 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,234 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,237 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:10,242 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:10,244 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,245 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:10,254 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,260 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,266 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,274 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 26, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,282 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"))\n",
      "2023-10-11 14:23:10,283 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,285 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:10,287 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:10,288 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,289 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:10,292 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:10,295 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:10,298 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:10,301 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:10,303 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:10,304 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,305 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:10,307 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:10,308 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,309 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:10,320 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:10,334 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:10,349 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:10,358 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:10,368 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:10,368 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,374 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:10,375 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:10,376 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:10,377 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:10,379 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:10,380 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:10,382 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:10,383 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:10,385 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:10,385 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,387 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:10,388 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:10,393 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 28])\", \"<class 'int'>: 27\")\n",
      "2023-10-11 14:23:10,394 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:10,395 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 28])\", \"<class 'int'>: 27\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:10,397 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 28])\", \"<class 'int'>: 27\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:10,399 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 28])\", \"<class 'int'>: 27\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:10,400 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 28])\", \"<class 'int'>: 27\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:10,402 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:10,403 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,404 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:10,409 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:10,414 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,415 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:10,424 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,431 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,474 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,482 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,487 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,488 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,491 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:10,496 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:10,500 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,501 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:10,515 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,522 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,539 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,545 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,559 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,560 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,562 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:10,567 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:10,572 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,573 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:10,579 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,585 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,591 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,597 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,603 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,604 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,607 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:10,611 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:10,616 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,617 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:10,626 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,632 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,691 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,744 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,755 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,756 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,759 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:10,764 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:10,769 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,770 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:10,780 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,786 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,791 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,805 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,855 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,856 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,859 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:10,864 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:10,869 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,870 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:10,890 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,903 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,922 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,930 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,934 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,935 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,938 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:10,943 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:10,948 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:10,949 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:10,955 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,965 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,977 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,983 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,988 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:10,988 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:10,991 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:10,995 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:11,001 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:11,002 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:11,011 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,025 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,033 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,042 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,080 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,081 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:11,083 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:11,088 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:11,092 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:11,094 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:11,101 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,107 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,119 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,129 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,137 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,138 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:11,140 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:11,145 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:11,150 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:11,150 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:11,159 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,164 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,174 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,180 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,185 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,185 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:11,188 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:11,192 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:11,197 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:11,198 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:11,207 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,216 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,222 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,227 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,234 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,235 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:11,237 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:11,242 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:11,244 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:11,244 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:11,254 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,263 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,276 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,347 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 27, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,380 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"))\n",
      "2023-10-11 14:23:11,381 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:11,384 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:11,386 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:11,387 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:11,388 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:11,390 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:11,393 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:11,396 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:11,398 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:11,400 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:11,401 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:11,402 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:11,403 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:11,405 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:11,406 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:11,417 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:11,428 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:11,438 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:11,451 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:11,519 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:11,524 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:11,537 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:11,539 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:11,540 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:11,541 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:11,543 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:11,544 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:11,546 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:11,547 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:11,549 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:11,549 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:11,551 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:11,552 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:11,557 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 29])\", \"<class 'int'>: 28\")\n",
      "2023-10-11 14:23:11,558 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:11,560 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 29])\", \"<class 'int'>: 28\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:11,562 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 29])\", \"<class 'int'>: 28\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:11,563 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 29])\", \"<class 'int'>: 28\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:11,565 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 29])\", \"<class 'int'>: 28\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:11,567 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:11,568 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:11,569 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:11,574 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:11,580 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:11,580 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:11,591 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,600 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,609 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,615 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,619 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,620 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:11,623 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:11,627 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:11,632 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:11,633 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:11,643 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,650 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,703 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,759 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,776 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,778 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:11,781 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:11,786 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:11,791 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:11,792 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:11,799 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,807 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,813 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,823 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,889 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,890 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:11,894 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:11,899 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:11,903 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:11,904 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:11,912 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,918 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,923 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:11,929 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,002 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,004 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,007 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:12,016 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:12,022 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,023 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,035 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,041 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,046 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,054 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,059 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,059 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,062 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:12,067 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:12,072 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,073 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,078 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,086 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,103 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,109 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,114 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,115 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,118 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:12,122 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:12,128 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,129 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,193 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,207 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,213 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,219 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,223 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,224 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,227 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:12,231 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:12,237 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,237 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,244 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,249 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,259 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,266 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,271 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,272 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,274 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:12,279 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:12,284 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,285 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,298 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,315 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,321 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,327 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,331 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,332 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,335 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:12,339 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:12,344 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,345 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,355 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,360 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,366 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,373 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,380 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,381 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,383 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:12,387 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:12,392 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,393 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,403 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,413 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,420 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,425 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,430 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,430 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,433 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:12,438 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:12,439 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,440 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,446 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,454 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,460 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,470 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 28, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,474 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"))\n",
      "2023-10-11 14:23:12,475 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,477 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:12,478 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:12,479 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,480 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:12,483 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:12,486 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:12,492 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:12,497 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:12,499 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:12,499 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,501 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:12,502 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:12,503 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,504 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:12,518 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:12,532 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:12,541 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:12,550 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:12,554 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:12,555 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,562 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:12,563 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:12,564 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:12,565 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:12,567 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:12,569 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:12,570 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:12,572 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:12,574 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:12,575 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,576 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:12,578 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:12,583 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 30])\", \"<class 'int'>: 29\")\n",
      "2023-10-11 14:23:12,584 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:12,586 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 30])\", \"<class 'int'>: 29\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:12,588 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 30])\", \"<class 'int'>: 29\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:12,589 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 30])\", \"<class 'int'>: 29\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:12,591 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 30])\", \"<class 'int'>: 29\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:12,593 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:12,593 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,595 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:12,600 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:12,605 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,606 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,613 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,642 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,704 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,731 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,736 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,736 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,740 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:12,746 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:12,750 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,752 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,765 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,773 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,782 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,792 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,797 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,798 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,800 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:12,805 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:12,809 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,810 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,817 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,821 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,826 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,831 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,844 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,845 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,848 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:12,852 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:12,856 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,857 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,870 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,876 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,885 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,893 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,898 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,899 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,901 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:12,906 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:12,910 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,911 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,916 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,921 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,933 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,952 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,963 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,964 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:12,967 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:12,971 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:12,976 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:12,977 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:12,987 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:12,993 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,001 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,006 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,013 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,014 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,016 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:13,020 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:13,024 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:13,025 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:13,031 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,038 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,050 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,056 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,062 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,063 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,066 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:13,070 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:13,075 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:13,075 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:13,082 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,090 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,097 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,104 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,108 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,109 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,111 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:13,115 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:13,121 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:13,122 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:13,127 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,134 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,146 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,155 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,159 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,160 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,162 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:13,167 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:13,171 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:13,172 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:13,178 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,186 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,197 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,205 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,209 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,210 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,212 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:13,217 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:13,222 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:13,222 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:13,228 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,278 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,327 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,372 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,378 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,379 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,382 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:13,386 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:13,388 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:13,389 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:13,395 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,402 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,416 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,421 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 29, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,425 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"))\n",
      "2023-10-11 14:23:13,426 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,428 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:13,430 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:13,431 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:13,432 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:13,434 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:13,435 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:13,437 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:13,439 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:13,440 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:13,441 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,443 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:13,444 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:13,445 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:13,446 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:13,458 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:13,468 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:13,479 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:13,495 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:13,503 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:13,504 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,531 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:13,535 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:13,537 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:13,538 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:13,540 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:13,542 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:13,543 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:13,545 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:13,547 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:13,548 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,550 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:13,552 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:13,557 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 31])\", \"<class 'int'>: 30\")\n",
      "2023-10-11 14:23:13,558 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:13,560 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 31])\", \"<class 'int'>: 30\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:13,562 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 31])\", \"<class 'int'>: 30\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:13,564 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 31])\", \"<class 'int'>: 30\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:13,565 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 31])\", \"<class 'int'>: 30\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:13,567 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:13,568 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,569 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:13,574 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:13,578 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:13,579 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:13,590 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,603 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,624 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,632 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,638 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,639 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,642 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:13,647 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:13,652 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:13,652 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:13,661 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,755 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,810 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,835 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,840 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,841 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,844 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:13,848 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:13,854 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:13,855 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:13,862 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,869 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,877 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,884 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,955 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:13,957 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:13,962 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:13,970 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:13,978 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:13,980 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:14,014 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,032 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,039 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,046 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,053 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,054 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,058 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:14,063 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:14,068 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:14,069 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:14,076 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,081 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,088 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,095 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,101 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,102 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,104 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:14,109 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:14,114 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:14,115 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:14,122 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,128 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,133 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,139 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,144 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,145 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,147 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:14,152 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:14,157 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:14,158 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:14,173 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,179 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,185 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,190 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,195 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,196 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,199 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:14,203 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:14,208 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:14,210 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:14,263 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,284 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,328 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,346 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,351 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,351 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,354 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:14,358 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:14,364 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:14,365 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:14,416 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,468 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,483 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,503 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,507 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,508 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,511 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:14,516 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:14,520 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:14,521 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:14,528 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,533 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,538 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,544 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,549 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,550 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,552 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:14,557 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:14,562 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:14,562 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:14,583 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,602 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,611 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,626 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,630 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,631 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,634 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:14,638 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:14,639 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:14,641 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:14,647 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,658 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,673 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,679 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 30, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,684 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"))\n",
      "2023-10-11 14:23:14,684 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,687 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:14,688 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:14,689 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:14,690 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:14,692 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:14,693 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:14,695 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:14,697 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:14,699 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:14,700 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,701 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:14,702 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:14,703 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:14,704 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:14,716 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:14,727 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:14,736 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:14,748 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:14,752 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:14,753 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,759 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:14,761 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:14,762 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:14,763 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:14,765 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:14,767 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:14,768 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:14,769 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:14,771 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:14,772 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,773 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:14,775 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:14,779 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 32])\", \"<class 'int'>: 31\")\n",
      "2023-10-11 14:23:14,780 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:14,781 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 32])\", \"<class 'int'>: 31\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:14,783 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 32])\", \"<class 'int'>: 31\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:14,784 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 32])\", \"<class 'int'>: 31\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:14,786 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 32])\", \"<class 'int'>: 31\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:14,788 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:14,789 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,790 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:14,795 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:14,800 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:14,800 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:14,809 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:14,817 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:14,822 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:14,832 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:14,837 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:14,838 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:14,841 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:14,845 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:14,850 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:14,851 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:14,858 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:14,879 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:14,915 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:14,988 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,004 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,005 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,008 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:15,013 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:15,018 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,019 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:15,025 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,030 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,036 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,042 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,046 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,047 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,050 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:15,054 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:15,059 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,059 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:15,065 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,071 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,076 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,084 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,089 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,090 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,092 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:15,097 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:15,101 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,102 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:15,122 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,147 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,196 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,203 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,209 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,210 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,213 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:15,218 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:15,223 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,224 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:15,246 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,258 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,262 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,272 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,277 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,278 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,280 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:15,284 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:15,289 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,290 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:15,299 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,307 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,314 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,322 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,326 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,327 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,330 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:15,334 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:15,338 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,339 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:15,348 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,355 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,438 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,447 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,452 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,453 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,455 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:15,459 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:15,465 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,465 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:15,474 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,479 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,491 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,497 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,502 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,503 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,505 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:15,509 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:15,514 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,515 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:15,523 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,530 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,537 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,542 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,547 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,547 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,550 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:15,554 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:15,559 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,560 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:15,566 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,594 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,669 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,675 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,681 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,682 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,684 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:15,689 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:15,691 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,691 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:15,698 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,704 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,715 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,734 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 31, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,739 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"))\n",
      "2023-10-11 14:23:15,740 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,743 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:15,745 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:15,746 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,747 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:15,750 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:15,753 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:15,754 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:15,757 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:15,759 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:15,760 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,762 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:15,763 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:15,764 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,765 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:15,775 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:15,786 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:15,802 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:15,821 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:15,840 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:15,841 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,857 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:15,859 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:15,860 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:15,862 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:15,863 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:15,865 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:15,867 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:15,868 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:15,870 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:15,871 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,873 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:15,875 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:15,880 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 33])\", \"<class 'int'>: 32\")\n",
      "2023-10-11 14:23:15,881 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:15,883 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 33])\", \"<class 'int'>: 32\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:15,885 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 33])\", \"<class 'int'>: 32\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:15,886 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 33])\", \"<class 'int'>: 32\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:15,888 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 33])\", \"<class 'int'>: 32\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:15,890 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:15,890 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,892 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:15,896 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:15,902 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,903 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:15,927 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:15,938 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:15,949 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:15,959 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:15,966 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:15,967 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:15,969 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:15,974 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:15,979 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:15,980 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:16,033 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,046 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,067 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,075 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,081 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,082 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,085 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:16,089 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:16,094 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:16,095 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:16,101 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,106 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,114 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,119 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,126 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,126 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,129 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:16,133 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:16,138 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:16,138 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:16,144 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,150 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,156 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,164 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,172 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,173 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,175 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:16,179 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:16,184 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:16,185 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:16,191 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,199 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,207 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,214 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,224 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,225 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,227 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:16,231 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:16,236 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:16,237 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:16,244 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,252 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,257 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,263 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,344 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,346 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,348 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:16,354 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:16,361 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:16,362 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:16,372 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,379 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,386 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,395 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,400 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,400 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,404 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:16,408 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:16,413 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:16,414 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:16,420 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,429 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,434 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,442 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,451 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,452 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,454 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:16,459 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:16,464 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:16,465 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:16,471 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,483 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,488 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,496 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,504 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,505 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,508 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:16,513 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:16,517 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:16,518 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:16,585 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,625 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,630 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,640 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,646 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,647 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,650 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:16,655 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:16,660 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:16,661 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:16,670 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,680 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,686 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,692 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,720 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,722 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,726 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:16,732 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:16,734 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:16,735 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:16,782 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,839 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,873 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,880 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 32, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,885 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"))\n",
      "2023-10-11 14:23:16,886 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,888 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:16,890 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:16,891 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:16,892 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:16,894 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:16,896 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:16,898 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:16,900 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:16,901 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:16,902 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,903 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:16,905 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:16,906 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:16,907 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:16,923 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:16,935 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:16,952 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:16,963 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:16,967 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:16,968 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,973 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:16,975 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:16,977 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:16,977 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:16,979 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:16,980 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:16,982 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:16,983 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:16,985 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:16,986 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:16,987 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:16,988 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:16,993 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 34])\", \"<class 'int'>: 33\")\n",
      "2023-10-11 14:23:16,994 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:16,995 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 34])\", \"<class 'int'>: 33\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:16,998 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 34])\", \"<class 'int'>: 33\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:16,999 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 34])\", \"<class 'int'>: 33\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:17,001 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 34])\", \"<class 'int'>: 33\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:17,003 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:17,004 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:17,005 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:17,010 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:17,015 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:17,016 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:17,081 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,119 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,131 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,138 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,152 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,154 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:17,156 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:17,161 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:17,166 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:17,167 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:17,230 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,275 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,283 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,293 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,312 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,313 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:17,316 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:17,322 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:17,326 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:17,327 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:17,397 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,427 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,435 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,446 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,451 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,452 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:17,455 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:17,460 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:17,464 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:17,465 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:17,471 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,479 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,486 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,491 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,496 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,497 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:17,500 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:17,504 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:17,509 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:17,510 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:17,518 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,523 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,529 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,538 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,543 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,543 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:17,546 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:17,551 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:17,556 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:17,557 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:17,566 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,573 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,579 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,594 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,599 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,600 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:17,602 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:17,607 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:17,612 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:17,613 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:17,619 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,626 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,636 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,642 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,650 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,651 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:17,653 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:17,657 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:17,662 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:17,663 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:17,707 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,765 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,785 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,791 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,800 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,801 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:17,804 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:17,808 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:17,814 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:17,815 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:17,822 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,828 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,833 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,879 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,897 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,899 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:17,901 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:17,906 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:17,911 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:17,912 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:17,935 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,942 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,948 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,954 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,961 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,962 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:17,964 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:17,969 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:17,974 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:17,975 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:17,981 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,987 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,993 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:17,999 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:18,007 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:18,009 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,012 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:18,016 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:18,018 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,019 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:18,031 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:18,036 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:18,045 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:18,054 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 33, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:18,147 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"))\n",
      "2023-10-11 14:23:18,149 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,151 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:18,153 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:18,154 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,155 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:18,158 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:18,164 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:18,166 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:18,167 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:18,169 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:18,170 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,171 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:18,173 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:18,174 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,175 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:18,186 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:18,196 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:18,210 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:18,221 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:18,267 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:18,271 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,281 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:18,282 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:18,284 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:18,285 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:18,286 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:18,288 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:18,290 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:18,291 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:18,293 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:18,294 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,295 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:18,297 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:18,302 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 35])\", \"<class 'int'>: 34\")\n",
      "2023-10-11 14:23:18,303 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:18,305 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 35])\", \"<class 'int'>: 34\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:18,306 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 35])\", \"<class 'int'>: 34\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:18,308 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 35])\", \"<class 'int'>: 34\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:18,310 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 35])\", \"<class 'int'>: 34\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:18,311 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:18,312 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,314 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:18,318 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:18,323 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,324 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:18,363 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,370 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,376 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,383 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,388 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,389 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,392 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:18,397 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:18,402 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,403 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:18,409 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,417 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,423 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,429 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,434 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,435 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,437 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:18,442 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:18,447 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,448 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:18,476 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,492 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,498 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,508 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,513 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,514 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,517 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:18,522 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:18,526 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,527 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:18,533 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,538 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,558 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,565 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,571 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,572 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,575 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:18,579 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:18,584 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,585 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:18,595 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,604 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,616 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,626 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,631 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,632 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,635 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:18,641 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:18,646 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,647 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:18,654 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,669 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,675 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,694 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,699 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,699 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,702 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:18,706 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:18,711 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,711 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:18,718 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,724 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,734 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,743 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,751 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,751 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,754 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:18,759 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:18,763 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,764 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:18,770 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,778 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,784 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,795 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,800 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,800 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,803 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:18,807 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:18,812 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,813 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:18,847 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,858 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,868 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,875 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,879 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,880 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,882 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:18,886 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:18,890 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,891 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:18,899 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,906 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,915 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,925 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,931 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:18,932 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:18,935 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:18,940 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:18,945 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:18,946 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:19,008 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:19,031 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:19,066 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:19,072 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:19,077 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:19,078 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:19,080 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:19,085 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:19,086 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:19,087 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:19,094 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:19,099 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:19,107 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:19,113 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 34, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:19,118 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"))\n",
      "2023-10-11 14:23:19,119 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:19,121 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:19,122 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:19,123 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:19,124 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:19,127 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:19,133 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:19,137 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:19,138 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:19,140 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:19,141 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:19,143 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:19,145 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:19,147 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:19,148 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:19,163 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:19,182 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:19,197 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:19,217 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:19,270 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:19,271 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:19,278 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:19,280 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:19,281 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:19,282 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:19,284 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:19,286 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:19,287 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:19,289 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:19,291 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:19,292 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:19,293 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:19,294 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:19,299 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 36])\", \"<class 'int'>: 35\")\n",
      "2023-10-11 14:23:19,300 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:19,302 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 36])\", \"<class 'int'>: 35\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:19,304 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 36])\", \"<class 'int'>: 35\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:19,305 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 36])\", \"<class 'int'>: 35\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:19,307 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 36])\", \"<class 'int'>: 35\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:19,308 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:19,309 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:19,310 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:19,315 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:19,320 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:19,321 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:19,337 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,349 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,358 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,364 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,409 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,410 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:19,413 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:19,417 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:19,422 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:19,423 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:19,438 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,446 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,456 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,462 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,468 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,469 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:19,472 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:19,476 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:19,481 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:19,482 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:19,489 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,497 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,503 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,518 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,523 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,524 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:19,526 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:19,531 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:19,536 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:19,537 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:19,611 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,623 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,675 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,741 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,746 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,747 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:19,750 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:19,754 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:19,759 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:19,760 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:19,768 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,774 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,779 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,784 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,794 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,795 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:19,797 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:19,802 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:19,806 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:19,807 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:19,814 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,819 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,824 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,829 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,901 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,904 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:19,906 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:19,910 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:19,915 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:19,916 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:19,922 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,930 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,936 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,943 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,955 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:19,956 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:19,959 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:19,963 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:19,968 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:19,969 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:20,003 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,013 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,021 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,030 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,114 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,115 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:20,118 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:20,123 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:20,128 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:20,129 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:20,145 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,152 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,160 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,168 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,176 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,177 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:20,180 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:20,185 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:20,190 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:20,191 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:20,199 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,209 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,215 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,220 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,225 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,226 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:20,229 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:20,233 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:20,238 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:20,239 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:20,248 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,254 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,261 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,268 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,342 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,343 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:20,346 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:20,353 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:20,354 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:20,355 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:20,411 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,473 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,483 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,489 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 35, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,497 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"))\n",
      "2023-10-11 14:23:20,498 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:20,500 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:20,502 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:20,503 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:20,504 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:20,507 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:20,510 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:20,512 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:20,516 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:20,518 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:20,519 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:20,521 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:20,522 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:20,523 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:20,524 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:20,538 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:20,547 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:20,562 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:20,581 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:20,631 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:20,632 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:20,638 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:20,640 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:20,641 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:20,642 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:20,644 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:20,646 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:20,647 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:20,649 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:20,651 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:20,652 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:20,653 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:20,654 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:20,659 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 37])\", \"<class 'int'>: 36\")\n",
      "2023-10-11 14:23:20,660 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:20,662 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 37])\", \"<class 'int'>: 36\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:20,663 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 37])\", \"<class 'int'>: 36\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:20,665 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 37])\", \"<class 'int'>: 36\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:20,666 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 37])\", \"<class 'int'>: 36\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:20,668 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:20,668 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:20,670 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:20,674 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:20,679 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:20,680 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:20,691 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:20,699 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:20,709 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:20,716 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:20,724 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:20,725 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:20,728 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:20,732 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:20,737 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:20,738 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:20,800 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:20,839 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:20,909 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:20,915 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:20,920 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:20,921 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:20,924 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:20,928 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:20,933 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:20,934 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:20,949 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:20,954 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,029 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,040 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,045 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,046 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:21,048 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:21,053 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:21,058 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:21,059 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:21,074 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,083 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,088 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,161 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,204 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,205 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:21,207 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:21,212 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:21,217 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:21,218 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:21,231 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,236 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,242 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,247 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,252 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,252 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:21,255 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:21,260 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:21,265 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:21,266 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:21,272 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,282 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,295 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,306 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,311 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,312 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:21,314 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:21,318 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:21,323 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:21,324 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:21,394 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,412 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,419 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,451 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,464 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,466 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:21,468 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:21,473 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:21,477 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:21,478 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:21,485 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,491 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,497 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,502 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,506 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,507 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:21,509 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:21,514 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:21,519 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:21,520 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:21,568 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,612 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,620 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,627 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,633 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,634 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:21,636 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:21,641 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:21,646 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:21,646 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:21,653 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,668 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,683 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,694 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,700 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,701 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:21,703 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:21,708 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:21,713 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:21,714 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:21,725 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,731 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,737 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,743 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,768 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,770 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:21,773 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:21,777 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:21,781 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:21,782 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:21,847 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,881 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,898 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,905 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 36, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,911 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"))\n",
      "2023-10-11 14:23:21,912 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:21,915 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:21,916 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:21,917 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:21,918 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:21,921 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:21,923 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:21,925 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:21,926 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:21,928 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:21,929 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:21,930 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:21,932 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:21,933 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:21,934 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:21,947 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:21,960 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:21,969 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:21,977 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:21,987 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:21,989 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:21,996 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:21,997 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:21,998 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 14:23:21,999 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:22,001 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:22,003 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:22,004 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:22,006 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:22,008 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:22,009 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,010 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 14:23:22,012 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:22,017 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 38])\", \"<class 'int'>: 37\")\n",
      "2023-10-11 14:23:22,017 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:22,019 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 38])\", \"<class 'int'>: 37\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:22,021 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 38])\", \"<class 'int'>: 37\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:22,023 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 38])\", \"<class 'int'>: 37\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:22,024 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 38])\", \"<class 'int'>: 37\"), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:22,026 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:22,027 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,028 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 14:23:22,033 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:22,038 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,038 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:22,046 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,051 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,058 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,066 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,073 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,074 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,076 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 14:23:22,082 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:22,087 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,087 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:22,112 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,121 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,143 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,149 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,155 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,156 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,158 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 14:23:22,163 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:22,168 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,169 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:22,178 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,183 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,195 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,204 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,209 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,210 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,213 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 14:23:22,217 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:22,222 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,223 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:22,235 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,242 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,248 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,253 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,259 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,260 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,263 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 14:23:22,268 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:22,273 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,274 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:22,280 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,286 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,294 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,308 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,314 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,315 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,317 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 14:23:22,322 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:22,327 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,328 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:22,336 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,347 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,358 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,365 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,370 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,371 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,373 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 14:23:22,378 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:22,383 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,384 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:22,398 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,406 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,415 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,430 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,444 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,445 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,448 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 14:23:22,452 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:22,457 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,458 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:22,465 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,470 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,482 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,487 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,491 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,492 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,496 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 14:23:22,501 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:22,506 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,506 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:22,513 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,530 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,535 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,619 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,631 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,632 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,635 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 14:23:22,640 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:22,645 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,646 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:22,659 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,665 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,673 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,680 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,685 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,686 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,689 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 14:23:22,693 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:22,707 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,708 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:22,776 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,796 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,802 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,810 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,815 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,816 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,818 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 14:23:22,823 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:22,824 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,825 [1175756643.py:24 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 14:23:22,834 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,840 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,849 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,855 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([2, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\", \"<class 'torch.Tensor'>: torch.Size([2, 12, 37, 64])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}, output: (\"<class '__main__.MixTensor'>: torch.Size([2, 1, 768])\", (\"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\", \"<class '__main__.MixTensor'>: torch.Size([2, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,905 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\", (\"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\", \"<class 'torch.Tensor'>: torch.Size([8, 12, 38, 64])\"))\n",
      "2023-10-11 14:23:22,906 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,908 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 14:23:22,910 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:22,911 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,911 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:22,914 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:22,918 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:22,922 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:22,927 [1175756643.py:40 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 768])\n",
      "2023-10-11 14:23:22,929 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 768])\n",
      "2023-10-11 14:23:22,930 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,931 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 14:23:22,932 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 14:23:22,934 [1175756643.py:23 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1, 768])\",)\n",
      "2023-10-11 14:23:22,934 [1175756643.py:24 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 14:23:22,950 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 0, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:22,962 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 1, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:22,972 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 2, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:22,984 [1175756643.py:40 in new_forward] DEBUG - layer: lm_head, batch: 3, args: (\"<class 'torch.Tensor'>: torch.Size([2, 1, 768])\",), kwargs: {}, output: <class '__main__.MixTensor'>: torch.Size([2, 1, 50272])\n",
      "2023-10-11 14:23:22,987 [1175756643.py:49 in new_forward] DEBUG - outputs after concat: <class 'torch.Tensor'>: torch.Size([8, 1, 50272])\n",
      "2023-10-11 14:23:22,988 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 14:23:22,994 [test.py:40 in test_hf_gen] INFO - for i in range(10): -\n",
      " dunno not the.\n",
      "I                      \n",
      "2023-10-11 14:23:22,995 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 14:23:22,996 [test.py:40 in test_hf_gen] INFO - Who are you? Are you conscious??Huawei Mate 60 Pro is a new smartphone with is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone\n",
      "2023-10-11 14:23:22,997 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 14:23:22,998 [test.py:40 in test_hf_gen] INFO - Where is Deutschland?\n",
      "I'm in Germany.\n",
      "2023-10-11 14:23:22,999 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 14:23:22,999 [test.py:40 in test_hf_gen] INFO - How is Huawei Mate 60 Pro?\n",
      "Huawei Mate 60 Pro is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone\n",
      "2023-10-11 14:23:23,000 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 14:23:23,001 [test.py:40 in test_hf_gen] INFO - for i in range(10): -\n",
      " dunno not the.\n",
      "I                      \n",
      "2023-10-11 14:23:23,002 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 14:23:23,003 [test.py:40 in test_hf_gen] INFO - Who are you? Are you conscious??Huawei Mate 60 Pro is a new smartphone with is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone\n",
      "2023-10-11 14:23:23,004 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 14:23:23,005 [test.py:40 in test_hf_gen] INFO - Where is Deutschland?\n",
      "I'm in Germany.\n",
      "2023-10-11 14:23:23,005 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 14:23:23,006 [test.py:40 in test_hf_gen] INFO - How is Huawei Mate 60 Pro?\n",
      "Huawei Mate 60 Pro is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone that is a premium smartphone\n",
      "2023-10-11 14:23:23,007 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 14:23:23,022 [520681597.py:17 in reset_forward] DEBUG - model.decoder.embed_tokens from flexgen to old.\n",
      "2023-10-11 14:23:23,023 [520681597.py:17 in reset_forward] DEBUG - model.decoder.embed_positions from flexgen to old.\n",
      "2023-10-11 14:23:23,024 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.0 from flexgen to old.\n",
      "2023-10-11 14:23:23,025 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.1 from flexgen to old.\n",
      "2023-10-11 14:23:23,025 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.2 from flexgen to old.\n",
      "2023-10-11 14:23:23,027 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.3 from flexgen to old.\n",
      "2023-10-11 14:23:23,028 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.4 from flexgen to old.\n",
      "2023-10-11 14:23:23,029 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.5 from flexgen to old.\n",
      "2023-10-11 14:23:23,029 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.6 from flexgen to old.\n",
      "2023-10-11 14:23:23,030 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.7 from flexgen to old.\n",
      "2023-10-11 14:23:23,031 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.8 from flexgen to old.\n",
      "2023-10-11 14:23:23,032 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.9 from flexgen to old.\n",
      "2023-10-11 14:23:23,033 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.10 from flexgen to old.\n",
      "2023-10-11 14:23:23,035 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.11 from flexgen to old.\n",
      "2023-10-11 14:23:23,036 [520681597.py:17 in reset_forward] DEBUG - model.decoder.final_layer_norm from flexgen to old.\n",
      "2023-10-11 14:23:23,037 [520681597.py:17 in reset_forward] DEBUG - lm_head from flexgen to old.\n",
      "100%|██████████| 197/197 [00:00<00:00, 3114.48it/s]\n"
     ]
    }
   ],
   "source": [
    "with flexgen(checkpoint, policy) as model:\n",
    "    num_prompts = policy.gpu_batch_size * policy.num_gpu_batches\n",
    "    test_hf_gen(checkpoint, model, num_prompts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
