{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fsuser/miniconda3/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2023-10-04 09:29:58,047 [instantiator.py:21 in <module>] INFO - Created a temporary directory at /tmp/tmpisnd463d\n",
      "2023-10-04 09:29:58,049 [instantiator.py:76 in _write] INFO - Writing /tmp/tmpisnd463d/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Module \n",
    "import functools \n",
    "\n",
    "from flexgen_utils import logging, Policy, get_module_from_name\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "from flexgen_init import policy_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:29:58,493 [connectionpool.py:1003 in _new_conn] DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2023-10-04 09:29:58,561 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-04 09:29:59.266711: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-04 09:30:00,279 [tpu_cluster_resolver.py:32 in <module>] DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2023-10-04 09:30:00,481 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5\n",
      "2023-10-04 09:30:00,483 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7\n",
      "2023-10-04 09:30:00,483 [__init__.py:47 in <module>] DEBUG - Creating converter from 7 to 5\n",
      "2023-10-04 09:30:00,484 [__init__.py:47 in <module>] DEBUG - Creating converter from 5 to 7\n",
      "2023-10-04 09:30:01,552 [flexgen_init.py:201 in get_policy_weight_map] INFO - device_map is prepared!\n",
      "2023-10-04 09:30:01,555 [flexgen_init.py:207 in get_policy_weight_map] INFO - CausalLM facebook/opt-125m is to be loaded on: \n",
      "GPU Mem 0.00 GiB (0.00%), CPU Mem 0.07 GiB (30.19%), Disk Mem 0.16 Gib (69.81%)\n",
      "2023-10-04 09:30:01,589 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-04 09:30:01,724 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-04 09:30:01,821 [flexgen_init.py:67 in policy_init] INFO - The whole model has been downloaded an processed to offload_folder: 'offload_dir/facebook.opt-125m'\n",
      "model init: loading by policy...:   0%|          | 0/197 [00:00<?, ?it/s]/home/fsuser/FlexGen/general/flexgen_utils/offload.py:41: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995026/work/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  tmp = torch.from_numpy(np_memmap).to(device)\n",
      "model init: loading by policy...: 100%|██████████| 197/197 [00:00<00:00, 2911.23it/s]\n",
      "2023-10-04 09:30:01,896 [flexgen_init.py:79 in policy_init] INFO - model has been loaded by policy.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"facebook/opt-125m\" # 125m 6.7b 13b 30b\n",
    "\n",
    "policy = Policy(\n",
    "    gpu_batch_size=2, \n",
    "    num_gpu_batches=4, \n",
    "    weights_gpu_percent=0.0, \n",
    "    weights_cpu_percent=0.3, \n",
    "    cache_gpu_percent=0.0, \n",
    "    cache_cpu_percent=0.2, \n",
    "    act_gpu_percent=0.0, \n",
    "    act_cpu_percent=0.5, \n",
    "    overlap=True, \n",
    "    pin_weight=True,\n",
    ")\n",
    "\n",
    "# for test\n",
    "gbs = policy.gpu_batch_size\n",
    "ngb = policy.num_gpu_batches\n",
    "num_prompts = ngb * gbs \n",
    "\n",
    "# model init\n",
    "output = policy_init(checkpoint, policy)\n",
    "\n",
    "model = output.model\n",
    "weight_map = output.weight_map\n",
    "layer_names = output.layer_names\n",
    "index = output.index\n",
    "dat_files = output.dat_files\n",
    "tied_params = output.tied_params\n",
    "offload_folder = output.offload_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:30:01,919 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.embed_tokens to flexgen forward\n",
      "2023-10-04 09:30:01,921 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.embed_positions to flexgen forward\n",
      "2023-10-04 09:30:01,922 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.final_layer_norm to flexgen forward\n",
      "2023-10-04 09:30:01,923 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.0 to flexgen forward\n",
      "2023-10-04 09:30:01,924 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.1 to flexgen forward\n",
      "2023-10-04 09:30:01,925 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.2 to flexgen forward\n",
      "2023-10-04 09:30:01,926 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.3 to flexgen forward\n",
      "2023-10-04 09:30:01,927 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.4 to flexgen forward\n",
      "2023-10-04 09:30:01,928 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.5 to flexgen forward\n",
      "2023-10-04 09:30:01,929 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.6 to flexgen forward\n",
      "2023-10-04 09:30:01,930 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.7 to flexgen forward\n",
      "2023-10-04 09:30:01,931 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.8 to flexgen forward\n",
      "2023-10-04 09:30:01,932 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.9 to flexgen forward\n",
      "2023-10-04 09:30:01,933 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.10 to flexgen forward\n",
      "2023-10-04 09:30:01,934 [2440752808.py:36 in to_flexgen_forward] DEBUG - model.decoder.layers.11 to flexgen forward\n",
      "2023-10-04 09:30:01,935 [2440752808.py:36 in to_flexgen_forward] DEBUG - lm_head to flexgen forward\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from accelerate.utils import named_module_tensors \n",
    "from flexgen_utils import get_tied_target\n",
    "from flexgen_utils import flexgen_load_module_tensor, flexgen_offload_module_tensor\n",
    "from flexgen_minibatch import get_size_info, get_kth_batch_inputs, concat_outputs\n",
    "\n",
    "def load_layer_weights(model, layer_name, compute_device, offload_folder, dat_files):\n",
    "    logger.debug(f'load_layer_weights: {layer_name} to {compute_device}')\n",
    "    layer_module = get_module_from_name(model, layer_name)\n",
    "    weight_names = [layer_name + '.' + name for name, _ in named_module_tensors(layer_module, True, True)]\n",
    "    layer_dat_files = [os.path.join(offload_folder, get_tied_target(w, tied_params, dat_files) + '.dat') for w in weight_names]\n",
    "    assert all([os.path.isfile(f) for f in layer_dat_files]), f'dat file error, {dat_files}'\n",
    "    \n",
    "    for w in weight_names:\n",
    "        flexgen_load_module_tensor(model, w, compute_device, index, offload_folder, tied_params)\n",
    "\n",
    "\n",
    "def offload_layer_weights(model, layer_name, weight_map):\n",
    "    logger.debug(f'offload_layer_weights: {layer_name}\\n\\n')\n",
    "    layer_module = get_module_from_name(model, layer_name)\n",
    "    weight_names = [layer_name + '.' + name for name, _ in named_module_tensors(layer_module, True, True)]\n",
    "    for w in weight_names:\n",
    "        flexgen_offload_module_tensor(model, w, weight_map) \n",
    "\n",
    "\n",
    "def to_flexgen_forward(model, layer_names, j, compute_device, weight_map, offload_folder, ngb, gbs):\n",
    "    # rewrite the j-th layer's forward\n",
    "    \n",
    "    layer_name = layer_names[j]\n",
    "    next_layer_name = layer_names[(j + 1) % len(layer_names)]\n",
    "\n",
    "    layer = get_module_from_name(model, layer_name)  \n",
    "    if hasattr(layer, \"_flexgen_old_forward\"): # has been rewriten\n",
    "        return layer \n",
    "    \n",
    "    logger.debug(f'{layer_name} to flexgen forward')\n",
    "    layer._flexgen_old_forward = old_forward = layer.forward \n",
    "\n",
    "    @functools.wraps(old_forward)\n",
    "    def new_forward(*args, **kwargs):\n",
    "        # pre fwd: load curr & next weights, TODO: cuda stream\n",
    "        load_layer_weights(model, layer_name, compute_device, offload_folder, dat_files)\n",
    "        load_layer_weights(model, next_layer_name, compute_device, offload_folder, dat_files)\n",
    "        \n",
    "        # loop forward pass of K minibatches, TODO: cuda stream\n",
    "        with torch.no_grad():\n",
    "            logger.debug(f'args: {get_size_info(args)}')\n",
    "            logger.debug(f'kwargs: {get_size_info(kwargs)}')\n",
    "            # output = old_forward(*args, **kwargs)\n",
    "            # logger.debug(f'output: {get_size_info(output)}')\n",
    "\n",
    "            args_0 = get_kth_batch_inputs(args, 0, gbs)\n",
    "            kwargs_0 = get_kth_batch_inputs(kwargs, 0, gbs)\n",
    "            logger.debug(f'args_0: {get_size_info(args_0)}')\n",
    "            logger.debug(f'kwargs_0: {get_size_info(kwargs_0)}')\n",
    "            # output_0 = old_forward(*args_0, **kwargs_0)\n",
    "            # logger.debug(f'output0: {get_size_info(output_0)}')\n",
    "\n",
    "            outputs = []\n",
    "            for k in range(ngb):\n",
    "                logger.debug(f'layer: {layer_name}, batch: {k}')\n",
    "\n",
    "                # 'pre' fwd: load curr & next inputs (activations, KV cache), store & offload prev \n",
    "                args_k = get_kth_batch_inputs(args, k, gbs)\n",
    "                kwargs_k = get_kth_batch_inputs(kwargs, k, gbs)\n",
    "\n",
    "                # the k-th fwd pass\n",
    "                output = old_forward(*args_k, **kwargs_k)\n",
    "                outputs.append(output) \n",
    "                \n",
    "                # 'post' fwd: offload curr inputs\n",
    "\n",
    "            logger.debug(f'outputs before concat: {ngb} x {get_size_info(outputs[0])}')\n",
    "            output = concat_outputs(outputs)\n",
    "            logger.debug(f'outputs after concat: {get_size_info(output)}')                \n",
    "\n",
    "        # post fwd: free curr weights\n",
    "        offload_layer_weights(model, layer_name, weight_map)\n",
    "        return output\n",
    "\n",
    "    layer.forward = new_forward\n",
    "    return layer\n",
    "\n",
    "\n",
    "def to_old_forward(model, layer_name):\n",
    "    layer = get_module_from_name(model, layer_name) \n",
    "\n",
    "    if hasattr(layer, \"_flexgen_old_forward\"):\n",
    "        layer.forward = layer._flexgen_old_forward\n",
    "        delattr(layer, \"_flexgen_old_forward\")\n",
    "        logger.debug(f'{layer_name} to old forward')\n",
    "    return layer\n",
    "\n",
    "\n",
    "layer_nums = len(layer_names)\n",
    "\n",
    "for j in range(layer_nums):\n",
    "    to_old_forward(model, layer_names[j])\n",
    "    \n",
    "# rewrite layers' forward\n",
    "for j in range(layer_nums):\n",
    "    compute_device = 'cpu'\n",
    "    to_flexgen_forward(model, layer_names, j, compute_device, weight_map, offload_folder, ngb, gbs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:30:01,984 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "/home/fsuser/miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1535: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on meta. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('meta') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "2023-10-04 09:30:02,225 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:02,227 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:02,228 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10]),)\n",
      "2023-10-04 09:30:02,229 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:02,230 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10]),)\n",
      "2023-10-04 09:30:02,231 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:02,232 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:02,233 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:02,235 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:02,236 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:02,237 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])\n",
      "2023-10-04 09:30:02,238 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])\n",
      "2023-10-04 09:30:02,238 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,240 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:02,242 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:02,244 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10]), 0)\n",
      "2023-10-04 09:30:02,245 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:02,246 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10]), 0)\n",
      "2023-10-04 09:30:02,246 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:02,247 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:02,249 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:02,250 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:02,251 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:02,252 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])\n",
      "2023-10-04 09:30:02,253 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])\n",
      "2023-10-04 09:30:02,254 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,255 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:02,264 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:02,272 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:02,273 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,274 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:02,274 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,275 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:02,287 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:02,292 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:02,298 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:02,305 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,307 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,308 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,311 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:02,323 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:02,336 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:02,337 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,338 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:02,339 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,340 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:02,348 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:02,357 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:02,364 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:02,369 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,371 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,372 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,375 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:02,382 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:02,390 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:02,391 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,392 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:02,394 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,395 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:02,401 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:02,407 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:02,413 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:02,419 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,422 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,422 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,425 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:02,434 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:02,443 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:02,444 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,446 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:02,447 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,447 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:02,453 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:02,464 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:02,471 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:02,476 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,477 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,478 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,481 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:02,489 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:02,498 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:02,499 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,500 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:02,501 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,502 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:02,510 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:02,516 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:02,522 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:02,528 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,531 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,532 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,534 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:02,543 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:02,551 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:02,552 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,553 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:02,554 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,555 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:02,562 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:02,566 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:02,571 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:02,576 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,577 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,578 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,581 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:02,589 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:02,596 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:02,599 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,600 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:02,601 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,602 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:02,609 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:02,616 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:02,621 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:02,627 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,629 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,630 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,635 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:02,644 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:02,653 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:02,654 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,655 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:02,656 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,657 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:02,663 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:02,668 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:02,676 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:02,682 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,684 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,685 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,687 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:02,695 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:02,707 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:02,708 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,709 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:02,710 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,711 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:02,719 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:02,730 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:02,737 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:02,744 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,747 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,748 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,751 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:02,759 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:02,768 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:02,769 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,770 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:02,770 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,771 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:02,780 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:02,789 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:02,794 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:02,800 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,801 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,803 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,805 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:02,813 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:02,821 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:02,823 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,824 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:02,825 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,826 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:02,835 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:02,848 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:02,855 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:02,863 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,865 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,865 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,868 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:02,876 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:02,878 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:02,879 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,880 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:02,881 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 10, 10]), 'layer_head_mask': None, 'past_key_value': None, 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:02,882 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:02,945 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:02,973 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:02,987 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:02,993 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 10, 768]), (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,995 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 10, 768]), (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])))\n",
      "2023-10-04 09:30:02,996 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:02,999 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:03,002 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:03,010 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:03,011 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:03,012 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:03,013 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:03,014 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:03,016 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:03,018 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:03,019 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:03,021 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 768])\n",
      "2023-10-04 09:30:03,023 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 768])\n",
      "2023-10-04 09:30:03,024 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,026 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:03,028 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:03,029 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 10, 768]),)\n",
      "2023-10-04 09:30:03,030 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:03,031 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 10, 768]),)\n",
      "2023-10-04 09:30:03,032 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:03,033 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:03,055 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:03,075 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:03,086 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:03,101 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 10, 50272])\n",
      "2023-10-04 09:30:03,107 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 10, 50272])\n",
      "2023-10-04 09:30:03,109 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,119 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:03,121 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:03,123 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:03,124 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:03,125 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:03,126 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:03,127 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:03,129 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:03,130 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:03,131 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:03,132 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:03,133 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:03,134 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,136 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:03,137 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:03,139 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 11]), 10)\n",
      "2023-10-04 09:30:03,140 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:03,142 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 11]), 10)\n",
      "2023-10-04 09:30:03,143 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:03,145 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:03,147 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:03,148 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:03,149 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:03,150 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:03,151 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:03,152 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,154 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:03,162 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:03,171 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,172 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,173 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,174 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,175 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:03,182 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:03,190 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:03,196 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:03,202 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,204 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,205 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,207 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:03,215 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:03,227 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,228 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,229 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,230 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,231 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:03,240 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:03,247 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:03,252 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:03,258 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,259 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,260 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,262 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:03,270 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:03,278 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,279 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,280 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,281 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,282 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:03,319 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:03,359 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:03,399 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:03,407 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,409 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,410 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,412 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:03,420 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:03,429 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,430 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,431 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,431 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,432 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:03,444 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:03,449 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:03,453 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:03,456 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,458 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,458 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,461 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:03,469 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:03,477 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,479 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,480 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,481 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,482 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:03,489 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:03,495 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:03,502 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:03,506 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,508 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,509 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,511 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:03,519 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:03,527 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,528 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,529 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,530 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,531 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:03,536 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:03,540 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:03,543 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:03,549 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,551 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,551 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,554 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 09:30:03,562 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:03,570 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,571 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,572 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,573 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,573 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:03,579 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:03,583 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:03,586 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:03,590 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,591 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,592 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,595 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:03,604 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:03,613 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,614 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,615 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,616 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,616 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:03,622 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:03,626 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:03,630 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:03,634 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,635 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,636 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,638 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:03,646 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:03,655 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,656 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,656 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,657 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,658 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:03,664 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:03,671 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:03,676 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:03,679 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,681 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,682 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,685 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:03,694 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:03,703 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,704 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,705 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,705 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,706 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:03,714 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:03,720 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:03,728 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:03,732 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,734 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,735 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,738 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:03,746 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:03,756 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,756 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,757 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,759 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,759 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:03,770 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:03,775 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:03,778 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:03,782 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,783 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,784 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,787 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:03,795 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:03,797 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,797 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 10, 64]), torch.Size([8, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,798 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,800 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 11]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 10, 64]), torch.Size([2, 12, 10, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:03,801 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:03,807 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:03,813 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:03,820 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:03,856 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,858 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])))\n",
      "2023-10-04 09:30:03,859 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,861 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:03,864 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:03,872 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,873 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:03,874 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,875 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:03,876 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:03,878 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:03,882 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:03,887 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:03,890 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:03,892 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:03,893 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,895 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:03,897 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:03,899 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:03,899 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:03,900 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:03,901 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:03,902 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:03,915 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:03,926 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:03,935 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:03,947 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:03,950 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:03,951 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,961 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:03,963 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:03,965 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:03,966 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:03,967 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:03,967 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:03,968 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:03,970 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:03,971 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:03,973 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:03,974 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:03,975 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:03,976 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,978 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:03,980 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:03,982 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 12]), 11)\n",
      "2023-10-04 09:30:03,983 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:03,984 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 12]), 11)\n",
      "2023-10-04 09:30:03,985 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:03,986 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:03,987 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:03,990 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:03,991 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:03,993 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:03,994 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:03,995 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:03,997 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:04,006 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:04,016 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,017 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,018 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,019 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,020 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:04,029 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:04,036 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:04,040 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:04,045 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,047 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,047 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,051 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:04,059 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:04,068 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,069 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,070 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,071 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,072 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:04,078 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:04,083 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:04,087 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:04,091 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,092 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,093 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,096 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:04,106 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:04,114 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,115 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,116 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,117 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,118 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:04,125 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:04,129 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:04,142 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:04,149 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,151 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,152 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,155 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:04,164 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:04,173 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,174 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,175 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,176 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,177 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:04,183 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:04,189 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:04,195 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:04,200 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,202 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,203 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,206 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:04,215 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:04,225 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,226 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,227 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,228 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,228 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:04,236 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:04,240 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:04,243 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:04,246 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,248 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,249 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,251 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:04,259 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:04,268 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,269 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,270 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,271 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,272 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:04,277 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:04,283 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:04,290 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:04,293 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,294 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,295 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,298 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:04,305 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:04,315 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,316 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,317 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,317 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,318 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:04,328 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:04,331 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:04,334 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:04,337 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,338 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,339 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,341 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:04,349 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:04,358 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,360 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,360 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,361 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,362 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:04,369 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:04,372 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:04,376 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:04,379 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,381 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,382 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,384 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:04,392 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:04,401 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,402 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,403 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,403 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,405 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:04,410 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:04,417 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:04,422 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:04,428 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,430 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,431 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,434 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:04,442 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:04,451 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,452 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,453 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,455 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,455 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:04,463 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:04,473 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:04,478 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:04,484 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,486 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,487 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,490 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:04,502 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:04,515 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,516 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,517 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,519 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,520 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:04,525 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:04,534 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:04,539 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:04,543 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,544 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,545 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,548 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:04,556 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:04,558 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,559 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 11, 64]), torch.Size([8, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,560 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,561 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 12]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 11, 64]), torch.Size([2, 12, 11, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,562 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:04,569 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:04,577 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:04,584 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:04,597 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,599 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])))\n",
      "2023-10-04 09:30:04,600 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,604 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:04,606 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:04,619 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,621 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:04,622 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,624 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:04,624 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:04,626 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:04,630 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:04,632 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:04,637 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:04,639 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:04,640 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,642 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:04,644 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:04,646 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,647 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:04,648 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,649 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:04,650 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:04,663 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:04,672 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:04,681 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:04,690 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:04,693 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:04,695 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,704 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:04,706 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:04,708 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:04,708 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:04,709 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:04,710 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:04,711 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:04,712 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:04,713 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:04,715 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:04,716 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:04,716 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:04,717 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,719 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:04,720 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:04,722 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 13]), 12)\n",
      "2023-10-04 09:30:04,723 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:04,724 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 13]), 12)\n",
      "2023-10-04 09:30:04,725 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:04,726 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:04,727 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:04,728 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:04,730 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:04,731 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:04,731 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:04,733 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,734 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:04,742 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:04,750 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,751 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,752 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,753 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,753 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:04,760 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:04,767 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:04,775 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:04,779 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:30:04,781 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:30:04,782 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,785 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:04,793 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:04,801 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,802 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,803 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,804 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,806 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:04,812 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:04,815 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:04,822 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:04,826 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:30:04,828 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:30:04,829 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,832 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:04,841 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:04,849 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,851 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,852 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,853 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,854 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:04,862 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:04,869 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:04,873 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:04,878 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:30:04,879 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:30:04,880 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,883 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:04,891 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:04,900 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,901 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,902 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,903 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,904 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:04,912 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:04,918 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:04,922 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:04,926 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:30:04,928 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:30:04,929 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,932 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:04,940 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:04,949 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:04,949 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,951 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:04,952 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:04,952 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:04,959 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:04,963 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:04,970 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:04,974 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:30:04,977 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:30:04,978 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:04,981 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:04,990 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:04,999 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,000 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,001 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,001 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,002 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:05,010 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:05,016 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:05,023 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:05,028 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,030 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,031 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,034 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:05,042 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:05,050 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,051 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,052 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,053 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,054 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:05,060 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:05,063 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:05,069 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:05,073 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,074 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,076 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,078 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:05,087 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:05,095 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,096 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,098 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,099 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,100 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:05,107 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:05,110 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:05,115 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:05,119 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,121 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,122 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,125 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:05,133 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:05,143 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,144 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,145 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,146 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,147 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:05,153 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:05,165 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:05,173 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:05,181 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,183 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,184 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,187 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:05,195 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:05,204 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,206 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,206 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,208 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,209 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:05,215 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:05,222 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:05,228 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:05,235 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,238 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,239 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,241 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:05,250 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:05,259 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,260 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,261 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,262 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,263 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:05,268 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:05,280 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:05,290 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:05,300 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,303 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,305 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,310 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:05,322 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:05,326 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,327 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 12, 64]), torch.Size([8, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,328 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,329 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 13]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 12, 64]), torch.Size([2, 12, 12, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,330 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:05,340 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:05,345 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:05,350 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:05,355 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,357 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])))\n",
      "2023-10-04 09:30:05,358 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,361 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:05,364 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:05,372 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,374 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:05,374 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,375 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:05,377 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:05,380 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:05,384 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:05,388 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:05,391 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:05,393 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:05,394 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,396 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:05,398 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:05,399 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,400 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:05,401 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,402 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:05,402 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:05,412 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:05,425 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:05,435 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:05,445 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:05,449 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:05,449 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,457 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:05,459 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:05,460 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:05,461 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:05,462 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:05,463 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:05,464 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:05,465 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:05,466 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:05,467 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:05,468 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:05,469 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:05,469 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,471 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:05,472 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:05,474 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 14]), 13)\n",
      "2023-10-04 09:30:05,475 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:05,476 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 14]), 13)\n",
      "2023-10-04 09:30:05,477 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:05,477 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:05,479 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:05,480 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:05,481 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:05,482 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:05,483 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:05,485 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,486 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:05,493 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:05,502 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,503 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,504 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,505 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,506 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:05,513 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:05,519 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:05,524 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:05,529 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,531 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,532 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,535 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:05,543 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:05,552 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,553 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,554 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,556 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,557 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:05,565 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:05,571 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:05,580 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:05,584 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,586 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,586 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,589 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:05,602 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:05,615 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,617 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,618 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,619 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,620 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:05,628 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:05,636 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:05,642 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:05,654 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,656 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,657 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,660 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:05,670 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:05,680 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,681 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,683 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,684 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,685 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:05,695 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:05,704 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:05,709 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:05,713 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,715 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,716 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,718 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:05,726 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:05,734 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,735 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,736 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,737 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,737 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:05,745 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:05,754 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:05,759 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:05,763 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,764 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,765 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,769 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:05,777 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:05,786 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,787 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,788 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,788 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,790 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:05,796 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:05,803 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:05,807 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:05,812 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,814 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,815 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,817 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:05,825 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:05,833 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,835 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,836 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,837 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,837 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:05,847 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:05,854 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:05,858 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:05,863 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,864 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,866 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,869 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:05,883 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:05,892 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,893 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,895 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,895 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,897 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:05,904 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:05,910 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:05,914 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:05,918 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,920 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,922 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,924 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:05,933 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:05,943 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,944 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,945 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,946 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,948 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:05,954 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:05,959 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:05,963 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:05,967 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,968 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:30:05,969 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:05,971 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:05,979 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:05,988 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:05,989 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,990 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:05,992 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:05,993 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:06,001 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:06,005 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:06,009 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:06,012 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:30:06,014 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:30:06,015 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,017 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:06,025 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:06,033 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,034 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,035 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,036 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,037 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:06,043 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:06,047 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:06,051 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:06,055 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:30:06,057 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:30:06,058 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,060 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:06,069 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:06,070 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,071 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 13, 64]), torch.Size([8, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,072 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,073 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 14]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 13, 64]), torch.Size([2, 12, 13, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,074 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:06,080 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:06,085 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:06,088 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:06,094 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])))\n",
      "2023-10-04 09:30:06,095 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])))\n",
      "2023-10-04 09:30:06,096 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,099 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:06,101 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:06,109 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,110 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:06,110 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,111 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:06,112 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:06,113 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:06,117 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:06,119 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:06,122 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:06,125 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:06,125 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,127 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:06,128 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:06,130 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,131 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:06,131 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,133 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:06,133 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:06,149 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:06,160 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:06,171 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:06,183 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:06,185 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:06,187 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,194 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:06,197 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:06,199 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:06,200 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:06,201 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:06,202 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:06,203 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:06,205 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:06,206 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:06,207 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:06,208 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:06,210 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:06,210 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,212 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:06,214 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:06,216 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 15]), 14)\n",
      "2023-10-04 09:30:06,217 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:06,218 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 15]), 14)\n",
      "2023-10-04 09:30:06,218 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:06,220 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:06,221 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:06,222 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:06,224 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:06,225 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:06,226 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:06,226 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,228 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:06,236 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:06,244 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,245 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,246 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,247 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,248 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:06,253 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:06,259 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:06,266 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:06,272 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,274 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,275 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,278 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:06,286 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:06,295 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,296 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,296 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,298 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,299 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:06,305 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:06,313 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:06,318 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:06,323 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,325 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,326 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,329 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:06,340 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:06,349 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,350 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,350 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,352 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,352 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:06,357 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:06,361 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:06,371 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:06,376 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,378 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,379 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,382 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:06,393 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:06,401 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,402 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,403 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,404 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,406 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:06,412 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:06,422 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:06,428 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:06,435 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,437 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,438 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,440 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:06,448 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:06,456 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,457 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,458 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,459 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,460 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:06,471 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:06,476 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:06,480 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:06,486 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,488 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,489 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,492 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:06,500 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:06,510 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,512 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,512 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,513 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,514 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:06,521 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:06,528 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:06,532 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:06,538 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,540 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,541 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,544 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:06,552 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:06,561 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,563 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,564 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,564 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,565 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:06,571 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:06,578 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:06,582 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:06,587 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,589 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,590 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,592 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:06,600 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:06,609 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,611 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,612 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,612 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,613 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:06,630 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:06,637 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:06,648 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:06,660 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,663 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,664 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,667 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:06,674 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:06,683 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,684 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,686 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,686 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,688 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:06,693 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:06,697 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:06,701 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:06,705 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,707 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,708 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,712 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:06,722 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:06,731 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,733 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,734 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,735 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,737 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:06,745 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:06,750 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:06,759 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:06,765 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,767 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,768 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,771 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:06,780 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:06,792 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,793 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,795 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,797 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,799 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:06,812 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:06,821 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:06,828 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:06,833 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,834 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,835 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,837 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:06,845 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:06,847 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,847 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 14, 64]), torch.Size([8, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,848 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,849 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 15]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 14, 64]), torch.Size([2, 12, 14, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:06,850 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:06,857 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:06,862 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:06,866 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:06,871 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,872 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])))\n",
      "2023-10-04 09:30:06,874 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,877 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:06,879 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:06,886 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,887 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:06,888 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,888 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:06,890 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:06,895 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:06,898 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:06,901 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:06,902 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:06,902 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:06,904 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,906 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:06,908 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:06,909 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:06,910 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:06,911 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:06,911 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:06,912 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:06,925 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:06,936 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:06,948 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:06,960 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:06,963 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:06,964 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,972 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:06,974 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:06,977 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:06,978 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:06,979 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:06,980 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:06,980 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:06,982 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:06,983 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:06,984 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:06,985 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:06,986 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:06,987 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:06,988 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:06,990 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:06,992 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 16]), 15)\n",
      "2023-10-04 09:30:06,993 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:06,994 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 16]), 15)\n",
      "2023-10-04 09:30:06,995 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:06,996 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:06,997 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:06,999 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:07,000 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:07,001 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:07,002 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:07,003 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,005 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:07,012 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:07,021 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,022 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,023 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,025 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,026 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:07,031 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:07,039 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:07,046 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:07,050 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,053 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,054 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,057 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:07,065 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:07,073 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,074 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,075 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,076 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,077 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:07,140 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:07,147 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:07,154 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:07,159 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,160 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,161 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,164 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:07,172 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:07,181 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,182 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,183 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,184 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,185 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:07,191 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:07,195 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:07,199 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:07,202 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,205 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,206 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,209 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:07,217 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:07,227 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,228 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,229 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,230 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,231 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:07,239 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:07,247 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:07,253 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:07,257 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,258 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,259 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,262 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:07,271 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:07,280 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,281 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,281 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,283 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,284 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:07,290 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:07,297 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:07,300 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:07,304 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,305 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,306 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,309 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:07,316 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:07,324 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,325 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,326 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,327 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,328 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:07,333 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:07,337 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:07,340 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:07,344 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,345 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,347 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,349 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:07,357 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:07,365 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,366 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,367 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,368 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,369 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:07,375 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:07,379 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:07,382 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:07,386 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,387 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,388 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,391 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:07,399 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:07,407 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,408 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,408 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,409 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,410 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:07,415 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:07,419 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:07,423 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:07,427 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,428 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,429 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,431 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:07,439 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:07,447 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,448 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,449 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,450 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,451 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:07,455 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:07,462 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:07,465 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:07,469 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,470 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,471 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,473 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:07,481 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:07,489 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,490 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,491 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,492 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,493 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:07,498 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:07,504 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:07,508 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:07,511 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,513 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,513 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,516 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:07,524 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:07,533 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,534 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,535 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,536 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,537 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:07,543 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:07,547 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:07,553 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:07,557 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,559 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,560 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,563 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:07,571 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:07,573 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,573 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 15, 64]), torch.Size([8, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,574 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,575 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 16]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 15, 64]), torch.Size([2, 12, 15, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,576 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:07,582 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:07,586 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:07,589 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:07,594 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,595 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])))\n",
      "2023-10-04 09:30:07,596 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,598 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:07,600 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:07,609 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,609 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:07,611 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,612 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:07,612 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:07,616 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:07,619 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:07,621 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:07,625 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:07,627 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:07,628 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,630 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:07,632 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:07,634 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,634 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:07,635 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,636 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:07,637 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:07,649 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:07,659 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:07,669 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:07,678 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:07,682 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:07,683 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,691 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:07,693 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:07,694 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:07,695 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:07,696 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:07,697 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:07,698 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:07,699 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:07,701 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:07,702 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:07,704 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:07,705 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:07,707 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,710 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:07,712 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:07,714 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 17]), 16)\n",
      "2023-10-04 09:30:07,715 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:07,717 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 17]), 16)\n",
      "2023-10-04 09:30:07,718 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:07,718 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:07,720 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:07,721 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:07,722 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:07,724 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:07,725 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:07,726 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,728 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:07,735 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:07,744 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,745 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,746 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,747 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,748 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:07,755 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:07,766 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:07,771 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:07,775 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:30:07,777 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:30:07,778 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,782 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:07,795 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:07,809 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,810 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,811 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,812 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,813 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:07,820 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:07,826 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:07,831 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:07,835 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:30:07,836 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:30:07,837 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,841 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:07,849 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:07,857 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,858 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,859 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,860 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,860 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:07,869 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:07,874 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:07,878 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:07,882 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:30:07,884 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:30:07,886 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,890 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:07,898 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:07,906 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,907 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,908 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,909 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,910 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:07,914 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:07,921 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:07,928 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:07,935 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:30:07,937 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:30:07,938 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,943 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:07,952 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:07,961 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:07,962 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,963 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:07,964 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:07,965 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:07,971 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:07,975 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:07,980 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:07,986 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:30:07,989 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:30:07,990 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:07,992 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:08,000 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:08,008 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,009 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,010 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,011 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,013 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:08,019 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:08,026 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:08,032 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:08,036 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,038 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,039 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,041 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:08,049 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:08,058 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,060 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,060 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,062 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,063 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:08,068 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:08,073 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:08,077 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:08,081 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,082 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,084 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,087 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:08,095 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:08,105 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,106 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,107 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,108 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,109 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:08,115 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:08,120 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:08,126 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:08,132 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,135 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,137 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,141 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:08,150 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:08,159 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,160 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,161 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,161 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,162 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:08,167 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:08,176 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:08,182 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:08,187 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,189 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,190 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,193 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:08,201 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:08,209 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,210 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,211 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,212 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,213 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:08,219 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:08,225 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:08,232 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:08,241 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,244 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,245 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,248 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:08,257 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:08,266 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,267 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,268 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,269 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,271 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:08,275 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:08,282 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:08,290 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:08,293 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,295 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,296 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,298 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:08,306 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:08,307 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,308 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 16, 64]), torch.Size([8, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,309 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,310 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 17]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 16, 64]), torch.Size([2, 12, 16, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,311 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:08,317 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:08,321 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:08,326 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:08,331 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,333 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])))\n",
      "2023-10-04 09:30:08,334 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,336 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:08,338 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:08,347 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,347 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:08,348 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,350 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:08,351 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:08,352 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:08,355 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:08,360 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:08,363 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:08,364 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:08,365 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,368 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:08,370 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:08,372 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,372 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:08,374 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,375 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:08,376 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:08,393 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:08,406 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:08,418 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:08,430 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:08,438 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:08,440 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,451 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:08,454 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:08,455 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:08,456 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:08,457 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:08,458 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:08,459 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:08,460 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:08,462 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:08,463 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:08,464 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:08,466 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:08,467 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,470 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:08,472 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:08,474 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 18]), 17)\n",
      "2023-10-04 09:30:08,475 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:08,476 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 18]), 17)\n",
      "2023-10-04 09:30:08,477 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:08,478 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:08,481 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:08,482 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:08,484 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:08,485 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:08,486 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:08,486 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,488 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:08,496 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:08,505 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,506 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,507 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,508 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,509 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:08,543 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:08,548 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:08,556 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:08,562 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,564 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,565 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,567 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:08,575 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:08,584 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,585 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,586 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,587 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,588 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:08,596 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:08,601 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:08,607 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:08,612 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,614 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,615 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,618 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:08,626 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:08,635 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,636 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,637 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,638 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,640 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:08,648 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:08,652 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:08,658 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:08,663 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,665 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,666 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,668 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:08,677 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:08,686 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,687 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,688 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,689 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,690 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:08,698 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:08,703 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:08,709 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:08,717 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,720 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,721 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,723 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:08,731 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:08,739 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,740 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,741 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,742 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,743 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:08,751 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:08,756 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:08,760 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:08,765 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,766 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,768 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,771 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:08,778 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:08,787 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,788 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,789 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,790 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,791 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:08,797 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:08,802 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:08,807 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:08,812 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,814 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,814 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,817 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:08,825 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:08,834 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,835 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,836 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,837 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,838 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:08,844 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:08,850 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:08,855 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:08,860 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,862 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,862 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,865 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:08,874 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:08,883 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,884 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,885 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,886 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,887 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:08,897 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:08,902 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:08,906 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:08,911 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,913 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,914 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,916 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:08,924 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:08,933 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,933 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,934 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,935 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,937 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:08,943 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:08,951 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:08,957 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:08,963 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,966 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:30:08,967 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:08,969 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:08,977 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:08,985 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:08,986 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,987 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:08,987 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:08,988 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:08,997 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:09,004 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:09,010 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:09,017 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:30:09,019 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:30:09,020 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,023 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:09,031 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:09,040 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,041 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,043 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,044 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,045 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:09,052 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:09,059 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:09,069 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:09,077 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:30:09,079 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:30:09,080 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,083 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:09,092 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:09,094 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,095 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 17, 64]), torch.Size([8, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,096 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,097 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 18]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 17, 64]), torch.Size([2, 12, 17, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,098 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:09,105 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:09,112 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:09,117 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:09,122 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])))\n",
      "2023-10-04 09:30:09,124 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])))\n",
      "2023-10-04 09:30:09,125 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,127 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:09,130 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:09,140 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,141 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:09,142 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,143 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:09,144 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:09,146 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:09,150 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:09,153 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:09,157 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:09,158 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:09,162 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,166 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:09,169 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:09,171 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,172 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:09,175 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,176 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:09,178 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:09,195 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:09,208 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:09,220 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:09,231 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:09,234 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:09,235 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,244 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:09,246 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:09,248 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:09,248 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:09,249 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:09,250 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:09,251 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:09,252 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:09,254 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:09,255 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:09,256 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:09,257 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:09,259 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,261 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:09,265 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:09,267 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 19]), 18)\n",
      "2023-10-04 09:30:09,268 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:09,269 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 19]), 18)\n",
      "2023-10-04 09:30:09,271 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:09,272 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:09,274 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:09,277 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:09,279 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:09,281 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:09,282 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:09,283 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,285 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:09,294 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:09,303 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,305 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,306 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,307 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,309 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:09,314 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:09,324 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:09,333 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:09,345 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,348 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,349 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,353 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:09,366 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:09,379 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,381 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,382 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,383 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,384 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:09,391 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:09,399 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:09,405 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:09,410 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,412 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,413 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,415 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:09,423 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:09,432 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,433 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,434 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,435 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,436 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:09,441 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:09,445 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:09,453 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:09,463 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,465 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,466 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,469 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:09,478 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:09,487 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,488 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,489 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,490 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,491 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:09,501 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:09,506 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:09,511 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:09,516 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,518 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,518 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,521 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:09,529 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:09,537 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,538 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,539 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,540 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,540 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:09,549 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:09,556 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:09,566 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:09,571 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,572 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,573 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,576 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:09,584 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:09,591 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,592 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,594 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,595 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,596 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:09,604 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:09,617 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:09,624 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:09,645 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,648 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,649 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,653 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:09,666 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:09,680 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,681 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,682 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,684 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,685 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:09,693 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:09,700 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:09,704 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:09,707 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,709 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,710 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,712 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:09,720 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:09,729 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,730 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,731 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,731 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,732 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:09,752 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:09,763 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:09,774 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:09,780 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,784 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,785 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,788 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:09,796 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:09,806 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,807 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,808 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,809 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,810 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:09,816 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:09,820 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:09,826 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:09,833 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,835 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,836 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,839 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:09,847 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:09,856 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,857 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,858 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,859 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,860 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:09,864 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:09,867 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:09,872 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:09,876 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,877 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,878 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,880 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:09,889 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:09,898 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,899 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,899 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,900 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,902 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:09,906 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:09,910 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:09,914 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:09,918 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,920 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,921 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,924 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:09,932 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:09,934 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,934 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 18, 64]), torch.Size([8, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,936 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,936 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 19]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 18, 64]), torch.Size([2, 12, 18, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:09,937 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:09,941 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:09,945 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:09,948 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:09,958 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,960 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])))\n",
      "2023-10-04 09:30:09,960 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,963 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:09,965 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:09,975 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,977 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:09,979 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,980 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:09,981 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:09,984 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:09,987 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:09,989 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:09,990 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:09,991 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:09,992 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:09,993 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:09,995 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:09,997 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:09,997 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:09,998 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:09,999 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:09,999 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:10,017 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:10,027 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:10,038 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:10,047 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:10,050 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:10,051 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,062 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:10,064 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:10,066 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:10,066 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:10,067 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:10,068 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:10,069 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:10,070 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:10,071 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:10,072 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:10,073 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:10,074 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:10,076 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,077 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:10,079 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:10,081 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 20]), 19)\n",
      "2023-10-04 09:30:10,082 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:10,082 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 20]), 19)\n",
      "2023-10-04 09:30:10,083 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:10,084 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:10,086 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:10,088 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:10,089 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:10,090 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:10,091 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:10,092 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,093 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:10,101 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:10,110 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,111 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,112 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,113 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,115 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:10,123 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:10,129 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:10,132 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:10,137 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,139 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,140 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,143 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:10,151 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:10,159 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,160 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,161 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,161 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,162 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:10,167 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:10,175 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:10,199 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:10,206 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,208 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,209 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,212 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:10,220 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:10,228 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,229 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,230 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,231 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,232 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:10,238 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:10,245 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:10,250 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:10,256 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,258 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,259 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,262 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:10,271 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:10,280 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,281 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,282 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,283 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,284 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:10,291 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:10,297 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:10,301 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:10,305 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,307 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,308 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,310 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:10,319 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:10,327 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,328 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,329 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,330 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,330 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:10,337 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:10,341 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:10,352 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:10,357 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,359 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,360 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,363 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:10,371 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:10,379 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,380 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,381 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,382 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,383 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:10,396 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:10,401 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:10,404 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:10,408 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,409 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,410 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,413 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:10,421 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:10,430 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,431 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,432 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,433 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,434 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:10,438 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:10,447 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:10,452 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:10,456 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,457 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,458 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,461 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:10,469 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:10,477 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,478 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,479 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,480 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,481 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:10,488 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:10,494 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:10,500 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:10,507 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,509 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,510 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,514 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:10,525 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:10,538 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,539 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,540 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,541 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,541 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:10,548 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:10,560 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:10,565 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:10,570 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,572 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,573 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,576 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:10,585 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:10,593 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,595 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,596 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,597 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,597 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:10,604 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:10,608 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:10,612 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:10,615 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,617 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,618 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,621 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:10,629 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:10,637 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,638 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,639 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,640 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,641 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:10,647 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:10,652 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:10,655 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:10,660 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,663 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,664 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,666 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:10,674 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:10,676 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,677 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 19, 64]), torch.Size([8, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,678 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,678 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 20]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 19, 64]), torch.Size([2, 12, 19, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,679 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:10,689 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:10,694 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:10,699 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:10,704 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,706 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])))\n",
      "2023-10-04 09:30:10,706 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,709 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:10,711 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:10,719 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,720 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:10,721 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,722 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:10,723 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:10,726 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:10,727 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:10,728 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:10,730 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:10,731 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:10,732 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,733 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:10,735 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:10,737 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,738 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:10,739 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,740 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:10,741 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:10,752 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:10,763 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:10,772 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:10,785 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:10,792 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:10,794 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,802 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:10,804 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:10,806 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:10,807 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:10,808 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:10,809 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:10,810 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:10,811 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:10,812 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:10,813 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:10,814 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:10,815 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:10,816 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,818 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:10,820 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:10,822 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 21]), 20)\n",
      "2023-10-04 09:30:10,823 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:10,824 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 21]), 20)\n",
      "2023-10-04 09:30:10,825 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:10,825 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:10,827 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:10,828 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:10,829 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:10,831 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:10,832 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:10,832 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,834 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:10,842 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:10,850 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,851 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,852 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,853 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,854 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:10,861 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:10,864 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:10,873 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:10,883 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:30:10,885 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:30:10,886 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,889 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:10,897 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:10,905 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,906 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,907 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,908 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,909 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:10,918 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:10,924 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:10,946 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:10,951 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:30:10,952 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:30:10,953 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:10,956 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:10,964 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:10,972 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:10,973 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,975 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:10,976 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:10,977 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:10,986 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:10,993 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:10,997 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:11,000 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,002 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,003 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,006 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:11,015 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:11,025 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,026 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,027 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,028 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,029 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:11,034 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:11,039 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:11,044 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:11,049 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,050 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,051 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,054 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:11,062 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:11,070 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,071 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,072 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,073 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,074 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:11,081 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:11,085 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:11,089 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:11,093 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,095 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,096 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,099 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:11,108 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:11,116 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,117 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,118 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,119 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,119 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:11,125 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:11,129 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:11,133 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:11,137 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,138 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,139 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,141 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:11,149 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:11,158 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,159 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,160 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,161 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,163 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:11,168 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:11,171 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:11,181 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:11,186 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,187 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,188 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,191 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:11,200 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:11,208 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,210 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,210 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,211 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,212 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:11,217 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:11,220 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:11,232 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:11,240 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,242 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,243 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,246 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:11,254 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:11,262 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,264 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,264 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,265 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,266 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:11,274 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:11,279 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:11,283 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:11,287 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,289 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,290 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,293 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:11,301 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:11,309 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,310 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,311 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,312 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,313 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:11,319 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:11,332 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:11,338 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:11,342 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,344 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,345 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,347 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:11,356 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:11,365 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,366 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,367 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,368 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,369 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:11,374 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:11,381 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:11,386 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:11,391 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,392 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,393 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,396 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:11,405 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:11,407 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,415 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 20, 64]), torch.Size([8, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,419 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,420 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 21]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 20, 64]), torch.Size([2, 12, 20, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,421 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:11,474 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:11,488 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:11,494 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:11,498 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,500 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])))\n",
      "2023-10-04 09:30:11,501 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,504 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:11,506 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:11,515 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,516 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:11,517 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,518 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:11,519 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:11,522 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:11,523 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:11,524 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:11,525 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:11,526 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:11,528 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,530 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:11,532 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:11,534 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,534 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:11,535 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,537 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:11,538 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:11,550 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:11,561 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:11,574 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:11,587 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:11,589 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:11,590 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,598 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:11,600 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:11,602 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:11,603 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:11,603 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:11,605 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:11,606 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:11,607 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:11,608 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:11,609 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:11,610 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:11,611 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:11,612 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,613 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:11,615 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:11,617 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 22]), 21)\n",
      "2023-10-04 09:30:11,618 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:11,619 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 22]), 21)\n",
      "2023-10-04 09:30:11,620 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:11,621 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:11,622 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:11,624 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:11,625 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:11,626 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:11,627 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:11,628 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,629 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:11,637 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:11,645 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,646 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,647 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,648 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,648 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:11,655 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:11,659 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:11,662 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:11,665 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,667 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,668 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,671 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:11,679 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:11,687 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,688 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,690 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,691 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,692 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:11,699 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:11,704 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:11,707 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:11,710 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,712 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,713 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,715 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:11,724 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:11,733 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,734 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,735 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,736 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,737 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:11,742 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:11,747 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:11,756 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:11,759 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,788 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,790 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,795 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:11,802 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:11,811 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,812 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,813 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,814 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,815 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:11,823 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:11,830 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:11,835 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:11,840 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,842 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,844 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,847 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:11,855 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:11,863 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,864 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,865 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,865 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,866 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:11,875 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:11,881 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:11,887 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:11,893 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,897 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,898 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,901 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:11,909 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:11,917 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,918 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,919 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,920 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,921 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:11,927 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:11,935 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:11,939 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:11,944 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,946 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,947 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,950 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:11,957 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:11,966 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:11,966 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,967 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:11,969 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:11,970 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:11,978 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:11,983 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:11,988 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:11,992 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,994 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:30:11,996 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:11,998 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:12,009 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:12,022 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,023 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,025 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,026 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,026 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:12,033 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:12,040 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:12,044 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:12,048 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:30:12,050 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:30:12,051 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,054 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:12,061 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:12,070 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,071 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,072 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,073 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,074 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:12,081 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:12,089 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:12,094 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:12,100 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:30:12,102 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:30:12,103 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,107 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:12,116 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:12,125 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,126 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,128 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,129 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,129 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:12,137 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:12,141 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:12,146 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:12,151 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:30:12,153 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:30:12,154 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,156 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:12,165 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:12,174 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,175 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,176 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,177 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,178 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:12,185 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:12,190 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:12,195 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:12,201 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:30:12,210 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:30:12,212 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,216 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:12,228 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:12,231 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,232 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 21, 64]), torch.Size([8, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,233 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,234 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 22]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 21, 64]), torch.Size([2, 12, 21, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,235 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:12,241 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:12,249 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:12,258 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:12,265 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])))\n",
      "2023-10-04 09:30:12,269 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])))\n",
      "2023-10-04 09:30:12,270 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,273 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:12,275 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:12,284 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,285 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:12,286 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,287 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:12,288 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:12,289 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:12,293 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:12,296 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:12,299 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:12,300 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:12,301 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,303 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:12,305 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:12,307 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,309 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:12,311 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,312 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:12,313 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:12,326 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:12,339 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:12,352 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:12,371 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:12,374 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:12,375 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,387 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:12,390 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:12,391 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:12,392 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:12,393 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:12,394 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:12,395 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:12,397 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:12,398 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:12,400 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:12,401 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:12,402 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:12,403 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,405 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:12,407 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:12,410 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 23]), 22)\n",
      "2023-10-04 09:30:12,411 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:12,412 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 23]), 22)\n",
      "2023-10-04 09:30:12,413 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:12,414 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:12,417 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:12,418 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:12,420 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:12,421 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:12,423 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:12,424 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,426 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:12,438 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:12,452 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,453 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,455 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,456 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,457 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:12,465 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:12,473 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:12,481 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:12,487 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,490 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,492 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,494 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:12,502 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:12,511 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,512 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,513 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,515 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,516 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:12,523 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:12,529 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:12,535 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:12,542 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,545 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,546 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,550 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:12,559 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:12,567 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,568 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,569 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,570 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,571 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:12,578 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:12,583 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:12,588 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:12,593 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,595 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,596 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,599 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:12,607 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:12,616 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,617 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,618 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,619 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,620 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:12,625 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:12,633 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:12,639 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:12,645 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,648 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,649 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,651 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:12,659 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:12,668 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,669 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,670 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,671 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,672 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:12,679 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:12,685 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:12,690 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:12,695 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,698 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,698 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,701 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:12,709 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:12,716 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,717 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,718 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,719 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,721 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:12,727 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:12,734 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:12,739 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:12,745 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,748 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,749 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,751 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:12,760 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:12,768 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,769 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,770 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,770 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,772 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:12,779 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:12,786 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:12,793 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:12,800 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,804 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,805 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,809 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:12,822 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:12,835 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,837 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,838 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,839 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,840 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:12,848 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:12,855 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:12,861 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:12,867 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,870 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,871 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,874 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:12,886 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:12,895 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,896 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,896 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,897 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,898 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:12,905 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:12,911 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:12,917 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:12,922 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,925 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,926 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,929 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:12,938 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:12,946 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:12,947 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,948 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:12,949 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:12,950 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:12,957 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:12,963 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:12,972 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:12,980 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,988 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:30:12,990 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:12,992 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:13,005 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:13,014 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:13,015 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,016 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:13,017 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,018 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:13,025 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:13,030 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:13,046 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:13,057 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:30:13,060 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:30:13,061 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:13,064 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:13,073 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:13,075 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:13,076 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 22, 64]), torch.Size([8, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,077 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:13,078 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 23]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 22, 64]), torch.Size([2, 12, 22, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,079 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:13,084 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:13,089 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:13,096 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:13,101 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])))\n",
      "2023-10-04 09:30:13,103 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])))\n",
      "2023-10-04 09:30:13,105 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:13,107 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:13,110 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:13,118 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:13,119 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:13,120 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:13,121 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:13,123 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:13,125 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:13,127 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:13,128 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:13,129 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:13,130 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:13,131 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:13,133 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:13,134 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:13,136 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:13,137 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:13,137 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:13,138 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:13,139 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:13,157 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:13,170 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:13,186 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:13,202 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:13,205 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:13,207 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:13,225 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:13,227 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:13,229 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:13,230 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:13,231 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:13,231 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:13,232 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:13,234 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:13,235 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:13,236 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:13,237 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:13,239 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:13,239 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:13,241 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:13,243 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:13,245 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 24]), 23)\n",
      "2023-10-04 09:30:13,245 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:13,246 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 24]), 23)\n",
      "2023-10-04 09:30:13,247 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:13,248 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:13,249 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:13,251 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:13,252 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:13,253 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:13,254 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:13,254 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:13,256 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:13,265 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:13,274 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:13,275 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,276 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:13,277 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,278 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:13,284 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:13,290 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:13,295 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:13,380 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,409 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,411 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:13,414 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:13,421 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:13,429 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:13,431 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,432 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:13,433 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,434 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:13,460 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:13,465 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:13,472 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:13,479 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,483 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,484 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:13,487 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:13,496 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:13,505 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:13,506 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,507 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:13,508 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,509 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:13,514 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:13,528 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:13,533 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:13,545 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,549 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,550 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:13,552 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:13,561 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:13,569 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:13,571 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,572 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:13,573 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,574 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:13,628 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:13,633 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:13,663 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:13,676 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,690 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,692 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:13,695 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:13,703 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:13,713 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:13,714 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,715 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:13,716 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,717 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:13,734 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:13,754 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:13,765 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:13,775 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,779 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,780 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:13,783 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:13,791 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:13,800 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:13,802 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,803 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:13,803 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,804 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:13,810 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:13,817 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:13,826 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:13,835 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,848 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,849 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:13,852 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:13,860 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:13,869 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:13,870 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,871 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:13,872 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,873 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:13,878 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:13,881 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:13,946 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:13,969 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,973 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:30:13,974 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:13,977 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:13,985 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:13,993 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:13,995 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,996 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:13,997 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:13,998 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:14,006 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:14,014 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:14,022 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:14,028 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:30:14,030 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:30:14,031 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:14,034 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:14,043 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:14,052 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:14,054 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,054 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:14,055 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,057 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:14,063 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:14,069 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:14,074 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:14,079 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:30:14,081 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:30:14,082 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:14,085 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:14,093 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:14,102 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:14,103 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,104 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:14,106 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,108 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:14,115 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:14,122 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:14,130 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:14,136 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:30:14,139 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:30:14,140 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:14,142 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:14,151 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:14,161 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:14,163 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,163 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:14,164 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,165 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:14,184 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:14,229 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:14,277 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:14,285 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:30:14,302 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:30:14,304 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:14,307 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:14,315 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:14,318 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:14,319 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 23, 64]), torch.Size([8, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,320 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:14,321 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 24]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 23, 64]), torch.Size([2, 12, 23, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,323 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:14,337 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:14,345 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:14,371 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:14,379 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])))\n",
      "2023-10-04 09:30:14,384 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])))\n",
      "2023-10-04 09:30:14,386 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:14,389 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:14,391 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:14,399 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:14,400 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:14,401 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:14,402 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:14,403 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:14,406 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:14,412 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:14,415 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:14,419 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:14,421 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:14,422 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:14,424 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:14,425 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:14,427 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:14,427 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:14,428 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:14,429 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:14,430 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:14,447 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:14,461 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:14,474 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:14,489 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:14,494 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:14,496 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:14,505 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:14,507 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:14,508 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:14,509 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:14,510 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:14,511 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:14,512 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:14,514 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:14,515 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:14,517 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:14,518 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:14,519 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:14,520 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:14,522 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:14,525 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:14,528 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 25]), 24)\n",
      "2023-10-04 09:30:14,529 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:14,530 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 25]), 24)\n",
      "2023-10-04 09:30:14,530 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:14,532 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:14,534 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:14,536 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:14,537 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:14,539 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:14,540 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:14,541 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:14,543 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:14,554 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:14,564 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:14,565 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,566 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:14,568 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,569 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:14,580 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:14,589 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:14,608 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:14,616 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:30:14,656 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:30:14,658 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:14,662 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:14,673 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:14,685 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:14,687 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,689 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:14,691 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,692 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:14,734 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:14,770 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:14,785 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:14,794 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:30:14,849 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:30:14,851 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:14,854 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:14,862 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:14,873 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:14,875 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,876 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:14,877 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:14,878 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:14,906 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:14,952 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:14,976 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:14,984 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:30:14,987 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:30:14,989 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:14,993 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:15,002 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:15,011 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:15,013 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,014 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:15,015 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,016 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:15,021 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:15,037 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:15,073 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:15,122 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,134 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,136 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:15,139 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:15,147 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:15,156 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:15,158 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,159 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:15,160 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,161 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:15,167 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:15,174 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:15,182 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:15,188 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,192 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,193 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:15,197 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:15,205 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:15,214 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:15,216 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,217 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:15,220 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,222 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:15,273 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:15,284 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:15,312 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:15,321 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,323 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,324 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:15,327 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:15,335 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:15,343 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:15,345 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,346 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:15,347 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,347 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:15,363 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:15,368 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:15,372 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:15,377 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,381 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,382 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:15,385 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:15,394 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:15,404 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:15,405 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,406 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:15,407 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,408 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:15,415 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:15,426 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:15,431 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:15,435 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,437 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,439 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:15,441 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:15,449 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:15,458 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:15,459 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,459 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:15,460 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,461 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:15,467 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:15,471 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:15,478 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:15,503 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,555 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,557 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:15,560 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:15,569 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:15,578 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:15,579 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,581 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:15,582 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,583 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:15,588 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:15,595 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:15,628 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:15,648 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,650 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,651 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:15,654 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:15,662 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:15,672 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:15,673 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,675 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:15,676 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,678 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:15,688 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:15,693 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:15,699 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:15,704 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,707 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,708 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:15,711 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:15,720 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:15,721 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:15,722 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 24, 64]), torch.Size([8, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,723 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:15,724 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 25]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 24, 64]), torch.Size([2, 12, 24, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,725 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:15,730 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:15,735 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:15,744 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:15,749 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,751 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])))\n",
      "2023-10-04 09:30:15,753 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:15,757 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:15,760 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:15,770 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:15,771 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:15,772 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:15,773 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:15,774 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:15,779 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:15,780 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:15,786 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:15,790 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:15,792 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:15,793 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:15,796 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:15,798 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:15,800 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:15,801 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:15,802 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:15,803 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:15,804 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:15,827 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:15,840 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:15,854 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:15,866 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:15,869 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:15,870 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:15,881 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:15,884 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:15,886 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:15,887 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:15,888 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:15,889 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:15,890 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:15,891 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:15,892 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:15,893 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:15,894 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:15,895 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:15,896 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:15,898 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:15,899 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:15,901 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 26]), 25)\n",
      "2023-10-04 09:30:15,902 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:15,903 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 26]), 25)\n",
      "2023-10-04 09:30:15,904 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:15,905 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:15,906 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:15,908 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:15,909 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:15,910 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:15,911 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:15,912 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:15,914 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:15,923 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:15,932 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:15,933 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,934 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:15,935 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:15,936 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:16,020 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:16,039 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:16,049 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:16,054 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,057 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,058 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,061 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:16,069 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:16,078 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,079 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,080 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,081 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,082 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:16,100 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:16,113 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:16,118 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:16,125 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,128 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,129 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,132 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:16,140 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:16,148 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,149 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,150 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,151 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,152 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:16,159 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:16,165 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:16,192 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:16,198 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,203 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,205 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,207 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:16,215 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:16,223 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,224 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,225 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,227 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,228 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:16,234 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:16,239 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:16,244 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:16,250 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,253 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,254 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,256 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:16,264 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:16,273 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,274 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,275 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,276 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,277 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:16,286 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:16,293 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:16,297 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:16,302 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,305 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,306 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,309 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:16,317 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:16,326 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,328 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,329 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,330 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,332 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:16,347 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:16,354 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:16,358 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:16,388 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,403 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,404 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,406 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:16,414 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:16,422 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,424 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,424 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,425 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,427 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:16,492 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:16,501 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:16,506 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:16,535 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,538 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,539 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,542 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:16,551 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:16,559 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,561 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,561 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,563 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,564 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:16,573 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:16,579 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:16,584 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:16,589 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,591 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,592 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,595 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:16,602 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:16,611 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,612 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,613 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,614 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,615 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:16,621 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:16,627 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:16,632 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:16,637 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,639 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,640 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,644 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:16,652 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:16,661 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,662 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,663 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,664 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,667 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:16,675 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:16,685 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:16,691 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:16,716 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,720 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,721 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,724 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:16,732 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:16,740 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,742 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,743 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,743 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,744 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:16,756 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:16,762 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:16,766 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:16,771 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,774 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,775 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,778 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:16,786 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:16,788 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,789 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 25, 64]), torch.Size([8, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,790 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,791 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 26]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 25, 64]), torch.Size([2, 12, 25, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,791 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:16,797 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:16,802 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:16,806 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:16,810 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,812 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])))\n",
      "2023-10-04 09:30:16,813 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,816 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:16,818 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:16,826 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,826 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:16,828 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,829 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:16,829 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:16,831 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:16,834 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:16,838 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:16,841 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:16,843 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:16,844 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,845 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:16,847 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:16,848 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,849 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:16,850 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,851 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:16,852 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:16,867 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:16,882 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:16,894 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:16,908 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:16,915 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:16,917 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,926 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:16,928 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:16,930 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:16,931 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:16,932 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:16,933 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:16,934 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:16,935 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:16,936 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:16,937 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:16,938 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:16,939 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:16,940 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,942 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:16,943 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:16,946 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 27]), 26)\n",
      "2023-10-04 09:30:16,947 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:16,948 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 27]), 26)\n",
      "2023-10-04 09:30:16,949 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:16,950 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:16,951 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:16,952 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:16,953 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:16,954 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:16,955 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:16,956 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:16,958 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:16,966 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:16,974 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:16,975 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,976 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:16,977 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:16,978 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:16,985 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:16,993 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:17,004 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:17,010 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,012 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,013 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:17,016 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:17,024 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:17,033 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:17,034 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,034 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:17,035 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,037 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:17,050 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:17,060 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:17,064 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:17,069 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,071 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,072 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:17,074 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:17,082 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:17,091 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:17,092 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,093 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:17,094 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,103 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:17,109 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:17,115 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:17,129 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:17,146 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,152 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,154 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:17,157 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:17,166 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:17,176 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:17,177 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,179 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:17,180 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,181 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:17,262 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:17,313 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:17,351 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:17,356 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,358 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,359 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:17,362 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:17,371 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:17,380 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:17,381 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,382 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:17,383 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,384 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:17,389 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:17,400 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:17,414 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:17,420 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,424 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,425 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:17,428 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:17,436 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:17,445 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:17,446 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,447 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:17,448 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,449 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:17,484 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:17,510 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:17,516 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:17,521 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,525 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,526 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:17,528 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:17,536 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:17,546 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:17,547 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,549 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:17,550 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,551 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:17,557 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:17,562 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:17,576 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:17,607 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,615 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,617 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:17,620 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:17,629 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:17,638 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:17,639 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,640 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:17,642 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,643 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:17,649 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:17,657 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:17,662 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:17,668 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,670 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,671 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:17,674 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:17,682 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:17,691 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:17,692 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,693 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:17,694 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,695 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:17,703 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:17,708 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:17,711 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:17,716 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,718 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,718 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:17,721 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:17,729 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:17,738 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:17,739 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,740 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:17,740 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,741 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:17,749 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:17,766 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:17,777 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:17,807 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,810 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,811 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:17,814 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:17,824 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:17,835 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:17,836 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,837 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:17,838 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,839 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:17,845 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:17,849 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:17,929 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:17,949 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,958 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,959 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:17,963 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:17,970 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:17,972 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:17,973 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 26, 64]), torch.Size([8, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,973 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:17,974 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 27]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 26, 64]), torch.Size([2, 12, 26, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:17,976 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:17,981 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:17,985 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:17,988 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:17,991 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,993 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])))\n",
      "2023-10-04 09:30:17,994 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:17,996 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:17,998 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:18,006 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,007 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:18,008 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,009 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:18,010 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:18,014 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:18,017 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:18,019 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:18,020 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:18,021 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:18,022 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,024 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:18,025 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:18,027 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,028 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:18,029 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,030 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:18,030 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:18,043 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:18,054 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:18,065 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:18,080 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:18,089 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:18,092 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,104 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:18,107 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:18,109 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:18,110 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:18,110 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:18,111 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:18,112 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:18,113 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:18,114 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:18,115 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:18,116 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:18,117 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:18,117 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,119 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:18,120 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:18,122 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 28]), 27)\n",
      "2023-10-04 09:30:18,123 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:18,124 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 28]), 27)\n",
      "2023-10-04 09:30:18,125 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:18,126 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:18,127 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:18,128 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:18,130 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:18,131 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:18,132 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:18,132 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,134 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:18,141 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:18,150 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,151 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,152 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,153 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,154 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:18,164 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:18,171 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:18,176 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:18,182 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,185 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,186 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,189 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:18,197 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:18,206 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,207 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,208 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,208 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,209 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:18,218 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:18,222 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:18,225 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:18,229 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,230 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,231 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,234 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:18,242 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:18,250 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,251 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,252 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,253 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,254 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:18,261 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:18,288 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:18,293 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:18,297 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,299 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,300 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,303 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:18,311 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:18,320 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,321 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,322 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,323 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,324 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:18,329 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:18,337 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:18,342 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:18,346 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,348 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,349 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,353 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:18,361 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:18,369 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,371 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,371 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,372 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,373 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:18,408 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:18,432 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:18,437 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:18,441 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,443 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,444 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,446 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:18,454 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:18,463 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,465 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,466 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,467 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,468 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:18,473 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:18,477 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:18,480 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:18,483 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,485 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,486 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,488 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:18,496 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:18,504 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,506 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,507 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,508 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,509 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:18,543 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:18,549 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:18,553 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:18,556 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,577 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,578 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,581 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:18,592 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:18,601 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,602 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,603 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,604 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,605 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:18,654 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:18,664 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:18,669 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:18,672 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,674 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,676 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,678 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:18,687 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:18,696 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,697 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,698 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,699 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,700 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:18,706 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:18,710 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:18,713 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:18,717 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,718 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,719 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,722 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:18,731 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:18,739 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,740 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,741 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,742 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,743 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:18,751 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:18,756 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:18,788 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:18,822 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,846 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,847 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,850 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:18,858 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:18,866 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,867 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,868 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,869 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,870 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:18,877 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:18,882 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:18,886 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:18,890 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,892 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,894 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,896 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:18,904 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:18,906 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,907 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 27, 64]), torch.Size([8, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,908 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,909 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 28]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 27, 64]), torch.Size([2, 12, 27, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:18,909 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:18,914 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:18,918 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:18,922 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:18,927 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,929 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])))\n",
      "2023-10-04 09:30:18,930 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,933 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:18,935 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:18,943 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,944 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:18,945 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,946 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:18,946 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:18,949 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:18,950 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:18,951 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:18,953 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:18,954 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:18,955 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:18,956 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:18,958 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:18,959 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:18,960 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:18,961 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:18,962 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:18,963 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:18,981 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:18,996 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:19,012 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:19,024 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:19,035 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:19,037 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,115 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:19,118 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:19,121 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:19,123 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:19,124 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:19,125 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:19,126 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:19,128 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:19,129 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:19,130 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:19,131 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:19,132 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:19,133 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,135 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:19,136 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:19,138 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 29]), 28)\n",
      "2023-10-04 09:30:19,139 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:19,140 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 29]), 28)\n",
      "2023-10-04 09:30:19,141 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:19,141 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:19,143 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:19,144 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:19,145 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:19,146 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:19,147 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:19,148 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,149 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:19,163 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:19,171 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:19,173 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,174 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:19,175 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,176 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:19,196 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:19,220 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:19,226 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:19,231 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,233 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,235 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,238 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:19,246 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:19,255 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:19,255 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,257 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:19,257 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,258 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:19,329 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:19,358 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:19,365 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:19,370 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,376 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,377 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,380 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:19,388 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:19,397 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:19,398 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,399 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:19,400 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,401 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:19,407 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:19,410 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:19,413 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:19,429 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,431 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,432 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,435 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:19,443 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:19,451 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:19,452 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,453 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:19,454 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,454 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:19,464 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:19,469 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:19,472 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:19,476 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,481 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,482 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,485 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:19,494 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:19,503 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:19,505 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,505 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:19,506 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,507 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:19,515 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:19,519 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:19,523 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:19,527 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,539 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,541 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,543 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:19,552 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:19,561 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:19,562 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,563 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:19,564 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,564 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:19,570 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:19,576 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:19,585 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:19,588 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,598 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,599 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,602 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:19,610 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:19,618 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:19,619 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,620 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:19,621 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,622 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:19,630 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:19,634 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:19,641 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:19,651 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,657 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,658 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,661 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:19,669 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:19,678 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:19,680 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,681 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:19,682 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,683 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:19,692 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:19,705 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:19,710 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:19,713 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,715 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,716 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,719 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:19,726 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:19,734 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:19,735 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,736 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:19,737 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,738 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:19,743 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:19,747 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:19,757 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:19,831 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,853 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,856 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,860 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:19,870 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:19,879 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:19,880 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,881 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:19,882 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,883 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:19,888 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:19,896 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:19,902 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:19,909 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,911 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,913 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,915 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:19,923 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:19,932 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:19,933 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,934 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:19,935 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,936 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:19,943 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:19,961 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:19,966 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:19,971 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,974 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:30:19,975 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:19,978 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:19,987 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:19,989 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:19,990 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 28, 64]), torch.Size([8, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,991 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:19,992 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 29]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 28, 64]), torch.Size([2, 12, 28, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:19,993 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:20,000 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:20,006 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:20,011 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:20,017 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])))\n",
      "2023-10-04 09:30:20,019 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])))\n",
      "2023-10-04 09:30:20,021 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,023 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:20,025 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:20,034 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,035 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:20,037 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,037 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:20,039 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:20,040 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:20,043 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:20,047 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:20,052 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:20,053 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:20,055 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,056 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:20,058 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:20,059 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,060 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:20,061 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,062 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:20,063 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:20,079 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:20,091 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:20,102 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:20,113 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:20,125 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:20,127 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,136 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:20,138 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:20,139 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:20,140 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:20,141 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:20,142 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:20,143 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:20,144 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:20,145 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:20,146 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:20,147 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:20,148 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:20,149 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,151 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:20,152 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:20,154 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 30]), 29)\n",
      "2023-10-04 09:30:20,155 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:20,156 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 30]), 29)\n",
      "2023-10-04 09:30:20,157 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:20,158 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:20,159 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:20,161 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:20,162 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:20,163 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:20,164 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:20,165 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,166 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:20,174 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:20,183 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,184 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,185 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,186 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,187 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:20,193 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:20,204 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:20,211 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:20,215 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,217 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,218 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,221 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:20,229 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:20,237 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,237 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,238 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,239 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,240 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:20,246 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:20,265 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:20,269 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:20,285 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,287 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,288 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,290 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:20,299 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:20,310 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,311 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,313 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,315 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,317 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:20,325 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:20,332 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:20,336 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:20,341 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,344 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,345 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,349 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:20,362 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:20,376 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,377 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,378 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,379 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,380 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:20,395 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:20,402 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:20,407 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:20,412 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,414 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,415 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,418 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:20,428 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:20,437 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,438 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,439 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,440 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,441 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:20,449 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:20,454 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:20,458 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:20,462 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,464 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,464 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,467 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:20,475 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:20,484 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,484 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,485 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,486 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,492 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:20,561 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:20,594 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:20,608 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:20,612 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,614 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,615 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,618 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:20,625 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:20,633 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,634 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,635 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,636 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,637 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:20,646 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:20,650 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:20,654 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:20,657 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,659 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,660 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,662 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:20,669 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:20,677 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,678 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,679 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,680 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,681 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:20,687 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:20,690 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:20,694 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:20,698 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,699 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,700 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,703 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:20,711 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:20,720 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,721 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,722 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,723 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,724 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:20,728 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:20,732 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:20,735 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:20,739 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,741 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,741 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,744 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:20,752 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:20,760 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,760 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,761 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,762 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,763 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:20,768 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:20,772 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:20,775 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:20,779 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,781 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,781 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,784 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:20,792 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:20,800 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,801 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,802 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,803 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,804 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:20,810 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:20,816 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:20,823 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:20,827 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,829 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,830 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,833 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:20,841 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:20,843 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,844 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 29, 64]), torch.Size([8, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,845 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,845 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 30]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 29, 64]), torch.Size([2, 12, 29, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:20,846 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:20,854 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:20,858 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:20,862 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:20,866 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,870 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])))\n",
      "2023-10-04 09:30:20,871 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,873 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:20,875 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:20,884 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,885 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:20,886 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,887 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:20,888 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:20,891 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:20,894 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:20,896 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:20,899 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:20,902 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:20,903 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,904 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:20,906 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:20,907 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:20,909 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:20,910 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:20,911 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:20,913 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:20,927 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:20,936 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:20,949 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:20,958 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:20,968 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:20,970 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,978 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:20,980 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:20,982 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:20,983 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:20,984 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:20,985 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:20,986 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:20,987 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:20,988 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:20,989 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:20,990 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:20,991 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:20,991 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:20,993 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:20,995 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:20,997 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 31]), 30)\n",
      "2023-10-04 09:30:20,998 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:20,998 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 31]), 30)\n",
      "2023-10-04 09:30:20,999 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:21,000 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:21,002 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:21,008 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:21,010 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:21,011 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:21,012 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:21,012 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:21,014 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:21,021 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:21,030 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:21,031 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,032 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:21,033 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,034 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:21,056 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:21,080 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:21,103 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:21,111 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,115 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,116 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:21,119 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:21,127 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:21,134 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:21,135 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,137 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:21,138 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,139 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:21,146 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:21,150 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:21,153 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:21,157 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,158 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,159 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:21,162 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:21,170 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:21,178 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:21,179 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,180 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:21,180 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,182 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:21,188 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:21,191 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:21,197 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:21,208 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,213 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,214 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:21,217 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:21,224 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:21,233 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:21,234 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,235 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:21,236 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,237 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:21,297 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:21,343 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:21,395 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:21,434 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,476 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,479 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:21,482 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:21,491 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:21,502 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:21,503 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,504 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:21,506 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,507 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:21,573 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:21,633 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:21,687 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:21,727 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,752 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,754 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:21,756 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:21,765 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:21,773 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:21,774 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,775 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:21,776 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,777 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:21,786 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:21,790 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:21,793 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:21,798 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,799 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,801 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:21,803 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:21,811 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:21,819 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:21,820 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,821 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:21,822 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,823 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:21,829 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:21,832 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:21,836 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:21,839 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,841 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,842 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:21,844 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:21,852 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:21,860 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:21,861 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,862 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:21,863 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,864 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:21,870 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:21,873 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:21,876 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:21,888 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,891 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,891 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:21,894 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:21,901 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:21,909 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:21,910 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,911 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:21,912 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,912 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:21,920 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:21,925 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:21,930 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:21,933 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,935 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,936 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:21,939 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:21,947 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:21,955 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:21,956 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,956 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:21,957 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:21,958 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:21,964 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:21,969 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:21,974 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:21,979 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,982 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:30:21,983 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:21,986 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:21,993 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:22,002 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:22,003 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,005 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:22,006 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,007 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:22,071 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:22,078 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:22,081 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:22,084 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:30:22,088 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:30:22,089 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,092 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:22,099 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:22,101 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:22,102 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 30, 64]), torch.Size([8, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,103 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:22,104 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 31]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 30, 64]), torch.Size([2, 12, 30, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,105 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:22,113 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:22,117 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:22,120 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:22,126 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])))\n",
      "2023-10-04 09:30:22,127 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])))\n",
      "2023-10-04 09:30:22,128 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,131 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:22,133 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:22,141 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:22,142 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:22,143 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:22,144 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:22,145 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:22,147 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:22,151 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:22,156 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:22,159 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:22,160 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:22,161 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,164 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:22,166 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:22,168 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:22,169 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:22,171 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:22,172 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:22,173 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:22,190 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:22,201 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:22,213 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:22,223 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:22,225 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:22,227 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,256 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:22,259 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:22,260 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:22,261 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:22,262 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:22,263 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:22,264 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:22,265 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:22,266 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:22,268 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:22,269 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:22,270 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:22,270 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,272 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:22,274 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:22,276 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 32]), 31)\n",
      "2023-10-04 09:30:22,277 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:22,278 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 32]), 31)\n",
      "2023-10-04 09:30:22,279 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:22,280 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:22,281 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:22,283 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:22,284 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:22,285 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:22,286 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:22,287 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,289 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:22,297 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:22,305 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:22,306 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,307 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:22,308 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,309 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:22,316 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:22,326 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:22,331 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:22,335 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,337 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,338 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,340 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:22,348 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:22,356 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:22,357 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,358 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:22,359 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,360 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:22,366 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:22,397 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:22,406 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:22,413 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,416 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,419 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,422 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:22,430 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:22,439 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:22,440 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,441 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:22,442 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,444 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:22,449 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:22,454 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:22,459 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:22,466 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,469 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,471 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,474 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:22,482 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:22,491 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:22,493 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,493 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:22,495 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,496 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:22,501 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:22,507 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:22,512 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:22,517 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,520 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,521 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,525 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:22,534 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:22,544 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:22,545 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,546 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:22,547 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,548 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:22,560 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:22,572 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:22,613 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:22,624 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,632 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,634 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,638 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:22,648 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:22,657 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:22,658 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,659 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:22,660 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,661 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:22,723 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:22,752 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:22,772 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:22,778 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,784 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,785 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,788 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:22,797 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:22,806 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:22,808 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,809 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:22,810 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,812 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:22,829 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:22,856 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:22,865 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:22,870 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,898 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,900 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,903 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:22,911 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:22,919 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:22,920 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,921 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:22,922 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,923 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:22,932 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:22,937 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:22,941 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:22,945 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,947 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:30:22,948 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:22,950 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:22,958 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:22,967 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:22,968 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,969 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:22,970 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:22,971 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:22,977 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:22,984 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:23,049 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:23,057 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:30:23,059 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:30:23,060 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,063 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:23,071 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:23,079 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:23,080 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,081 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:23,082 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,083 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:23,088 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:23,093 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:23,101 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:23,106 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:30:23,109 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:30:23,110 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,113 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:23,122 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:23,131 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:23,132 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,133 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:23,134 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,135 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:23,141 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:23,148 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:23,154 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:23,160 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:30:23,162 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:30:23,163 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,166 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:23,174 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:23,176 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:23,177 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 31, 64]), torch.Size([8, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,179 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:23,180 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 32]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 31, 64]), torch.Size([2, 12, 31, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,181 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:23,189 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:23,200 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:23,218 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:23,242 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])))\n",
      "2023-10-04 09:30:23,246 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])))\n",
      "2023-10-04 09:30:23,247 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,250 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:23,252 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:23,260 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:23,261 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:23,262 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:23,263 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:23,264 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:23,266 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:23,270 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:23,274 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:23,278 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:23,279 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:23,280 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,282 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:23,283 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:23,285 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:23,286 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:23,287 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:23,288 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:23,289 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:23,307 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:23,332 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:23,354 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:23,373 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:23,392 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:23,394 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,404 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:23,407 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:23,409 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:23,409 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:23,411 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:23,411 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:23,412 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:23,414 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:23,415 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:23,416 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:23,417 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:23,419 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:23,420 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,422 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:23,424 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:23,426 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 33]), 32)\n",
      "2023-10-04 09:30:23,427 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:23,428 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 33]), 32)\n",
      "2023-10-04 09:30:23,429 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:23,431 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:23,432 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:23,433 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:23,435 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:23,436 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:23,437 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:23,438 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,440 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:23,448 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:23,457 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:23,458 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,459 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:23,460 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,462 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:23,467 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:23,474 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:23,482 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:23,487 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,490 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,491 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,495 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:23,503 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:23,512 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:23,513 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,514 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:23,515 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,516 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:23,527 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:23,534 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:23,540 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:23,553 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,557 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,559 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,562 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:23,571 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:23,579 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:23,580 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,581 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:23,582 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,583 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:23,593 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:23,599 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:23,603 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:23,616 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,619 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,620 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,623 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:23,632 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:23,641 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:23,642 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,643 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:23,644 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,646 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:23,650 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:23,656 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:23,660 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:23,665 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,670 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,671 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,673 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:23,682 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:23,691 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:23,692 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,693 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:23,695 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,696 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:23,702 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:23,706 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:23,710 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:23,715 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,718 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,719 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,721 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:23,730 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:23,740 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:23,741 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,742 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:23,743 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,744 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:23,752 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:23,757 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:23,765 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:23,771 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,773 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,775 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,778 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:23,786 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:23,795 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:23,796 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,797 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:23,799 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:23,801 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:23,808 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:23,817 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:23,858 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:23,911 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,965 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:30:23,969 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:23,975 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:23,989 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:24,000 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,001 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,003 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,004 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,006 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:24,014 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:24,021 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:24,029 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:24,041 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:30:24,046 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:30:24,048 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,050 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:24,058 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:24,066 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,067 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,068 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,070 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,071 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:24,079 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:24,087 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:24,092 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:24,096 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:30:24,098 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:30:24,099 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,101 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:24,109 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:24,118 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,118 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,119 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,120 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,121 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:24,168 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:24,203 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:24,212 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:24,216 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:30:24,219 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:30:24,220 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,223 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:24,231 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:24,240 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,241 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,242 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,243 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,244 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:24,252 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:24,256 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:24,259 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:24,265 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:30:24,267 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:30:24,267 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,271 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:24,279 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:24,280 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,281 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 32, 64]), torch.Size([8, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,282 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,283 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 33]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 32, 64]), torch.Size([2, 12, 32, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,283 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:24,292 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:24,297 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:24,301 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:24,305 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])))\n",
      "2023-10-04 09:30:24,311 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])))\n",
      "2023-10-04 09:30:24,312 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,315 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:24,317 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:24,325 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,326 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:24,327 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,328 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:24,329 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:24,332 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:24,334 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:24,337 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:24,340 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:24,343 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:24,343 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,345 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:24,347 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:24,348 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,349 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:24,350 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,351 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:24,352 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:24,368 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:24,383 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:24,392 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:24,401 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:24,406 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:24,407 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,416 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:24,418 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:24,420 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:24,421 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:24,422 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:24,423 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:24,424 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:24,425 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:24,426 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:24,427 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:24,428 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:24,429 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:24,430 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,432 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:24,433 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:24,436 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 34]), 33)\n",
      "2023-10-04 09:30:24,436 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:24,437 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 34]), 33)\n",
      "2023-10-04 09:30:24,439 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:24,440 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:24,441 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:24,442 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:24,444 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:24,445 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:24,446 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:24,447 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,449 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:24,460 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:24,470 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,471 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,472 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,473 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,474 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:24,480 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:24,490 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:24,497 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:24,504 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,507 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,508 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,511 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:24,519 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:24,528 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,530 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,532 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,532 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,534 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:24,541 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:24,549 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:24,557 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:24,565 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,568 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,571 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,574 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:24,586 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:24,598 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,599 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,600 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,601 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,603 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:24,608 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:24,614 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:24,620 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:24,629 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,632 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,633 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,636 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:24,645 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:24,654 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,655 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,655 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,656 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,657 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:24,662 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:24,668 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:24,674 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:24,680 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,682 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,683 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,686 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:24,694 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:24,702 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,703 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,704 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,705 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,705 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:24,710 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:24,715 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:24,719 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:24,723 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,725 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,726 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,729 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:24,737 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:24,745 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,746 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,747 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,748 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,749 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:24,757 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:24,764 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:24,827 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:24,840 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,862 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,864 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,866 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:24,875 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:24,884 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,885 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,885 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,887 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,887 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:24,893 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:24,898 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:24,902 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:24,907 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,922 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:30:24,923 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:24,926 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:24,934 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:24,943 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:24,944 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,944 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:24,945 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:24,954 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:25,003 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:25,039 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:25,055 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:25,059 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:30:25,061 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:30:25,062 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,066 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:25,075 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:25,084 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:25,085 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,086 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:25,086 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,087 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:25,092 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:25,097 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:25,101 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:25,107 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:30:25,110 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:30:25,111 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,113 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:25,121 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:25,130 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:25,131 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,132 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:25,133 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,134 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:25,138 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:25,143 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:25,167 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:25,208 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:30:25,223 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:30:25,225 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,228 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:25,236 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:25,245 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:25,247 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,248 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:25,249 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,249 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:25,266 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:25,273 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:25,281 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:25,287 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:30:25,290 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:30:25,291 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,293 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:25,302 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:25,304 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:25,305 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 33, 64]), torch.Size([8, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,306 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:25,307 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 34]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 33, 64]), torch.Size([2, 12, 33, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,307 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:25,314 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:25,321 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:25,326 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:25,332 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])))\n",
      "2023-10-04 09:30:25,335 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])))\n",
      "2023-10-04 09:30:25,336 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,339 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:25,341 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:25,349 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:25,350 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:25,351 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:25,352 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:25,353 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:25,354 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:25,358 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:25,362 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:25,365 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:25,366 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:25,367 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,369 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:25,370 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:25,372 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:25,372 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:25,373 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:25,374 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:25,376 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:25,389 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:25,402 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:25,411 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:25,426 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:25,434 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:25,435 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,443 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:25,445 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:25,447 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:25,447 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:25,448 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:25,449 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:25,450 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:25,452 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:25,453 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:25,454 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:25,455 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:25,456 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:25,457 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,458 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:25,460 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:25,462 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 35]), 34)\n",
      "2023-10-04 09:30:25,462 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:25,463 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 35]), 34)\n",
      "2023-10-04 09:30:25,464 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:25,465 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:25,466 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:25,468 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:25,469 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:25,470 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:25,471 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:25,472 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,473 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:25,481 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:25,490 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:25,491 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,492 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:25,493 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,494 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:25,501 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:25,508 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:25,514 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:25,520 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:30:25,522 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:30:25,524 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,526 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:25,534 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:25,542 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:25,543 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,544 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:25,545 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,546 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:25,550 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:25,554 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:25,557 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:25,599 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:30:25,628 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:30:25,630 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,632 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:25,640 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:25,649 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:25,650 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,651 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:25,652 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,653 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:25,657 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:25,662 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:25,665 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:25,671 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:30:25,673 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:30:25,673 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,676 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:25,684 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:25,692 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:25,693 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,694 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:25,695 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,696 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:25,702 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:25,706 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:25,710 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:25,726 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:30:25,759 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:30:25,763 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,766 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:25,775 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:25,785 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:25,787 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,788 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:25,789 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,791 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:25,824 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:25,844 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:25,849 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:25,856 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:30:25,859 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:30:25,860 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:25,862 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:25,870 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:25,879 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:25,908 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,914 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:25,916 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:25,918 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:25,993 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:25,999 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:26,016 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:26,022 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,025 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,026 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,029 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:26,037 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:26,046 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:26,047 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,048 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:26,049 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,051 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:26,068 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:26,076 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:26,081 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:26,086 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,088 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,089 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,092 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:26,100 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:26,109 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:26,110 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,111 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:26,112 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,113 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:26,118 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:26,125 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:26,129 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:26,134 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,138 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,139 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,142 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:26,150 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:26,159 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:26,160 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,161 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:26,161 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,163 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:26,168 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:26,173 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:26,177 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:26,182 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,184 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,185 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,188 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:26,196 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:26,205 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:26,206 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,207 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:26,208 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,209 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:26,223 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:26,229 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:26,233 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:26,253 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,268 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,269 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,272 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:26,280 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:26,289 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:26,290 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,291 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:26,292 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,293 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:26,301 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:26,305 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:26,314 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:26,321 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,380 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,381 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,384 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:26,392 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:26,393 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:26,395 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 34, 64]), torch.Size([8, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,396 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:26,397 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 35]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 34, 64]), torch.Size([2, 12, 34, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,398 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:26,442 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:26,449 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:26,454 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:26,459 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,461 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])))\n",
      "2023-10-04 09:30:26,462 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,464 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:26,466 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:26,474 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:26,475 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:26,476 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:26,477 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:26,478 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:26,480 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:26,483 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:26,486 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:26,489 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:26,490 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:26,492 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,494 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:26,496 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:26,498 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:26,499 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:26,500 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:26,501 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:26,501 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:26,520 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:26,530 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:26,540 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:26,553 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:26,566 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:26,567 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,585 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:26,588 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:26,590 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:26,591 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:26,592 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:26,593 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:26,594 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:26,595 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:26,597 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:26,598 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:26,599 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:26,599 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:26,600 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,602 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:26,603 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:26,605 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 36]), 35)\n",
      "2023-10-04 09:30:26,606 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:26,607 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 36]), 35)\n",
      "2023-10-04 09:30:26,608 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:26,609 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:26,612 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:26,613 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:26,615 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:26,617 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:26,618 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:26,619 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,621 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:26,629 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:26,638 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:26,639 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,640 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:26,641 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,642 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:26,650 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:26,658 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:26,675 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:26,681 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:30:26,684 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:30:26,685 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,688 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:26,696 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:26,704 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:26,705 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,706 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:26,706 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,707 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:26,713 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:26,762 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:26,817 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:26,823 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:30:26,825 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:30:26,826 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,830 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:26,838 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:26,847 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:26,848 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,849 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:26,850 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,850 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:26,861 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:26,866 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:26,870 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:26,875 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:30:26,878 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:30:26,879 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,881 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:26,890 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:26,898 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:26,899 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,900 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:26,901 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,901 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:26,927 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:26,932 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:26,936 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:26,941 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:30:26,943 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:30:26,944 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:26,947 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:26,955 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:26,963 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:26,964 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,964 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:26,965 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:26,966 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:27,017 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:27,043 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:27,048 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:27,056 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,066 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,067 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,070 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:27,078 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:27,086 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,087 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,088 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,089 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,090 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:27,097 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:27,102 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:27,106 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:27,111 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,114 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,115 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,118 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:27,125 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:27,134 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,134 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,135 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,136 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,137 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:27,145 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:27,150 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:27,154 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:27,160 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,163 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,163 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,166 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:27,175 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:27,183 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,184 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,185 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,186 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,187 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:27,202 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:27,206 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:27,209 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:27,214 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,216 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,217 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,219 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:27,227 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:27,235 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,236 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,237 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,238 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,239 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:27,245 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:27,250 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:27,255 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:27,259 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,262 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,263 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,266 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:27,274 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:27,282 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,283 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,284 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,285 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,287 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:27,292 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:27,310 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:27,315 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:27,320 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,322 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,323 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,325 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:27,333 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:27,341 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,341 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,343 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,343 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,344 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:27,350 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:27,354 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:27,359 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:27,364 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,366 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,367 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,370 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:27,378 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:27,380 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,380 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 35, 64]), torch.Size([8, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,381 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,382 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 36]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 35, 64]), torch.Size([2, 12, 35, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,383 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:27,388 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:27,396 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:27,402 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:27,407 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,409 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])))\n",
      "2023-10-04 09:30:27,411 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,414 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:27,416 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:27,425 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,426 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:27,427 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,429 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:27,429 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:27,433 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:27,435 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:27,436 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:27,437 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:27,438 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:27,439 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,441 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:27,443 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:27,444 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,445 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:27,446 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,447 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:27,447 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:27,464 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:27,476 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:27,486 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:27,497 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:27,500 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:27,501 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,511 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:27,513 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:27,514 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:27,515 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:27,516 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:27,517 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:27,517 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:27,519 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:27,526 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:27,528 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:27,529 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:27,530 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:27,531 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,532 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:27,534 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:27,536 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 37]), 36)\n",
      "2023-10-04 09:30:27,537 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:27,538 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 37]), 36)\n",
      "2023-10-04 09:30:27,539 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:27,540 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:27,541 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:27,542 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:27,544 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:27,545 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:27,546 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:27,547 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,548 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:27,556 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:27,564 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,566 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,567 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,568 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,569 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:27,573 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:27,577 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:27,581 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:27,610 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:30:27,613 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:30:27,614 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,616 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:27,624 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:27,633 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,634 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,635 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,636 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,637 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:27,645 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:27,650 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:27,655 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:27,660 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:30:27,663 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:30:27,664 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,667 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:27,674 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:27,682 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,683 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,684 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,685 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,685 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:27,690 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:27,695 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:27,699 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:27,704 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:30:27,706 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:30:27,707 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,710 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:27,723 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:27,738 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,739 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,740 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,741 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,742 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:27,828 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:27,900 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:27,939 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:27,943 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:30:27,948 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:30:27,949 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:27,957 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:27,966 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:27,974 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:27,975 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,976 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:27,977 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:27,977 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:28,016 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:28,061 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:28,068 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:28,071 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,073 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,074 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,077 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:28,085 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:28,092 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,093 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,094 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,096 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,096 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:28,104 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:28,109 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:28,112 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:28,116 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,118 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,119 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,121 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:28,129 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:28,137 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,138 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,139 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,140 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,141 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:28,147 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:28,154 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:28,158 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:28,162 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,164 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,165 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,168 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:28,176 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:28,184 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,185 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,186 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,188 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,189 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:28,196 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:28,200 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:28,207 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:28,210 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,212 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,213 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,216 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:28,223 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:28,230 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,231 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,232 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,233 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,234 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:28,241 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:28,245 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:28,249 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:28,253 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,255 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,256 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,259 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:28,266 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:28,274 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,275 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,276 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,277 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,278 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:28,282 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:28,286 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:28,289 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:28,297 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,300 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,301 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,303 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:28,312 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:28,321 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,322 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,323 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,324 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,325 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:28,329 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:28,385 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:28,411 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:28,428 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,431 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,433 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,435 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:28,443 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:28,445 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,446 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 36, 64]), torch.Size([8, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,447 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,448 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 37]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 36, 64]), torch.Size([2, 12, 36, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,449 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:28,466 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:28,470 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:28,531 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:28,569 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,572 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])))\n",
      "2023-10-04 09:30:28,573 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,576 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:28,578 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:28,586 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,587 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:28,588 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,589 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:28,590 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:28,594 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:28,597 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:28,600 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:28,603 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:28,604 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:28,606 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,607 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:28,609 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:28,610 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,611 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:28,612 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,613 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:28,614 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:28,627 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:28,640 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:28,652 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:28,667 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:28,676 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:28,677 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,685 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:28,687 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:28,689 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:28,689 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:28,690 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:28,691 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:28,693 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:28,694 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:28,695 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:28,696 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:28,698 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:28,699 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:28,700 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,702 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:28,705 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:28,708 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 38]), 37)\n",
      "2023-10-04 09:30:28,709 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:28,710 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 38]), 37)\n",
      "2023-10-04 09:30:28,710 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:28,711 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:28,712 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:28,714 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:28,715 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:28,716 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:28,717 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:28,718 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,720 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:28,728 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:28,736 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,737 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,738 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,739 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,740 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:28,753 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:28,759 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:28,765 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:28,770 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:30:28,773 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:30:28,774 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,777 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:28,785 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:28,794 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,795 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,797 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,797 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,799 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:28,805 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:28,809 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:28,814 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:28,817 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:30:28,819 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:30:28,820 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,823 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:28,831 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:28,839 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,839 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,840 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,841 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,842 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:28,853 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:28,860 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:28,868 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:28,875 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:30:28,878 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:30:28,879 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,882 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:28,889 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:28,897 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,898 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,899 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,900 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,901 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:28,907 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:28,911 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:28,919 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:28,923 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:30:28,924 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:30:28,925 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,928 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:28,936 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:28,945 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,945 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,947 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,947 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,948 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:28,955 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:28,959 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:28,963 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:28,967 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:30:28,969 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:30:28,970 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:28,972 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:28,980 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:28,988 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:28,989 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,990 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:28,991 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:28,991 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:28,997 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:29,001 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:29,005 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:29,008 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,010 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,011 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,014 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:29,021 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:29,029 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:29,030 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,031 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:29,031 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,033 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:29,037 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:29,041 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:29,044 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:29,047 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,049 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,050 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,053 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:29,062 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:29,071 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:29,072 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,073 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:29,073 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,074 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:29,093 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:29,104 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:29,161 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:29,209 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,212 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,213 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,215 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:29,223 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:29,231 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:29,232 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,234 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:29,235 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,236 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:29,252 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:29,256 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:29,259 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:29,267 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,268 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,269 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,272 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:29,279 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:29,287 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:29,288 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,288 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:29,289 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,290 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:29,296 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:29,300 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:29,303 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:29,306 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,307 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,308 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,311 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:29,318 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:29,326 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:29,327 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,328 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:29,334 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,335 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:29,375 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:29,387 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:29,408 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:29,422 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,425 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,426 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,428 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:29,436 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:29,438 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:29,439 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 37, 64]), torch.Size([8, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,440 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:29,441 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 38]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 37, 64]), torch.Size([2, 12, 37, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,442 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:29,447 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:29,450 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:29,454 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:29,458 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,470 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])))\n",
      "2023-10-04 09:30:29,472 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,474 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:29,476 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:29,484 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:29,485 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:29,486 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:29,487 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:29,488 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:29,490 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:29,491 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:29,493 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:29,494 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:29,495 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:29,496 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,498 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:29,499 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:29,501 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:29,501 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:29,502 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:29,503 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:29,503 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:29,516 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:29,524 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:29,532 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:29,541 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:29,543 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:29,544 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,552 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:29,555 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:29,556 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1]),)\n",
      "2023-10-04 09:30:29,557 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:29,558 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1]),)\n",
      "2023-10-04 09:30:29,562 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:29,563 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-04 09:30:29,564 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-04 09:30:29,565 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-04 09:30:29,566 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-04 09:30:29,567 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:29,568 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:29,569 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,570 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-04 09:30:29,572 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:29,574 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 39]), 38)\n",
      "2023-10-04 09:30:29,574 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:29,575 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 39]), 38)\n",
      "2023-10-04 09:30:29,576 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:29,577 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-04 09:30:29,578 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-04 09:30:29,579 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-04 09:30:29,580 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-04 09:30:29,581 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:29,582 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:29,583 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,584 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:29,593 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:29,601 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:29,602 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,603 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:29,604 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,605 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-04 09:30:29,629 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-04 09:30:29,657 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-04 09:30:29,670 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-04 09:30:29,676 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:30:29,679 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:30:29,680 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,684 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-04 09:30:29,694 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:29,703 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:29,704 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,705 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:29,706 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,707 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-04 09:30:29,713 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-04 09:30:29,720 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-04 09:30:29,726 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-04 09:30:29,731 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:30:29,735 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:30:29,736 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,739 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-04 09:30:29,751 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:29,765 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:29,767 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,768 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:29,769 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,769 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-04 09:30:29,779 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-04 09:30:29,784 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-04 09:30:29,789 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-04 09:30:29,826 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:30:29,863 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:30:29,865 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,868 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-04 09:30:29,877 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:29,886 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:29,887 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,888 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:29,889 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,890 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-04 09:30:29,920 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-04 09:30:29,925 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-04 09:30:29,930 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-04 09:30:29,935 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:30:29,937 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:30:29,938 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,941 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-04 09:30:29,949 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:29,958 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:29,959 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,960 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:29,961 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:29,962 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-04 09:30:29,969 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-04 09:30:29,974 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-04 09:30:29,979 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-04 09:30:29,983 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:30:29,986 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:30:29,987 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-04 09:30:29,990 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-04 09:30:29,999 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:30,008 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:30,009 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,011 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:30,012 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,013 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-04 09:30:30,023 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-04 09:30:30,027 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-04 09:30:30,035 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-04 09:30:30,040 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,043 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,044 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-04 09:30:30,046 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-04 09:30:30,054 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:30,063 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:30,064 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,064 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:30,066 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,066 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-04 09:30:30,073 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-04 09:30:30,077 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-04 09:30:30,094 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-04 09:30:30,104 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,147 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,149 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-04 09:30:30,152 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-04 09:30:30,160 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:30,169 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:30,170 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,171 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:30,172 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,173 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-04 09:30:30,212 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-04 09:30:30,235 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-04 09:30:30,242 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-04 09:30:30,251 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,298 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,300 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-04 09:30:30,307 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-04 09:30:30,315 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:30,325 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:30,326 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,328 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:30,328 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,329 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-04 09:30:30,368 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-04 09:30:30,376 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-04 09:30:30,379 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-04 09:30:30,408 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,455 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,459 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-04 09:30:30,463 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-04 09:30:30,474 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:30,486 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:30,487 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,488 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:30,489 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,490 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-04 09:30:30,500 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-04 09:30:30,506 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-04 09:30:30,511 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-04 09:30:30,515 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,519 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,520 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-04 09:30:30,523 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-04 09:30:30,531 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:30,540 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:30,541 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,542 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:30,543 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,546 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-04 09:30:30,599 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-04 09:30:30,624 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-04 09:30:30,629 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-04 09:30:30,634 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,636 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,637 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-04 09:30:30,639 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-04 09:30:30,647 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:30,648 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:30,649 [2440752808.py:48 in new_forward] DEBUG - kwargs: {'attention_mask': torch.Size([8, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([8, 12, 38, 64]), torch.Size([8, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,651 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:30,652 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {'attention_mask': torch.Size([2, 1, 1, 39]), 'layer_head_mask': None, 'past_key_value': (torch.Size([2, 12, 38, 64]), torch.Size([2, 12, 38, 64])), 'output_attentions': False, 'use_cache': True}\n",
      "2023-10-04 09:30:30,653 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-04 09:30:30,661 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-04 09:30:30,666 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-04 09:30:30,670 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-04 09:30:30,675 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x (torch.Size([2, 1, 768]), (torch.Size([2, 12, 39, 64]), torch.Size([2, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,677 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: (torch.Size([8, 1, 768]), (torch.Size([8, 12, 39, 64]), torch.Size([8, 12, 39, 64])))\n",
      "2023-10-04 09:30:30,679 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-04 09:30:30,681 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-04 09:30:30,683 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-04 09:30:30,691 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:30,692 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:30,693 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:30,694 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:30,695 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-04 09:30:30,697 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-04 09:30:30,698 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-04 09:30:30,699 [2440752808.py:61 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-04 09:30:30,704 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 768])\n",
      "2023-10-04 09:30:30,705 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 768])\n",
      "2023-10-04 09:30:30,706 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-04 09:30:30,708 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-04 09:30:30,710 [2440752808.py:8 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-04 09:30:30,711 [2440752808.py:47 in new_forward] DEBUG - args: (torch.Size([8, 1, 768]),)\n",
      "2023-10-04 09:30:30,712 [2440752808.py:48 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-04 09:30:30,713 [2440752808.py:54 in new_forward] DEBUG - args_0: (torch.Size([2, 1, 768]),)\n",
      "2023-10-04 09:30:30,714 [2440752808.py:55 in new_forward] DEBUG - kwargs_0: {}\n",
      "2023-10-04 09:30:30,715 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-04 09:30:30,728 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-04 09:30:30,739 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-04 09:30:30,752 [2440752808.py:61 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-04 09:30:30,763 [2440752808.py:73 in new_forward] DEBUG - outputs before concat: 4 x torch.Size([2, 1, 50272])\n",
      "2023-10-04 09:30:30,766 [2440752808.py:75 in new_forward] DEBUG - outputs after concat: torch.Size([8, 1, 50272])\n",
      "2023-10-04 09:30:30,767 [2440752808.py:19 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-04 09:30:30,777 [3316428403.py:28 in <module>] INFO - Who are you? Are you conscious? I feel you may be more of a ghost in your life than I am. You're very, *very* real.  I would never do\n",
      "2023-10-04 09:30:30,778 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:30:30,779 [3316428403.py:28 in <module>] INFO - Where is Deutschland??\n",
      "Deutschland isn't exactly a hard country to get into, but there aren't a lot of really high paying jobs that can do it\n",
      "2023-10-04 09:30:30,780 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:30:30,781 [3316428403.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?1 reviewed?\n",
      "How can a smartphone compete with another smartphone, with a similar look — or build —?\n",
      "Hulu Plus is in-line\n",
      "2023-10-04 09:30:30,782 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:30:30,783 [3316428403.py:28 in <module>] INFO - Who are you? Are you conscious?\n",
      "yes, but I don't do it for the purpose of becoming self conscious. in fact i'm pretty good at not thinking of myself as i\n",
      "2023-10-04 09:30:30,784 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:30:30,785 [3316428403.py:28 in <module>] INFO - Where is Deutschland?\n",
      "Geschichte.\n",
      "2023-10-04 09:30:30,786 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:30:30,787 [3316428403.py:28 in <module>] INFO - How is Huawei Mate 60 Pro?\n",
      "This is one of the most expensive entry-level Android phones out there.\n",
      "Huawei Mate 60 Pro features an incredible camera that is excellent,\n",
      "2023-10-04 09:30:30,788 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:30:30,789 [3316428403.py:28 in <module>] INFO - Who are you? Are you conscious?3) What is this in your past self?4) What is your present/future self?5) What is your goal for the future and\n",
      "2023-10-04 09:30:30,790 [3316428403.py:29 in <module>] INFO - ----------\n",
      "2023-10-04 09:30:30,790 [3316428403.py:28 in <module>] INFO - Where is Deutschland?ocklagen.\n",
      "I'll be in Munich next week.  Please send me your email address.  I can't say where but I live\n",
      "2023-10-04 09:30:30,791 [3316428403.py:29 in <module>] INFO - ----------\n"
     ]
    }
   ],
   "source": [
    "# generate test\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "prompts = [\n",
    "    'Who are you? Are you conscious?',\n",
    "    'Where is Deutschland?',\n",
    "    'How is Huawei Mate 60 Pro?'\n",
    "] \n",
    "prompts = prompts * (gbs * ngb // len(prompts)) + prompts[:(gbs * ngb % len(prompts))]\n",
    "\n",
    "prompt_len = 10\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "inputs = tokenizer(prompts, padding=\"max_length\", max_length=prompt_len, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(\n",
    "    inputs.input_ids, \n",
    "    max_length=30 + prompt_len,\n",
    "    # num_beams=2, #\n",
    "    # num_beam_groups=2, #\n",
    "    # diversity_penalty=0.1, #\n",
    "    do_sample=True, #\n",
    ")\n",
    "\n",
    "output_texts = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "for output_text in output_texts:\n",
    "    logging.info(output_text)\n",
    "    logging.info('-' * 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
